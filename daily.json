{"2025-04-15": {"2408.07817": "|[myogestic: emg interfacing framework for decoding multiple spared degrees of freedom of the hand in individuals with neural lesions](https://arxiv.org/abs/2408.07817)|[MyoGestic](https://github.com/NsquaredLab/MyoGestic)|\n", "2408.10397": "|[webcam-based pupil diameter prediction benefits from upscaling](https://arxiv.org/abs/2408.10397)|[webcam-based-pupil-diameter-estimation](https://github.com/vijulshah/webcam-based-pupil-diameter-estimation)|\n", "2412.00905": "|[ref-gs: directional factorization for 2d gaussian splatting](https://arxiv.org/abs/2412.00905)|[Ref-GS](https://github.com/YoujiaZhang/Ref-GS)|\n", "2503.03953": "|[geoden: a visual exploration tool for analysing the geographic spread of dengue serotypes](https://arxiv.org/abs/2503.03953)|[GeoDEN](https://github.com/geohai/GeoDEN)|\n", "2503.04707": "|[iris style transfer: enhancing iris recognition with style features and privacy preservation through neural style transfer](https://arxiv.org/abs/2503.04707)|[Iris-Style-Transfer](https://gitlab.lrz.de/hctl/Iris-Style-Transfer)|\n", "2504.07210": "|[mesa: text-driven terrain generation using latent diffusion and global copernicus data](https://arxiv.org/abs/2504.07210)|[MESA](https://github.com/PaulBorneP/MESA)|\n", "2504.08256": "|[rag-vr: leveraging retrieval-augmented generation for 3d question answering in vr environments](https://arxiv.org/abs/2504.08256)|[RAG-VR](https://github.com/sding11/RAG-VR)|\n", "2504.08875": "|[datamap: a portable application for visualizing high-dimensional data](https://arxiv.org/abs/2504.08875)|[datamap](https://github.com/gexijin/datamap)|\n", "2504.09213": "|[spiking neural network for intra-cortical brain signal decoding](https://arxiv.org/abs/2504.09213)|[SNN_iBCIs](https://github.com/SongYang008/SNN_iBCIs)|\n", "2504.09221": "|[cmcrd: cross-modal contrastive representation distillation for emotion recognition](https://arxiv.org/abs/2504.09221)|[cmcrd](https://github.com/kssyyy/cmcrd)|\n", "2504.09352": "|[explorer: robust collection of interactable gui elements](https://arxiv.org/abs/2504.09352)|[Explorer](https://github.com/varnelis/Explorer)|\n", "2504.09623": "|[ges3vig: incorporating pointing gestures into language-based 3d visual grounding for embodied reference understanding](https://arxiv.org/abs/2504.09623)|[ges3vig](https://github.com/atharvmane/ges3vig)|\n", "2504.09689": "|[emoagent: assessing and safeguarding human-ai interaction for mental health safety](https://arxiv.org/abs/2504.09689)|[emoagent](https://github.com/1akaman/emoagent)|\n", "2504.09697": "|[spice: a synergistic, precise, iterative, and customizable image editing workflow](https://arxiv.org/abs/2504.09697)|[spice](https://github.com/kenantang/spice)|\n", "2504.09717": "|[adapting robot's explanation for failures based on observed human behavior in human-robot collaboration](https://arxiv.org/abs/2504.09717)|[adapting-robot-explanation-for-failures](https://github.com/andreasnaoum/adapting-robot-explanation-for-failures)|\n", "2504.09734": "|[dynamik: syntactically-driven dynamic font sizing for emphasis of key information](https://arxiv.org/abs/2504.09734)|[Dynamik_experiment](https://github.com/nawta/Dynamik_experiment)|\n", "2504.09737": "|[can llm feedback enhance review quality? a randomized study of 20k reviews at iclr 2025](https://arxiv.org/abs/2504.09737)|[review_feedback_agent](https://github.com/zou-group/review_feedback_agent)|\n", "2504.09846": "|[glytwin: digital twin for glucose control in type 1 diabetes through optimal behavioral modifications using patient-centric counterfactuals](https://arxiv.org/abs/2504.09846)|[glytwin](https://github.com/arefeen06088/glytwin)|\n", "2504.09865": "|[labeling messages as ai-generated does not reduce their persuasive effects](https://arxiv.org/abs/2504.09865)|[ai-authorship-persuasion](https://github.com/i-gallegos/ai-authorship-persuasion)|\n", "2504.10134": "|[let's talk about it: making scientific computational reproducibility easy](https://arxiv.org/abs/2504.10134)|[adsketch](https://github.com/opspai/adsketch)|\n", "2504.10258": "|[xy-cut++: advanced layout ordering via hierarchical mask mechanism on a novel benchmark](https://arxiv.org/abs/2504.10258)|[PaddleXrc](https://github.com/liushuai35/PaddleXrc)|\n", "2504.10443": "|[multimodal long video modeling based on temporal dynamic context](https://arxiv.org/abs/2504.10443)|[tdc-video](https://github.com/hoar012/tdc-video)|\n"}, "2025-04-14": {"2311.08957": "|[i was blind but now i see: implementing vision-enabled dialogue in social robots](https://arxiv.org/abs/2311.08957)|[vision-enabled-dialogue](https://github.com/giubots/vision-enabled-dialogue)|\n", "2406.14567": "|[dragposer: motion reconstruction from variable sparse tracking signals via latent space optimization](https://arxiv.org/abs/2406.14567)|[DragPoser](https://github.com/UPC-ViRVIG/DragPoser)|\n", "2409.16938": "|[generative object insertion in gaussian splatting with a multi-view diffusion model](https://arxiv.org/abs/2409.16938)|[multiview_inpaint](https://github.com/jiutongbro/multiview_inpaint)|\n", "2501.08561": "|[ansr-dt: an adaptive neuro-symbolic learning and reasoning framework for digital twins](https://arxiv.org/abs/2501.08561)|[ansr-dt](https://github.com/sbhakim/ansr-dt)|\n", "2504.01153": "|[catch me if you search: when contextual web search results affect the detection of hallucinations](https://arxiv.org/abs/2504.01153)|[CatchMeIfYouSearch](https://github.com/MahjabinNahar/CatchMeIfYouSearch)|\n", "2504.07999": "|[igg: image generation informed by geodesic dynamics in deformation spaces](https://arxiv.org/abs/2504.07999)|[igg](https://github.com/nellie689/igg)|\n"}, "2025-04-13": {}, "2025-04-12": {}, "2025-04-11": {"2412.03371": "|[sgsst: scaling gaussian splatting styletransfer](https://arxiv.org/abs/2412.03371)|[SGSST](https://github.com/JianlingWANG2021/SGSST)|\n", "2412.08912": "|[reversing the damage: a qp-aware transformer-diffusion approach for 8k video restoration under codec compression](https://arxiv.org/abs/2412.08912)|[DiQP](https://github.com/alimd94/DiQP)|\n", "2502.18348": "|[towards softerware: enabling personalization of interactive data representations for users with disabilities](https://arxiv.org/abs/2502.18348)|[highcharts-a11y-prototyping](https://github.com/highcharts/highcharts-a11y-prototyping)|\n", "2504.07521": "|[why we feel: breaking boundaries in emotional reasoning with multimodal large language models](https://arxiv.org/abs/2504.07521)|[eibench](https://github.com/lum1104/eibench)|\n", "2504.07870": "|[open datasets for grid modeling and visualization: an alberta power network case](https://arxiv.org/abs/2504.07870)|[carbondistributionmap](https://github.com/bencheng2/carbondistributionmap)|\n"}, "2025-04-10": {"2409.17550": "|[a simple but strong baseline for sounding video generation: effective adaptation of audio and video diffusion models for joint generation](https://arxiv.org/abs/2409.17550)|[svg_baseline](https://github.com/sonyresearch/svg_baseline)|\n", "2412.12225": "|[dlf: disentangled-language-focused multimodal sentiment analysis](https://arxiv.org/abs/2412.12225)|[dlf](https://github.com/pwang322/dlf)|\n", "2503.05639": "|[videopainter: any-length video inpainting and editing with plug-and-play context control](https://arxiv.org/abs/2503.05639)|[VideoPainter](https://github.com/TencentARC/VideoPainter)|\n", "2504.06677": "|[setup-invariant augmented reality for teaching by demonstration with surgical robots](https://arxiv.org/abs/2504.06677)|[dv-stear_public](https://github.com/alexandrebanks6/dv-stear_public)|\n", "2504.06751": "|[visualisation of a multidimensional point cloud as a 3d swarm of avatars](https://arxiv.org/abs/2504.06751)|[n-dim-view](https://github.com/iitis/n-dim-view)|\n"}, "2025-04-16": {"2210.04723": "|[experiential explanations for reinforcement learning](https://arxiv.org/abs/2210.04723)|[experiential-explanations-rl](https://github.com/amal994/experiential-explanations-rl)|\n", "2303.01396": "|[mlanet: multi-level attention network with sub-instruction for continuous vision-and-language navigation](https://arxiv.org/abs/2303.01396)|[mla](https://github.com/ravenkiller/mla)|\n", "2402.04620": "|[cataractbot: an llm-powered expert-in-the-loop chatbot for cataract patients](https://arxiv.org/abs/2402.04620)|[byoeb](https://github.com/microsoft/byoeb)|\n", "2407.19631": "|[\"a good bot always knows its limitations\": assessing autonomous system decision-making competencies through factorized machine self-confidence](https://arxiv.org/abs/2407.19631)|[FaMSeC](https://github.com/COHRINT/FaMSeC)|\n", "2412.09353": "|[causal graphical models for vision-language compositional understanding](https://arxiv.org/abs/2412.09353)|[COGT](https://github.com/aimagelab/COGT)|\n", "2504.05862": "|[are generative ai agents effective personalized financial advisors?](https://arxiv.org/abs/2504.05862)|[LLMAdvisor_supplementary](https://github.com/TTsamurai/LLMAdvisor_supplementary)|\n", "2504.09861": "|[ethosgpt: mapping human value diversity to advance sustainable development goals (sdgs)](https://arxiv.org/abs/2504.09861)|[EthoGPT-DB](https://github.com/sunshineluyao/EthoGPT-DB)|\n", "2504.09975": "|[octgpt: octree-based multiscale autoregressive models for 3d shape generation](https://arxiv.org/abs/2504.09975)|[octgpt](https://github.com/octree-nn/octgpt)|\n", "2504.10489": "|[roamify: designing and evaluating an llm based google chrome extension for personalised itinerary planning](https://arxiv.org/abs/2504.10489)|[roamify](https://github.com/roamify-research/roamify)|\n", "2504.10739": "|[hippomm: hippocampal-inspired multimodal memory for long audiovisual event understanding](https://arxiv.org/abs/2504.10739)|[hippomm](https://github.com/linyueqian/hippomm)|\n", "2504.11349": "|[explicit and implicit representations in ai-based 3d reconstruction for radiology: a systematic literature review](https://arxiv.org/abs/2504.11349)|[ai4med](https://github.com/bean-young/ai4med)|\n"}, "2025-04-17": {"2309.12029": "|[exploring self-supervised skeleton-based action recognition in occluded environments](https://arxiv.org/abs/2309.12029)|[opstl](https://github.com/cyfml/opstl)|\n", "2403.14773": "|[streamingt2v: consistent, dynamic, and extendable long video generation from text](https://arxiv.org/abs/2403.14773)|[streamingt2v](https://github.com/picsart-ai-research/streamingt2v)|\n", "2408.14477": "|[rise-ieeg: robust to inter-subject electrodes implantation variability ieeg classifier](https://arxiv.org/abs/2408.14477)|[RISE-iEEG](https://github.com/MaryamOstadsharif/RISE-iEEG)|\n", "2502.04942": "|[wikireddit: tracing information and attention flows between online platforms](https://arxiv.org/abs/2502.04942)|[wikireddit](https://github.com/pgilders/wikireddit)|\n", "2502.06817": "|[diffusion-empowered autoprompt medsam](https://arxiv.org/abs/2502.06817)|[autopromptmedsam](https://github.com/hp-ml/autopromptmedsam)|\n", "2504.11491": "|[attention ghostunet++: enhanced segmentation of adipose tissue and liver in ct images](https://arxiv.org/abs/2504.11491)|[attention-ghostunetplusplus](https://github.com/mansoorhayat777/attention-ghostunetplusplus)|\n"}, "2025-04-18": {"2408.05667": "|[phishlang: a real-time, fully client-side phishing detection framework using mobilebert](https://arxiv.org/abs/2408.05667)|[phishlang](https://github.com/uta-sprlab/phishlang)|\n", "2409.14319": "|[scene-text grounding for text-based video question answering](https://arxiv.org/abs/2409.14319)|[vitxt-gqa](https://github.com/zhousheng97/vitxt-gqa)|\n", "2410.10291": "|[evaluating semantic variation in text-to-image synthesis: a causal perspective](https://arxiv.org/abs/2410.10291)|[semvarbench](https://github.com/zhuxiangru/semvarbench)|\n", "2501.09012": "|[multimodal llms can reason about aesthetics in zero-shot](https://arxiv.org/abs/2501.09012)|[mllm4art](https://github.com/songrise/mllm4art)|\n", "2504.07521": "|[why we feel: breaking boundaries in emotional reasoning with multimodal large language models](https://arxiv.org/abs/2504.07521)|[eibench](https://github.com/lum1104/eibench)|\n", "2504.12451": "|[one model to rig them all: diverse skeleton rigging with unirig](https://arxiv.org/abs/2504.12451)|[UniRig](https://github.com/VAST-AI-Research/UniRig)|\n", "2504.12452": "|[planglow: personalized study planning with an explainable and controllable llm-driven system](https://arxiv.org/abs/2504.12452)|[PlanGlow](https://github.com/dreamlab-24/PlanGlow)|\n", "2504.12492": "|[mobileposer: real-time full-body pose estimation and 3d human translation from imus in mobile consumer devices](https://arxiv.org/abs/2504.12492)|[MobilePoser](https://github.com/SPICExLAB/MobilePoser)|\n", "2504.12809": "|[saliency-aware diffusion reconstruction for effective invisible watermark removal](https://arxiv.org/abs/2504.12809)|[sadre](https://github.com/inzamamuldu/sadre)|\n", "2504.12900": "|[fashiondpo:fine-tune fashion outfit generation model using direct preference optimization](https://arxiv.org/abs/2504.12900)|[fashiondpo](https://github.com/yzcreator/fashiondpo)|\n"}, "2025-04-19": {}, "2025-04-20": {}, "2025-04-21": {"2502.12110": "|[a-mem: agentic memory for llm agents](https://arxiv.org/abs/2502.12110)|[a-mem](https://github.com/agiresearch/a-mem)|\n", "2504.11936": "|[mind2matter: creating 3d models from eeg signals](https://arxiv.org/abs/2504.11936)|[mind2matter](https://github.com/sddwwww/mind2matter)|\n"}, "2025-04-22": {"2406.00888": "|[aligning language models with demonstrated feedback](https://arxiv.org/abs/2406.00888)|[demonstrated-feedback](https://github.com/SALT-NLP/demonstrated-feedback)|\n", "2408.13611": "|[real-time rendering of glints in the presence of area lights](https://arxiv.org/abs/2408.13611)|[arealightglintsunityproject](https://github.com/tomix1024/arealightglintsunityproject)|\n", "2503.21088": "|[zjuklab at semeval-2025 task 4: unlearning via model merging](https://arxiv.org/abs/2503.21088)|[unlearn](https://github.com/zjunlp/unlearn)|\n", "2504.09689": "|[emoagent: assessing and safeguarding human-ai interaction for mental health safety](https://arxiv.org/abs/2504.09689)|[emoagent](https://github.com/1akaman/emoagent)|\n", "2504.13095": "|[should we tailor the talk? understanding the impact of conversational styles on preference elicitation in conversational recommender systems](https://arxiv.org/abs/2504.13095)|[umap2025-convstyles](https://github.com/iai-group/umap2025-convstyles)|\n", "2504.15101": "|[neugaze: reshaping the future bci](https://arxiv.org/abs/2504.15101)|[neugaze](https://github.com/neuspeech/neugaze)|\n", "2504.15133": "|[easyedit2: an easy-to-use steering framework for editing large language models](https://arxiv.org/abs/2504.15133)|[easyedit](https://github.com/zjunlp/easyedit)|\n"}, "2025-04-23": {"2410.02003": "|[terrainav sim: an open-source simulation of uav aerial imaging from satellite data](https://arxiv.org/abs/2410.02003)|[TerrAInav-Sim](https://github.com/JacobsSensorLab/TerrAInav-Sim)|\n", "2410.07369": "|[an undetectable watermark for generative image models](https://arxiv.org/abs/2410.07369)|[prc-watermark](https://github.com/xuandongzhao/prc-watermark)|\n", "2504.09697": "|[spice: a synergistic, precise, iterative, and customizable image editing workflow](https://arxiv.org/abs/2504.09697)|[spice](https://github.com/kenantang/spice)|\n", "2504.09865": "|[labeling messages as ai-generated does not reduce their persuasive effects](https://arxiv.org/abs/2504.09865)|[ai-authorship-persuasion](https://github.com/i-gallegos/ai-authorship-persuasion)|\n", "2504.12977": "|[a phenomenological approach to analyzing user queries in it systems using heidegger's fundamental ontology](https://arxiv.org/abs/2504.12977)|[15241370](https://zenodo.org/record/15241370)|\n"}, "2025-04-24": {"2403.13924": "|[lfs-aware surface reconstruction from unoriented 3d point clouds](https://arxiv.org/abs/2403.13924)|[lfs-aware-reconstruction](https://github.com/bizerfr/lfs-aware-reconstruction)|\n", "2405.07229": "|[mm-instructeval: zero-shot evaluation of (multimodal) large language models on multimodal reasoning tasks](https://arxiv.org/abs/2405.07229)|[MM-InstructEval](https://github.com/declare-lab/MM-InstructEval)|\n", "2407.15842": "|[diffartist: towards structure and appearance controllable image stylization](https://arxiv.org/abs/2407.15842)|[Artist](https://github.com/songrise/Artist)|\n", "2504.16323": "|[media content atlas: a pipeline to explore and investigate multidimensional media space using multimodal llms](https://arxiv.org/abs/2504.16323)|[mediacontentatlas](https://github.com/mediacontentatlas/mediacontentatlas)|\n"}, "2025-04-25": {"2504.17253": "|[dive: inverting conditional diffusion models for discriminative tasks](https://arxiv.org/abs/2504.17253)|[DIVE](https://github.com/LiYinqi/DIVE)|\n"}, "2025-04-26": {}, "2025-04-27": {}, "2025-04-28": {"2309.14786": "|[treating motion as option with output selection for unsupervised video object segmentation](https://arxiv.org/abs/2309.14786)|[tmo](https://github.com/suhwan-cho/tmo)|\n", "2310.19380": "|[transxnet: learning both global and local dynamics with a dual dynamic token mixer for visual recognition](https://arxiv.org/abs/2310.19380)|[transxnet](https://github.com/lmmmeng/transxnet)|\n", "2312.02252": "|[storygpt-v: large language models as consistent story visualizers](https://arxiv.org/abs/2312.02252)|[StoryGPT-V](https://github.com/xiaoqian-shen/StoryGPT-V)|\n", "2402.11908": "|[semantic textual similarity assessment in chest x-ray reports using a domain-specific cosine-based metric](https://arxiv.org/abs/2402.11908)|[medical-corpus-semantic-similarity-evaluation](https://github.com/sayeh1994/medical-corpus-semantic-similarity-evaluation)|\n", "2405.15638": "|[m4u: evaluating multilingual understanding and reasoning for large multimodal models](https://arxiv.org/abs/2405.15638)|[m4u](https://github.com/m4u-benchmark/m4u)|\n", "2406.18037": "|[towards synchronous memorizability and generalizability with site-modulated diffusion replay for cross-site continual segmentation](https://arxiv.org/abs/2406.18037)|[smg-learning](https://github.com/dyxu-cuhkcse/smg-learning)|\n", "2408.10581": "|[multi-view hand reconstruction with a point-embedded transformer](https://arxiv.org/abs/2408.10581)|[poem-v2](https://github.com/jubsteven/poem-v2)|\n", "2408.11748": "|[understanding depth and height perception in large visual-language models](https://arxiv.org/abs/2408.11748)|[dh-bench](https://github.com/sacrcv/dh-bench)|\n", "2409.09366": "|[mhad: multimodal home activity dataset with multi-angle videos and synchronized physiological signals](https://arxiv.org/abs/2409.09366)|[mhad-dataset](https://github.com/jdh-algo/mhad-dataset)|\n", "2410.22784": "|[contrastive learning and adversarial disentanglement for task-oriented semantic communications](https://arxiv.org/abs/2410.22784)|[clad](https://github.com/omarerak/clad)|\n", "2411.12792": "|[clic: contrastive learning framework for unsupervised image complexity representation](https://arxiv.org/abs/2411.12792)|[clic](https://github.com/xauat-liushipeng/clic)|\n", "2411.16718": "|[neuro-symbolic evaluation of text-to-video models using formal verification](https://arxiv.org/abs/2411.16718)|[NeuS-V](https://github.com/UTAustin-SwarmLab/NeuS-V)|\n", "2412.07199": "|[a parametric approach to adversarial augmentation for cross-domain iris presentation attack detection](https://arxiv.org/abs/2412.07199)|[adv-gen-irispad](https://github.com/iprobe-lab/adv-gen-irispad)|\n", "2501.10917": "|[decomposing and fusing intra- and inter-sensor spatio-temporal signal for multi-sensor wearable human activity recognition](https://arxiv.org/abs/2501.10917)|[decomposewhar](https://github.com/anakin2555/decomposewhar)|\n", "2502.19260": "|[emt: a visual multi-task benchmark dataset for autonomous driving in the arab gulf region](https://arxiv.org/abs/2502.19260)|[emt-dataset](https://github.com/av-lab/emt-dataset)|\n", "2504.03096": "|[scaling open-vocabulary action detection](https://arxiv.org/abs/2504.03096)|[sia_act](https://github.com/siatheindochinese/sia_act)|\n", "2504.14509": "|[dreamid: high-fidelity and fast diffusion-based face swapping via triplet id group learning](https://arxiv.org/abs/2504.14509)|[DreamID](https://github.com/superhero-7/DreamID)|\n", "2504.14603": "|[ufo2: the desktop agentos](https://arxiv.org/abs/2504.14603)|[UFO](https://github.com/microsoft/UFO)|\n", "2504.16656": "|[skywork r1v2: multimodal hybrid reinforcement learning for reasoning](https://arxiv.org/abs/2504.16656)|[Skywork-R1V](https://github.com/SkyworkAI/Skywork-R1V)|\n", "2504.17815": "|[visibility-uncertainty-guided 3d gaussian inpainting via scene conceptional learning](https://arxiv.org/abs/2504.17815)|[VISTA](https://github.com/Aswhalefall/VISTA)|\n", "2504.18419": "|[a multimodal hybrid late-cascade fusion network for enhanced 3d object detection](https://arxiv.org/abs/2504.18419)|[HybridLateCascadeFusion](https://github.com/CarloSgaravatti/HybridLateCascadeFusion)|\n"}, "2025-04-29": {"2109.08843": "|[memory regulation and alignment toward generalizer rgb-infrared person](https://arxiv.org/abs/2109.08843)|[MGMRA](https://github.com/Chenfeng1271/MGMRA)|\n", "2110.12915": "|[revealing unforeseen diagnostic image features with deep learning by detecting cardiovascular diseases from apical four-chamber ultrasounds](https://arxiv.org/abs/2110.12915)|[disease-detection-and-diagnostic-image-feature](https://github.com/lishinc/disease-detection-and-diagnostic-image-feature)|\n", "2211.13726": "|[lightweight event-based optical flow estimation via iterative deblurring](https://arxiv.org/abs/2211.13726)|[idnet](https://github.com/tudelft/idnet)|\n", "2304.04421": "|[local-global temporal difference learning for satellite video super-resolution](https://arxiv.org/abs/2304.04421)|[lgtd](https://github.com/xy-boy/lgtd)|\n", "2305.15956": "|[anomaly detection with conditioned denoising diffusion models](https://arxiv.org/abs/2305.15956)|[DDAD](https://github.com/arimousa/DDAD)|\n", "2310.18961": "|[anomalyclip: object-agnostic prompt learning for zero-shot anomaly detection](https://arxiv.org/abs/2310.18961)|[anomalyclip](https://github.com/zqhang/anomalyclip)|\n", "2311.01090": "|[infusion: internal diffusion for inpainting of dynamic textures and complex motion](https://arxiv.org/abs/2311.01090)|[infusion](https://github.com/ncherel/infusion)|\n", "2401.17515": "|[semantic-syntactic discrepancy in images (ssdi): learning meaning and order of features from natural images](https://arxiv.org/abs/2401.17515)|[SSDI](https://github.com/ChunTao1999/SSDI)|\n", "2402.12185": "|[chartx & chartvlm: a versatile benchmark and foundation model for complicated chart reasoning](https://arxiv.org/abs/2402.12185)|[chartvlm](https://github.com/alpha-innovator/chartvlm)|\n", "2403.09554": "|[cloud gap-filling with deep learning for improved grassland monitoring](https://arxiv.org/abs/2403.09554)|[deep-learning-for-cloud-gap-filling-on-normalized-difference-vegetation-index](https://github.com/agri-hub/deep-learning-for-cloud-gap-filling-on-normalized-difference-vegetation-index)|\n", "2403.10413": "|[real-time image segmentation via hybrid convolutional-transformer architecture search](https://arxiv.org/abs/2403.10413)|[hyctas](https://github.com/marvinyu1995/hyctas)|\n", "2403.13642": "|[h-vmunet: high-order vision mamba unet for medical image segmentation](https://arxiv.org/abs/2403.13642)|[h-vmunet](https://github.com/wurenkai/h-vmunet)|\n", "2403.20331": "|[unsolvable problem detection: robust understanding evaluation for large multimodal models](https://arxiv.org/abs/2403.20331)|[upd](https://github.com/atsumiyai/upd)|\n", "2404.08535": "|[generalized contrastive learning for multi-modal retrieval and ranking](https://arxiv.org/abs/2404.08535)|[gcl](https://github.com/marqo-ai/gcl)|\n", "2408.08784": "|[multi-task learning approach for intracranial hemorrhage prognosis](https://arxiv.org/abs/2408.08784)|[multitasklearning_ich_prognosis](https://github.com/miriamcobo/multitasklearning_ich_prognosis)|\n", "2409.08775": "|[what should we engineer in prompts? training humans in requirement-driven llm use](https://arxiv.org/abs/2409.08775)|[rope](https://github.com/mqo00/rope)|\n", "2409.09497": "|[multi-scale grouped prototypes for interpretable semantic segmentation](https://arxiv.org/abs/2409.09497)|[scaleprotoseg](https://github.com/eceo-epfl/scaleprotoseg)|\n", "2409.09649": "|[sparx: a sparse cross-layer connection mechanism for hierarchical vision mamba and transformer networks](https://arxiv.org/abs/2409.09649)|[sparx](https://github.com/lmmmeng/sparx)|\n", "2409.17993": "|[sshnet: unsupervised cross-modal homography estimation via problem reformulation and split optimization](https://arxiv.org/abs/2409.17993)|[internet](https://github.com/junchen-yu/internet)|\n", "2409.19954": "|[domain consistency representation learning for lifelong person re-identification](https://arxiv.org/abs/2409.19954)|[DCR](https://github.com/LiuShiBen/DCR)|\n", "2409.20332": "|[devil is in details: locality-aware 3d abdominal ct volume generation for self-supervised organ segmentation](https://arxiv.org/abs/2409.20332)|[Lad](https://github.com/Ryann-Ran/Lad)|\n", "2409.20407": "|[open-source periorbital segmentation dataset for ophthalmic applications](https://arxiv.org/abs/2409.20407)|[periorbital-dataset](https://github.com/aiolab/periorbital-dataset)|\n", "2410.06140": "|[estimating the number of http/3 responses in quic using deep learning](https://arxiv.org/abs/2410.06140)|[VisQUIC](https://github.com/robshahla/VisQUIC)|\n", "2410.07149": "|[towards interpreting visual information processing in vision-language models](https://arxiv.org/abs/2410.07149)|[llava-interp](https://github.com/clemneo/llava-interp)|\n", "2410.16719": "|[progressive compositionality in text-to-image generative models](https://arxiv.org/abs/2410.16719)|[evogen](https://github.com/evansh666/evogen)|\n", "2411.11927": "|[flame: frozen large language models enable data-efficient language-image pre-training](https://arxiv.org/abs/2411.11927)|[flame](https://github.com/miv-xjtu/flame)|\n", "2411.18279": "|[large language model-brained gui agents: a survey](https://arxiv.org/abs/2411.18279)|[LLM-Brained-GUI-Agents-Survey](https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey)|\n", "2412.04653": "|[hidden in the noise: two-stage robust watermarking for images](https://arxiv.org/abs/2412.04653)|[Hidden-in-the-Noise](https://github.com/Kasraarabi/Hidden-in-the-Noise)|\n", "2412.20047": "|[simltd: simple supervised and semi-supervised long-tailed object detection](https://arxiv.org/abs/2412.20047)|[simltd](https://github.com/lexisnexis-risk-open-source/simltd)|\n", "2501.01568": "|[interruption handling for conversational robots](https://arxiv.org/abs/2501.01568)|[interruption-handling-system](https://github.com/intuitivecomputing/interruption-handling-system)|\n", "2501.15579": "|[an explainable biomedical foundation model via large-scale concept-enhanced vision-language pre-training](https://arxiv.org/abs/2501.15579)|[ConceptCLIP](https://github.com/JerrryNie/ConceptCLIP)|\n", "2501.18951": "|[draw2cut: direct on-material annotations for cnc milling](https://arxiv.org/abs/2501.18951)|[Draw2Cut](https://github.com/ApisXia/Draw2Cut)|\n", "2502.02097": "|[vertenet -- a multi-context hybrid cnn transformer for accurate vertebral landmark localization in lateral spine dxa images](https://arxiv.org/abs/2502.02097)|[vertenet](https://github.com/zaidilyas89/vertenet)|\n", "2502.05173": "|[videorope: what makes for good video rotary position embedding?](https://arxiv.org/abs/2502.05173)|[videorope](https://github.com/wiselnn570/videorope)|\n", "2502.08025": "|[from brainwaves to brain scans: a robust neural network for eeg-to-fmri synthesis](https://arxiv.org/abs/2502.08025)|[e2fnet](https://github.com/kgr20/e2fnet)|\n", "2502.10872": "|[corotational hinge-based thin plates/shells](https://arxiv.org/abs/2502.10872)|[libThinPlateShells](https://github.com/liangqx-hku/libThinPlateShells)|\n", "2502.20087": "|[overlock: an overview-first-look-closely-next convnet with context-mixing dynamic kernels](https://arxiv.org/abs/2502.20087)|[overlock](https://github.com/lmmmeng/overlock)|\n", "2503.01576": "|[mri super-resolution reconstruction using efficient diffusion probabilistic model with residual shifting](https://arxiv.org/abs/2503.01576)|[res-srdiff](https://github.com/mosaf/res-srdiff)|\n", "2503.12150": "|[point-cache: test-time dynamic and hierarchical cache for robust and generalizable point cloud analysis](https://arxiv.org/abs/2503.12150)|[point-cache](https://github.com/auniquesun/point-cache)|\n", "2503.13777": "|[8-calves image dataset](https://arxiv.org/abs/2503.13777)|[8-calves](https://github.com/tonyfang04/8-calves)|\n", "2503.23452": "|[videogen-eval: agent-based system for video generation evaluation](https://arxiv.org/abs/2503.23452)|[videogen-eval](https://github.com/ailab-cvc/videogen-eval)|\n", "2504.07089": "|[omnicaptioner: one captioner to rule them all](https://arxiv.org/abs/2504.07089)|[omnicaptioner](https://github.com/alpha-innovator/omnicaptioner)|\n", "2504.07957": "|[mm-ifengine: towards multimodal instruction following](https://arxiv.org/abs/2504.07957)|[mm-ifengine](https://github.com/syuan03/mm-ifengine)|\n", "2504.11019": "|[drift open dataset: a drone-derived intelligence for traffic analysis in urban environment](https://arxiv.org/abs/2504.11019)|[the-drift](https://github.com/aixmobility/the-drift)|\n", "2504.12909": "|[real-time high-fidelity gaussian human avatars with position-based interpolation of spatially distributed mlps](https://arxiv.org/abs/2504.12909)|[mmlphuman](https://github.com/1231234zhan/mmlphuman)|\n", "2504.13499": "|[u-shape mamba: state space model for faster diffusion](https://arxiv.org/abs/2504.13499)|[U-Shape-Mamba](https://github.com/ErgastiAlex/U-Shape-Mamba)|\n", "2504.13617": "|[compile scene graphs with reinforcement learning](https://arxiv.org/abs/2504.13617)|[r1-sgg](https://github.com/gpt4vision/r1-sgg)|\n", "2504.15280": "|[seeing from another perspective: evaluating multi-view understanding in mllms](https://arxiv.org/abs/2504.15280)|[All-Angles-Bench](https://github.com/Chenyu-Wang567/All-Angles-Bench)|\n", "2504.18983": "|[mediaug: exploring visual augmentation in medical imaging](https://arxiv.org/abs/2504.18983)|[MediAug](https://github.com/AIGeeksGroup/MediAug)|\n", "2504.19546": "|[crowd detection using very-fine-resolution satellite imagery](https://arxiv.org/abs/2504.19546)|[CrowdSat-Net](https://github.com/Tong-777777/CrowdSat-Net)|\n", "2504.19863": "|[towards ball spin and trajectory analysis in table tennis broadcast videos via physically grounded synthetic-to-real transfer](https://arxiv.org/abs/2504.19863)|[SpinAndTrajectoryTableTennis](https://github.com/KieDani/SpinAndTrajectoryTableTennis)|\n"}, "2025-04-30": {"2303.01903": "|[prophet: prompting large language models with complementary answer heuristics for knowledge-based visual question answering](https://arxiv.org/abs/2303.01903)|[prophet](https://github.com/milvlg/prophet)|\n", "2306.07520": "|[instruct-reid: a multi-purpose person re-identification task with instructions](https://arxiv.org/abs/2306.07520)|[instruct-reid](https://github.com/hwz-zju/instruct-reid)|\n", "2310.18511": "|[3dcompat$^{++}$: an improved large-scale 3d vision dataset for compositional recognition](https://arxiv.org/abs/2310.18511)|[3dcompat-challenge](https://github.com/cattalyya/3dcompat-challenge)|\n", "2403.12743": "|[controllable face synthesis with semantic latent diffusion models](https://arxiv.org/abs/2403.12743)|[ldm-diffusion-sem](https://github.com/ergastialex/ldm-diffusion-sem)|\n", "2405.17790": "|[instruct-reid++: towards universal purpose instruction-guided person re-identification](https://arxiv.org/abs/2405.17790)|[instruct-reid](https://github.com/hwz-zju/instruct-reid)|\n", "2406.11357": "|[refiner: restructure retrieval content efficiently to advance question-answering capabilities](https://arxiv.org/abs/2406.11357)|[refiner-rag](https://github.com/allen-li1231/refiner-rag)|\n", "2408.13509": "|[dual-interrelated diffusion model for few-shot anomaly image generation](https://arxiv.org/abs/2408.13509)|[dualanodiff](https://github.com/yinyjin/dualanodiff)|\n", "2409.16902": "|[underwater camouflaged object tracking meets vision-language sam2](https://arxiv.org/abs/2409.16902)|[awesome-multimodal-object-tracking](https://github.com/983632847/awesome-multimodal-object-tracking)|\n", "2410.13675": "|[pose-based sign language appearance transfer](https://arxiv.org/abs/2410.13675)|[pose-anonymization](https://github.com/sign-language-processing/pose-anonymization)|\n", "2410.20084": "|[univst: a unified framework for training-free localized video style transfer](https://arxiv.org/abs/2410.20084)|[UniVST](https://github.com/QuanjianSong/UniVST)|\n", "2411.01411": "|[mapping global floods with 10 years of satellite radar data](https://arxiv.org/abs/2411.01411)|[ai4g-flood](https://github.com/microsoft/ai4g-flood)|\n", "2411.10013": "|[efficient depth estimation for unstable stereo camera systems on ar glasses](https://arxiv.org/abs/2411.10013)|[MultiHeadDepth-HomoDepth](https://github.com/UCI-ISA-Lab/MultiHeadDepth-HomoDepth)|\n", "2411.14280": "|[easyhoi: unleashing the power of large models for reconstructing hand-object interactions in the wild](https://arxiv.org/abs/2411.14280)|[EasyHOI](https://github.com/lym29/EasyHOI)|\n", "2411.17982": "|[hi-slam2: geometry-aware gaussian slam for fast monocular scene reconstruction](https://arxiv.org/abs/2411.17982)|[HI-SLAM2](https://github.com/Willyzw/HI-SLAM2)|\n", "2412.16086": "|[towards interpretable radiology report generation via concept bottlenecks using a multi-agentic rag](https://arxiv.org/abs/2412.16086)|[irr-with-cbm-rag](https://github.com/tifat58/irr-with-cbm-rag)|\n", "2501.11153": "|[efficient frame extraction: a novel approach through frame similarity and surgical tool tracking for video segmentation](https://arxiv.org/abs/2501.11153)|[kinematics-afr](https://github.com/leonlha/kinematics-afr)|\n", "2501.16326": "|[movement- and traffic-based user identification in commercial virtual reality applications: threats and opportunities](https://arxiv.org/abs/2501.16326)|[vr_user_id](https://github.com/signetlabdei/vr_user_id)|\n", "2503.00063": "|[nopain: no-box point cloud attack via optimal transport singular boundary](https://arxiv.org/abs/2503.00063)|[nopain](https://github.com/cognaclee/nopain)|\n", "2503.06698": "|[what's in a latent? leveraging diffusion latent space for domain generalization](https://arxiv.org/abs/2503.06698)|[GUIDE](https://github.com/XThomasBU/GUIDE)|\n", "2504.10143": "|[negate or embrace: on how misalignment shapes multimodal representation learning](https://arxiv.org/abs/2504.10143)|[crossmodal_mislaignment](https://github.com/yichaocai1/crossmodal_mislaignment)|\n", "2504.13754": "|[towards accurate and interpretable neuroblastoma diagnosis via contrastive multi-scale pathological image analysis](https://arxiv.org/abs/2504.13754)|[cmswinkan](https://github.com/jsliam94/cmswinkan)|\n", "2504.14582": "|[ntire 2025 challenge on image super-resolution ($\\times$4): methods and results](https://arxiv.org/abs/2504.14582)|[ntire2025_imagesr_x4](https://github.com/zhengchen1999/ntire2025_imagesr_x4)|\n", "2504.20405": "|[scope-mri: bankart lesion detection as a case study in data curation and deep learning for challenging diagnoses](https://arxiv.org/abs/2504.20405)|[scope-mri](https://github.com/sahilsethi0105/scope-mri)|\n"}, "2025-05-01": {"2305.13800": "|[generalizable synthetic image detection via language-guided contrastive learning](https://arxiv.org/abs/2305.13800)|[lasted](https://github.com/highwaywu/lasted)|\n", "2309.06129": "|[leyes: a lightweight framework for deep learning-based eye tracking using synthetic eye images](https://arxiv.org/abs/2309.06129)|[byrneetal_leyes](https://github.com/dcnieho/byrneetal_leyes)|\n", "2401.09736": "|[ddm: a metric for comparing 3d shapes using directional distance fields](https://arxiv.org/abs/2401.09736)|[dirdist](https://github.com/rsy6318/dirdist)|\n", "2403.10635": "|[medslip: medical dual-stream language-image pre-training with pathology-anatomy semantic alignment](https://arxiv.org/abs/2403.10635)|[MeDSLIP](https://github.com/Shef-AIRE/MeDSLIP)|\n", "2407.05679": "|[bevworld: a multimodal world simulator for autonomous driving via scene-level bev latents](https://arxiv.org/abs/2407.05679)|[bevworld](https://github.com/zympsyche/bevworld)|\n", "2409.15545": "|[addressing emotion bias in music emotion recognition and generation with frechet audio distance](https://arxiv.org/abs/2409.15545)|[fadtk](https://github.com/microsoft/fadtk)|\n", "2409.15551": "|[revise, reason, and recognize: llm-based emotion recognition via emotion-specific prompts and asr error correction](https://arxiv.org/abs/2409.15551)|[emotion-prompt](https://github.com/yc-li20/emotion-prompt)|\n", "2409.16920": "|[cross-lingual speech emotion recognition: humans vs. self-supervised models](https://arxiv.org/abs/2409.16920)|[crosslingual_ser](https://github.com/zhan7721/crosslingual_ser)|\n", "2409.16937": "|[semi-supervised cognitive state classification from speech with multi-view pseudo-labeling](https://arxiv.org/abs/2409.16937)|[semi-supervised-training](https://github.com/yc-li20/semi-supervised-training)|\n", "2410.16284": "|[a 3d framework for improving low-latency multi-channel live streaming](https://arxiv.org/abs/2410.16284)|[livestreaming](https://github.com/aizierjiang/livestreaming)|\n", "2411.15388": "|[a contrast-agnostic method for ultra-high resolution claustrum segmentation](https://arxiv.org/abs/2411.15388)|[claustrum_segmentation](https://github.com/chiara-mauri/claustrum_segmentation)|\n", "2411.19509": "|[ditto: motion-space diffusion for controllable realtime talking head synthesis](https://arxiv.org/abs/2411.19509)|[ditto-talkinghead](https://github.com/antgroup/ditto-talkinghead)|\n", "2412.04204": "|[pangaea: a global and inclusive benchmark for geospatial foundation models](https://arxiv.org/abs/2412.04204)|[pangaea-bench](https://github.com/vmarsocci/pangaea-bench)|\n", "2412.06314": "|[cad-unet: a capsule network-enhanced unet architecture for accurate segmentation of covid-19 lung infections from ct images](https://arxiv.org/abs/2412.06314)|[cad-unet](https://github.com/amanotooko-jie/cad-unet)|\n", "2501.16289": "|[multi-view structural convolution network for domain-invariant point cloud recognition of autonomous vehicles](https://arxiv.org/abs/2501.16289)|[mscn](https://github.com/mlmlab/mscn)|\n", "2501.17690": "|[segmentation-aware generative reinforcement network (grn) for tissue layer segmentation in 3-d ultrasound images for chronic low-back pain (clbp) assessment](https://arxiv.org/abs/2501.17690)|[GRN](https://github.com/Francisdadada/GRN)|\n", "2502.03649": "|[all-in-one image compression and restoration](https://arxiv.org/abs/2502.03649)|[all-in-one](https://github.com/zeldam1/all-in-one)|\n", "2502.06805": "|[efficient diffusion models: a survey](https://arxiv.org/abs/2502.06805)|[efficient-diffusion-model-survey](https://github.com/aiot-mlsys-lab/efficient-diffusion-model-survey)|\n", "2503.03327": "|[scalefusionnet: transformer-guided multi-scale feature fusion for skin lesion segmentation](https://arxiv.org/abs/2503.03327)|[scalefusionnet](https://github.com/sqbqamar/scalefusionnet)|\n", "2503.06669": "|[agibot world colosseo: a large-scale manipulation platform for scalable and intelligent embodied systems](https://arxiv.org/abs/2503.06669)|[agibot-world](https://github.com/opendrivelab/agibot-world)|\n", "2503.13435": "|[widerange4d: enabling high-quality 4d reconstruction with wide-range movements and scenes](https://arxiv.org/abs/2503.13435)|[widerange4d](https://github.com/gen-verse/widerange4d)|\n", "2504.09689": "|[emoagent: assessing and safeguarding human-ai interaction for mental health safety](https://arxiv.org/abs/2504.09689)|[emoagent](https://github.com/1akaman/emoagent)|\n", "2504.20114": "|[treehop: generate and filter next query embeddings efficiently for multi-hop question answering](https://arxiv.org/abs/2504.20114)|[treehop-rag](https://github.com/allen-li1231/treehop-rag)|\n", "2504.20923": "|[end-to-end audio deepfake detection from raw waveforms: a rawnet-based approach with cross-dataset evaluation](https://arxiv.org/abs/2504.20923)|[RawNetLite](https://github.com/adipiz99/RawNetLite)|\n", "2504.20948": "|[ds_fusionnet: dynamic dual-stream fusion with bidirectional knowledge distillation for plant disease recognition](https://arxiv.org/abs/2504.20948)|[DS_FusionNet](https://github.com/YanghuiSong/DS_FusionNet)|\n", "2504.21194": "|[geolocating earth imagery from iss: integrating machine learning with astronaut photography for enhanced geographic mapping](https://arxiv.org/abs/2504.21194)|[GeoMapper](https://github.com/VedikaSrivastava/GeoMapper)|\n", "2504.21263": "|[embracing collaboration over competition: condensing multiple prompts for visual in-context learning](https://arxiv.org/abs/2504.21263)|[CVPR25-Condenser](https://github.com/gimpong/CVPR25-Condenser)|\n", "2504.21435": "|[seriesbench: a benchmark for narrative-driven drama series understanding](https://arxiv.org/abs/2504.21435)|[seriesbench-cvpr2025](https://github.com/zackhxn/seriesbench-cvpr2025)|\n"}, "2025-05-02": {"2211.06841": "|[point-dae: denoising autoencoders for self-supervised point cloud learning](https://arxiv.org/abs/2211.06841)|[point-dae](https://github.com/ybzh/point-dae)|\n", "2309.08035": "|[interpretability-aware vision transformer](https://arxiv.org/abs/2309.08035)|[ia-vit](https://github.com/qiangyao1988/ia-vit)|\n", "2312.12028": "|[eyepreserve: identity-preserving iris synthesis](https://arxiv.org/abs/2312.12028)|[EyePreserve](https://github.com/CVRL/EyePreserve)|\n", "2401.03048": "|[latte: latent diffusion transformer for video generation](https://arxiv.org/abs/2401.03048)|[Latte](https://github.com/maxin-cn/Latte)|\n", "2403.16677": "|[fool: addressing the downlink bottleneck in satellite computing with neural feature compression](https://arxiv.org/abs/2403.16677)|[the-fool](https://github.com/rezafuru/the-fool)|\n", "2406.03184": "|[ouroboros3d: image-to-3d generation via 3d-aware recursive diffusion](https://arxiv.org/abs/2406.03184)|[Ouroboros3D](https://github.com/Costwen/Ouroboros3D)|\n", "2409.07284": "|[tld-ready: traffic light detection -- relevance estimation and deployment analysis](https://arxiv.org/abs/2409.07284)|[traffic-light-detection](https://github.com/kastel-mobilitylab/traffic-light-detection)|\n", "2409.08091": "|[ezigen: enhancing zero-shot personalized image generation with precise subject encoding and decoupled guidance](https://arxiv.org/abs/2409.08091)|[EZIGen](https://github.com/ZichengDuan/EZIGen)|\n", "2409.12002": "|[towards global localization using multi-modal object-instance re-identification](https://arxiv.org/abs/2409.12002)|[instance-based-loc](https://github.com/instance-based-loc/instance-based-loc)|\n", "2411.16508": "|[all languages matter: evaluating lmms on culturally diverse 100 languages](https://arxiv.org/abs/2411.16508)|[ALM-Bench](https://github.com/mbzuai-oryx/ALM-Bench)|\n", "2412.18086": "|[generating traffic scenarios via in-context learning to learn better motion planner](https://arxiv.org/abs/2412.18086)|[AutoSceneGen](https://github.com/Ezharjan/AutoSceneGen)|\n", "2501.09503": "|[anystory: towards unified single and multiple subject personalization in text-to-image generation](https://arxiv.org/abs/2501.09503)|[AnyStory](https://github.com/junjiehe96/AnyStory)|\n", "2502.18137": "|[spargeattn: accurate sparse attention accelerating any model inference](https://arxiv.org/abs/2502.18137)|[spargeattn](https://github.com/thu-ml/spargeattn)|\n", "2504.05304": "|[gaussian mixture flow matching models](https://arxiv.org/abs/2504.05304)|[gmflow](https://github.com/lakonik/gmflow)|\n", "2504.21707": "|[recursive kl divergence optimization: a dynamic framework for representation learning](https://arxiv.org/abs/2504.21707)|[RKDO-recursive-kl-divergence-optimization](https://github.com/anthonymartin/RKDO-recursive-kl-divergence-optimization)|\n", "2505.00312": "|[aware-net: adaptive weighted averaging for robust ensemble network in deepfake detection](https://arxiv.org/abs/2505.00312)|[AWARE-NET](https://github.com/recluzegeek/AWARE-NET)|\n", "2505.00502": "|[towards scalable human-aligned benchmark for text-guided image editing](https://arxiv.org/abs/2505.00502)|[HATIE](https://github.com/SuhoRyu/HATIE)|\n", "2505.00681": "|[minerva: evaluating complex video reasoning](https://arxiv.org/abs/2505.00681)|[neptune](https://github.com/google-deepmind/neptune)|\n", "2505.00684": "|[visual test-time scaling for gui agent grounding](https://arxiv.org/abs/2505.00684)|[regionfocus](https://github.com/tiangeluo/regionfocus)|\n", "2505.00703": "|[t2i-r1: reinforcing image generation with collaborative semantic-level and token-level cot](https://arxiv.org/abs/2505.00703)|[t2i-r1](https://github.com/caraj7/t2i-r1)|\n"}, "2025-05-03": {}, "2025-05-04": {}, "2025-05-05": {"2306.03271": "|[volumetric medical image segmentation through dual self-distillation in u-shaped networks](https://arxiv.org/abs/2306.03271)|[dualselfdistillation](https://github.com/soumbane/dualselfdistillation)|\n", "2310.15402": "|[towards contrast-agnostic soft segmentation of the spinal cord](https://arxiv.org/abs/2310.15402)|[contrast-agnostic-softseg-spinalcord](https://github.com/sct-pipeline/contrast-agnostic-softseg-spinalcord)|\n", "2403.02411": "|[ninformer: a network in network transformer with token mixing generated gating function](https://arxiv.org/abs/2403.02411)|[NiNformer](https://github.com/Abdullah-88/NiNformer)|\n", "2404.01330": "|[p-hologen: an end-to-end generative framework for phase-only holograms](https://arxiv.org/abs/2404.01330)|[p-hologen](https://github.com/james0223/p-hologen)|\n", "2404.17347": "|[inspectorraget: an introspection platform for rag evaluation](https://arxiv.org/abs/2404.17347)|[inspectorraget](https://github.com/ibm/inspectorraget)|\n", "2404.18624": "|[do vision & language decoders use images and text equally? how self-consistent are their explanations?](https://arxiv.org/abs/2404.18624)|[cc-shap-vlm](https://github.com/heidelberg-nlp/cc-shap-vlm)|\n", "2406.01494": "|[robust classification by coupling data mollification with label smoothing](https://arxiv.org/abs/2406.01494)|[supervised-mollification](https://github.com/markusheinonen/supervised-mollification)|\n", "2408.08518": "|[visual-friendly concept protection via selective adversarial perturbations](https://arxiv.org/abs/2408.08518)|[VCPro](https://github.com/KululuMi/VCPro)|\n", "2410.01723": "|[harmonica: harmonizing training and inference for better feature caching in diffusion transformer acceleration](https://arxiv.org/abs/2410.01723)|[harmonica](https://github.com/modeltc/harmonica)|\n", "2410.03359": "|[an enhanced harmonic densely connected hybrid transformer network architecture for chronic wound segmentation utilising multi-colour space tensor merging](https://arxiv.org/abs/2410.03359)|[hardnet-cws](https://github.com/mmu-dermatology-research/hardnet-cws)|\n", "2410.19816": "|[divshift: exploring domain-specific distribution shifts in large-scale, volunteer-collected biodiversity datasets](https://arxiv.org/abs/2410.19816)|[DivShift](https://github.com/moiexpositoalonsolab/DivShift)|\n", "2411.06224": "|[stiffgipc: advancing gpu ipc for stiff affine-deformable simulation](https://arxiv.org/abs/2411.06224)|[muda](https://github.com/mugdxy/muda)|\n", "2411.14432": "|[insight-v: exploring long-chain visual reasoning with multimodal large language models](https://arxiv.org/abs/2411.14432)|[insight-v](https://github.com/dongyh20/insight-v)|\n", "2411.16721": "|[steering away from harm: an adaptive approach to defending vision language model against jailbreaks](https://arxiv.org/abs/2411.16721)|[ASTRA](https://github.com/ASTRAL-Group/ASTRA)|\n", "2411.17662": "|[robopepp: vision-based robot pose and joint angle estimation through embedding predictive pre-training](https://arxiv.org/abs/2411.17662)|[robopepp](https://github.com/raktimgg/robopepp)|\n", "2503.05214": "|[gaussian random fields as an abstract representation of patient metadata for multimodal medical image segmentation](https://arxiv.org/abs/2503.05214)|[multimodal-grf](https://github.com/mmu-dermatology-research/multimodal-grf)|\n", "2503.12623": "|[maven: multi-modal attention for valence-arousal emotion network](https://arxiv.org/abs/2503.12623)|[maven_8th_abaw](https://github.com/vrushank-ahire/maven_8th_abaw)|\n", "2504.02782": "|[gpt-imgeval: a comprehensive benchmark for diagnosing gpt4o in image generation](https://arxiv.org/abs/2504.02782)|[gpt-imgeval](https://github.com/picotrex/gpt-imgeval)|\n", "2504.16276": "|[an automated pipeline for few-shot bird call classification: a case study with the tooth-billed pigeon](https://arxiv.org/abs/2504.16276)|[few-shot-bird-call](https://github.com/colossal-compsci/few-shot-bird-call)|\n", "2504.18317": "|[task-oriented communications for visual navigation with edge-aerial collaboration in low altitude economy](https://arxiv.org/abs/2504.18317)|[TOC-Edge-Aerial](https://github.com/fangzr/TOC-Edge-Aerial)|\n", "2505.00056": "|[clustering internet memes through template matching and multi-dimensional similarity](https://arxiv.org/abs/2505.00056)|[meme-clustering](https://github.com/tygobl/meme-clustering)|\n", "2505.00568": "|[multimodal masked autoencoder pre-training for 3d mri-based brain tumor analysis with missing modalities](https://arxiv.org/abs/2505.00568)|[bm-mae](https://github.com/lucas-rbnt/bm-mae)|\n", "2505.00740": "|[fast2comm:collaborative perception combined with prior knowledge](https://arxiv.org/abs/2505.00740)|[fast2comm](https://github.com/zhangzhengbin-tj/fast2comm)|\n", "2505.00772": "|[person detection and re-identification in open-world settings of retail stores and public spaces](https://arxiv.org/abs/2505.00772)|[personReID](https://github.com/brkljac/personReID)|\n", "2505.00866": "|[are minimal radial distortion solvers really necessary for relative pose estimation?](https://arxiv.org/abs/2505.00866)|[rdnet](https://github.com/kocurvik/rdnet)|\n", "2505.00938": "|[cdformer: cross-domain few-shot object detection transformer against feature confusion](https://arxiv.org/abs/2505.00938)|[CDFormer_code](https://github.com/LONGXUANX/CDFormer_code)|\n", "2505.01172": "|[freepca: integrating consistency information across long-short frames in training-free long video generation via principal component analysis](https://arxiv.org/abs/2505.01172)|[freepca](https://github.com/josephtitan/freepca)|\n", "2505.01224": "|[rd-uie: relation-driven state space modeling for underwater image enhancement](https://arxiv.org/abs/2505.01224)|[rd-uie](https://github.com/kkoucy/rd-uie)|\n", "2505.01225": "|[core-set selection for data-efficient land cover segmentation](https://arxiv.org/abs/2505.01225)|[data-centric-rs-classification](https://github.com/keillernogueira/data-centric-rs-classification)|\n", "2505.01257": "|[cameltrack: context-aware multi-cue exploitation for online multi-object tracking](https://arxiv.org/abs/2505.01257)|[CAMELTrack](https://github.com/TrackingLaboratory/CAMELTrack)|\n", "2505.01406": "|[vidstamp: a temporally-aware watermark for ownership and integrity in video diffusion models](https://arxiv.org/abs/2505.01406)|[vidstamp](https://github.com/spin-umass/vidstamp)|\n"}, "2025-05-06": {"2308.04369": "|[sstformer: bridging spiking neural network and memory support transformer for frame-event based recognition](https://arxiv.org/abs/2308.04369)|[sstformer](https://github.com/event-ahu/sstformer)|\n", "2402.04168": "|[informed reinforcement learning for situation-aware traffic rule exceptions](https://arxiv.org/abs/2402.04168)|[informed_rl](https://github.com/fzi-forschungszentrum-informatik/informed_rl)|\n", "2402.15388": "|[on the usability of next-generation authentication: a study on eye movement and brainwave-based mechanisms](https://arxiv.org/abs/2402.15388)|[mockup_paper](https://github.com/kit-ps/mockup_paper)|\n", "2403.07569": "|[exploring challenges in deep learning of single-station ground motion records](https://arxiv.org/abs/2403.07569)|[mage](https://github.com/caglarmert/mage)|\n", "2404.01249": "|[fireants: adaptive riemannian optimization for multi-scale diffeomorphic matching](https://arxiv.org/abs/2404.01249)|[fireants](https://github.com/rohitrango/fireants)|\n", "2405.00318": "|[covariant spatio-temporal receptive fields for spiking neural networks](https://arxiv.org/abs/2405.00318)|[nrf](https://github.com/jegp/nrf)|\n", "2405.01101": "|[enhancing person re-identification via uncertainty feature fusion method and auto-weighted measure combination](https://arxiv.org/abs/2405.01101)|[Enhancing-Person-Re-Identification-via-UFFM-and-AMC](https://github.com/chequanghuy/Enhancing-Person-Re-Identification-via-UFFM-and-AMC)|\n", "2406.07361": "|[deep implicit optimization enables robust learnable features for deformable image registration](https://arxiv.org/abs/2406.07361)|[dio](https://github.com/rohitrango/dio)|\n", "2407.02329": "|[migc++: advanced multi-instance generation controller for image synthesis](https://arxiv.org/abs/2407.02329)|[migc](https://github.com/limuloo/migc)|\n", "2407.05576": "|[care-ego: contact-aware relationship modeling for egocentric interactive hand-object segmentation](https://arxiv.org/abs/2407.05576)|[care-ego](https://github.com/yuggiehk/care-ego)|\n", "2407.12772": "|[lmms-eval: reality check on the evaluation of large multimodal models](https://arxiv.org/abs/2407.12772)|[lmms-eval](https://github.com/evolvinglmms-lab/lmms-eval)|\n", "2408.05411": "|[how does audio influence visual attention in omnidirectional videos? database and model](https://arxiv.org/abs/2408.05411)|[avs-odv](https://github.com/intmegroup/avs-odv)|\n", "2408.13431": "|[face clustering via early stopping and edge recall](https://arxiv.org/abs/2408.13431)|[fc-eser](https://github.com/jumptoliujj/fc-eser)|\n", "2408.17090": "|[fissionvae: federated non-iid image generation with latent space and decoder decomposition](https://arxiv.org/abs/2408.17090)|[fissionvae](https://github.com/rand2ai/fissionvae)|\n", "2409.07271": "|[cfcpalsy: facial image synthesis with cross-fusion cycle diffusion model for facial paralysis individuals](https://arxiv.org/abs/2409.07271)|[cfcpalsy](https://github.com/gaovix/cfcpalsy)|\n", "2409.09724": "|[mfclip: multi-modal fine-grained clip for generalizable diffusion face forgery detection](https://arxiv.org/abs/2409.09724)|[mfclip](https://github.com/jenine-321/mfclip)|\n", "2410.10821": "|[tex4d: zero-shot 4d scene texturing with video diffusion models](https://arxiv.org/abs/2410.10821)|[Tex4D](https://github.com/ZqlwMatt/Tex4D)|\n", "2411.15539": "|[large language model with region-guided referring and grounding for ct report generation](https://arxiv.org/abs/2411.15539)|[reg2rg](https://github.com/zhi-xuan-chen/reg2rg)|\n", "2411.19415": "|[amo sampler: enhancing text rendering with overshooting](https://arxiv.org/abs/2411.19415)|[amo-release](https://github.com/hxixixh/amo-release)|\n", "2412.18165": "|[parallel neural computing for scene understanding from lidar perception in autonomous racing](https://arxiv.org/abs/2412.18165)|[parallel-perception-network](https://github.com/suwesh/parallel-perception-network)|\n", "2501.04206": "|[graphite: graph-based interpretable tissue examination for enhanced explainability in breast cancer histopathology](https://arxiv.org/abs/2501.04206)|[graphite](https://github.com/raktim-mondol/graphite)|\n", "2501.10098": "|[landmarker: a toolkit for anatomical landmark localization in 2d/3d images](https://arxiv.org/abs/2501.10098)|[landmarker](https://github.com/predict-idlab/landmarker)|\n", "2501.10977": "|[smarte-vr: student monitoring and adaptive response technology for e-learning in virtual reality](https://arxiv.org/abs/2501.10977)|[smarte-vr-db](https://github.com/blancelin1/smarte-vr-db)|\n", "2502.00968": "|[code: blockwise control for denoising diffusion models](https://arxiv.org/abs/2502.00968)|[code](https://github.com/anujinho/code)|\n", "2502.01710": "|[dagnet: a dual-view attention-guided network for efficient x-ray security inspection](https://arxiv.org/abs/2502.01710)|[dagnet](https://github.com/shilonghong/dagnet)|\n", "2502.15251": "|[simhand: mining similar hands for large-scale 3d hand pose pre-training](https://arxiv.org/abs/2502.15251)|[simhand](https://github.com/ut-vision/simhand)|\n", "2502.15666": "|[almost ai, almost human: the challenge of detecting ai-polished writing](https://arxiv.org/abs/2502.15666)|[ai-polished-text](https://github.com/ShoumikSaha/ai-polished-text)|\n", "2502.20490": "|[egonormia: benchmarking physical social norm understanding](https://arxiv.org/abs/2502.20490)|[egonormia](https://github.com/open-social-world/egonormia)|\n", "2503.02910": "|[langgas: introducing language in selective zero-shot background subtraction for semi-transparent gas leak detection with a new dataset](https://arxiv.org/abs/2503.02910)|[Lang-Gas](https://github.com/weathon/Lang-Gas)|\n", "2503.06457": "|[geometric knowledge-guided localized global distribution alignment for federated learning](https://arxiv.org/abs/2503.06457)|[2025cvpr_ggeur](https://github.com/weidai-david/2025cvpr_ggeur)|\n", "2504.03471": "|[dynamic importance in diffusion u-net for enhanced image synthesis](https://arxiv.org/abs/2504.03471)|[unetreweighting](https://github.com/hytidel/unetreweighting)|\n", "2504.04519": "|[sam2mot: a novel paradigm of multi-object tracking by segmentation](https://arxiv.org/abs/2504.04519)|[SAM2MOT](https://github.com/TripleJoy/SAM2MOT)|\n", "2504.07392": "|[id-booth: identity-consistent face generation with diffusion models](https://arxiv.org/abs/2504.07392)|[id-booth](https://github.com/dariant/id-booth)|\n", "2504.11936": "|[mind2matter: creating 3d models from eeg signals](https://arxiv.org/abs/2504.11936)|[mind2matter](https://github.com/sddwwww/mind2matter)|\n", "2504.14693": "|[video-mmlu: a massive multi-discipline lecture understanding benchmark](https://arxiv.org/abs/2504.14693)|[video-mmlu](https://github.com/espere-1119-song/video-mmlu)|\n", "2504.20682": "|[og-hfyolo :orientation gradient guidance and heterogeneous feature fusion for deformation table cell instance segmentation](https://arxiv.org/abs/2504.20682)|[oghfyolo](https://github.com/justliulong/oghfyolo)|\n", "2504.20898": "|[cbm-rag: demonstrating enhanced interpretability in radiology report generation with multi-agent rag and concept bottleneck models](https://arxiv.org/abs/2504.20898)|[enhanced-interpretable-report-generation-demo](https://github.com/tifat58/enhanced-interpretable-report-generation-demo)|\n", "2504.20903": "|[modeling ai-human collaboration as a multi-agent adaptation](https://arxiv.org/abs/2504.20903)|[NKC-Multi-Agent-Models](https://github.com/saimihirj/NKC-Multi-Agent-Models)|\n", "2505.00630": "|[vision mamba in remote sensing: a comprehensive survey of techniques, applications and outlook](https://arxiv.org/abs/2505.00630)|[awesome-mamba-in-remote-sensing](https://github.com/baobao0926/awesome-mamba-in-remote-sensing)|\n", "2505.01431": "|[zs-vcos: zero-shot outperforms supervised video camouflaged object segmentation](https://arxiv.org/abs/2505.01431)|[vcos](https://github.com/weathon/vcos)|\n", "2505.01456": "|[unlearning sensitive information in multimodal llms: benchmark and attack-defense evaluation](https://arxiv.org/abs/2505.01456)|[unlok-vqa](https://github.com/vaidehi99/unlok-vqa)|\n", "2505.01476": "|[costfilter-ad: enhancing anomaly detection through matching cost filtering](https://arxiv.org/abs/2505.01476)|[costfilter-ad](https://github.com/zhe-sapi/costfilter-ad)|\n", "2505.01481": "|[videohallu: evaluating and mitigating multi-modal hallucinations for synthetic videos](https://arxiv.org/abs/2505.01481)|[videohallu](https://github.com/zli12321/videohallu)|\n", "2505.01548": "|[rethinking rgb-event semantic segmentation with a novel bidirectional motion-enhanced event representation](https://arxiv.org/abs/2505.01548)|[BRENet](https://github.com/zyaocoder/BRENet)|\n", "2505.01583": "|[tempura: temporal event masked prediction and understanding for reasoning in action](https://arxiv.org/abs/2505.01583)|[tempura](https://github.com/andy-cheng/tempura)|\n", "2505.01644": "|[a dual-task synergy-driven generalization framework for pancreatic cancer segmentation in ct scans](https://arxiv.org/abs/2505.01644)|[dual-task-seg](https://github.com/sjtubme-qianlab/dual-task-seg)|\n", "2505.01699": "|[component-based fairness in face attribute classification with bayesian network-informed meta learning](https://arxiv.org/abs/2505.01699)|[bnmr-faircompface](https://github.com/yliuaa/bnmr-faircompface)|\n", "2505.01724": "|[vistaxa: developing a taxonomy of historical visualizations](https://arxiv.org/abs/2505.01724)|[image-taxonomy-labeler](https://github.com/oldvis/image-taxonomy-labeler)|\n", "2505.01755": "|[lensnet: an end-to-end learning framework for empirical point spread function modeling and lensless imaging reconstruction](https://arxiv.org/abs/2505.01755)|[Lensnet](https://github.com/baijiesong/Lensnet)|\n", "2505.01779": "|[polar interpolants for thin-shell microstructure homogenization](https://arxiv.org/abs/2505.01779)|[polarinterpolants](https://github.com/antoine-chan-lock/polarinterpolants)|\n", "2505.01790": "|[enhancing the learning experience: using vision-language models to generate questions for educational videos](https://arxiv.org/abs/2505.01790)|[aied_2025_video_qg](https://github.com/markossta/aied_2025_video_qg)|\n", "2505.01854": "|[accelerating volumetric medical image annotation via short-long memory sam 2](https://arxiv.org/abs/2505.01854)|[slm-sam2](https://github.com/mazurowski-lab/slm-sam2)|\n", "2505.01938": "|[hybridgs: high-efficiency gaussian splatting data compression using dual-channel sparse representation and point cloud encoder](https://arxiv.org/abs/2505.01938)|[hybridgs](https://github.com/qi-yangsjtu/hybridgs)|\n", "2505.02005": "|[learning heterogeneous mixture of scene experts for large-scale neural radiance fields](https://arxiv.org/abs/2505.02005)|[Switch-NeRF](https://github.com/MiZhenxing/Switch-NeRF)|\n", "2505.02075": "|[benchmarking feature upsampling methods for vision foundation models using interactive segmentation](https://arxiv.org/abs/2505.02075)|[isegprobe](https://github.com/havrylovv/isegprobe)|\n", "2505.02159": "|[small clips, big gains: learning long-range refocused temporal information for video super-resolution](https://arxiv.org/abs/2505.02159)|[lrti-vsr](https://github.com/labshuhanggu/lrti-vsr)|\n", "2505.02179": "|[prodisc-vad: an efficient system for weakly-supervised anomaly detection in video surveillance applications](https://arxiv.org/abs/2505.02179)|[ProDisc-VAD](https://github.com/modadundun/ProDisc-VAD)|\n", "2505.02182": "|[robust ai-generated face detection with imbalanced data](https://arxiv.org/abs/2505.02182)|[sp_cup](https://github.com/purdue-m2/sp_cup)|\n", "2505.02246": "|[cricket: a self-powered chirping pixel](https://arxiv.org/abs/2505.02246)|[cricket-public](https://github.com/columbiacomputervision/cricket-public)|\n", "2505.02325": "|[teda: boosting vision-lanuage models for zero-shot 3d object retrieval via testing-time distribution alignment](https://arxiv.org/abs/2505.02325)|[teda](https://github.com/wangzhichuan123/teda)|\n", "2505.02331": "|[vaemo: efficient representation learning for visual-audio emotion with knowledge injection](https://arxiv.org/abs/2505.02331)|[VAEmo](https://github.com/MSA-LMC/VAEmo)|\n", "2505.02350": "|[sparse ellipsoidal radial basis function network for point cloud surface representation](https://arxiv.org/abs/2505.02350)|[se-rbfnet](https://github.com/lianbobo/se-rbfnet)|\n", "2505.02370": "|[superedit: rectifying and facilitating supervision for instruction-based image editing](https://arxiv.org/abs/2505.02370)|[superedit](https://github.com/bytedance/superedit)|\n", "2505.02385": "|[an arbitrary-modal fusion network for volumetric cranial nerves tract segmentation](https://arxiv.org/abs/2505.02385)|[cntseg](https://github.com/ipis-xielei/cntseg)|\n", "2505.02414": "|[quadrupedal spine control strategies: exploring correlations between system dynamic responses and human perspectives](https://arxiv.org/abs/2505.02414)|[ester](https://github.com/nickick-icrs/ester)|\n", "2505.02481": "|[finger pose estimation for under-screen fingerprint sensor](https://arxiv.org/abs/2505.02481)|[draco](https://github.com/xiongjunguan/draco)|\n", "2505.02654": "|[sim2real in endoscopy segmentation with a novel structure aware image translation](https://arxiv.org/abs/2505.02654)|[sim2real-endoscopysegmentation](https://github.com/ropertuz/sim2real-endoscopysegmentation)|\n", "2505.02705": "|[multi-view learning with context-guided receptance for image denoising](https://arxiv.org/abs/2505.02705)|[crwkv](https://github.com/seeker98/crwkv)|\n", "2505.02746": "|[using knowledge graphs to harvest datasets for efficient clip model training](https://arxiv.org/abs/2505.02746)|[entitynet](https://github.com/lmb-freiburg/entitynet)|\n", "2505.02753": "|[advancing generalizable tumor segmentation with anomaly-aware open-vocabulary attention maps and frozen foundation diffusion models](https://arxiv.org/abs/2505.02753)|[diffugts](https://github.com/yankai96/diffugts)|\n", "2505.02780": "|[beyond the monitor: mixed reality visualization and ai for enhanced digital pathology workflow](https://arxiv.org/abs/2505.02780)|[path_vis](https://github.com/jaiprakash1824/path_vis)|\n", "2505.02823": "|[musar: exploring multi-subject customization from single-subject dataset via attention routing](https://arxiv.org/abs/2505.02823)|[musar](https://github.com/guozinan126/musar)|\n", "2505.02824": "|[towards dataset copyright evasion attack against personalized text-to-image diffusion models](https://arxiv.org/abs/2505.02824)|[ceat2i](https://github.com/csyufei/ceat2i)|\n"}, "2025-05-07": {"2303.12675": "|[vecfontsdf: learning to reconstruct and synthesize high-quality vector fonts via signed distance functions](https://arxiv.org/abs/2303.12675)|[VecFontSDF](https://github.com/ymxbj/VecFontSDF)|\n", "2305.18708": "|[infrared image deturbulence restoration using degradation parameter-assisted wide & deep learning](https://arxiv.org/abs/2305.18708)|[DparNet](https://github.com/Ydo-W/DparNet)|\n", "2311.14284": "|[paragraph-to-image generation with information-enriched diffusion model](https://arxiv.org/abs/2311.14284)|[paradiffusion](https://github.com/weijiawu/paradiffusion)|\n", "2312.01581": "|[plum: improving inference efficiency by leveraging repetition-sparsity trade-off](https://arxiv.org/abs/2312.01581)|[plum](https://github.com/sachitkuhar/plum)|\n", "2401.12033": "|[momentum-sam: sharpness aware minimization without computational overhead](https://arxiv.org/abs/2401.12033)|[msam](https://github.com/marlonbecker/msam)|\n", "2403.08256": "|[ig-fiqa: improving face image quality assessment through intra-class variance guidance robust to inaccurate pseudo-labels](https://arxiv.org/abs/2403.08256)|[IG-FIQA](https://github.com/kim1102/IG-FIQA)|\n", "2407.06606": "|[tailored design of audio-visual speech recognition models using branchformers](https://arxiv.org/abs/2407.06606)|[tailored-avsr](https://github.com/david-gimeno/tailored-avsr)|\n", "2407.08277": "|[stixelnext: toward monocular low-weight perception for object segmentation and free space detection](https://arxiv.org/abs/2407.08277)|[StixelNExT](https://github.com/MarcelVSHNS/StixelNExT)|\n", "2409.07012": "|[towards predicting temporal changes in a patient's chest x-ray images based on electronic health records](https://arxiv.org/abs/2409.07012)|[ehrxdiff](https://github.com/dek924/ehrxdiff)|\n", "2411.03239": "|[decoupling fine detail and global geometry for compressed depth map super-resolution](https://arxiv.org/abs/2411.03239)|[gdnet](https://github.com/ian0926/gdnet)|\n", "2411.18279": "|[large language model-brained gui agents: a survey](https://arxiv.org/abs/2411.18279)|[LLM-Brained-GUI-Agents-Survey](https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey)|\n", "2412.04280": "|[humanedit: a high-quality human-rewarded dataset for instruction-based image editing](https://arxiv.org/abs/2412.04280)|[humanedit](https://github.com/viiika/humanedit)|\n", "2501.18630": "|[deformable beta splatting](https://arxiv.org/abs/2501.18630)|[beta-splatting](https://github.com/RongLiu-Leo/beta-splatting)|\n", "2502.07328": "|[music for all: representational bias and cross-cultural adaptability of music generation models](https://arxiv.org/abs/2502.07328)|[music4all](https://github.com/atharva20038/music4all)|\n", "2502.17648": "|[calibrefine: deep learning-based online automatic targetless lidar-camera calibration with iterative and attention-driven post-refinement](https://arxiv.org/abs/2502.17648)|[Lidar_Camera_Automatic_Calibration](https://github.com/radar-lab/Lidar_Camera_Automatic_Calibration)|\n", "2502.18225": "|[liver cirrhosis stage estimation from mri with deep learning](https://arxiv.org/abs/2502.18225)|[cirrhosisstage](https://github.com/junzengz/cirrhosisstage)|\n", "2503.03307": "|[full-dof egomotion estimation for event cameras using geometric solvers](https://arxiv.org/abs/2503.03307)|[relpose-event](https://github.com/jizhaox/relpose-event)|\n", "2503.04114": "|[organize, then vote: exploring cognitive load in quadratic survey interfaces](https://arxiv.org/abs/2503.04114)|[Quadratic-Survey-Dataset-and-Analysis](https://github.com/CrowdDynamicsLab/Quadratic-Survey-Dataset-and-Analysis)|\n", "2504.01153": "|[catch me if you search: when contextual web search results affect the detection of hallucinations](https://arxiv.org/abs/2504.01153)|[CatchMeIfYouSearch](https://github.com/MahjabinNahar/CatchMeIfYouSearch)|\n", "2504.07606": "|[heart failure prediction using modal decomposition and masked autoencoders for scarce echocardiography databases](https://arxiv.org/abs/2504.07606)|[modelflows-app](https://github.com/modelflows/modelflows-app)|\n", "2504.13754": "|[towards accurate and interpretable neuroblastoma diagnosis via contrastive multi-scale pathological image analysis](https://arxiv.org/abs/2504.13754)|[cmswinkan](https://github.com/jsliam94/cmswinkan)|\n", "2504.17761": "|[step1x-edit: a practical framework for general image editing](https://arxiv.org/abs/2504.17761)|[step1x-edit](https://github.com/stepfun-ai/step1x-edit)|\n", "2504.19244": "|[semantic-aligned learning with collaborative refinement for unsupervised vi-reid](https://arxiv.org/abs/2504.19244)|[code-for-salcr](https://github.com/franklinlingfeng/code-for-salcr)|\n", "2505.01884": "|[adversarial robustness of deep learning models for inland water body segmentation from sar images](https://arxiv.org/abs/2505.01884)|[iwseg-sar-poison](https://github.com/gvcl/iwseg-sar-poison)|\n", "2505.02048": "|[regression is all you need for medical image translation](https://arxiv.org/abs/2505.02048)|[yoda](https://github.com/deep-mi/yoda)|\n", "2505.02064": "|[rtv-bench: benchmarking mllm continuous perception, understanding and reasoning through real-time video](https://arxiv.org/abs/2505.02064)|[rtv-bench](https://github.com/ljungang/rtv-bench)|\n", "2505.02704": "|[vgld: visually-guided linguistic disambiguation for monocular depth scale recovery](https://arxiv.org/abs/2505.02704)|[vgld](https://github.com/pakinwu/vgld)|\n", "2505.02971": "|[adversarial robustness analysis of vision-language models in medical image segmentation](https://arxiv.org/abs/2505.02971)|[secure-private-ai](https://github.com/anjilab/secure-private-ai)|\n", "2505.03007": "|[ntire 2025 challenge on ugc video enhancement: methods and results](https://arxiv.org/abs/2505.03007)|[ntire25_ugc_video_enhancement](https://github.com/msu-video-group/ntire25_ugc_video_enhancement)|\n", "2505.03046": "|[sim2real transfer for vision-based grasp verification](https://arxiv.org/abs/2505.03046)|[hsr-graspsynth](https://github.com/pauamargant/hsr-graspsynth)|\n", "2505.03114": "|[path and bone-contour regularized unpaired mri-to-ct translation](https://arxiv.org/abs/2505.03114)|[pabot](https://github.com/kennysyp/pabot)|\n", "2505.03153": "|[robust fairness vision-language learning for medical image analysis](https://arxiv.org/abs/2505.03153)|[robust_fairness_for_medical_image](https://github.com/purdue-m2/robust_fairness_for_medical_image)|\n", "2505.03242": "|[seeing the abstract: translating the abstract language for vision language models](https://arxiv.org/abs/2505.03242)|[fashionact](https://github.com/davidetalon/fashionact)|\n", "2505.03299": "|[towards efficient benchmarking of foundation models in remote sensing: a capabilities encoding approach](https://arxiv.org/abs/2505.03299)|[capabilities-encoding](https://github.com/pierreadorni/capabilities-encoding)|\n", "2505.03319": "|[sd-vsum: a method and dataset for script-driven video summarization](https://arxiv.org/abs/2505.03319)|[sd-vsum](https://github.com/idt-iti/sd-vsum)|\n", "2505.03401": "|[ddatr: dynamic difference-aware temporal residual network for longitudinal radiology report generation](https://arxiv.org/abs/2505.03401)|[ddatr](https://github.com/xmed-lab/ddatr)|\n", "2505.03422": "|[liftfeat: 3d geometry-aware local feature matching](https://arxiv.org/abs/2505.03422)|[liftfeat](https://github.com/lyp-deeplearning/liftfeat)|\n", "2505.03427": "|[medarabiq: benchmarking large language models on arabic medical tasks](https://arxiv.org/abs/2505.03427)|[medarabiq](https://github.com/nyuad-cai/medarabiq)|\n", "2505.03431": "|[a fusion-guided inception network for hyperspectral image super-resolution](https://arxiv.org/abs/2505.03431)|[fusion](https://github.com/usman1021/fusion)|\n", "2505.03470": "|[blending 3d geometry and machine learning for multi-view stereopsis](https://arxiv.org/abs/2505.03470)|[GC-MVSNet-PlusPlus](https://github.com/vkvats/GC-MVSNet-PlusPlus)|\n", "2505.03480": "|[modeling musical genre trajectories through pathlet learning](https://arxiv.org/abs/2505.03480)|[music_pathlets](https://github.com/lilianmarey/music_pathlets)|\n", "2505.03494": "|[upmad-net: a brain tumor segmentation network with uncertainty guidance and adaptive multimodal feature fusion](https://arxiv.org/abs/2505.03494)|[upmad_net_brainseg](https://github.com/chenzhao2023/upmad_net_brainseg)|\n", "2505.03507": "|[modality-guided dynamic graph fusion and temporal diffusion for self-supervised rgb-t tracking](https://arxiv.org/abs/2505.03507)|[gdstrack](https://github.com/lishenglana/gdstrack)|\n", "2505.03538": "|[rail: region-aware instructive learning for semi-supervised tooth segmentation in cbct](https://arxiv.org/abs/2505.03538)|[rail](https://github.com/tournesol-saturday/rail)|\n", "2505.03539": "|[panoramic out-of-distribution segmentation](https://arxiv.org/abs/2505.03539)|[panoos](https://github.com/mengfeid/panoos)|\n", "2505.03568": "|[familiarizing with music: discovery patterns for different music discovery needs](https://arxiv.org/abs/2505.03568)|[familiarizing_with_music](https://github.com/hcai-mms/familiarizing_with_music)|\n", "2505.03581": "|[dygenc: encoding a sequence of textual scene graphs to reason and answer questions in dynamic scenes](https://arxiv.org/abs/2505.03581)|[dygenc](https://github.com/linukc/dygenc)|\n", "2505.03597": "|[fixed-length dense fingerprint representation](https://arxiv.org/abs/2505.03597)|[flare](https://github.com/yu-yy/flare)|\n", "2505.03623": "|[bounding box-guided diffusion for synthesizing industrial images and segmentation map](https://arxiv.org/abs/2505.03623)|[diffusion_labeling](https://github.com/covisionlab/diffusion_labeling)|\n", "2505.03692": "|[matching distance and geometric distribution aided learning multiview point cloud registration](https://arxiv.org/abs/2505.03692)|[mdgd](https://github.com/shi-qi-li/mdgd)|\n"}, "2025-05-08": {"2301.02008": "|[expressive speech-driven facial animation with controllable emotions](https://arxiv.org/abs/2301.02008)|[facialanimation](https://github.com/on1262/facialanimation)|\n", "2306.07971": "|[xraygpt: chest radiographs summarization using medical vision-language models](https://arxiv.org/abs/2306.07971)|[xraygpt](https://github.com/mbzuai-oryx/xraygpt)|\n", "2311.18681": "|[radialog: a large vision-language model for radiology report generation and conversational assistance](https://arxiv.org/abs/2311.18681)|[radialog](https://github.com/chantalmp/radialog)|\n", "2406.04321": "|[vidmuse: a simple video-to-music generation framework with long-short-term modeling](https://arxiv.org/abs/2406.04321)|[vidmuse](https://github.com/zeyuet/vidmuse)|\n", "2406.17774": "|[uncertainty for svbrdf acquisition using frequency analysis](https://arxiv.org/abs/2406.17774)|[svbrdf_uncertainty](https://github.com/rubenwiersma/svbrdf_uncertainty)|\n", "2407.08364": "|[scalar function topology divergence: comparing topology of 3d objects](https://arxiv.org/abs/2407.08364)|[sftd](https://github.com/ilyatrofimov/sftd)|\n", "2409.15511": "|[bayesian computation with generative diffusion models by multilevel monte carlo](https://arxiv.org/abs/2409.15511)|[mlmcfordms](https://github.com/lshaw8317/mlmcfordms)|\n", "2409.19911": "|[replace anyone in videos](https://arxiv.org/abs/2409.19911)|[unianimate-dit](https://github.com/ali-vilab/unianimate-dit)|\n", "2410.01495": "|[ov-mer: towards open-vocabulary multimodal emotion recognition](https://arxiv.org/abs/2410.01495)|[affectgpt](https://github.com/zeroqiaoba/affectgpt)|\n", "2411.04997": "|[llm2clip: powerful language model unlocks richer visual representation](https://arxiv.org/abs/2411.04997)|[LLM2CLIP](https://github.com/microsoft/LLM2CLIP)|\n", "2411.06911": "|[gaussian process emulators for few-shot segmentation in cardiac mri](https://arxiv.org/abs/2411.06911)|[gpe_4_cardiac_fss](https://gitlab.com/bruno_viti/gpe_4_cardiac_fss)|\n", "2412.03413": "|[deep learning for sea surface temperature reconstruction under cloud occlusion](https://arxiv.org/abs/2412.03413)|[sst_reconstruction](https://github.com/asperti/sst_reconstruction)|\n", "2412.04472": "|[stereo anywhere: robust zero-shot deep stereo matching even where either stereo or mono fail](https://arxiv.org/abs/2412.04472)|[stereoanywhere](https://github.com/bartn8/stereoanywhere)|\n", "2501.16566": "|[affectgpt: a new dataset, model, and benchmark for emotion understanding with multimodal large language models](https://arxiv.org/abs/2501.16566)|[affectgpt](https://github.com/zeroqiaoba/affectgpt)|\n", "2502.01547": "|[mwhisper-flamingo for multilingual audio-visual noise-robust speech recognition](https://arxiv.org/abs/2502.01547)|[whisper-flamingo](https://github.com/roudimit/whisper-flamingo)|\n", "2502.10156": "|[monoforce: learnable image-conditioned physics engine](https://arxiv.org/abs/2502.10156)|[monoforce](https://github.com/ctu-vras/monoforce)|\n", "2502.11178": "|[da-mamba: domain adaptive hybrid mamba-transformer based one-stage object detection](https://arxiv.org/abs/2502.11178)|[damamba](https://github.com/enesdoruk/damamba)|\n", "2504.02287": "|[multisensor-home: a wide-area multi-modal multi-view dataset for action recognition and transformer-based sensor fusion](https://arxiv.org/abs/2504.02287)|[multitsf](https://github.com/thanhhff/multitsf)|\n", "2504.19186": "|[lrfusionpr: a polar bev-based lidar-radar fusion network for place recognition](https://arxiv.org/abs/2504.19186)|[lrfusionpr](https://github.com/qizs-bit/lrfusionpr)|\n", "2504.20468": "|[antidote: a unified framework for mitigating lvlm hallucinations in counterfactual presupposition and object perception](https://arxiv.org/abs/2504.20468)|[antidote](https://github.com/wu0409/antidote)|\n", "2505.01880": "|[weakly-supervised audio temporal forgery localization via progressive audio-language co-learning network](https://arxiv.org/abs/2505.01880)|[LOCO](https://github.com/ItzJuny/LOCO)|\n", "2505.02406": "|[token coordinated prompt attention is needed for visual prompting](https://arxiv.org/abs/2505.02406)|[icml2025-tcpa](https://github.com/zhoujiahuan1991/icml2025-tcpa)|\n", "2505.02471": "|[ming-lite-uni: advancements in unified architecture for natural multimodal interaction](https://arxiv.org/abs/2505.02471)|[ming](https://github.com/inclusionai/ming)|\n", "2505.02567": "|[unified multimodal understanding and generation models: advances, challenges, and opportunities](https://arxiv.org/abs/2505.02567)|[awesome-unified-multimodal-models](https://github.com/aidc-ai/awesome-unified-multimodal-models)|\n", "2505.03440": "|[manvr3d: a platform for human-in-the-loop cell tracking in virtual reality](https://arxiv.org/abs/2505.03440)|[manvr3d](https://github.com/scenerygraphics/manvr3d)|\n", "2505.03631": "|[breaking annotation barriers: generalized video quality assessment via ranking-based self-supervision](https://arxiv.org/abs/2505.03631)|[LMM-PVQA](https://github.com/clh124/LMM-PVQA)|\n", "2505.03836": "|[obd-finder: explainable coarse-to-fine text-centric oracle bone duplicates discovery](https://arxiv.org/abs/2505.03836)|[obd-finder](https://github.com/cszhanglmu/obd-finder)|\n", "2505.03859": "|[deepfakes on demand: the rise of accessible non-consensual deepfake image generators](https://arxiv.org/abs/2505.03859)|[deepfakesondemand](https://github.com/WillHawkins3/deepfakesondemand)|\n", "2505.03896": "|[novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation](https://arxiv.org/abs/2505.03896)|[attukan](https://github.com/stevezs315/attukan)|\n", "2505.03912": "|[openhelix: a short survey, empirical analysis, and open-source dual-system vla model for robotic manipulation](https://arxiv.org/abs/2505.03912)|[OpenHelix](https://github.com/OpenHelix-robot/OpenHelix)|\n", "2505.04003": "|[prototype-based information compensation network for multi-source remote sensing data classification](https://arxiv.org/abs/2505.04003)|[picnet](https://github.com/oucailab/picnet)|\n", "2505.04058": "|[as3d: 2d-assisted cross-modal understanding with semantic-spatial scene graphs for 3d visual grounding](https://arxiv.org/abs/2505.04058)|[AS3D](https://github.com/onmyoji-xiao/AS3D)|\n", "2505.04095": "|[scalable aerial gnss localization for marine robots](https://arxiv.org/abs/2505.04095)|[aerial_gnss](https://github.com/stevvwen/aerial_gnss)|\n", "2505.04119": "|[gaprompt: geometry-aware point cloud prompt for 3d vision model](https://arxiv.org/abs/2505.04119)|[icml2025-vgp](https://github.com/zhoujiahuan1991/icml2025-vgp)|\n", "2505.04121": "|[vision graph prompting via semantic low-rank decomposition](https://arxiv.org/abs/2505.04121)|[icml2025-vgp](https://github.com/zhoujiahuan1991/icml2025-vgp)|\n", "2505.04185": "|[s3d: sketch-driven 3d model generation](https://arxiv.org/abs/2505.04185)|[s3d](https://github.com/hailsong/s3d)|\n", "2505.04192": "|[videopath-llava: pathology diagnostic reasoning through video instruction tuning](https://arxiv.org/abs/2505.04192)|[videopath-llava](https://github.com/trinhvg/videopath-llava)|\n", "2505.04258": "|[rgb-event fusion with self-attention for collision prediction](https://arxiv.org/abs/2505.04258)|[eva](https://github.com/pbonazzi/eva)|\n", "2505.04276": "|[hdifftg: a lightweight hybrid diffusion-transformer-gcn architecture for 3d human pose estimation](https://arxiv.org/abs/2505.04276)|[hdifftg](https://github.com/circejie/hdifftg)|\n", "2505.04369": "|[wdmamba: when wavelet degradation prior meets vision mamba for image dehazing](https://arxiv.org/abs/2505.04369)|[wdmamba](https://github.com/sunj000/wdmamba)|\n", "2505.04410": "|[declip: decoupled learning for open-vocabulary dense perception](https://arxiv.org/abs/2505.04410)|[declip](https://github.com/xiaomoguhz/declip)|\n", "2505.04526": "|[dfvo: learning darkness-free visible and infrared image disentanglement and fusion all at once](https://arxiv.org/abs/2505.04526)|[dfvo](https://github.com/davin-qi530/dfvo)|\n", "2505.04540": "|[registration of 3d point sets using exponential-based similarity matrix](https://arxiv.org/abs/2505.04540)|[esm_icp](https://github.com/aralab-unr/esm_icp)|\n", "2505.04575": "|[componential prompt-knowledge alignment for domain incremental learning](https://arxiv.org/abs/2505.04575)|[icml2025-ka-prompt](https://github.com/zhoujiahuan1991/icml2025-ka-prompt)|\n", "2505.04584": "|[slideitright: using ai to find relevant slides and provide feedback for open-ended questions](https://arxiv.org/abs/2505.04584)|[slideitright](https://github.com/zqh0421/slideitright)|\n", "2505.04623": "|[echoink-r1: exploring audio-visual reasoning in multimodal llms via reinforcement learning](https://arxiv.org/abs/2505.04623)|[echoink](https://github.com/harryhsing/echoink)|\n"}, "2025-05-09": {"2208.03571": "|[transformer-based assignment decision network for multiple object tracking](https://arxiv.org/abs/2208.03571)|[tadn-mot](https://github.com/psaltaath/tadn-mot)|\n", "2211.05781": "|[demystify transformers & convolutions in modern image deep networks](https://arxiv.org/abs/2211.05781)|[stm-evaluation](https://github.com/opengvlab/stm-evaluation)|\n", "2309.14630": "|[free discontinuity regression: with an application to the economic effects of internet shutdowns](https://arxiv.org/abs/2309.14630)|[fdr](https://github.com/davidvandijcke/fdr)|\n", "2406.06050": "|[generalizable human gaussians from single-view image](https://arxiv.org/abs/2406.06050)|[HGM](https://github.com/jinnan-chen/HGM)|\n", "2408.16859": "|[evaluating deep learning models for breast cancer classification: a comparative study](https://arxiv.org/abs/2408.16859)|[Breast-Cancer-Classification](https://github.com/saniaesk/Breast-Cancer-Classification)|\n", "2409.09085": "|[hesso: towards automatic efficient and user friendly any neural network training and pruning](https://arxiv.org/abs/2409.09085)|[only_train_once](https://github.com/microsoft/only_train_once)|\n", "2409.16111": "|[cloudtrack: scalable uav tracking with cloud semantics](https://arxiv.org/abs/2409.16111)|[CloudTrack](https://github.com/yblei/CloudTrack)|\n", "2410.03577": "|[look twice before you answer: memory-space visual retracing for hallucination mitigation in multimodal large language models](https://arxiv.org/abs/2410.03577)|[MemVR](https://github.com/1zhou-Wang/MemVR)|\n", "2410.09049": "|[scenecraft: layout-guided 3d scene generation](https://arxiv.org/abs/2410.09049)|[scenecraft](https://github.com/orangesodahub/scenecraft)|\n", "2410.12705": "|[worldcuisines: a massive-scale benchmark for multilingual and multicultural visual question answering on global cuisines](https://arxiv.org/abs/2410.12705)|[worldcuisines](https://github.com/worldcuisines/worldcuisines)|\n", "2410.16296": "|[large scale mri collection and segmentation of cirrhotic liver](https://arxiv.org/abs/2410.16296)|[cirrmri600plus](https://github.com/nubagcilab/cirrmri600plus)|\n", "2411.01742": "|[learning from convolution-based unlearnable datasets](https://arxiv.org/abs/2411.01742)|[RSK](https://github.com/aseriesof-tubes/RSK)|\n", "2412.03093": "|[expanding event modality applications through a robust clip-based encoder](https://arxiv.org/abs/2412.03093)|[Event_Modality_Application](https://github.com/EavnJeong/Event_Modality_Application)|\n", "2412.16698": "|[interact with me: joint egocentric forecasting of intent to interact, attitude and social actions](https://arxiv.org/abs/2412.16698)|[SocialEgoNet](https://github.com/biantongfei/SocialEgoNet)|\n", "2501.04597": "|[frontiernet: learning visual cues to explore](https://arxiv.org/abs/2501.04597)|[frontiernet](https://github.com/cvg/frontiernet)|\n", "2502.08821": "|[dejaivu: identifying and explaining ai art on the web in real-time with saliency maps](https://arxiv.org/abs/2502.08821)|[dejaivu](https://github.com/noodulz/dejaivu)|\n", "2503.10042": "|[how do multimodal large language models handle complex multimodal reasoning? placing them in an extensible escape game](https://arxiv.org/abs/2503.10042)|[EscapeCraft](https://github.com/THUNLP-MT/EscapeCraft)|\n", "2504.11895": "|[search is all you need for few-shot anomaly detection](https://arxiv.org/abs/2504.11895)|[visionad](https://github.com/qiqigeww/visionad)|\n", "2504.21356": "|[nexus-gen: a unified model for image understanding, generation, and editing](https://arxiv.org/abs/2504.21356)|[nexus-gen](https://github.com/modelscope/nexus-gen)|\n", "2504.21487": "|[dgsolver: diffusion generalist solver with universal posterior sampling for image restoration](https://arxiv.org/abs/2504.21487)|[dgsolver](https://github.com/mililab/dgsolver)|\n", "2505.00735": "|[leveraging depth maps and attention mechanisms for enhanced image inpainting](https://arxiv.org/abs/2505.00735)|[CSCE748_Computational-Photography](https://github.com/7201krap/CSCE748_Computational-Photography)|\n", "2505.02060": "|[transforming faces into video stories -- videoface2.0](https://arxiv.org/abs/2505.02060)|[videoface2.0](https://github.com/brkljac/videoface2.0)|\n", "2505.02393": "|[uncertainty-weighted image-event multimodal fusion for video anomaly detection](https://arxiv.org/abs/2505.02393)|[ief-vad](https://github.com/eavnjeong/ief-vad)|\n", "2505.03808": "|[ai-driven multi-source data fusion for algal bloom severity classification in small inland water bodies: leveraging sentinel-2, dem, and noaa climate data](https://arxiv.org/abs/2505.03808)|[harmfulalgalbloomdetection](https://github.com/ioannisnasios/harmfulalgalbloomdetection)|\n", "2505.03838": "|[intellicardiac: an intelligent platform for cardiac image segmentation and classification](https://arxiv.org/abs/2505.03838)|[IntelliCardiac](https://github.com/tiffany9056/IntelliCardiac)|\n", "2505.03856": "|[an active inference model of covert and overt visual attention](https://arxiv.org/abs/2505.03856)|[ainf-visual-attention](https://github.com/unizgfer-lamor/ainf-visual-attention)|\n", "2505.04046": "|[reliable disentanglement multi-view learning against view adversarial attacks](https://arxiv.org/abs/2505.04046)|[2025-IJCAI-RDML](https://github.com/Willy1005/2025-IJCAI-RDML)|\n", "2505.04066": "|[llamapie: proactive in-ear conversation assistants](https://arxiv.org/abs/2505.04066)|[LlamaPIE](https://github.com/chentuochao/LlamaPIE)|\n", "2505.04281": "|[ts-diff: two-stage diffusion model for low-light raw image enhancement](https://arxiv.org/abs/2505.04281)|[ts-diff](https://github.com/circcclek/ts-diff)|\n", "2505.04586": "|[active sampling for mri-based sequential decision making](https://arxiv.org/abs/2505.04586)|[mri_sequential_active_sampling](https://github.com/vios-s/mri_sequential_active_sampling)|\n", "2505.04590": "|[tetweave: isosurface extraction using on-the-fly delaunay tetrahedral grids for gradient-based mesh optimization](https://arxiv.org/abs/2505.04590)|[TetWeave](https://github.com/AlexandreBinninger/TetWeave)|\n", "2505.04650": "|[multimodal benchmarking and recommendation of text-to-image generation models](https://arxiv.org/abs/2505.04650)|[Evaluation_generated_images](https://github.com/kapilw25/Evaluation_generated_images)|\n", "2505.04652": "|[rethinking boundary detection in deep learning-based medical image segmentation](https://arxiv.org/abs/2505.04652)|[cto](https://github.com/xiaofang007/cto)|\n", "2505.04656": "|[meshgen: generating pbr textured mesh with render-enhanced auto-encoder and generative data augmentation](https://arxiv.org/abs/2505.04656)|[meshgen](https://github.com/heheyas/meshgen)|\n", "2505.04659": "|[gssplat: generalizable semantic gaussian splatting for novel-view synthesis in 3d scenes](https://arxiv.org/abs/2505.04659)|[gssplat](https://github.com/onmyoji-xiao/gssplat)|\n", "2505.04668": "|[sgcr: spherical gaussians for efficient 3d curve reconstruction](https://arxiv.org/abs/2505.04668)|[sgcr](https://github.com/martinyxr/sgcr)|\n", "2505.04672": "|[histo-miner: deep learning based tissue features extraction pipeline from h&e whole slide images of cutaneous squamous cell carcinoma](https://arxiv.org/abs/2505.04672)|[Histo-Miner](https://github.com/bozeklab/Histo-Miner)|\n", "2505.04720": "|[false promises in medical imaging ai? assessing validity of outperformance claims](https://arxiv.org/abs/2505.04720)|[probability-of-false-claims](https://github.com/IMSY-DKFZ/probability-of-false-claims)|\n", "2505.04788": "|[convex relaxation for robust vanishing point estimation in manhattan world](https://arxiv.org/abs/2505.04788)|[globustvp](https://github.com/wu-cvgl/globustvp)|\n", "2505.04831": "|[steerable scene generation with post training and inference-time search](https://arxiv.org/abs/2505.04831)|[steerable-scene-generation](https://github.com/nepfaff/steerable-scene-generation)|\n", "2505.04835": "|[are synthetic corruptions a reliable proxy for real-world corruptions?](https://arxiv.org/abs/2505.04835)|[benchmarking_robustness](https://github.com/shashankskagnihotri/benchmarking_robustness)|\n", "2505.04899": "|[owt: a foundational organ-wise tokenization framework for medical imaging](https://arxiv.org/abs/2505.04899)|[OWT](https://github.com/SifanSong/OWT)|\n", "2505.04917": "|[a simple detector with frame dynamics is a strong tracker](https://arxiv.org/abs/2505.04917)|[A-Simple-Detector-is-a-Strong-Tracker](https://github.com/facias914/A-Simple-Detector-is-a-Strong-Tracker)|\n", "2505.04921": "|[perception, reason, think, and plan: a survey on large multimodal reasoning models](https://arxiv.org/abs/2505.04921)|[awesome-large-multimodal-reasoning-models](https://github.com/hitsz-tmg/awesome-large-multimodal-reasoning-models)|\n", "2505.04941": "|[building-guided pseudo-label learning for cross-modal building damage mapping](https://arxiv.org/abs/2505.04941)|[Building-Guided-Pseudo-Label-Learning-for-Cross-Modal-Building-Damage-Mapping](https://github.com/Henryjiepanli/Building-Guided-Pseudo-Label-Learning-for-Cross-Modal-Building-Damage-Mapping)|\n", "2505.05001": "|[stabstitch++: unsupervised online video stitching with spatiotemporal bidirectional warps](https://arxiv.org/abs/2505.05001)|[stabstitch2](https://github.com/nie-lang/stabstitch2)|\n", "2505.05004": "|[automated thoracolumbar stump rib detection and analysis in a large ct cohort](https://arxiv.org/abs/2505.05004)|[rib-segmentation](https://github.com/Hendrik-code/rib-segmentation)|\n", "2505.05022": "|[soap: style-omniscient animatable portraits](https://arxiv.org/abs/2505.05022)|[soap](https://github.com/tingtingliao/soap)|\n", "2505.05076": "|[the city that never settles: simulation-based lidar dataset for long-term place recognition under extreme structural changes](https://arxiv.org/abs/2505.05076)|[cns_dataset](https://github.com/hyunho111/cns_dataset)|\n", "2505.05091": "|[dispbench: benchmarking disparity estimation to synthetic corruptions](https://arxiv.org/abs/2505.05091)|[benchmarking_robustness](https://github.com/shashankskagnihotri/benchmarking_robustness)|\n", "2505.05163": "|[probabilistic embeddings for frozen vision-language models: uncertainty quantification with gaussian process latent variable models](https://arxiv.org/abs/2505.05163)|[GroVE](https://github.com/vaishwarya96/GroVE)|\n", "2505.05309": "|[augmented deep contexts for spatially embedded video coding](https://arxiv.org/abs/2505.05309)|[sevc](https://github.com/esakak/sevc)|\n", "2505.05343": "|[hearing and seeing through clip: a framework for self-supervised sound source localization](https://arxiv.org/abs/2505.05343)|[ACL-SSL](https://github.com/swimmiing/ACL-SSL)|\n", "2505.05422": "|[toklip: marry visual tokens to clip for multimodal comprehension and generation](https://arxiv.org/abs/2505.05422)|[toklip](https://github.com/tencentarc/toklip)|\n", "2505.05446": "|[adaptive markup language generation for contextually-grounded visual document understanding](https://arxiv.org/abs/2505.05446)|[DocMark](https://github.com/Euphoria16/DocMark)|\n", "2505.05469": "|[generating physically stable and buildable lego designs from text](https://arxiv.org/abs/2505.05469)|[LegoGPT](https://github.com/AvaLovelace1/LegoGPT)|\n", "2505.05474": "|[3d scene generation: a survey](https://arxiv.org/abs/2505.05474)|[awesome-3d-scene-generation](https://github.com/hzxie/awesome-3d-scene-generation)|\n", "2505.05475": "|[svad: from single image to 3d avatar via synthetic data generation with video diffusion and data augmentation](https://arxiv.org/abs/2505.05475)|[SVAD](https://github.com/yc4ny/SVAD)|\n"}, "2025-05-10": {}, "2025-05-11": {}, "2025-05-12": {"2203.01207": "|[container localisation and mass estimation with an rgb-d camera](https://arxiv.org/abs/2203.01207)|[visual](https://github.com/corsmal/visual)|\n", "2303.17051": "|[towards foundation models and few-shot parameter-efficient fine-tuning for volumetric organ segmentation](https://arxiv.org/abs/2303.17051)|[fewshot-finetuning](https://github.com/jusiro/fewshot-finetuning)|\n", "2306.14070": "|[superbench: a super-resolution benchmark dataset for scientific machine learning](https://arxiv.org/abs/2306.14070)|[superbench](https://github.com/erichson/superbench)|\n", "2308.11233": "|[affordance segmentation of hand-occluded containers from exocentric images](https://arxiv.org/abs/2308.11233)|[acanet](https://github.com/SEAlab-unige/acanet)|\n", "2312.09968": "|[human perception-inspired grain segmentation refinement using conditional random fields](https://arxiv.org/abs/2312.09968)|[hierarchicalcrf](https://github.com/dorukaksoy/hierarchicalcrf)|\n", "2312.12429": "|[the endoscapes dataset for surgical scene segmentation, object detection, and critical view of safety assessment: official splits and benchmark](https://arxiv.org/abs/2312.12429)|[endoscapes](https://github.com/camma-public/endoscapes)|\n", "2404.09957": "|[how to build the best medical image segmentation algorithm using foundation models: a comprehensive empirical study with segment anything model](https://arxiv.org/abs/2404.09957)|[finetune-sam](https://github.com/mazurowski-lab/finetune-sam)|\n", "2405.13637": "|[curriculum direct preference optimization for diffusion and consistency models](https://arxiv.org/abs/2405.13637)|[curriculum-dpo](https://github.com/croitorualin/curriculum-dpo)|\n", "2407.11243": "|[representation learning and identity adversarial training for facial behavior understanding](https://arxiv.org/abs/2407.11243)|[fmae-iat](https://github.com/forever208/fmae-iat)|\n", "2412.14123": "|[anysat: one earth observation model for many resolutions, scales, and modalities](https://arxiv.org/abs/2412.14123)|[anysat](https://github.com/gastruc/anysat)|\n", "2412.20002": "|[learning an adaptive and view-invariant vision transformer for real-time uav tracking](https://arxiv.org/abs/2412.20002)|[AVTrack](https://github.com/wuyou3474/AVTrack)|\n", "2501.02704": "|[persistence of backdoor-based watermarks for neural networks: a comprehensive evaluation](https://arxiv.org/abs/2501.02704)|[dnn-watermark-persistence](https://github.com/anhtu96/dnn-watermark-persistence)|\n", "2501.03525": "|[texhoi: reconstructing textures of 3d unknown objects in monocular hand-object interaction scenes](https://arxiv.org/abs/2501.03525)|[texhoi](https://github.com/alakhag/texhoi)|\n", "2502.04521": "|[generative autoregressive transformers for model-agnostic federated mri reconstruction](https://arxiv.org/abs/2502.04521)|[FedGAT](https://github.com/icon-lab/FedGAT)|\n", "2502.06380": "|[structure-preserving contrastive learning for spatial time series](https://arxiv.org/abs/2502.06380)|[spclt](https://github.com/Yiru-Jiao/spclt)|\n", "2503.24166": "|[foundation models for seismic data processing: an extensive review](https://arxiv.org/abs/2503.24166)|[foundation-models-seismic-processing](https://codeberg.org/fuchsfa/foundation-models-seismic-processing)|\n", "2504.06751": "|[visualization of a multidimensional point cloud as a 3d swarm of avatars](https://arxiv.org/abs/2504.06751)|[n-dim-view](https://github.com/iitis/n-dim-view)|\n", "2504.08049": "|[patch distribution modeling framework adaptive cosine estimator (padim-ace) for anomaly detection and localization in synthetic aperture radar imagery](https://arxiv.org/abs/2504.08049)|[padim-ace](https://github.com/advanced-vision-and-learning-lab/padim-ace)|\n", "2505.02539": "|[marker-based extrinsic calibration method for accurate multi-camera 3d reconstruction](https://arxiv.org/abs/2505.02539)|[CalibMarker](https://github.com/Tech4DLab/CalibMarker)|\n", "2505.02835": "|[r1-reward: training multimodal reward model through stable reinforcement learning](https://arxiv.org/abs/2505.02835)|[r1_reward](https://github.com/yfzhang114/r1_reward)|\n", "2505.05049": "|[uncertainsam: fast and efficient uncertainty quantification of the segment anything model](https://arxiv.org/abs/2505.05049)|[UncertainSAM](https://github.com/GreenAutoML4FAS/UncertainSAM)|\n", "2505.05375": "|[threshold modulation for online test-time adaptation of spiking neural networks](https://arxiv.org/abs/2505.05375)|[tm-otta-snn](https://github.com/nneurotransmitterr/tm-otta-snn)|\n", "2505.05504": "|[image restoration via multi-domain learning](https://arxiv.org/abs/2505.05504)|[swformer](https://github.com/deng-ai-lab/swformer)|\n", "2505.05505": "|[apply hierarchical-chain-of-generation to complex attributes text-to-3d generation](https://arxiv.org/abs/2505.05505)|[gascol](https://github.com/wakals/gascol)|\n", "2505.05510": "|[how to train your metamorphic deep neural network](https://arxiv.org/abs/2505.05510)|[htty_neumeta](https://github.com/tsommariva/htty_neumeta)|\n", "2505.05528": "|[x-transfer attacks: towards super transferable adversarial attacks on clip](https://arxiv.org/abs/2505.05528)|[XTransferBench](https://github.com/HanxunH/XTransferBench)|\n", "2505.05599": "|[enhancing satellite object localization with dilated convolutions and attention-aided spatial pooling](https://arxiv.org/abs/2505.05599)|[satellite-object-localization](https://github.com/ai-4-atmosphere-remote-sensing/satellite-object-localization)|\n", "2505.05621": "|[a preliminary study for gpt-4o on image restoration](https://arxiv.org/abs/2505.05621)|[gpt_restoration](https://github.com/noxsine/gpt_restoration)|\n", "2505.05657": "|[unsupervised blind speech separation with a diffusion prior](https://arxiv.org/abs/2505.05657)|[arraydps](https://github.com/arraydps/arraydps)|\n", "2505.05659": "|[v-efficientnets: vector-valued efficiently scaled convolutional neural network models](https://arxiv.org/abs/2505.05659)|[v-nets](https://github.com/mevalle/v-nets)|\n", "2505.05689": "|[equivariant imaging biomarkers for robust unsupervised segmentation of histopathology](https://arxiv.org/abs/2505.05689)|[sre_unsupervised_segm](https://github.com/fyc423/sre_unsupervised_segm)|\n", "2505.05711": "|[digit: multi-dilated gated encoder and central-adjacent region integrated decoder for temporal action detection transformer](https://arxiv.org/abs/2505.05711)|[digit](https://github.com/dotori-hj/digit)|\n", "2505.05736": "|[multimodal integrated knowledge transfer to large language models through preference optimization with biomedical applications](https://arxiv.org/abs/2505.05736)|[mint-llm](https://github.com/wglab/mint-llm)|\n", "2505.05752": "|[automating infrastructure surveying: a framework for geometric measurements and compliance assessment using point cloud data](https://arxiv.org/abs/2505.05752)|[surveyautomation](https://github.com/soltanilara/surveyautomation)|\n", "2505.05812": "|[towards order of magnitude x-ray dose reduction in breast cancer imaging using phase contrast and deep denoising](https://arxiv.org/abs/2505.05812)|[quell](https://github.com/quell-devs/quell)|\n", "2505.05829": "|[accelerating diffusion transformer via increment-calibrated caching with channel-aware singular value decomposition](https://arxiv.org/abs/2505.05829)|[icc](https://github.com/ccccczzy/icc)|\n", "2505.05834": "|[dual-level fuzzy learning with patch guidance for image ordinal regression](https://arxiv.org/abs/2505.05834)|[dfpg-ord](https://github.com/zjumai/dfpg-ord)|\n", "2505.05895": "|[leveraging vision-language models for visual grounding and analysis of automotive ui](https://arxiv.org/abs/2505.05895)|[ELAM-7B](https://huggingface.co/sparks-solutions/ELAM-7B)|\n", "2505.05913": "|[dfen: dual feature equalization network for medical image segmentation](https://arxiv.org/abs/2505.05913)|[dfen](https://github.com/jianjianyin/dfen)|\n", "2505.05936": "|[cgtrack: cascade gating network with hierarchical feature aggregation for uav tracking](https://arxiv.org/abs/2505.05936)|[cgtrack](https://github.com/nightwatch-fox11/cgtrack)|\n", "2505.06002": "|[task-adapter++: task-specific adaptation with order-aware alignment for few-shot action recognition](https://arxiv.org/abs/2505.06002)|[task-adapter-pp](https://github.com/jaulin-bage/task-adapter-pp)|\n", "2505.06003": "|[from pixels to perception: interpretable predictions via instance-wise grouped feature selection](https://arxiv.org/abs/2505.06003)|[p2p](https://github.com/mvandenhi/p2p)|\n", "2505.06030": "|[why are you wrong? counterfactual explanations for language grounding with 3d objects](https://arxiv.org/abs/2505.06030)|[why-are-you-wrong](https://github.com/toprei/why-are-you-wrong)|\n", "2505.06064": "|[context informed incremental learning improves myoelectric control performance in virtual reality object manipulation tasks](https://arxiv.org/abs/2505.06064)|[ciil-emg-vr](https://github.com/biomedicalits/ciil-emg-vr)|\n", "2505.06068": "|[noise-consistent siamese-diffusion for medical image synthesis and segmentation](https://arxiv.org/abs/2505.06068)|[siamese-diffusion](https://github.com/qiukunpeng/siamese-diffusion)|\n", "2505.06107": "|[differentiating emigration from return migration of scholars using name-based nationality detection models](https://arxiv.org/abs/2505.06107)|[NameBasedNationalityDetection](https://github.com/FaezeGhorbanpour/NameBasedNationalityDetection)|\n", "2505.06120": "|[llms get lost in multi-turn conversation](https://arxiv.org/abs/2505.06120)|[lost_in_conversation](https://github.com/microsoft/lost_in_conversation)|\n", "2505.06134": "|[realistic adversarial attacks for robustness evaluation of trajectory prediction models via future state perturbation](https://arxiv.org/abs/2505.06134)|[general-framework-update-adversarial-jeroen](https://github.com/jhagenus/general-framework-update-adversarial-jeroen)|\n", "2505.06152": "|[mm-skin: enhancing dermatology vision-language model with an image-text dataset derived from textbooks](https://arxiv.org/abs/2505.06152)|[mm-skin](https://github.com/zwq803/mm-skin)|\n"}, "2025-05-13": {"2312.14999": "|[leveraging habitat information for fine-grained bird identification](https://arxiv.org/abs/2312.14999)|[reasoning](https://github.com/ngthanhtin/reasoning)|\n", "2403.05581": "|[can interpretability layouts influence human perception of offensive sentences?](https://arxiv.org/abs/2403.05581)|[user_study](https://bitbucket.org/thiago-phd/user_study)|\n", "2405.06198": "|[mapl: memory augmentation and pseudo-labeling for semi-supervised anomaly detection](https://arxiv.org/abs/2405.06198)|[mapl](https://github.com/jzc777/mapl)|\n", "2405.17456": "|[generalized compressed sensing for image reconstruction with diffusion probabilistic models](https://arxiv.org/abs/2405.17456)|[optimal-measurement](https://github.com/lingqiz/optimal-measurement)|\n", "2407.01330": "|[a lightweight udf learning framework for 3d reconstruction based on local shape functions](https://arxiv.org/abs/2407.01330)|[LoSF](https://github.com/jbHu67/LoSF)|\n", "2407.13120": "|[hppp: halpern-type preconditioned proximal point algorithms and applications to image restoration](https://arxiv.org/abs/2407.13120)|[HPPP](https://github.com/zsc15/HPPP)|\n", "2408.10919": "|[crossfi: a cross domain wi-fi sensing framework based on siamese network](https://arxiv.org/abs/2408.10919)|[CrossFi](https://github.com/RS2002/CrossFi)|\n", "2409.00638": "|[igev++: iterative multi-range geometry encoding volumes for stereo matching](https://arxiv.org/abs/2409.00638)|[igev](https://github.com/gangweix/igev)|\n", "2409.02426": "|[diffusion models learn low-dimensional distributions via subspace clustering](https://arxiv.org/abs/2409.02426)|[Diffusion-Model-Generalizability](https://github.com/huijieZH/Diffusion-Model-Generalizability)|\n", "2409.18653": "|[when sam2 meets video camouflaged object segmentation: a comprehensive evaluation and adaptation](https://arxiv.org/abs/2409.18653)|[sam2-vcos](https://github.com/zhoustan/sam2-vcos)|\n", "2410.03311": "|[scaling large motion models with million-level human motions](https://arxiv.org/abs/2410.03311)|[being-m0](https://github.com/beingbeyond/being-m0)|\n", "2411.11904": "|[geoground: a unified large vision-language model for remote sensing visual grounding](https://arxiv.org/abs/2411.11904)|[geoground](https://github.com/zytx121/geoground)|\n", "2412.01818": "|[beyond text-visual attention: exploiting visual cues for effective token pruning in vlms](https://arxiv.org/abs/2412.01818)|[fastervlm](https://github.com/theia-4869/fastervlm)|\n", "2501.00843": "|[fusionsort: fusion methods for online multi-object visual tracking](https://arxiv.org/abs/2501.00843)|[FusionSORT](https://github.com/nathanlem1/FusionSORT)|\n", "2501.16003": "|[improving tropical cyclone forecasting with video diffusion models](https://arxiv.org/abs/2501.16003)|[forecast-video-diffmodels](https://github.com/ren-creater/forecast-video-diffmodels)|\n", "2502.12110": "|[a-mem: agentic memory for llm agents](https://arxiv.org/abs/2502.12110)|[a-mem](https://github.com/agiresearch/a-mem)|\n", "2502.14908": "|[segsub: evaluating robustness to knowledge conflicts and hallucinations in vision-language models](https://arxiv.org/abs/2502.14908)|[SegSub](https://github.com/CASOS-IDeaS-CMU/SegSub)|\n", "2503.01103": "|[direct discriminative optimization: your likelihood-based visual generative model is secretly a gan discriminator](https://arxiv.org/abs/2503.01103)|[ddo](https://github.com/nvlabs/ddo)|\n", "2503.04318": "|[infl-ux: a toolkit for web-based interactive federated learning](https://arxiv.org/abs/2503.04318)|[interactive-fl-poc](https://github.com/tmaurer42/interactive-fl-poc)|\n", "2503.08507": "|[referring to any person](https://arxiv.org/abs/2503.08507)|[rexseek](https://github.com/idea-research/rexseek)|\n", "2503.15970": "|[v-naw: video-based noise-aware adaptive weighting for facial expression recognition](https://arxiv.org/abs/2503.15970)|[V-NAW](https://github.com/jungyu0413/V-NAW)|\n", "2503.16188": "|[think or not think: a study of explicit thinking in rule-based visual reinforcement fine-tuning](https://arxiv.org/abs/2503.16188)|[CLS-RL](https://github.com/minglllli/CLS-RL)|\n", "2504.11416": "|[deep learning-based bathymetry retrieval without in-situ depths using remote sensing imagery and sfm-mvs dsms with data gaps](https://arxiv.org/abs/2504.11416)|[swin-bathyunet](https://github.com/pagraf/swin-bathyunet)|\n", "2504.12157": "|[focusedad: character-centric movie audio description](https://arxiv.org/abs/2504.12157)|[focusedad](https://github.com/thorin215/focusedad)|\n", "2504.13617": "|[compile scene graphs with reinforcement learning](https://arxiv.org/abs/2504.13617)|[r1-sgg](https://github.com/gpt4vision/r1-sgg)|\n", "2504.14906": "|[omniaudio: generating spatial audio from 360-degree video](https://arxiv.org/abs/2504.14906)|[omniaudio](https://github.com/liuhuadai/omniaudio)|\n", "2504.17522": "|[tablecenternet: a one-stage network for table structure recognition](https://arxiv.org/abs/2504.17522)|[tablecenternet](https://github.com/dreamy-xay/tablecenternet)|\n", "2504.21497": "|[magicportrait: temporally consistent face reenactment with 3d geometric guidance](https://arxiv.org/abs/2504.21497)|[magicportrait](https://github.com/weimengting/magicportrait)|\n", "2505.02350": "|[sparse ellipsoidal radial basis function network for point cloud surface representation](https://arxiv.org/abs/2505.02350)|[se-rbfnet](https://github.com/lianbobo/se-rbfnet)|\n", "2505.05007": "|[driving with context: online map matching for complex roads using lane markings and scenario recognition](https://arxiv.org/abs/2505.05007)|[lmsr-omm](https://github.com/trv-lab/lmsr-omm)|\n", "2505.05470": "|[flow-grpo: training flow matching models via online rl](https://arxiv.org/abs/2505.05470)|[flow_grpo](https://github.com/yifan123/flow_grpo)|\n", "2505.05573": "|[prompt to polyp: medical text-conditioned image synthesis with diffusion models](https://arxiv.org/abs/2505.05573)|[imageclefmed-medvqa-gi-2024-mmcp-team](https://github.com/thundercondor/imageclefmed-medvqa-gi-2024-mmcp-team)|\n", "2505.06393": "|[toward advancing license plate super-resolution in real-world scenarios: a dataset and benchmark](https://arxiv.org/abs/2505.06393)|[lpsrgan](https://github.com/valfride/lpsrgan)|\n", "2505.06428": "|[what do people want to know about artificial intelligence (ai)? the importance of answering end-user questions to explain autonomous vehicle (av) decisions](https://arxiv.org/abs/2505.06428)|[conversationalXAV](https://github.com/comp-hci-lab/conversationalXAV)|\n", "2505.06469": "|[kcluster: an llm-based clustering approach to knowledge component discovery](https://arxiv.org/abs/2505.06469)|[KCluster](https://github.com/weiyumou/KCluster)|\n", "2505.06507": "|[text-to-cadquery: a new paradigm for cad generation with scalable large model capabilities](https://arxiv.org/abs/2505.06507)|[text-to-cadquery](https://github.com/text-to-cadquery/text-to-cadquery)|\n", "2505.06517": "|[edge-enabled vio with long-tracked features for high-accuracy low-altitude iot navigation](https://arxiv.org/abs/2505.06517)|[FLOW-VIO](https://github.com/xiaohong-huang/FLOW-VIO)|\n", "2505.06527": "|[improving generalization of medical image registration foundation model](https://arxiv.org/abs/2505.06527)|[fm_sam](https://github.com/promise13/fm_sam)|\n", "2505.06536": "|[tacfn: transformer-based adaptive cross-modal fusion network for multimodal emotion recognition](https://arxiv.org/abs/2505.06536)|[tacfn](https://github.com/shuzihuaiyu/tacfn)|\n", "2505.06578": "|[compact and efficient neural networks for image recognition based on learned 2d separable transform](https://arxiv.org/abs/2505.06578)|[lst-2d](https://github.com/mak-sim/lst-2d)|\n", "2505.06592": "|[batch augmentation with unimodal fine-tuning for multimodal learning](https://arxiv.org/abs/2505.06592)|[multimodal](https://github.com/dipuk0506/multimodal)|\n", "2505.06646": "|[reproducing and improving chexnet: deep learning for chest x-ray disease classification](https://arxiv.org/abs/2505.06646)|[Deep-Learning-Project](https://github.com/dstrick17/Deep-Learning-Project)|\n", "2505.06663": "|[metor: a unified framework for mutual enhancement of objects and relationships in open-vocabulary video visual relationship detection](https://arxiv.org/abs/2505.06663)|[METOR](https://github.com/wangyongqi558/METOR)|\n", "2505.06684": "|[fnbench: benchmarking robust federated learning against noisy labels](https://arxiv.org/abs/2505.06684)|[fnbench](https://github.com/sprinter1999/fnbench)|\n", "2505.06702": "|[do language model agents align with humans in rating visualizations? an empirical study](https://arxiv.org/abs/2505.06702)|[Agents-Ratings-in-VIS-Experiments](https://github.com/ZekaiShao25/Agents-Ratings-in-VIS-Experiments)|\n", "2505.06796": "|[multimodal fake news detection: mfnd dataset and shallow-deep multitask learning](https://arxiv.org/abs/2505.06796)|[sdml](https://github.com/yunan-wang33/sdml)|\n", "2505.06934": "|[whitened clip as a likelihood surrogate of images and captions](https://arxiv.org/abs/2505.06934)|[W_CLIP](https://github.com/rbetser/W_CLIP)|\n", "2505.06937": "|[transformer-based dual-optical attention fusion crowd head point counting and localization network](https://arxiv.org/abs/2505.06937)|[tapnet](https://github.com/zz-zik/tapnet)|\n", "2505.06948": "|[unsupervised learning for class distribution mismatch](https://arxiv.org/abs/2505.06948)|[research](https://github.com/ruc-dwbi-ml/research)|\n", "2505.06975": "|[high-frequency prior-driven adaptive masking for accelerating image super-resolution](https://arxiv.org/abs/2505.06975)|[amsr](https://github.com/shangwei5/amsr)|\n", "2505.07001": "|[hallucination-aware multimodal benchmark for gastrointestinal image analysis with large vision-language models](https://arxiv.org/abs/2505.07001)|[hallucination-aware-vlm](https://github.com/bhattarailab/hallucination-aware-vlm)|\n", "2505.07007": "|[mellm: exploring llm-powered micro-expression understanding enhanced by subtle motion perception](https://arxiv.org/abs/2505.07007)|[mellm](https://github.com/zyzhangustc/mellm)|\n", "2505.07019": "|[a vision-language foundation model for leaf disease identification](https://arxiv.org/abs/2505.07019)|[scold](https://huggingface.co/enalis/scold)|\n", "2505.07071": "|[semantic-guided diffusion model for single-step image super-resolution](https://arxiv.org/abs/2505.07071)|[samsr](https://github.com/liu-zihang/samsr)|\n", "2505.07159": "|[skull stripping with purely synthetic data](https://arxiv.org/abs/2505.07159)|[PUMBA](https://github.com/pjsjongsung/PUMBA)|\n", "2505.07161": "|[towards actionable pedagogical feedback: a multi-perspective analysis of mathematics teaching and tutoring dialogue](https://arxiv.org/abs/2505.07161)|[speak-turn-emb-dialog-act-clf](https://github.com/zihaohe123/speak-turn-emb-dialog-act-clf)|\n", "2505.07164": "|[emovlm-kd: fusing distilled expertise with vision-language models for visual emotion analysis](https://arxiv.org/abs/2505.07164)|[emovlm-kd](https://github.com/sange1104/emovlm-kd)|\n", "2505.07175": "|[metrics that matter: evaluating image quality metrics for medical image generation](https://arxiv.org/abs/2505.07175)|[GenMed](https://github.com/YashDeo-York/GenMed)|\n", "2505.07219": "|[language-driven dual style mixing for single-domain generalized object detection](https://arxiv.org/abs/2505.07219)|[ldds](https://github.com/qinhongda8/ldds)|\n", "2505.07340": "|[thalamus: a user simulation toolkit for prototyping multimodal sensing studies](https://arxiv.org/abs/2505.07340)|[Thalamus](https://github.com/kayhan-latifzadeh/Thalamus)|\n", "2505.07375": "|[boosting global-local feature matching via anomaly synthesis for multi-class point cloud anomaly detection](https://arxiv.org/abs/2505.07375)|[GLFM-Multi-class-3DAD](https://github.com/hustCYQ/GLFM-Multi-class-3DAD)|\n", "2505.07387": "|[feature visualization in 3d convolutional neural networks](https://arxiv.org/abs/2505.07387)|[3dkernelvisualizer](https://github.com/yatanglilab/3dkernelvisualizer)|\n", "2505.07447": "|[unified continuous generative models](https://arxiv.org/abs/2505.07447)|[UCGM](https://github.com/LINs-Lab/UCGM)|\n", "2505.07477": "|[you only look one step: accelerating backpropagation in diffusion sampling with gradient shortcuts](https://arxiv.org/abs/2505.07477)|[sdo](https://github.com/deng-ai-lab/sdo)|\n", "2505.07496": "|[docvxqa: context-aware visual explanations for document question answering](https://arxiv.org/abs/2505.07496)|[docvxqa](https://github.com/dali92002/docvxqa)|\n", "2505.07689": "|[anatomical attention alignment representation for radiology report generation](https://arxiv.org/abs/2505.07689)|[a3net](https://github.com/vinh-ai/a3net)|\n", "2505.07812": "|[continuous visual autoregressive generation via score maximization](https://arxiv.org/abs/2505.07812)|[ear](https://github.com/shaochenze/ear)|\n"}, "2025-05-14": {"1907.01131": "|[learnable gated temporal shift module for deep video inpainting](https://arxiv.org/abs/1907.01131)|[Free-Form-Video-Inpainting](https://github.com/amjltc295/Free-Form-Video-Inpainting)|\n", "2307.05033": "|[towards anytime optical flow estimation with event cameras](https://arxiv.org/abs/2307.05033)|[eva-flow](https://github.com/yaozhuwa/eva-flow)|\n", "2308.13174": "|[deep learning-based interactive segmentation in remote sensing](https://arxiv.org/abs/2308.13174)|[segmap-qgis](https://github.com/titorx/segmap-qgis)|\n", "2310.00868": "|[rt-gan: recurrent temporal gan for adding lightweight temporal consistency to frame-based domain translation approaches](https://arxiv.org/abs/2310.00868)|[CEP](https://github.com/nadeemlab/CEP)|\n", "2312.06198": "|[optimized view and geometry distillation from multi-view diffuser](https://arxiv.org/abs/2312.06198)|[USD](https://github.com/YoujiaZhang/USD)|\n", "2401.12133": "|[vrmn-bd: a multi-modal natural behavior dataset of immersive human fear responses in vr stand-up interactive games](https://arxiv.org/abs/2401.12133)|[vrmn-bd](https://github.com/kindopstar/vrmn-bd)|\n", "2404.11824": "|[textcengen: attention-guided text-centric background adaptation for text-to-image generation](https://arxiv.org/abs/2404.11824)|[textcengen_background_adapt](https://github.com/tianyilt/textcengen_background_adapt)|\n", "2407.11802": "|[discriminative and consistent representation distillation](https://arxiv.org/abs/2407.11802)|[distillers](https://github.com/giakoumoglou/distillers)|\n", "2407.12073": "|[relational representation distillation](https://arxiv.org/abs/2407.12073)|[distillers](https://github.com/giakoumoglou/distillers)|\n", "2408.09030": "|[studying the effects of collaboration in interactive theme discovery systems](https://arxiv.org/abs/2408.09030)|[interactive-systems](https://github.com/blast-cu/interactive-systems)|\n", "2410.01723": "|[harmonica: harmonizing training and inference for better feature caching in diffusion transformer acceleration](https://arxiv.org/abs/2410.01723)|[harmonica](https://github.com/modeltc/harmonica)|\n", "2410.02240": "|[sca: improve semantic consistent in unrestricted adversarial attacks via ddpm inversion](https://arxiv.org/abs/2410.02240)|[sca](https://github.com/pan-zihao/sca)|\n", "2410.13757": "|[moba: multifaceted memory-enhanced adaptive planning for efficient mobile task automation](https://arxiv.org/abs/2410.13757)|[MobA](https://github.com/OpenDFM/MobA)|\n", "2411.18145": "|[choice: benchmarking the remote sensing capabilities of large vision-language models](https://arxiv.org/abs/2411.18145)|[choice](https://github.com/shawnan-whu/choice)|\n", "2412.06488": "|[enhancing scene coordinate regression with efficient keypoint detection and sequential information](https://arxiv.org/abs/2412.06488)|[SeqACE](https://github.com/sair-lab/SeqACE)|\n", "2412.10255": "|[anisora: exploring the frontiers of animation video generation in the sora era](https://arxiv.org/abs/2412.10255)|[index-anisora](https://github.com/bilibili/index-anisora)|\n", "2501.00958": "|[2.5 years in class: a multimodal textbook for vision-language pretraining](https://arxiv.org/abs/2501.00958)|[multimodal_textbook](https://github.com/damo-nlp-sg/multimodal_textbook)|\n", "2501.01645": "|[hlv-1k: a large-scale hour-long video benchmark for time-specific long video understanding](https://arxiv.org/abs/2501.01645)|[hlv-1k](https://github.com/vincent-zhq/hlv-1k)|\n", "2501.05014": "|[uav-vla: vision-language-action system for large scale aerial mission generation](https://arxiv.org/abs/2501.05014)|[uav-vla](https://github.com/sautenich/uav-vla)|\n", "2502.02283": "|[gp-gs: gaussian processes for enhanced gaussian splatting](https://arxiv.org/abs/2502.02283)|[GPGS](https://github.com/zhihaohaoran/GPGS)|\n", "2502.13818": "|[building age estimation: a new multi-modal benchmark dataset and community challenge](https://arxiv.org/abs/2502.13818)|[ai4eo_map_your_city](https://github.com/xmba15/ai4eo_map_your_city)|\n", "2503.01739": "|[videoufo: a million-scale user-focused dataset for text-to-video generation](https://arxiv.org/abs/2503.01739)|[benchufo](https://github.com/wangwenhao0716/benchufo)|\n", "2503.04325": "|[gbt-sam: adapting a foundational deep learning model for generalizable brain tumor segmentation via efficient integration of multi-parametric mri data](https://arxiv.org/abs/2503.04325)|[med-sam-brain](https://github.com/vpulab/med-sam-brain)|\n", "2503.09040": "|[motion blender gaussian splatting for dynamic scene reconstruction](https://arxiv.org/abs/2503.09040)|[motion-blender-gs](https://github.com/mlzxy/motion-blender-gs)|\n", "2503.10156": "|[automatic quality control in multi-centric fetal brain mri super-resolution reconstruction](https://arxiv.org/abs/2503.10156)|[fetmrqc_sr](https://github.com/medical-image-analysis-laboratory/fetmrqc_sr)|\n", "2504.02697": "|[learning phase distortion with selective state space models for video turbulence mitigation](https://arxiv.org/abs/2504.02697)|[mambatm](https://github.com/xg416/mambatm)|\n", "2504.17696": "|[hierarchical and multimodal data for daily activity understanding](https://arxiv.org/abs/2504.17696)|[DARai](https://github.com/olivesgatech/DARai)|\n", "2504.21435": "|[seriesbench: a benchmark for narrative-driven drama series understanding](https://arxiv.org/abs/2504.21435)|[seriesbench-cvpr2025](https://github.com/zackhxn/seriesbench-cvpr2025)|\n", "2504.21650": "|[holotime: taming video diffusion models for panoramic 4d scene generation](https://arxiv.org/abs/2504.21650)|[holotime](https://github.com/pku-yuangroup/holotime)|\n", "2505.05071": "|[fg-clip: fine-grained visual and textual alignment](https://arxiv.org/abs/2505.05071)|[fg-clip](https://github.com/360cvgroup/fg-clip)|\n", "2505.07530": "|[fluxsynid: a framework for identity-controlled synthetic face generation with document and live images](https://arxiv.org/abs/2505.07530)|[FLUXSynID](https://github.com/Raul2718/FLUXSynID)|\n", "2505.08031": "|[measuring and predicting variation in the difficulty of questions about data visualizations](https://arxiv.org/abs/2505.08031)|[viz_item_measures_cogsci2025](https://github.com/cogtoolslab/viz_item_measures_cogsci2025)|\n", "2505.08101": "|[topology-guided knowledge distillation for efficient point cloud processing](https://arxiv.org/abs/2505.08101)|[pointdistill](https://github.com/hysonlab/pointdistill)|\n", "2505.08117": "|[now you see it, now you don't: damage label agreement in drone & satellite post-disaster imagery](https://arxiv.org/abs/2505.08117)|[NowYouSeeItNowYouDont](https://github.com/TManzini/NowYouSeeItNowYouDont)|\n", "2505.08126": "|[asynchronous multi-object tracking with an event camera](https://arxiv.org/abs/2505.08126)|[AEMOT](https://github.com/angus-apps/AEMOT)|\n", "2505.08137": "|[large language models for computer-aided design: a survey](https://arxiv.org/abs/2505.08137)|[llms-cad-survey-taxonomy](https://github.com/lichengzhanguom/llms-cad-survey-taxonomy)|\n", "2505.08190": "|[unsupervised raindrop removal from a single image using conditional diffusion models](https://arxiv.org/abs/2505.08190)|[DropWiper](https://github.com/lhfazry/DropWiper)|\n", "2505.08196": "|[adc-gs: anchor-driven deformable and compressed gaussian splatting for dynamic scene reconstruction](https://arxiv.org/abs/2505.08196)|[adc-gs](https://github.com/h-huang774/adc-gs)|\n", "2505.08231": "|[hmpnet: a feature aggregation architecture for maritime object detection from a shipborne perspective](https://arxiv.org/abs/2505.08231)|[hmpnet](https://github.com/tustailab/hmpnet)|\n", "2505.08234": "|[removing watermarks with partial regeneration using semantic information](https://arxiv.org/abs/2505.08234)|[semanticregen](https://github.com/krtit/semanticregen)|\n", "2505.08245": "|[large language model psychometrics: a systematic review of evaluation, validation, and enhancement](https://arxiv.org/abs/2505.08245)|[awesome-llm-psychometrics](https://github.com/valuebyte-ai/awesome-llm-psychometrics)|\n", "2505.08246": "|[identifying memorization of diffusion models through p-laplace analysis](https://arxiv.org/abs/2505.08246)|[identifying-memorization-of-diffusion-models-through-p-laplace-analysis](https://github.com/jonathanbrok/identifying-memorization-of-diffusion-models-through-p-laplace-analysis)|\n", "2505.08247": "|[skeleton-guided diffusion model for accurate foot x-ray synthesis in hallux valgus diagnosis](https://arxiv.org/abs/2505.08247)|[sccdm](https://github.com/midisec/sccdm)|\n", "2505.08260": "|[few-shot novel category discovery](https://arxiv.org/abs/2505.08260)|[fsncd](https://github.com/ashengl/fsncd)|\n", "2505.08273": "|[irrmap: a large-scale comprehensive dataset for irrigation method mapping](https://arxiv.org/abs/2505.08273)|[irrmap](https://github.com/nibir088/irrmap)|\n", "2505.08316": "|[improving unsupervised task-driven models of ventral visual stream via relative position predictivity](https://arxiv.org/abs/2505.08316)|[unsup-vvs](https://github.com/rdz98/unsup-vvs)|\n", "2505.08437": "|[tt-df: a large-scale diffusion-based dataset and benchmark for human body forgery detection](https://arxiv.org/abs/2505.08437)|[tt-df](https://github.com/hashtag00002/tt-df)|\n", "2505.08455": "|[vcrbench: exploring long-form causal reasoning capabilities of large video language models](https://arxiv.org/abs/2505.08455)|[vcrbench](https://github.com/pritamqu/vcrbench)|\n", "2505.08468": "|[judging the judges: can large vision-language models fairly evaluate chart comprehension and reasoning?](https://arxiv.org/abs/2505.08468)|[chart_lvlm_judge](https://github.com/tahmedge/chart_lvlm_judge)|\n", "2505.08581": "|[resurgsam2: referring segment anything in surgical video via credible long-term tracking](https://arxiv.org/abs/2505.08581)|[resurgsam2](https://github.com/jinlab-imvr/resurgsam2)|\n", "2505.08601": "|[rejoining fragmented ancient bamboo slips with physics-driven deep learning](https://arxiv.org/abs/2505.08601)|[wisepanda](https://github.com/zhujinchi/wisepanda)|\n", "2505.08604": "|[unsupervised out-of-distribution detection in medical imaging using multi-exit class activation maps and feature masking](https://arxiv.org/abs/2505.08604)|[mecam-ood](https://github.com/windstormer/mecam-ood)|\n", "2505.08617": "|[openthinkimg: learning to think with images via visual tool reinforcement learning](https://arxiv.org/abs/2505.08617)|[openthinkimg](https://github.com/zhaochen0110/openthinkimg)|\n", "2505.08723": "|[timo: spatiotemporal foundation model for satellite image time series](https://arxiv.org/abs/2505.08723)|[timo](https://github.com/mililab/timo)|\n", "2505.08725": "|[extending large vision-language model for diverse interactive tasks in autonomous driving](https://arxiv.org/abs/2505.08725)|[drivemonkey](https://github.com/zc-zhao/drivemonkey)|\n"}, "2025-05-15": {"2207.14425": "|[3d cartoon face generation with controllable expressions from a single gan image](https://arxiv.org/abs/2207.14425)|[3D-Cartoon-Face-Generation](https://github.com/hwang1996/3D-Cartoon-Face-Generation)|\n", "2305.10947": "|[revisiting 16-bit neural network training: a practical approach for resource-limited learning](https://arxiv.org/abs/2305.10947)|[standalone_16bits_nn](https://github.com/yunblak/standalone_16bits_nn)|\n", "2306.14725": "|[error correcting 2d-3d cascaded network for myocardial infarct scar segmentation on late gadolinium enhancement cardiac magnetic resonance images](https://arxiv.org/abs/2306.14725)|[ecorc](https://github.com/matthi99/ecorc)|\n", "2312.15686": "|[pulaski: learning inter-rater variability using statistical distances to improve probabilistic segmentation](https://arxiv.org/abs/2312.15686)|[pulaski](https://github.com/soumickmj/pulaski)|\n", "2401.07378": "|[efficient approximation of earth mover's distance based on nearest neighbor search](https://arxiv.org/abs/2401.07378)|[nns-emd](https://github.com/gm3g11/nns-emd)|\n", "2402.00045": "|[detecting multimedia generated by large ai models: a survey](https://arxiv.org/abs/2402.00045)|[detect-laim-generated-multimedia-survey](https://github.com/purdue-m2/detect-laim-generated-multimedia-survey)|\n", "2407.19708": "|[alen: a dual-approach for uniform and non-uniform low-light image enhancement](https://arxiv.org/abs/2407.19708)|[alen](https://github.com/xingyumex/alen)|\n", "2408.08070": "|[mambamim: pre-training mamba with state space token interpolation and its application to medical image segmentation](https://arxiv.org/abs/2408.08070)|[mambamim](https://github.com/fenghetan9/mambamim)|\n", "2409.02562": "|[one homography is all you need: imm-based joint homography and multiple object state estimation](https://arxiv.org/abs/2409.02562)|[imm-jhse](https://github.com/Paulkie99/imm-jhse)|\n", "2409.15511": "|[bayesian computation with generative diffusion models by multilevel monte carlo](https://arxiv.org/abs/2409.15511)|[mlmcfordms](https://github.com/lshaw8317/mlmcfordms)|\n", "2409.18769": "|[state-of-the-art periorbital distance prediction and disease classification using periorbital features](https://arxiv.org/abs/2409.18769)|[periorbital_package](https://github.com/monkeygobah/periorbital_package)|\n", "2409.18872": "|[simulating dynamic tumor contrast enhancement in breast mri using conditional generative adversarial networks](https://arxiv.org/abs/2409.18872)|[SimulatingDCE](https://github.com/RichardObi/SimulatingDCE)|\n", "2410.07795": "|[optimal-state dynamics estimation for physics-based human motion capture from videos](https://arxiv.org/abs/2410.07795)|[osdcap](https://github.com/cuongle1206/osdcap)|\n", "2410.23854": "|[reflecting topology consistency and abnormality via learnable attentions for airway labeling](https://arxiv.org/abs/2410.23854)|[reflecting-topology-consistency-and-abnormality-via-learnable-attentions](https://github.com/endoluminalsurgicalvision-imr/reflecting-topology-consistency-and-abnormality-via-learnable-attentions)|\n", "2412.05888": "|[mcp-medsam: a powerful lightweight medical segment anything model trained with a single gpu in just one day](https://arxiv.org/abs/2412.05888)|[mcp-medsam](https://github.com/dong845/mcp-medsam)|\n", "2502.07409": "|[mgpath: vision-language model with multi-granular prompt learning for few-shot wsi classification](https://arxiv.org/abs/2502.07409)|[MGPATH](https://github.com/HauschildLab/MGPATH)|\n", "2503.18938": "|[adaworld: learning adaptable world models with latent actions](https://arxiv.org/abs/2503.18938)|[adaworld](https://github.com/little-podi/adaworld)|\n", "2503.21696": "|[embodied-reasoner: synergizing visual search, reasoning, and action for embodied interactive tasks](https://arxiv.org/abs/2503.21696)|[embodied_reasoner](https://github.com/zwq2018/embodied_reasoner)|\n", "2504.14988": "|[benchmarking large vision-language models on fine-grained image tasks: a comprehensive evaluation](https://arxiv.org/abs/2504.14988)|[fg-bmk](https://github.com/seu-vipgroup/fg-bmk)|\n", "2504.17938": "|[machine learning-based prediction of quality shifts on video streaming over 5g](https://arxiv.org/abs/2504.17938)|[5g-qoe-prediction](https://github.com/razaulmustafa852/5g-qoe-prediction)|\n", "2505.07634": "|[neural brain: a neuroscience-inspired framework for embodied agents](https://arxiv.org/abs/2505.07634)|[Neural-Brain-for-Embodied-Agents](https://github.com/CNJianLiu/Neural-Brain-for-Embodied-Agents)|\n", "2505.08527": "|[leveraging segment anything model for source-free domain adaptation via dual feature guided auto-prompting](https://arxiv.org/abs/2505.08527)|[dfg](https://github.com/xmed-lab/dfg)|\n", "2505.08568": "|[thermal detection of people with mobility restrictions for barrier reduction at traffic lights controlled intersections](https://arxiv.org/abs/2505.08568)|[yolo-thermal](https://github.com/leon2014dresden/yolo-thermal)|\n", "2505.08614": "|[waveguard: robust deepfake detection and source tracing via dual-tree complex wavelet and graph neural networks](https://arxiv.org/abs/2505.08614)|[waveguard](https://github.com/vpsg-research/waveguard)|\n", "2505.08817": "|[towards sfw sampling for diffusion models via external conditioning](https://arxiv.org/abs/2505.08817)|[sfws-stable-diffusion](https://github.com/camilocarvajalreyes/sfws-stable-diffusion)|\n", "2505.08854": "|[generative ai for autonomous driving: frontiers and opportunities](https://arxiv.org/abs/2505.08854)|[genai4ad](https://github.com/taco-group/genai4ad)|\n", "2505.08919": "|[template-guided reconstruction of pulmonary segments with neural implicit functions](https://arxiv.org/abs/2505.08919)|[impulse](https://github.com/m3dv/impulse)|\n", "2505.08932": "|[parameter-efficient fine-tuning of vision foundation model for forest floor segmentation from uav imagery](https://arxiv.org/abs/2505.08932)|[sam_peft](https://github.com/garrulus-project/sam_peft)|\n", "2505.08961": "|[differentiable channel selection in self-attention for person re-identification](https://arxiv.org/abs/2505.08961)|[dcs-attention](https://github.com/statistical-deep-learning/dcs-attention)|\n", "2505.08971": "|[prioritizing image-related tokens enhances vision-language pre-training](https://arxiv.org/abs/2505.08971)|[prior](https://github.com/yangyi-chen/prior)|\n", "2505.08999": "|[towards adaptive meta-gradient adversarial examples for visual tracking](https://arxiv.org/abs/2505.08999)|[amga](https://github.com/pgao-lab/amga)|\n", "2505.09092": "|[openlka: an open dataset of lane keeping assist from recent car models under real-world driving conditions](https://arxiv.org/abs/2505.09092)|[openlka](https://github.com/openlka/openlka)|\n", "2505.09140": "|[topodit-3d: topology-aware diffusion transformer with bottleneck structure for 3d point cloud generation](https://arxiv.org/abs/2505.09140)|[topodit-3d](https://github.com/zechao-guan/topodit-3d)|\n", "2505.09168": "|[drrnet: macro-micro feature fusion and dual reverse refinement for camouflaged object detection](https://arxiv.org/abs/2505.09168)|[drrnet](https://github.com/jerrysunning/drrnet)|\n", "2505.09252": "|[zero-shot multi-modal large language model v.s. supervised deep learning: a comparative study on ct-based intracranial hemorrhage subtyping](https://arxiv.org/abs/2505.09252)|[ich_mllms_validation](https://github.com/mileswyn/ich_mllms_validation)|\n", "2505.09262": "|[edbench: large-scale electron density data for molecular modeling](https://arxiv.org/abs/2505.09262)|[EDBench](https://github.com/HongxinXiang/EDBench)|\n", "2505.09263": "|[few-shot anomaly-driven generation for anomaly classification and segmentation](https://arxiv.org/abs/2505.09263)|[anogen](https://github.com/gaobb/anogen)|\n", "2505.09264": "|[learning to detect multi-class anomalies with just one normal image prompt](https://arxiv.org/abs/2505.09264)|[onenip](https://github.com/gaobb/onenip)|\n", "2505.09306": "|[predicting butterfly species presence from satellite imagery using soft contrastive regularisation](https://arxiv.org/abs/2505.09306)|[pecl](https://github.com/vdplasthijs/pecl)|\n", "2505.09323": "|[q-space guided collaborative attention translation network for flexible diffusion-weighted images synthesis](https://arxiv.org/abs/2505.09323)|[q-catn](https://github.com/idea89560041/q-catn)|\n", "2505.09350": "|[procedural low-poly terrain generation with terracing for computer games](https://arxiv.org/abs/2505.09350)|[Procedural-Low-Poly-Terrain-Generation](https://github.com/richardtivolt/Procedural-Low-Poly-Terrain-Generation)|\n", "2505.09356": "|[apr-transformer: initial pose estimation for localization in complex environments through absolute pose regression](https://arxiv.org/abs/2505.09356)|[apr-transformer](https://github.com/gt-arc/apr-transformer)|\n", "2505.09358": "|[marigold: affordable adaptation of diffusion-based image generators for image analysis](https://arxiv.org/abs/2505.09358)|[marigold](https://github.com/prs-eth/marigold)|\n", "2505.09372": "|[make: multi-aspect knowledge-enhanced vision-language pretraining for zero-shot dermatological assessment](https://arxiv.org/abs/2505.09372)|[make](https://github.com/siyuanyan1/make)|\n", "2505.09393": "|[umotion: uncertainty-driven human motion estimation from inertial and ultra-wideband units](https://arxiv.org/abs/2505.09393)|[umotion](https://github.com/kk9six/umotion)|\n", "2505.09413": "|[sparse point cloud patches rendering via splitting 2d gaussians](https://arxiv.org/abs/2505.09413)|[gaupcrender](https://github.com/murcherful/gaupcrender)|\n", "2505.09521": "|[spec2volcamu-net: a spectrogram-to-volume model for eeg-to-fmri reconstruction based on multi-directional time-frequency convolutional attention encoder and vision-mamba u-net](https://arxiv.org/abs/2505.09521)|[spec2volcamu-net](https://github.com/hdy6438/spec2volcamu-net)|\n", "2505.09528": "|[conformal bounds on full-reference image quality for imaging inverse problems](https://arxiv.org/abs/2505.09528)|[quality_uq](https://github.com/jwen307/quality_uq)|\n", "2505.09529": "|[contactless cardiac pulse monitoring using event cameras](https://arxiv.org/abs/2505.09529)|[contactless_cardiac_pulse_monitoring_using_event_cameras](https://github.com/c3imaging/contactless_cardiac_pulse_monitoring_using_event_cameras)|\n", "2505.09558": "|[wavreward: spoken dialogue models with generalist reward evaluators](https://arxiv.org/abs/2505.09558)|[wavreward](https://github.com/jishengpeng/wavreward)|\n", "2505.09568": "|[blip3-o: a family of fully open unified multimodal models-architecture, training and dataset](https://arxiv.org/abs/2505.09568)|[blip3o](https://github.com/jiuhaichen/blip3o)|\n"}, "2025-05-16": {"2303.09681": "|[highly efficient 3d human pose tracking from events with spiking spatiotemporal transformer](https://arxiv.org/abs/2303.09681)|[humanposetracking_snn](https://github.com/jimmyzou/humanposetracking_snn)|\n", "2306.07615": "|[uod: universal one-shot detection of anatomical landmarks](https://arxiv.org/abs/2306.07615)|[uod_universal_oneshot_detection](https://github.com/heqin-zhu/uod_universal_oneshot_detection)|\n", "2309.00287": "|[fast diffusion em: a diffusion model for blind inverse problems with application to deconvolution](https://arxiv.org/abs/2309.00287)|[fastdiffusionem](https://github.com/claroche-r/fastdiffusionem)|\n", "2311.08043": "|[contrastive learning for multi-object tracking with transformers](https://arxiv.org/abs/2311.08043)|[ContrasTR](https://github.com/pfdp0/ContrasTR)|\n", "2311.14435": "|[local concept embeddings for analysis of concept distributions in vision dnn feature spaces](https://arxiv.org/abs/2311.14435)|[local-concept-embeddings](https://github.com/continental/local-concept-embeddings)|\n", "2312.01797": "|[llm a*: human in the loop large language models enabled a* search for robotics](https://arxiv.org/abs/2312.01797)|[llm-a-](https://github.com/speedhawk/llm-a-)|\n", "2401.14066": "|[creativesynth: cross-art-attention for artistic image synthesis with multimodal diffusion](https://arxiv.org/abs/2401.14066)|[CreativeSynth](https://github.com/haha-lisa/CreativeSynth)|\n", "2403.07547": "|[smurf: continuous dynamics for motion-deblurring radiance fields](https://arxiv.org/abs/2403.07547)|[smurf](https://github.com/jho-yonsei/smurf)|\n", "2403.17525": "|[equipping sketch patches with context-aware positional encoding for graphic sketch representation](https://arxiv.org/abs/2403.17525)|[dc-gra2seq](https://github.com/sczang/dc-gra2seq)|\n", "2406.12632": "|[cyclic 2.5d perceptual loss for cross-modal 3d medical image synthesis: t1w mri to tau pet](https://arxiv.org/abs/2406.12632)|[Cyclic-2.5D-Perceptual-Loss](https://github.com/labhai-dev/Cyclic-2.5D-Perceptual-Loss)|\n", "2410.01262": "|[improving fine-grained control via aggregation of multiple diffusion models](https://arxiv.org/abs/2410.01262)|[amdm](https://github.com/hammour-steak/amdm)|\n", "2411.08665": "|[osmloc: single image-based visual localization in openstreetmap with fused geometric and semantic guidance](https://arxiv.org/abs/2411.08665)|[osmloc](https://github.com/whu-usi3dv/osmloc)|\n", "2411.13602": "|[translating electrocardiograms to cardiac magnetic resonance imaging useful for cardiac assessment and disease screening: a multi-center study ai for ecg to cmr translation study](https://arxiv.org/abs/2411.13602)|[ecg-cmr](https://github.com/yukui-1999/ecg-cmr)|\n", "2411.14347": "|[dino-x: a unified vision model for open-world object detection and understanding](https://arxiv.org/abs/2411.14347)|[dino-x-api](https://github.com/idea-research/dino-x-api)|\n", "2501.01482": "|[an unsupervised method for mri recovery: deep image prior with structured sparsity](https://arxiv.org/abs/2501.01482)|[discus](https://github.com/osu-mr/discus)|\n", "2501.03021": "|[a trust-guided approach to mr image reconstruction with side information](https://arxiv.org/abs/2501.03021)|[tgvn](https://github.com/sodicksonlab/tgvn)|\n", "2501.12331": "|[cinepro: robust training of foundation models for cancer detection in prostate ultrasound cineloops](https://arxiv.org/abs/2501.12331)|[cinepro](https://github.com/mharmanani/cinepro)|\n", "2502.19090": "|[endomamba: an efficient foundation model for endoscopic videos via hierarchical pre-training](https://arxiv.org/abs/2502.19090)|[endomamba](https://github.com/tiancuteqy/endomamba)|\n", "2502.19159": "|[a sliding layer merging method for efficient depth-wise pruning in llms](https://arxiv.org/abs/2502.19159)|[slm-a-sliding-layer-merging-method](https://github.com/920927/slm-a-sliding-layer-merging-method)|\n", "2503.20291": "|[cryosamu: enhancing 3d cryo-em density maps of protein structures at intermediate resolution with structure-aware multimodal u-nets](https://arxiv.org/abs/2503.20291)|[cryosamu](https://github.com/chenwei-zhang/cryosamu)|\n", "2503.21776": "|[video-r1: reinforcing video reasoning in mllms](https://arxiv.org/abs/2503.21776)|[video-r1](https://github.com/tulerfeng/video-r1)|\n", "2504.00496": "|[learned image compression with dictionary-based entropy model](https://arxiv.org/abs/2504.00496)|[dcae](https://github.com/labshuhanggu/dcae)|\n", "2504.02522": "|[charm: the missing piece in vit fine-tuning for image aesthetic assessment](https://arxiv.org/abs/2504.02522)|[charm](https://github.com/fbehrad/charm)|\n", "2504.13231": "|[wildfirecan-mmd: a multimodal dataset for classification of user-generated content during wildfires in canada](https://arxiv.org/abs/2504.13231)|[WildfireCanMMD-Multimedia-Classification-on-user-generated-content-During-Wildfires-in-Canada](https://github.com/Multimodal-Social-Media-Data-Analysis/WildfireCanMMD-Multimedia-Classification-on-user-generated-content-During-Wildfires-in-Canada)|\n", "2504.19458": "|[mitigating modality bias in multi-modal entity alignment from a causal perspective](https://arxiv.org/abs/2504.19458)|[CDMEA](https://github.com/sutaoyu/CDMEA)|\n", "2505.03186": "|[cogenav: versatile audio-visual representation learning via contrastive-generative synchronization](https://arxiv.org/abs/2505.03186)|[cogenav](https://github.com/humanmllm/cogenav)|\n", "2505.05901": "|[examining the source of defects from a mechanical perspective for 3d anomaly detection](https://arxiv.org/abs/2505.05901)|[mc4ad](https://github.com/hzzzzzhappy/mc4ad)|\n", "2505.06512": "|[hcma: hierarchical cross-model alignment for grounded text-to-image generation](https://arxiv.org/abs/2505.06512)|[hcma](https://github.com/hwang-cs-ime/hcma)|\n", "2505.08910": "|[behind maya: building a multilingual vision language model](https://arxiv.org/abs/2505.08910)|[maya](https://github.com/nahidalam/maya)|\n", "2505.09858": "|[mission balance: generating under-represented class samples using video diffusion models](https://arxiv.org/abs/2505.09858)|[surgvgen](https://gitlab.com/nct_tso_public/surgvgen)|\n", "2505.09901": "|[comparing exploration-exploitation strategies of llms and humans: insights from standard multi-armed bandit tasks](https://arxiv.org/abs/2505.09901)|[exploration](https://github.com/sjgershm/exploration)|\n", "2505.09927": "|[ddfp: data-dependent frequency prompt for source free domain adaptation of medical image segmentation](https://arxiv.org/abs/2505.09927)|[SFDA-DDFP](https://github.com/YYinn/SFDA-DDFP)|\n", "2505.09939": "|[non-registration change detection: a novel change detection task and benchmark dataset](https://arxiv.org/abs/2505.09939)|[nrcd](https://github.com/shanzard/nrcd)|\n", "2505.09943": "|[cspenet: contour-aware and saliency priors embedding network for infrared small target detection](https://arxiv.org/abs/2505.09943)|[cspenet](https://github.com/idip2025/cspenet)|\n", "2505.09971": "|[apcotta: continual test-time adaptation for semantic segmentation of airborne lidar point clouds](https://arxiv.org/abs/2505.09971)|[apcotta](https://github.com/gaoyuan2/apcotta)|\n", "2505.10046": "|[exploring the deep fusion of large language models and diffusion transformers for text-to-image synthesis](https://arxiv.org/abs/2505.10046)|[fuse-dit](https://github.com/tang-bd/fuse-dit)|\n", "2505.10049": "|[advances in radiance field for dynamic scene: from neural field to gaussian field](https://arxiv.org/abs/2505.10049)|[dynamic-radiation-field-paper-list](https://github.com/moonflo/dynamic-radiation-field-paper-list)|\n", "2505.10055": "|[psocr: benchmarking large multimodal models for optical character recognition in low-resource pashto language](https://arxiv.org/abs/2505.10055)|[pashtoocr](https://github.com/zirak-ai/pashtoocr)|\n", "2505.10088": "|[mmrl++: parameter-efficient and interaction-aware representation learning for vision-language models](https://arxiv.org/abs/2505.10088)|[MMRL](https://github.com/yunncheng/MMRL)|\n", "2505.10124": "|[imitate: image registration with context for unknown time frame recovery](https://arxiv.org/abs/2505.10124)|[imitate](https://github.com/kheil-z/imitate)|\n", "2505.10144": "|[vrsplat: fast and robust gaussian splatting for virtual reality](https://arxiv.org/abs/2505.10144)|[vrsplat](https://github.com/cekavis/vrsplat)|\n", "2505.10223": "|[data-agnostic augmentations for unknown variations: out-of-distribution generalisation in mri segmentation](https://arxiv.org/abs/2505.10223)|[augmentations-for-the-unknown](https://github.com/miagrouput/augmentations-for-the-unknown)|\n", "2505.10231": "|[on the interplay of human-ai alignment,fairness, and performance trade-offs in medical imaging](https://arxiv.org/abs/2505.10231)|[aligner](https://github.com/roypic/aligner)|\n", "2505.10250": "|[adhmr: aligning diffusion-based human mesh recovery via direct preference optimization](https://arxiv.org/abs/2505.10250)|[adhmr](https://github.com/shenwenhao01/adhmr)|\n", "2505.10281": "|[mfoghub: bridging multi-regional and multi-satellite data for global marine fog detection and forecasting](https://arxiv.org/abs/2505.10281)|[mfoghub](https://github.com/kaka0910/mfoghub)|\n", "2505.10289": "|[msci: addressing clip's inherent limitations for compositional zero-shot learning](https://arxiv.org/abs/2505.10289)|[msci](https://github.com/ltpwy/msci)|\n", "2505.10292": "|[storyreasoning dataset: using chain-of-thought for scene understanding and grounded story generation](https://arxiv.org/abs/2505.10292)|[storyreasoning](https://github.com/daniel3303/storyreasoning)|\n", "2505.10294": "|[miphei-vit: multiplex immunofluorescence prediction from h&e images using vit foundation models](https://arxiv.org/abs/2505.10294)|[miphei-vit](https://github.com/sanofi-public/miphei-vit)|\n", "2505.10348": "|[listennet: a lightweight spatio-temporal enhancement nested network for auditory attention detection](https://arxiv.org/abs/2505.10348)|[listennet](https://github.com/fchest/listennet)|\n", "2505.10351": "|[a unified and scalable membership inference method for visual self-supervised encoder via part-aware capability](https://arxiv.org/abs/2505.10351)|[partcrop](https://github.com/jiepku/partcrop)|\n", "2505.10420": "|[learned lightweight smartphone isp with unpaired data](https://arxiv.org/abs/2505.10420)|[learned-lightweight-smartphone-isp-with-unpaired-data](https://github.com/andreiiarhire/learned-lightweight-smartphone-isp-with-unpaired-data)|\n", "2505.10457": "|[seal: searching expandable architectures for incremental learning](https://arxiv.org/abs/2505.10457)|[seal](https://github.com/ai-tech-research-lab/seal)|\n", "2505.10473": "|[consistent quantity-quality control across scenes for deployment-aware gaussian splatting](https://arxiv.org/abs/2505.10473)|[ControlGS](https://github.com/zhang-fengdi/ControlGS)|\n", "2505.10496": "|[chexgenbench: a unified benchmark for fidelity, privacy and utility of synthetic chest radiographs](https://arxiv.org/abs/2505.10496)|[CheXGenBench](https://github.com/Raman1121/CheXGenBench)|\n", "2505.10518": "|[multi-token prediction needs registers](https://arxiv.org/abs/2505.10518)|[mutor](https://github.com/nasosger/mutor)|\n", "2505.10541": "|[exploring implicit visual misunderstandings in multimodal large language models through attention analysis](https://arxiv.org/abs/2505.10541)|[stme](https://github.com/welldonepf/stme)|\n", "2505.10551": "|[does feasibility matter? understanding the impact of feasibility on synthetic training data](https://arxiv.org/abs/2505.10551)|[syntheticdatafeasibility](https://github.com/yiveen/syntheticdatafeasibility)|\n", "2505.10557": "|[mathcoder-vl: bridging vision and code for enhanced multimodal mathematical reasoning](https://arxiv.org/abs/2505.10557)|[mathcoder](https://github.com/mathllm/mathcoder)|\n"}, "2025-05-17": {}, "2025-05-18": {}, "2025-05-19": {"2404.13274": "|[augmented object intelligence with xr-objects](https://arxiv.org/abs/2404.13274)|[xr-objects](https://github.com/google/xr-objects)|\n", "2406.11624": "|[words in motion: extracting interpretable control vectors for motion transformers](https://arxiv.org/abs/2406.11624)|[future-motion](https://github.com/kit-mrt/future-motion)|\n", "2407.03653": "|[reben: refined bigearthnet dataset for remote sensing image analysis](https://arxiv.org/abs/2407.03653)|[rico-hdl](https://github.com/rsim-tu-berlin/rico-hdl)|\n", "2409.04388": "|[question-answering dense video events](https://arxiv.org/abs/2409.04388)|[deve-qa](https://github.com/qhuni/deve-qa)|\n", "2409.18865": "|[positional encoder graph quantile neural networks for geographic data](https://arxiv.org/abs/2409.18865)|[pe-gnn](https://github.com/konstantinklemmer/pe-gnn)|\n", "2411.09101": "|[heuristical comparison of vision transformers against convolutional neural networks for semantic segmentation on remote sensing imagery](https://arxiv.org/abs/2411.09101)|[vit-vs-cnn-image-segmentation](https://github.com/ashimdahal/vit-vs-cnn-image-segmentation)|\n", "2411.09263": "|[rethinking weight-averaged model-merging](https://arxiv.org/abs/2411.09263)|[rethink-merge](https://github.com/billhhh/rethink-merge)|\n", "2411.12919": "|[robust multi-coil mri reconstruction via self-supervised denoising](https://arxiv.org/abs/2411.12919)|[gsure-diffusion-mri](https://github.com/utcsilab/gsure-diffusion-mri)|\n", "2411.17141": "|[learning robust anymodal segmentor with unimodal and cross-modal distillation](https://arxiv.org/abs/2411.17141)|[AnySeg](https://github.com/zhengxuJosh/AnySeg)|\n", "2411.18440": "|[understanding galaxy morphology evolution through cosmic time via redshift conditioned diffusion models](https://arxiv.org/abs/2411.18440)|[lizarraga_2024](https://github.com/astrodatalab/lizarraga_2024)|\n", "2412.09765": "|[l-wise: boosting human visual category learning through model-based image selection and enhancement](https://arxiv.org/abs/2412.09765)|[l-wise](https://github.com/morganbdt/l-wise)|\n", "2412.13303": "|[fastvlm: efficient vision encoding for vision language models](https://arxiv.org/abs/2412.13303)|[ml-fastvlm](https://github.com/apple/ml-fastvlm)|\n", "2501.11803": "|[automating high quality rt planning at scale](https://arxiv.org/abs/2501.11803)|[gdp-hmm_aapmchallenge](https://github.com/riqianggao/gdp-hmm_aapmchallenge)|\n", "2503.04114": "|[organize, then vote: exploring cognitive load in quadratic survey interfaces](https://arxiv.org/abs/2503.04114)|[Quadratic-Survey-Dataset-and-Analysis](https://github.com/CrowdDynamicsLab/Quadratic-Survey-Dataset-and-Analysis)|\n", "2503.17715": "|[normalized matching transformer](https://arxiv.org/abs/2503.17715)|[normmatchtrans](https://github.com/apollos1301/normmatchtrans)|\n", "2503.18931": "|[comp: continual multimodal pre-training for vision foundation models](https://arxiv.org/abs/2503.18931)|[CoMP-MM](https://github.com/SliMM-X/CoMP-MM)|\n", "2503.24121": "|[impact: a generic semantic loss for multimodal medical image registration](https://arxiv.org/abs/2503.24121)|[impactloss](https://github.com/vboussot/impactloss)|\n", "2504.04893": "|[scam: a real-world typographic robustness evaluation for multimodal foundation models](https://arxiv.org/abs/2504.04893)|[scam](https://github.com/bliss-e-v/scam)|\n", "2504.06148": "|[v-mage: a game evaluation framework for assessing vision-centric capabilities in multimodal large language models](https://arxiv.org/abs/2504.06148)|[v-mage](https://github.com/csu-jpg/v-mage)|\n", "2504.10400": "|[towards low-latency event-based obstacle avoidance on a fpga-drone](https://arxiv.org/abs/2504.10400)|[eva](https://github.com/pbonazzi/eva)|\n", "2504.13580": "|[leveraging automatic cad annotations for supervised learning in 3d scene understanding](https://arxiv.org/abs/2504.13580)|[SCANnotatepp](https://github.com/stefan-ainetter/SCANnotatepp)|\n", "2505.01481": "|[videohallu: evaluating and mitigating multi-modal hallucinations on synthetic video understanding](https://arxiv.org/abs/2505.01481)|[videohallu](https://github.com/zli12321/videohallu)|\n", "2505.04258": "|[rgb-event fusion with self-attention for collision prediction](https://arxiv.org/abs/2505.04258)|[eva](https://github.com/pbonazzi/eva)|\n", "2505.05848": "|[refref: a synthetic dataset and benchmark for reconstructing refractive and reflective objects](https://arxiv.org/abs/2505.05848)|[refref](https://github.com/yueyin27/refref)|\n", "2505.06003": "|[from pixels to perception: interpretable predictions via instance-wise grouped feature selection](https://arxiv.org/abs/2505.06003)|[p2p](https://github.com/mvandenhi/p2p)|\n", "2505.07449": "|[ophora: a large-scale data-driven text-guided ophthalmic surgical video generation model](https://arxiv.org/abs/2505.07449)|[ophora](https://github.com/mar-cry/ophora)|\n", "2505.10595": "|[arfc-wahnet: adaptive receptive field convolution and wavelet-attentive hierarchical network for infrared small target detection](https://arxiv.org/abs/2505.10595)|[arfc-wahnet](https://github.com/leaf2001/arfc-wahnet)|\n", "2505.10610": "|[mmlongbench: benchmarking long-context vision-language models effectively and thoroughly](https://arxiv.org/abs/2505.10610)|[mmlongbench](https://github.com/edinburghnlp/mmlongbench)|\n", "2505.10679": "|[are spatial-temporal graph convolution networks for human action recognition over-parameterized?](https://arxiv.org/abs/2505.10679)|[sparse-st-gcn](https://github.com/davelailai/sparse-st-gcn)|\n", "2505.10686": "|[neolightning: a modern reimagination of gesture-based sound design](https://arxiv.org/abs/2505.10686)|[reimaginingthebuchlalightning](https://github.com/yonghyunk1m/reimaginingthebuchlalightning)|\n", "2505.10687": "|[roisgan: a region guided generative adversarial framework for murine hippocampal subregion segmentation](https://arxiv.org/abs/2505.10687)|[roisgan](https://github.com/mehediazim/roisgan)|\n", "2505.10787": "|[ea-3dgs: efficient and adaptive 3d gaussians with highly enhanced quality for outdoor scenes](https://arxiv.org/abs/2505.10787)|[ea-3dgs](https://github.com/scut-bip-lab/ea-3dgs)|\n", "2505.10824": "|[textured mesh quality assessment using geometry and color field similarity](https://arxiv.org/abs/2505.10824)|[fmqm](https://github.com/yyyykf/fmqm)|\n", "2505.10836": "|[multimodal event detection: current approaches and defining the new playground through llms and vlms](https://arxiv.org/abs/2505.10836)|[multimodeleventdetection](https://github.com/salokr/multimodeleventdetection)|\n", "2505.10873": "|[hashing for structure-based anomaly detection](https://arxiv.org/abs/2505.10873)|[hashing-for-structure-based-anomaly-detection](https://github.com/ineveloppilif/hashing-for-structure-based-anomaly-detection)|\n", "2505.10874": "|[multilink: multi-class structure recovery via agglomerative clustering and model selection](https://arxiv.org/abs/2505.10874)|[multilink](https://github.com/magrilu/multilink)|\n", "2505.10888": "|[posebench3d: a cross-dataset analysis framework for 3d human pose estimation](https://arxiv.org/abs/2505.10888)|[poselab3d](https://github.com/bryanjvela/poselab3d)|\n", "2505.10931": "|[m4-sar: a multi-resolution, multi-polarization, multi-scene, multi-source dataset and benchmark for optical-sar fusion object detection](https://arxiv.org/abs/2505.10931)|[m4-sar](https://github.com/wchao0601/m4-sar)|\n", "2505.11003": "|[forensichub: a unified benchmark & codebase for all-domain fake image detection and localization](https://arxiv.org/abs/2505.11003)|[forensichub](https://github.com/scu-zjz/forensichub)|\n", "2505.11034": "|[cleanpatrick: a benchmark for image data cleaning](https://arxiv.org/abs/2505.11034)|[cleanpatrick](https://github.com/digital-dermatology/cleanpatrick)|\n", "2505.11060": "|[cubic: concept embeddings for unsupervised bias identification using vlms](https://arxiv.org/abs/2505.11060)|[cubic](https://github.com/david-mnd/cubic)|\n", "2505.11062": "|[hsrmamba: efficient wavelet stripe state space model for hyperspectral image super-resolution](https://arxiv.org/abs/2505.11062)|[hsrmamba](https://github.com/oldsweet/hsrmamba)|\n", "2505.11099": "|[hybrid-emba3d: geometry-aware and cross-path feature hybrid enhanced state space model for point cloud classification](https://arxiv.org/abs/2505.11099)|[hybrid-emba3d](https://github.com/l1277471578/hybrid-emba3d)|\n", "2505.11129": "|[phinet v2: a mask-free brain-inspired vision foundation model from video](https://arxiv.org/abs/2505.11129)|[phinetv2](https://github.com/oist/phinetv2)|\n", "2505.11131": "|[one image is worth a thousand words: a usability preservable text-image collaborative erasing framework](https://arxiv.org/abs/2505.11131)|[co-erasing](https://github.com/ferry-li/co-erasing)|\n", "2505.11146": "|[x2c: a dataset featuring nuanced facial expressions for realistic humanoid imitation](https://arxiv.org/abs/2505.11146)|[x2cnet](https://github.com/lipzh5/x2cnet)|\n", "2505.11196": "|[dico: revitalizing convnets for scalable and efficient diffusion modeling](https://arxiv.org/abs/2505.11196)|[dico](https://github.com/shallowdream204/dico)|\n", "2505.11237": "|[concept drift guided layernorm tuning for efficient multimodal metaphor identification](https://arxiv.org/abs/2505.11237)|[CDGLT](https://github.com/MSA-LMC/CDGLT)|\n", "2505.11245": "|[diffusion-npo: negative preference optimization for better preference aligned generation of diffusion models](https://arxiv.org/abs/2505.11245)|[diffusion-npo](https://github.com/g-u-n/diffusion-npo)|\n", "2505.11246": "|[entropy-driven genetic optimization for deep-feature-guided low-light image enhancement](https://arxiv.org/abs/2505.11246)|[entropy-driven-genetic-optimization-for-deep-feature-guided-low-light-image-enhancement](https://github.com/nirjhor-datta/entropy-driven-genetic-optimization-for-deep-feature-guided-low-light-image-enhancement)|\n", "2505.11293": "|[breaking the batch barrier (b3) of contrastive learning via smart batch mining](https://arxiv.org/abs/2505.11293)|[b3](https://github.com/raghavlite/b3)|\n", "2505.11326": "|[temporally-grounded language generation: a benchmark for real-time vision-language models](https://arxiv.org/abs/2505.11326)|[tglg](https://github.com/yukw777/tglg)|\n", "2505.11366": "|[learning multimodal ai algorithms for amplifying limited user input into high-dimensional control space](https://arxiv.org/abs/2505.11366)|[aras](https://github.com/abirilab/aras)|\n", "2505.11383": "|[dynam3d: dynamic layered 3d tokens empower vlm for vision-and-language navigation](https://arxiv.org/abs/2505.11383)|[dynam3d](https://github.com/mrzihan/dynam3d)|\n", "2505.11394": "|[from fibers to cells: fourier-based registration enables virtual cresyl violet staining from 3d polarized light imaging](https://arxiv.org/abs/2505.11394)|[pli2cells](https://github.com/fzj-inm1-bda/pli2cells)|\n", "2505.11405": "|[emotionhallucer: evaluating emotion hallucinations in multimodal large language models](https://arxiv.org/abs/2505.11405)|[emotionhallucer](https://github.com/xxtars/emotionhallucer)|\n", "2505.11409": "|[visual planning: let's think only with images](https://arxiv.org/abs/2505.11409)|[visualplanning](https://github.com/yix8/visualplanning)|\n", "2505.11417": "|[edgewisepersona: a dataset for on-device user profiling from natural language interactions](https://arxiv.org/abs/2505.11417)|[edgewisepersona](https://github.com/tclresearcheurope/edgewisepersona)|\n", "2505.11454": "|[humanibench: a human-centric framework for large multimodal models evaluation](https://arxiv.org/abs/2505.11454)|[humanibench](https://github.com/vectorinstitute/humanibench)|\n"}, "2025-05-20": {"2206.05751": "|[consistent attack: universal adversarial perturbation on embodied vision navigation](https://arxiv.org/abs/2206.05751)|[Consistent-Attack](https://github.com/yingchengyang/Consistent-Attack)|\n", "2207.06817": "|[pseudo-labeling based practical semi-supervised meta-training for few-shot learning](https://arxiv.org/abs/2207.06817)|[plml](https://github.com/ouyangtianran/plml)|\n", "2211.01095": "|[dpm-solver++: fast solver for guided sampling of diffusion probabilistic models](https://arxiv.org/abs/2211.01095)|[dpm-solver](https://github.com/luchengthu/dpm-solver)|\n", "2303.08730": "|[diffusionad: norm-guided one-step denoising diffusion for anomaly detection](https://arxiv.org/abs/2303.08730)|[diffusionad](https://github.com/huizhang0812/diffusionad)|\n", "2303.12267": "|[auto: adaptive outlier optimization for test-time ood detection](https://arxiv.org/abs/2303.12267)|[AUTO-for-OOD-detection](https://github.com/Puning97/AUTO-for-OOD-detection)|\n", "2305.15560": "|[differentially private synthetic data via foundation model apis 1: images](https://arxiv.org/abs/2305.15560)|[dpsda](https://github.com/microsoft/dpsda)|\n", "2306.05612": "|[spatial re-parameterization for n:m sparsity](https://arxiv.org/abs/2306.05612)|[spre](https://github.com/zyxxmu/spre)|\n", "2306.11766": "|[agreeing and disagreeing in collaborative knowledge graph construction: an analysis of wikidata](https://arxiv.org/abs/2306.11766)|[wikidata_disagreements](https://github.com/elisavetk/wikidata_disagreements)|\n", "2308.05257": "|[developing a hybrid convolutional neural network for automatic aphid counting in sugar beet fields](https://arxiv.org/abs/2308.05257)|[counting-aphids](https://github.com/junfenggaolab/counting-aphids)|\n", "2308.09307": "|[rethinking image forgery detection via soft contrastive learning and unsupervised clustering](https://arxiv.org/abs/2308.09307)|[focal](https://github.com/highwaywu/focal)|\n", "2310.10378": "|[cross-lingual consistency of factual knowledge in multilingual language models](https://arxiv.org/abs/2310.10378)|[Cross-Lingual-Consistency](https://github.com/Betswish/Cross-Lingual-Consistency)|\n", "2311.13706": "|[multi-view hybrid graph convolutional network for volume-to-mesh reconstruction in cardiovascular mri](https://arxiv.org/abs/2311.13706)|[hybridgnet_3d](https://github.com/ngaggion/hybridgnet_3d)|\n", "2312.03406": "|[does vector quantization fail in spatio-temporal forecasting? exploring a differentiable sparse soft-vector quantization approach](https://arxiv.org/abs/2312.03406)|[SVQ-Forecasting](https://github.com/Pachark/SVQ-Forecasting)|\n", "2312.04831": "|[towards enhanced image inpainting: mitigating unwanted object insertion and preserving color consistency](https://arxiv.org/abs/2312.04831)|[asuka-misato](https://github.com/yikai-wang/asuka-misato)|\n", "2402.15679": "|[scalable density-based clustering with random projections](https://arxiv.org/abs/2402.15679)|[sDbscan](https://github.com/NinhPham/sDbscan)|\n", "2403.08504": "|[offboard occupancy refinement with hybrid propagation for autonomous driving](https://arxiv.org/abs/2403.08504)|[occfiner](https://github.com/masterhow/occfiner)|\n", "2403.15576": "|[data-centric prediction explanation via kernelized stein discrepancy](https://arxiv.org/abs/2403.15576)|[hdexplain](https://github.com/mahtabsarvmaili/hdexplain)|\n", "2404.07495": "|[pillartrack:boosting pillar representation for transformer-based 3d single object tracking on point clouds](https://arxiv.org/abs/2404.07495)|[pillartrack](https://github.com/stiphyjay/pillartrack)|\n", "2405.02564": "|[probing human visual robustness with neurally-guided deep neural networks](https://arxiv.org/abs/2405.02564)|[NeuralGuidance](https://github.com/shaox192/NeuralGuidance)|\n", "2406.04207": "|[cdmamba: incorporating local clues into mamba for remote sensing image binary change detection](https://arxiv.org/abs/2406.04207)|[cdmamba](https://github.com/zmoka-zht/cdmamba)|\n", "2406.07089": "|[rs-agent: automating remote sensing tasks through intelligent agent](https://arxiv.org/abs/2406.07089)|[rs-agent](https://github.com/intellisensing/rs-agent)|\n", "2407.01976": "|[a bounding box is worth one token: interleaving layout and text in a large language model for document understanding](https://arxiv.org/abs/2407.01976)|[laytextllm](https://github.com/laytextllm/laytextllm)|\n", "2407.06159": "|[a semantic-aware and multi-guided network for infrared-visible image fusion](https://arxiv.org/abs/2407.06159)|[smfnet](https://github.com/abraham-einstein/smfnet)|\n", "2407.13195": "|[scalable exploration via ensemble++](https://arxiv.org/abs/2407.13195)|[ensemble_plus_plus](https://github.com/szrlee/ensemble_plus_plus)|\n", "2408.02803": "|[sico: an interactive size-controllable virtual try-on approach for informed decision-making](https://arxiv.org/abs/2408.02803)|[sico](https://github.com/sherryxtchen/sico)|\n", "2408.05159": "|[easyinv: toward fast and better ddim inversion](https://arxiv.org/abs/2408.05159)|[easyinv](https://github.com/potato-kitty/easyinv)|\n", "2409.14319": "|[scene-text grounding for text-based video question answering](https://arxiv.org/abs/2409.14319)|[vitxt-gqa](https://github.com/zhousheng97/vitxt-gqa)|\n", "2409.16902": "|[underwater camouflaged object tracking meets vision-language sam2](https://arxiv.org/abs/2409.16902)|[awesome-multimodal-object-tracking](https://github.com/983632847/awesome-multimodal-object-tracking)|\n", "2410.08151": "|[progressive autoregressive video diffusion models](https://arxiv.org/abs/2410.08151)|[pa_vdm](https://github.com/desaixie/pa_vdm)|\n", "2410.10733": "|[deep compression autoencoder for efficient high-resolution diffusion models](https://arxiv.org/abs/2410.10733)|[efficientvit](https://github.com/mit-han-lab/efficientvit)|\n", "2410.18388": "|[irregular tensor low-rank representation for hyperspectral image representation](https://arxiv.org/abs/2410.18388)|[itlrr](https://github.com/hb-studying/itlrr)|\n", "2410.21759": "|[intlora: integral low-rank adaptation of quantized diffusion models](https://arxiv.org/abs/2410.21759)|[intlora](https://github.com/csguoh/intlora)|\n", "2410.22076": "|[uspeech: ultrasound-enhanced speech with minimal human effort via cross-modal synthesis](https://arxiv.org/abs/2410.22076)|[USpeech](https://github.com/aiot-lab/USpeech)|\n", "2411.19551": "|[bootstraping clustering of gaussians for view-consistent 3d scene understanding](https://arxiv.org/abs/2411.19551)|[FreeGS](https://github.com/wb014/FreeGS)|\n", "2411.19722": "|[jetformer: an autoregressive generative model of raw images and text](https://arxiv.org/abs/2411.19722)|[big_vision](https://github.com/google-research/big_vision)|\n", "2411.19939": "|[vlsbench: unveiling visual leakage in multimodal safety](https://arxiv.org/abs/2411.19939)|[vlsbench](https://github.com/ai45lab/vlsbench)|\n", "2412.03210": "|[parametric perceptnet: a bio-inspired deep-net trained for image quality assessment](https://arxiv.org/abs/2412.03210)|[PerceptualTests](https://github.com/Jorgvt/PerceptualTests)|\n", "2412.09945": "|[going beyond feature similarity: effective dataset distillation based on class-aware conditional mutual information](https://arxiv.org/abs/2412.09945)|[cmidd](https://github.com/ndhg1213/cmidd)|\n", "2412.20056": "|[gsplatloc: ultra-precise camera localization via 3d gaussian splatting](https://arxiv.org/abs/2412.20056)|[gsplatloc](https://github.com/atticuszeller/gsplatloc)|\n", "2501.04697": "|[grokking at the edge of numerical stability](https://arxiv.org/abs/2501.04697)|[grokking-at-the-edge-of-numerical-stability](https://github.com/lucasprietoal/grokking-at-the-edge-of-numerical-stability)|\n", "2501.18116": "|[deepfrc: an end-to-end deep learning model for functional registration and classification](https://arxiv.org/abs/2501.18116)|[deepfrc](https://github.com/drivergo-93589/deepfrc)|\n", "2501.18427": "|[sana 1.5: efficient scaling of training-time and inference-time compute in linear diffusion transformer](https://arxiv.org/abs/2501.18427)|[Sana](https://github.com/NVlabs/Sana)|\n", "2501.19098": "|[$\\infty$-video: a training-free approach to long video understanding via continuous-time memory consolidation](https://arxiv.org/abs/2501.19098)|[infinite-video](https://github.com/deep-spin/infinite-video)|\n", "2502.00392": "|[refdrone: a challenging benchmark for referring expression comprehension in drone scenes](https://arxiv.org/abs/2502.00392)|[refdrone](https://github.com/sunzc-sunny/refdrone)|\n", "2502.03950": "|[lr0.fm: low-res benchmark and improving robustness for zero-shot classification in foundation models](https://arxiv.org/abs/2502.03950)|[LR0.FM](https://github.com/shyammarjit/LR0.FM)|\n", "2502.05415": "|[unicms: a unified consistency model for efficient multimodal generation and understanding](https://arxiv.org/abs/2502.05415)|[unicms](https://github.com/zhijie-group/unicms)|\n", "2502.09620": "|[exploring the potential of encoder-free architectures in 3d lmms](https://arxiv.org/abs/2502.09620)|[enel](https://github.com/ivan-tang-3d/enel)|\n", "2502.13407": "|[jl1-cd: a new benchmark for remote sensing change detection and a robust multi-teacher knowledge distillation framework](https://arxiv.org/abs/2502.13407)|[mtkd-cd](https://github.com/circlelzy/mtkd-cd)|\n", "2502.14471": "|[integrating extra modality helps segmentor find camouflaged objects well](https://arxiv.org/abs/2502.14471)|[multicos](https://github.com/cnyvfang/multicos)|\n", "2502.20034": "|[vision-encoders (already) know what they see: mitigating object hallucination via simple fine-grained clipscore](https://arxiv.org/abs/2502.20034)|[f-clip](https://github.com/abzb1/f-clip)|\n", "2502.20321": "|[unitok: a unified tokenizer for visual generation and understanding](https://arxiv.org/abs/2502.20321)|[unitok](https://github.com/foundationvision/unitok)|\n", "2503.05423": "|[semantic shift estimation via dual-projection and classifier reconstruction for exemplar-free class-incremental learning](https://arxiv.org/abs/2503.05423)|[icml25-dpcr](https://github.com/rhe502/icml25-dpcr)|\n", "2503.09641": "|[sana-sprint: one-step diffusion with continuous-time consistency distillation](https://arxiv.org/abs/2503.09641)|[Sana](https://github.com/NVlabs/Sana)|\n", "2503.14553": "|[redefining non-iid data in federated learning for computer vision tasks: migrating from labels to embeddings for task-specific data distributions](https://arxiv.org/abs/2503.14553)|[task-perspective-het](https://github.com/kasraborazjani/task-perspective-het)|\n", "2503.15558": "|[cosmos-reason1: from physical common sense to embodied reasoning](https://arxiv.org/abs/2503.15558)|[cosmos-reason1](https://github.com/nvidia-cosmos/cosmos-reason1)|\n", "2503.18225": "|[delora: decoupling angles and strength in low-rank adaptation](https://arxiv.org/abs/2503.18225)|[delora](https://github.com/explainableml/delora)|\n", "2503.18430": "|[cq-dino: mitigating gradient dilution via category queries for vast vocabulary object detection](https://arxiv.org/abs/2503.18430)|[cq-dino](https://github.com/redaigc/cq-dino)|\n", "2503.19325": "|[long-context autoregressive video modeling with next-frame prediction](https://arxiv.org/abs/2503.19325)|[FAR](https://github.com/showlab/FAR)|\n", "2503.21246": "|[dynamictrl: rethinking the basic structure and the role of text for high-quality human image animation](https://arxiv.org/abs/2503.21246)|[dynamictrl](https://github.com/gulucaptain/dynamictrl)|\n", "2504.02277": "|[beyond conventional transformers: the medical x-ray attention (mxa) block for improved multi-label diagnosis using knowledge distillation](https://arxiv.org/abs/2504.02277)|[beyond-conventional-transformers](https://github.com/hadi-m-ibrahim/beyond-conventional-transformers)|\n", "2504.07285": "|[a scalable approach to clustering embedding projections](https://arxiv.org/abs/2504.07285)|[embedding-atlas](https://github.com/apple/embedding-atlas)|\n", "2504.09897": "|[tamp: token-adaptive layerwise pruning in multimodal large language models](https://arxiv.org/abs/2504.09897)|[tamp](https://github.com/g-jwlee/tamp)|\n", "2504.10143": "|[on the value of cross-modal misalignment in multimodal representation learning](https://arxiv.org/abs/2504.10143)|[crossmodal_mislaignment](https://github.com/yichaocai1/crossmodal_mislaignment)|\n", "2504.11349": "|[explicit and implicit representations in ai-based 3d reconstruction for radiology: a systematic review](https://arxiv.org/abs/2504.11349)|[ai4radiology](https://github.com/bean-young/ai4radiology)|\n", "2504.16096": "|[brainprompt: multi-level brain prompt enhancement for neurological condition identification](https://arxiv.org/abs/2504.16096)|[brainprompt](https://github.com/angusmonroe/brainprompt)|\n", "2504.18165": "|[perfcam: digital twinning for production lines using 3d gaussian splatting and vision models](https://arxiv.org/abs/2504.18165)|[PerfCam](https://github.com/AstraZeneca/PerfCam)|\n", "2504.20518": "|[dynamic attention analysis for backdoor detection in text-to-image diffusion models](https://arxiv.org/abs/2504.20518)|[daa](https://github.com/robin-wzq/daa)|\n", "2504.20734": "|[universalrag: retrieval-augmented generation over corpora of diverse modalities and granularities](https://arxiv.org/abs/2504.20734)|[UniversalRAG](https://github.com/wgcyeo/UniversalRAG)|\n", "2505.01000": "|[togedule: scheduling meetings with large language models and adaptive representations of group availability](https://arxiv.org/abs/2505.01000)|[togedule](https://github.com/jyoonsong/togedule)|\n", "2505.01212": "|[high dynamic range novel view synthesis with single exposure](https://arxiv.org/abs/2505.01212)|[mono-hdr-3d](https://github.com/prinasi/mono-hdr-3d)|\n", "2505.02831": "|[no other representation component is needed: diffusion transformers can provide representation guidance by themselves](https://arxiv.org/abs/2505.02831)|[sra](https://github.com/vvvvvjdy/sra)|\n", "2505.03654": "|[regrap-llava: reasoning enabled graph-based personalized large language and vision assistant](https://arxiv.org/abs/2505.03654)|[regrap](https://github.com/xyfyyds/regrap)|\n", "2505.05022": "|[soap: style-omniscient animatable portraits](https://arxiv.org/abs/2505.05022)|[soap](https://github.com/tingtingliao/soap)|\n", "2505.05621": "|[a preliminary study for gpt-4o on image restoration](https://arxiv.org/abs/2505.05621)|[gpt_restoration](https://github.com/noxsine/gpt_restoration)|\n", "2505.05657": "|[arraydps: unsupervised blind speech separation with a diffusion prior](https://arxiv.org/abs/2505.05657)|[arraydps](https://github.com/arraydps/arraydps)|\n", "2505.05678": "|[instancegen: image generation with instance-level instructions](https://arxiv.org/abs/2505.05678)|[SLD](https://github.com/tsunghan-wu/SLD)|\n", "2505.05834": "|[dual-level fuzzy learning with patch guidance for image ordinal regression](https://arxiv.org/abs/2505.05834)|[dfpg-ord](https://github.com/zjumai/dfpg-ord)|\n", "2505.08586": "|[preprompt: predictive prompting for class incremental learning](https://arxiv.org/abs/2505.08586)|[PrePrompt](https://github.com/libo-huang/PrePrompt)|\n", "2505.09926": "|[adaptclip: adapting clip for universal visual anomaly detection](https://arxiv.org/abs/2505.09926)|[AdaptCLIP](https://github.com/gaobb/AdaptCLIP)|\n", "2505.11032": "|[dexgarmentlab: dexterous garment manipulation environment with generalizable policy](https://arxiv.org/abs/2505.11032)|[dexgarmentlab](https://github.com/wayrise/dexgarmentlab)|\n", "2505.11538": "|[brainnetmlp: an efficient and effective baseline for functional brain network classification](https://arxiv.org/abs/2505.11538)|[brainnetmlp](https://github.com/jayceonho/brainnetmlp)|\n", "2505.11581": "|[questioning representational optimism in deep learning: the fractured entangled representation hypothesis](https://arxiv.org/abs/2505.11581)|[fer](https://github.com/akarshkumar0101/fer)|\n", "2505.11594": "|[sageattention3: microscaling fp4 attention for inference and an exploration of 8-bit training](https://arxiv.org/abs/2505.11594)|[SageAttention](https://github.com/thu-ml/SageAttention)|\n", "2505.11612": "|[heart2mind: human-centered contestable psychiatric disorder diagnosis system using wearable ecg monitors](https://arxiv.org/abs/2505.11612)|[heart2mind](https://github.com/analytics-everywhere-lab/heart2mind)|\n", "2505.11703": "|[loft: lora-fused training dataset generation with few-shot guidance](https://arxiv.org/abs/2505.11703)|[loft](https://github.com/explainableml/loft)|\n", "2505.11720": "|[ugodit: unsupervised group deep image prior via transferable weights](https://arxiv.org/abs/2505.11720)|[ugodit](https://github.com/sjames40/ugodit)|\n", "2505.11797": "|[medvkan: efficient feature extraction with mamba and kan for medical image segmentation](https://arxiv.org/abs/2505.11797)|[medvkan](https://github.com/beginner-cjh/medvkan)|\n", "2505.11800": "|[self-learning hyperspectral and multispectral image fusion via adaptive residual guided subspace diffusion model](https://arxiv.org/abs/2505.11800)|[args-diff](https://github.com/zhu1116/args-diff)|\n", "2505.11838": "|[rvtbench: a benchmark for visual reasoning tasks](https://arxiv.org/abs/2505.11838)|[rvt](https://github.com/yiqings/rvt)|\n", "2505.11842": "|[video-safetybench: a benchmark for safety evaluation of video lvlms](https://arxiv.org/abs/2505.11842)|[video-safetybench](https://github.com/flageval-baai/video-safetybench)|\n", "2505.11882": "|[genzsl: generative zero-shot learning via inductive variational autoencoder](https://arxiv.org/abs/2505.11882)|[genzsl](https://github.com/shiming-chen/genzsl)|\n", "2505.11909": "|[bridging the inter-domain gap through low-level features for cross-modal medical image segmentation](https://arxiv.org/abs/2505.11909)|[lowbridge](https://github.com/joshualpf/lowbridge)|\n", "2505.11913": "|[joint manifold learning and optimal transport for dynamic imaging](https://arxiv.org/abs/2505.11913)|[joint-manifold-learning-and-ot](https://github.com/SCdummer/joint-manifold-learning-and-ot)|\n", "2505.12021": "|[cross-model transfer of task vectors via few-shot orthogonal alignment](https://arxiv.org/abs/2505.12021)|[crossmodeltransfer](https://github.com/kawakera-lab/crossmodeltransfer)|\n", "2505.12051": "|[enhanced multimodal hate video detection via channel-wise and modality-wise fusion](https://arxiv.org/abs/2505.12051)|[cmfusion](https://github.com/evelynz10/cmfusion)|\n", "2505.12066": "|[beluga whale detection from satellite imagery with point labels](https://arxiv.org/abs/2505.12066)|[beluga-seeker](https://github.com/voyagerxvoyagerx/beluga-seeker)|\n", "2505.12098": "|[love: benchmarking and evaluating text-to-video generation and video-to-text interpretation](https://arxiv.org/abs/2505.12098)|[love](https://github.com/intmegroup/love)|\n", "2505.12120": "|[histai: an open-source, large-scale whole slide image dataset for computational pathology](https://arxiv.org/abs/2505.12120)|[histai](https://github.com/histai/histai)|\n", "2505.12155": "|[softpq: robust instance segmentation evaluation via soft matching and tunable thresholds](https://arxiv.org/abs/2505.12155)|[SoftPQ](https://github.com/rkarmaka/SoftPQ)|\n", "2505.12191": "|[ditch the denoiser: emergence of noise robustness in self-supervised learning from data curriculum](https://arxiv.org/abs/2505.12191)|[noisy_dinov2](https://github.com/wenquanlu/noisy_dinov2)|\n", "2505.12199": "|[always clear depth: robust monocular depth estimation under adverse weather](https://arxiv.org/abs/2505.12199)|[acdepth](https://github.com/msscao/acdepth)|\n", "2505.12217": "|[hyperspectral image land cover captioning dataset for vision language models](https://arxiv.org/abs/2505.12217)|[hypercap](https://github.com/arya-domain/hypercap)|\n", "2505.12261": "|[openpros: a large-scale dataset for limited view prostate ultrasound computed tomography](https://arxiv.org/abs/2505.12261)|[openpros](https://github.com/hanchenwang/openpros)|\n", "2505.12266": "|[pmq-ve: progressive multi-frame quantization for video enhancement](https://arxiv.org/abs/2505.12266)|[pmq-ve](https://github.com/xiaobigfeng/pmq-ve)|\n", "2505.12267": "|[real-time spatial reasoning by mobile robots for reconstruction and navigation in dynamic lidar scenes](https://arxiv.org/abs/2505.12267)|[RTRecon](https://github.com/SZU-VCC/RTRecon)|\n", "2505.12280": "|[temporal-spectral-spatial unified remote sensing dense prediction](https://arxiv.org/abs/2505.12280)|[official_tssun](https://github.com/walking-shadow/official_tssun)|\n", "2505.12307": "|[logicocr: do your large multimodal models excel at logical reasoning on text-rich images?](https://arxiv.org/abs/2505.12307)|[logicocr](https://github.com/mililab/logicocr)|\n", "2505.12335": "|[is artificial intelligence generated image detection a solved problem?](https://arxiv.org/abs/2505.12335)|[aigibench](https://github.com/horizontel/aigibench)|\n", "2505.12363": "|[towards visuospatial cognition via hierarchical fusion of visual experts](https://arxiv.org/abs/2505.12363)|[vica](https://github.com/nkkbr/vica)|\n", "2505.12432": "|[observe-r1: unlocking reasoning abilities of mllms with dynamic progressive reinforcement learning](https://arxiv.org/abs/2505.12432)|[observe-r1](https://github.com/zrguo/observe-r1)|\n", "2505.12434": "|[videorft: incentivizing video reasoning capability in mllms via reinforced fine-tuning](https://arxiv.org/abs/2505.12434)|[videorft](https://github.com/qiwang98/videorft)|\n", "2505.12513": "|[globalgeotree: a multi-granular vision-language dataset for global tree species classification](https://arxiv.org/abs/2505.12513)|[globalgeotree](https://github.com/muyang99/globalgeotree)|\n", "2505.12532": "|[exploring sparsity for parameter efficient fine tuning using wavelets](https://arxiv.org/abs/2505.12532)|[sparse_peft](https://github.com/bilican/sparse_peft)|\n", "2505.12547": "|[promi: an efficient prototype-mixture baseline for few-shot segmentation with bounding-box annotations](https://arxiv.org/abs/2505.12547)|[promi](https://github.com/thalesgroup/promi)|\n", "2505.12630": "|[degradation-aware feature perturbation for all-in-one image restoration](https://arxiv.org/abs/2505.12630)|[dfpir](https://github.com/txphome/dfpir)|\n", "2505.12631": "|[multi-resolution haar network: enhancing human motion prediction via haar transform](https://arxiv.org/abs/2505.12631)|[haarmodic](https://github.com/xhaughearl/haarmodic)|\n", "2505.12650": "|[automat: enabling automated crystal structure reconstruction from microscopy via agentic tool use](https://arxiv.org/abs/2505.12650)|[automat](https://github.com/yyt-2378/automat)|\n", "2505.12669": "|[text2midi-inferalign: improving symbolic music generation with inference-time alignment](https://arxiv.org/abs/2505.12669)|[t2m-inferalign](https://github.com/amaai-lab/t2m-inferalign)|\n", "2505.12674": "|[few-step diffusion via score identity distillation](https://arxiv.org/abs/2505.12674)|[sid-lsg](https://github.com/mingyuanzhou/sid-lsg)|\n", "2505.12718": "|[automated bias assessment in ai-generated educational content using ceat framework](https://arxiv.org/abs/2505.12718)|[Automated-Word-Extraction](https://github.com/EricP66/Automated-Word-Extraction)|\n", "2505.12742": "|[mvar: visual autoregressive modeling with scale and spatial markovian conditioning](https://arxiv.org/abs/2505.12742)|[mvar](https://github.com/labshuhanggu/mvar)|\n", "2505.12766": "|[reasoning-ocr: can large multimodal models solve complex logical reasoning problems from ocr cues?](https://arxiv.org/abs/2505.12766)|[reasoningocr](https://github.com/hxyz-123/reasoningocr)|\n", "2505.12820": "|[rethinking features-fused-pyramid-neck for object detection](https://arxiv.org/abs/2505.12820)|[rethinking-fpn](https://github.com/alanli1997/rethinking-fpn)|\n", "2505.12834": "|[a study on the refining handwritten font by mixing font styles](https://arxiv.org/abs/2505.12834)|[FontFusionGAN](https://github.com/KumarAvinash44/FontFusionGAN)|\n", "2505.12835": "|[flightgpt: towards generalizable and interpretable uav vision-and-language navigation with vision-language models](https://arxiv.org/abs/2505.12835)|[flightgpt](https://github.com/pendulumclock/flightgpt)|\n", "2505.12849": "|[accelerate tarflow sampling with gs-jacobi iteration](https://arxiv.org/abs/2505.12849)|[gs-jacobi_for_tarflow](https://github.com/encoreus/gs-jacobi_for_tarflow)|\n", "2505.12861": "|[robust multimodal segmentation with representation regularization and hybrid prototype distillation](https://arxiv.org/abs/2505.12861)|[robustseg](https://github.com/robustseg/robustseg)|\n", "2505.12897": "|[epic: explanation of pretrained image classification networks via prototype](https://arxiv.org/abs/2505.12897)|[epic](https://github.com/piotr310100/epic)|\n", "2505.12903": "|[towards low-latency event stream-based visual object tracking: a slow-fast approach](https://arxiv.org/abs/2505.12903)|[slowfast_event_track](https://github.com/event-ahu/slowfast_event_track)|\n", "2505.12908": "|[dynamic graph induced contour-aware heat conduction network for event-based object detection](https://arxiv.org/abs/2505.12908)|[openevdet](https://github.com/event-ahu/openevdet)|\n", "2505.12911": "|[hiero: understanding the hierarchy of human behavior enhances reasoning on egocentric videos](https://arxiv.org/abs/2505.12911)|[hiero](https://github.com/sapeirone/hiero)|\n", "2505.12912": "|[uniformity first: uniformity-aware test-time adaptation of vision-language models against image corruption](https://arxiv.org/abs/2505.12912)|[uninfo](https://github.com/kzkadc/uninfo)|\n", "2505.12944": "|[calm-pde: continuous and adaptive convolutions for latent space modeling of time-dependent pdes](https://arxiv.org/abs/2505.12944)|[calm-pde](https://github.com/jhagnberger/calm-pde)|\n", "2505.12998": "|[a skull-adaptive framework for ai-based 3d transcranial focused ultrasound simulation](https://arxiv.org/abs/2505.12998)|[tfuscapes](https://github.com/camma-public/tfuscapes)|\n", "2505.12999": "|[a generalisable head mri defacing pipeline: evaluation on 2,566 meningioma scans](https://arxiv.org/abs/2505.12999)|[defacing_pipeline](https://github.com/cai4cai/defacing_pipeline)|\n", "2505.13010": "|[to bias or not to bias: detecting bias in news with bias-detector](https://arxiv.org/abs/2505.13010)|[newsbiasdetector](https://github.com/himel1996/newsbiasdetector)|\n", "2505.13032": "|[mmar: a challenging benchmark for deep reasoning in speech, audio, music, and their mix](https://arxiv.org/abs/2505.13032)|[mmar](https://github.com/ddlbojack/mmar)|\n", "2505.13088": "|[cross-modal feature fusion for robust point cloud registration with ambiguous geometry](https://arxiv.org/abs/2505.13088)|[coff](https://github.com/zhaoyiww/coff)|\n", "2505.13137": "|[learning to adapt to position bias in vision transformer classifiers](https://arxiv.org/abs/2505.13137)|[position-shap](https://github.com/rjbruin/position-shap)|\n", "2505.13152": "|[higher fidelity perceptual image and video compression with a latent conditioned residual denoising diffusion model](https://arxiv.org/abs/2505.13152)|[rescdc](https://github.com/jbrenig/rescdc)|\n", "2505.13201": "|[matpredict: a dataset and benchmark for learning material properties of diverse indoor objects](https://arxiv.org/abs/2505.13201)|[matpredict](https://github.com/arpan-kusari/matpredict)|\n", "2505.13211": "|[magi-1: autoregressive video generation at scale](https://arxiv.org/abs/2505.13211)|[magiattention](https://github.com/sandai-org/magiattention)|\n", "2505.13215": "|[hybrid 3d-4d gaussian splatting for fast dynamic scene representation](https://arxiv.org/abs/2505.13215)|[3D-4DGS](https://github.com/ohsngjun/3D-4DGS)|\n", "2505.13218": "|[human response to decision support in face matching: the influence of task difficulty and machine accuracy](https://arxiv.org/abs/2505.13218)|[humanresponse-dss-facematching](https://github.com/ealmenzar/humanresponse-dss-facematching)|\n", "2505.13233": "|[from local details to global context: advancing vision-language models with attention-based selection](https://arxiv.org/abs/2505.13233)|[abs](https://github.com/bit-da/abs)|\n", "2505.13235": "|[writevit: handwritten text generation with vision transformer](https://arxiv.org/abs/2505.13235)|[writevit](https://github.com/hnam-1765/writevit)|\n", "2505.13307": "|[rbf++: quantifying and optimizing reasoning boundaries across measurable and unmeasurable capabilities for chain-of-thought reasoning](https://arxiv.org/abs/2505.13307)|[reasoning-boundary](https://github.com/lightchen233/reasoning-boundary)|\n", "2505.13316": "|[denoising diffusion probabilistic model for point cloud compression at low bit-rates](https://arxiv.org/abs/2505.13316)|[ddpm-pcc](https://github.com/eidoslab/ddpm-pcc)|\n", "2505.13390": "|[mgpbd: a multigrid accelerated global xpbd solver](https://arxiv.org/abs/2505.13390)|[mgpbd](https://github.com/chunleili/mgpbd)|\n", "2505.13419": "|[feallm: advancing facial emotion analysis in multimodal large language models with emotional synergy and reasoning](https://arxiv.org/abs/2505.13419)|[feallm](https://github.com/953206211/feallm)|\n", "2505.13426": "|[g1: bootstrapping perception and reasoning abilities of vision-language model via reinforcement learning](https://arxiv.org/abs/2505.13426)|[g1](https://github.com/chenllliang/g1)|\n", "2505.13427": "|[mm-prm: enhancing multimodal mathematical reasoning with scalable step-level supervision](https://arxiv.org/abs/2505.13427)|[mm-prm](https://github.com/modalminds/mm-prm)|\n", "2505.13439": "|[vtbench: evaluating visual tokenizers for autoregressive image generation](https://arxiv.org/abs/2505.13439)|[VTBench](https://github.com/huawei-lin/VTBench)|\n", "2505.13440": "|[recollection from pensieve: novel view synthesis via learning from uncalibrated videos](https://arxiv.org/abs/2505.13440)|[pensieve](https://github.com/dwawayu/pensieve)|\n"}, "2025-05-21": {"2301.05191": "|[a unified framework for event-based frame interpolation with ad-hoc deblurring in the wild](https://arxiv.org/abs/2301.05191)|[refid](https://github.com/ahupujr/refid)|\n", "2305.04095": "|[gradient leakage defense with key-lock module for federated learning](https://arxiv.org/abs/2305.04095)|[fedkl](https://github.com/rand2ai/fedkl)|\n", "2311.00721": "|[empathy detection from text, audiovisual, audio or physiological signals: a systematic review of task formulations and machine learning methods](https://arxiv.org/abs/2311.00721)|[boolean-search-bib-abstract](https://github.com/hasan-rakibul/boolean-search-bib-abstract)|\n", "2311.16515": "|[automatic synthetic data and fine-grained adaptive feature alignment for composed person retrieval](https://arxiv.org/abs/2311.16515)|[Word4Per](https://github.com/Delong-liu-bupt/Word4Per)|\n", "2403.11083": "|[customizing visual-language foundation models for multi-modal anomaly detection and reasoning](https://arxiv.org/abs/2403.11083)|[customizable-vlm](https://github.com/xiaohao-xu/customizable-vlm)|\n", "2405.14979": "|[craftsman3d: high-fidelity mesh generation with 3d native generation and interactive geometry refiner](https://arxiv.org/abs/2405.14979)|[craftsman](https://github.com/wyysf-98/craftsman)|\n", "2407.10707": "|[interactive rendering of relightable and animatable gaussian avatars](https://arxiv.org/abs/2407.10707)|[interactraga](https://github.com/1231234zhan/interactraga)|\n", "2407.11850": "|[spacejam: a lightweight and regularization-free method for fast joint alignment of images](https://arxiv.org/abs/2407.11850)|[SpaceJAM](https://github.com/BGU-CS-VIL/SpaceJAM)|\n", "2407.19451": "|[perm: a parametric representation for multi-style 3d hair modeling](https://arxiv.org/abs/2407.19451)|[perm](https://github.com/c-he/perm)|\n", "2408.07337": "|[kind: knowledge integration and diversion for training decomposable models](https://arxiv.org/abs/2408.07337)|[kind](https://github.com/te4p0t/kind)|\n", "2409.09451": "|[on the generalizability of foundation models for crop type mapping](https://arxiv.org/abs/2409.09451)|[crop-type-transfer-learning](https://github.com/yichiac/crop-type-transfer-learning)|\n", "2409.11726": "|[revealing and mitigating the challenge of detecting character knowledge errors in llm role-playing](https://arxiv.org/abs/2409.11726)|[rp_kw_errors](https://github.com/wyripple/rp_kw_errors)|\n", "2411.15633": "|[orthogonal subspace decomposition for generalizable ai-generated image detection](https://arxiv.org/abs/2411.15633)|[effort-aigi-detection](https://github.com/yzy-stack/effort-aigi-detection)|\n", "2412.02508": "|[towards rich emotions in 3d avatars: a text-to-3d avatar generation benchmark](https://arxiv.org/abs/2412.02508)|[emoava](https://github.com/walkermitty/emoava)|\n", "2412.12974": "|[attentive eraser: unleashing diffusion model's object removal potential via self-attention redirection guidance](https://arxiv.org/abs/2412.12974)|[attentiveeraser](https://github.com/anonym0u3/attentiveeraser)|\n", "2501.02040": "|[a separable self-attention inspired by the state space model for computer vision](https://arxiv.org/abs/2501.02040)|[vminet](https://github.com/yws-wxs/vminet)|\n", "2501.03757": "|[neuroincept decoder for high-fidelity speech reconstruction from neural activity](https://arxiv.org/abs/2501.03757)|[NeuroInceptDecoder](https://github.com/owaismujtaba/NeuroInceptDecoder)|\n", "2501.12368": "|[internlm-xcomposer2.5-reward: a simple yet effective multi-modal reward model](https://arxiv.org/abs/2501.12368)|[internlm-xcomposer](https://github.com/internlm/internlm-xcomposer)|\n", "2502.01051": "|[diffusion model as a noise-aware latent reward model for step-level preference optimization](https://arxiv.org/abs/2502.01051)|[lpo](https://github.com/kwai-kolors/lpo)|\n", "2502.02171": "|[deepforest: sensing into self-occluding volumes of vegetation with aerial imaging](https://arxiv.org/abs/2502.02171)|[DeepForest-Sensing-Into-Self-Occluding-Volumes-of-Vegetation-With-Aerial-Imaging](https://github.com/mohamedhaiham94/DeepForest-Sensing-Into-Self-Occluding-Volumes-of-Vegetation-With-Aerial-Imaging)|\n", "2502.05505": "|[differentially private synthetic data via apis 3: using simulators instead of foundation model](https://arxiv.org/abs/2502.05505)|[dpsda](https://github.com/microsoft/dpsda)|\n", "2502.11163": "|[vlms as geoguessr masters: exceptional performance, hidden biases, and privacy risks](https://arxiv.org/abs/2502.11163)|[fairlocator](https://github.com/uscnlp-lime/fairlocator)|\n", "2502.13146": "|[re-align: aligning vision language models via retrieval-augmented direct preference optimization](https://arxiv.org/abs/2502.13146)|[re-align](https://github.com/taco-group/re-align)|\n", "2503.01776": "|[beyond matryoshka: revisiting sparse coding for adaptive representation](https://arxiv.org/abs/2503.01776)|[CSR_Adaptive_Rep](https://github.com/neilwen987/CSR_Adaptive_Rep)|\n", "2503.07035": "|[universal incremental learning: mitigating confusion from inter- and intra-task distribution randomness](https://arxiv.org/abs/2503.07035)|[uil](https://github.com/rolsheng/uil)|\n", "2503.07575": "|[visbias: measuring explicit and implicit social biases in vision language models](https://arxiv.org/abs/2503.07575)|[visbias](https://github.com/uscnlp-lime/visbias)|\n", "2503.11094": "|[open3dvqa: a benchmark for comprehensive spatial reasoning with multimodal large language model in open space](https://arxiv.org/abs/2503.11094)|[open3dvqa](https://github.com/weichenzh/open3dvqa)|\n", "2503.16282": "|[generalized few-shot 3d point cloud segmentation with vision-language model](https://arxiv.org/abs/2503.16282)|[gfs-vl](https://github.com/zhaochongan/gfs-vl)|\n", "2503.16505": "|[scalable evaluation of online facilitation strategies via synthetic simulation of discussions](https://arxiv.org/abs/2503.16505)|[synthetic_moderation_experiments](https://github.com/dimits-ts/synthetic_moderation_experiments)|\n", "2504.14440": "|[sg-reg: generalizable and efficient scene graph registration](https://arxiv.org/abs/2504.14440)|[sg-reg](https://github.com/hkust-aerial-robotics/sg-reg)|\n", "2504.14783": "|[how effective can dropout be in multiple instance learning ?](https://arxiv.org/abs/2504.14783)|[mildropout](https://github.com/chongqingnosubway/mildropout)|\n", "2504.17821": "|[videovista-culturallingo: 360$^\\circ$ horizons-bridging cultures, languages, and domains in video comprehension](https://arxiv.org/abs/2504.17821)|[videovista](https://github.com/hitsz-tmg/videovista)|\n", "2505.04058": "|[as3d: 2d-assisted cross-modal understanding with semantic-spatial scene graphs for 3d visual grounding](https://arxiv.org/abs/2505.04058)|[AS3D](https://github.com/onmyoji-xiao/AS3D)|\n", "2505.04612": "|[fastmap: revisiting dense and scalable structure from motion](https://arxiv.org/abs/2505.04612)|[fastmap](https://github.com/pals-ttic/fastmap)|\n", "2505.06699": "|[model steering: learning with a reference model improves generalization bounds and scaling laws](https://arxiv.org/abs/2505.06699)|[drrho-clip](https://github.com/optimization-ai/drrho-clip)|\n", "2505.07447": "|[unified continuous generative models](https://arxiv.org/abs/2505.07447)|[UCGM](https://github.com/LINs-Lab/UCGM)|\n", "2505.08175": "|[fast text-to-audio generation with adversarial post-training](https://arxiv.org/abs/2505.08175)|[stable-audio-tools](https://github.com/stability-ai/stable-audio-tools)|\n", "2505.10238": "|[mtvcrafter: 4d motion tokenization for open-world human image animation](https://arxiv.org/abs/2505.10238)|[mtvcrafter](https://github.com/dingyanb/mtvcrafter)|\n", "2505.10464": "|[hwa-unetr: hierarchical window aggregate unetr for 3d multimodal gastric lesion segmentation](https://arxiv.org/abs/2505.10464)|[hwa-unetr](https://github.com/jeming-creater/hwa-unetr)|\n", "2505.12427": "|[draglora: online optimization of lora adapters for drag-based image editing in diffusion model](https://arxiv.org/abs/2505.12427)|[draglora](https://github.com/sylvie-x/draglora)|\n", "2505.12482": "|[spectral-spatial self-supervised learning for few-shot hyperspectral image classification](https://arxiv.org/abs/2505.12482)|[s4l-fsc](https://github.com/wenchen-chen/s4l-fsc)|\n", "2505.12499": "|[contrastive alignment with semantic gap-aware corrections in text-video retrieval](https://arxiv.org/abs/2505.12499)|[gare-text-video-retrieval](https://github.com/musicman217/gare-text-video-retrieval)|\n", "2505.13232": "|[starft: robust fine-tuning of zero-shot models via spuriosity alignment](https://arxiv.org/abs/2505.13232)|[starft](https://github.com/alinlab/starft)|\n", "2505.13483": "|[emometa: a multimodal dataset for fine-grained emotion classification in chinese metaphors](https://arxiv.org/abs/2505.13483)|[emometa](https://github.com/dutir-ysq/emometa)|\n", "2505.13539": "|[eulearn: a 3d database for learning euler characteristics](https://arxiv.org/abs/2505.13539)|[eulearn_db](https://github.com/appliedgeometry/eulearn_db)|\n", "2505.13669": "|[geovlm: improving automated vehicle geolocalisation using vision-language matching](https://arxiv.org/abs/2505.13669)|[geovlm](https://github.com/cav-research-lab/geovlm)|\n", "2505.13773": "|[model cards for ai teammates: comparing human-ai team familiarization methods for high-stakes environments](https://arxiv.org/abs/2505.13773)|[maisr](https://github.com/gt-cec/maisr)|\n", "2505.13784": "|[transfer learning from visual speech recognition to mouthing recognition in german sign language](https://arxiv.org/abs/2505.13784)|[transfer-learning-vsr-mouthing-sign-language](https://github.com/nphamdinh/transfer-learning-vsr-mouthing-sign-language)|\n", "2505.13813": "|[flashkat: understanding and addressing performance bottlenecks in the kolmogorov-arnold transformer](https://arxiv.org/abs/2505.13813)|[flashkat](https://github.com/osu-starlab/flashkat)|\n", "2505.13839": "|[mgstream: motion-aware 3d gaussian for streamable dynamic scene reconstruction](https://arxiv.org/abs/2505.13839)|[mgstream](https://github.com/pcl3dv/mgstream)|\n", "2505.13906": "|[xdementnet: an explainable attention based deep convolutional network to detect alzheimer progression from mri data](https://arxiv.org/abs/2505.13906)|[XdementNET](https://github.com/SoyabulIslamLincoln/XdementNET)|\n", "2505.13928": "|[lovr: a benchmark for long video retrieval in multimodal contexts](https://arxiv.org/abs/2505.13928)|[lovr-benchmark](https://github.com/technomad-ds/lovr-benchmark)|\n", "2505.14008": "|[multi-label stereo matching for transparent scene depth estimation](https://arxiv.org/abs/2505.14008)|[TranScene](https://github.com/BFZD233/TranScene)|\n", "2505.14017": "|[end-to-end cortical surface reconstruction from clinical magnetic resonance images](https://arxiv.org/abs/2505.14017)|[brainnet](https://github.com/simnibs/brainnet)|\n", "2505.14042": "|[adversarially pretrained transformers may be universally robust in-context learners](https://arxiv.org/abs/2505.14042)|[universally-robust-in-context-learner](https://github.com/s-kumano/universally-robust-in-context-learner)|\n", "2505.14049": "|[learning concept-driven logical rules for interpretable and generalizable medical image classification](https://arxiv.org/abs/2505.14049)|[crl](https://github.com/obiyoag/crl)|\n", "2505.14059": "|[dolphin: document image parsing via heterogeneous anchor prompting](https://arxiv.org/abs/2505.14059)|[dolphin](https://github.com/bytedance/dolphin)|\n", "2505.14124": "|[intra-class patch swap for self-distillation](https://arxiv.org/abs/2505.14124)|[intra-class-patch-swap](https://github.com/hchoi71/intra-class-patch-swap)|\n", "2505.14246": "|[visual agentic reinforcement fine-tuning](https://arxiv.org/abs/2505.14246)|[visual-rft](https://github.com/liuziyu77/visual-rft)|\n", "2505.14254": "|[instructing text-to-image diffusion models via classifier-guided semantic optimization](https://arxiv.org/abs/2505.14254)|[caso](https://github.com/chang-yuanyuan/caso)|\n", "2505.14260": "|[speculative decoding reimagined for multimodal large language models](https://arxiv.org/abs/2505.14260)|[msd](https://github.com/lyn-lucy/msd)|\n", "2505.14318": "|[radar: enhancing radiology report generation with supplementary knowledge injection](https://arxiv.org/abs/2505.14318)|[Radar](https://github.com/wjhou/Radar)|\n", "2505.14329": "|[tf-mamba: text-enhanced fusion mamba with missing modalities for robust multimodal sentiment analysis](https://arxiv.org/abs/2505.14329)|[tf-mamba](https://github.com/codemous/tf-mamba)|\n", "2505.14333": "|[domain adaptation for multi-label image classification: a discriminator-free approach](https://arxiv.org/abs/2505.14333)|[dda-mlic](https://github.com/cvi2snt/dda-mlic)|\n", "2505.14346": "|[egocentric action-aware inertial localization in point clouds](https://arxiv.org/abs/2505.14346)|[ego-inertial-localization](https://github.com/mf-zhang/ego-inertial-localization)|\n", "2505.14362": "|[deepeyes: incentivizing \"thinking with images\" via reinforcement learning](https://arxiv.org/abs/2505.14362)|[deepeyes](https://github.com/visual-agent/deepeyes)|\n", "2505.14377": "|[when bias backfires: the modulatory role of counterfactual explanations on the adoption of algorithmic bias in xai-supported human decision-making](https://arxiv.org/abs/2505.14377)|[biasbackfiresxai2025](https://github.com/ukuhl/biasbackfiresxai2025)|\n", "2505.14414": "|[diving into the fusion of monocular priors for generalized stereo matching](https://arxiv.org/abs/2505.14414)|[Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching](https://github.com/YaoChengTang/Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching)|\n", "2505.14454": "|[video compression commander: plug-and-play inference acceleration for video large language models](https://arxiv.org/abs/2505.14454)|[vidcom2](https://github.com/xuyang-liu16/vidcom2)|\n", "2505.14460": "|[visualquality-r1: reasoning-induced image quality assessment via reinforcement learning to rank](https://arxiv.org/abs/2505.14460)|[visualquality-r1](https://github.com/tianhewu/visualquality-r1)|\n", "2505.14462": "|[ravenea: a benchmark for multimodal retrieval-augmented visual culture understanding](https://arxiv.org/abs/2505.14462)|[ravenea](https://github.com/yfyuan01/ravenea)|\n", "2505.14556": "|[dynadiff: single-stage decoding of images from continuously evolving fmri](https://arxiv.org/abs/2505.14556)|[dynadiff](https://github.com/facebookresearch/dynadiff)|\n", "2505.14629": "|[kerl: knowledge-enhanced personalized recipe recommendation using large language models](https://arxiv.org/abs/2505.14629)|[kerl](https://github.com/mohbattharani/kerl)|\n", "2505.14633": "|[will ai tell lies to save sick children? litmus-testing ai values prioritization with airiskdilemmas](https://arxiv.org/abs/2505.14633)|[litmusvalues](https://github.com/kellycyy/litmusvalues)|\n", "2505.14638": "|[dual precision quantization for efficient and accurate deep neural networks inference](https://arxiv.org/abs/2505.14638)|[neural-compressor](https://github.com/intel/neural-compressor)|\n", "2505.14646": "|[cad-coder: an open-source vision-language model for computer-aided design code generation](https://arxiv.org/abs/2505.14646)|[cad-coder](https://github.com/anniedoris/cad-coder)|\n", "2505.14664": "|[akrmap: adaptive kernel regression for trustworthy visualization of cross-modal embeddings](https://arxiv.org/abs/2505.14664)|[akrmap](https://github.com/yilinye/akrmap)|\n", "2505.14687": "|[grouping first, attending smartly: training-free acceleration for diffusion transformers](https://arxiv.org/abs/2505.14687)|[grat](https://github.com/oliverrensu/grat)|\n"}, "2025-05-22": {"2108.08532": "|[an information theory-inspired strategy for automatic network pruning](https://arxiv.org/abs/2108.08532)|[itpruner](https://github.com/mac-automl/itpruner)|\n", "2309.02244": "|[augmenting chest x-ray datasets with non-expert annotations](https://arxiv.org/abs/2309.02244)|[chestxr-label-reliability](https://github.com/purrlab/chestxr-label-reliability)|\n", "2310.06488": "|[spikeclip: a contrastive language-image pretrained spiking neural network](https://arxiv.org/abs/2310.06488)|[spikeclip](https://github.com/lvchangze/spikeclip)|\n", "2310.10224": "|[generalizing medical image representations via quaternion wavelet networks](https://arxiv.org/abs/2310.10224)|[QWT](https://github.com/ispamm/QWT)|\n", "2401.16991": "|[category-wise fine-tuning: resisting incorrect pseudo-labels in multi-label image classification with partial labels](https://arxiv.org/abs/2401.16991)|[category-wise-fine-tuning](https://github.com/maxium0526/category-wise-fine-tuning)|\n", "2404.14955": "|[a comprehensive survey for hyperspectral image classification: the evolution from conventional to transformers and mamba models](https://arxiv.org/abs/2404.14955)|[conventional-to-transformer-for-hyperspectral-image-classification-survey-2024](https://github.com/mahmad00/conventional-to-transformer-for-hyperspectral-image-classification-survey-2024)|\n", "2406.12030": "|[spa-vl: a comprehensive safety preference alignment dataset for vision language model](https://arxiv.org/abs/2406.12030)|[spa-vl-rlhf](https://github.com/echosechen/spa-vl-rlhf)|\n", "2406.18443": "|[boosting few-shot open-set object detection via prompt learning and robust decision boundary](https://arxiv.org/abs/2406.18443)|[ced-food](https://github.com/zjzwzw/ced-food)|\n", "2407.08800": "|[local clustering for lung cancer image classification via sparse solution technique](https://arxiv.org/abs/2407.08800)|[LocalClustering4LungCancer](https://github.com/zzzzms/LocalClustering4LungCancer)|\n", "2408.10007": "|[p3p: pseudo-3d pre-training for scaling 3d voxel-based masked autoencoders](https://arxiv.org/abs/2408.10007)|[p3p-mae](https://github.com/xuechaochen/p3p-mae)|\n", "2409.06000": "|[rayflex: an open-source rtl implementation of the hardware ray tracer datapath](https://arxiv.org/abs/2409.06000)|[rayflex](https://github.com/purdue-aalp/rayflex)|\n", "2409.07098": "|[diversity-driven view subset selection for indoor novel view synthesis](https://arxiv.org/abs/2409.07098)|[indoortraj](https://github.com/zehao-wang/indoortraj)|\n", "2409.07267": "|[minidrive: more efficient vision-language models with multi-level 2d features as text tokens for autonomous driving](https://arxiv.org/abs/2409.07267)|[minidrive](https://github.com/emzucas/minidrive)|\n", "2409.07571": "|[favor: features via voxel rendering for camera relocalization](https://arxiv.org/abs/2409.07571)|[FaVoR](https://github.com/utiasSTARS/FaVoR)|\n", "2409.12108": "|[sprmamba: surgical phase recognition for endoscopic submucosal dissection with mamba](https://arxiv.org/abs/2409.12108)|[sprmamba](https://github.com/zxnyyyyy/sprmamba)|\n", "2409.15477": "|[mediconfusion: can you trust your ai radiologist? probing the reliability of multimodal medical foundation models](https://arxiv.org/abs/2409.15477)|[MediConfusion](https://github.com/AIF4S/MediConfusion)|\n", "2411.08334": "|[mire: enhancing multimodal queries representation via fusion-free modality interaction for multimodal retrieval](https://arxiv.org/abs/2411.08334)|[mire](https://github.com/yeongjoonju/mire)|\n", "2411.10316": "|[m3tr: a generalist model for real-world hd map completion](https://arxiv.org/abs/2411.10316)|[m3tr](https://github.com/immel-f/m3tr)|\n", "2411.16375": "|[ca2-vdm: efficient autoregressive video diffusion model with causal generation and cache sharing](https://arxiv.org/abs/2411.16375)|[causalcache-vdm](https://github.com/dawn-lx/causalcache-vdm)|\n", "2412.03378": "|[volumetrically consistent 3d gaussian rasterization](https://arxiv.org/abs/2412.03378)|[Vol3DGS](https://github.com/chinmay0301ucsd/Vol3DGS)|\n", "2412.06141": "|[mmedpo: aligning medical vision-language models with clinical-aware multimodal preference optimization](https://arxiv.org/abs/2412.06141)|[mmedpo](https://github.com/aiming-lab/mmedpo)|\n", "2412.17806": "|[reconstructing people, places, and cameras](https://arxiv.org/abs/2412.17806)|[hsfm_release](https://github.com/hongsukchoi/hsfm_release)|\n", "2412.18884": "|[hv-bev: decoupling horizontal and vertical feature sampling for multi-view 3d object detection](https://arxiv.org/abs/2412.18884)|[hv-bev](https://github.com/uddd821/hv-bev)|\n", "2502.01081": "|[the jumping reasoning curve? tracking the evolution of reasoning performance in gpt-[n] and o-[n] models on multimodal puzzles](https://arxiv.org/abs/2502.01081)|[llm-puzzletest](https://github.com/declare-lab/llm-puzzletest)|\n", "2502.03654": "|[gompertz linear units: leveraging asymmetry for enhanced learning dynamics](https://arxiv.org/abs/2502.03654)|[GoLU](https://github.com/automl/GoLU)|\n", "2502.12562": "|[sea: low-resource safety alignment for multimodal large language models via synthetic embeddings](https://arxiv.org/abs/2502.12562)|[sea](https://github.com/zeronlp/sea)|\n", "2502.17429": "|[climb-3d: continual learning for imbalanced 3d instance segmentation](https://arxiv.org/abs/2502.17429)|[climb3d](https://github.com/vgthengane/climb3d)|\n", "2504.01805": "|[spacer: reinforcing mllms in video spatial reasoning](https://arxiv.org/abs/2504.01805)|[spacer](https://github.com/ouyangkun10/spacer)|\n", "2504.12739": "|[mask image watermarking](https://arxiv.org/abs/2504.12739)|[maskmark](https://github.com/hurunyi/maskmark)|\n", "2504.20930": "|[chestx-reasoner: advancing radiology foundation models with reasoning through step-by-step verification](https://arxiv.org/abs/2504.20930)|[ChestX-Reasoner](https://github.com/MAGIC-AI4Med/ChestX-Reasoner)|\n", "2505.01237": "|[cav-mae sync: improving contrastive audio-visual mask autoencoders via fine-grained alignment](https://arxiv.org/abs/2505.01237)|[cav-mae-sync](https://github.com/edsonroteia/cav-mae-sync)|\n", "2505.04046": "|[reliable disentanglement multi-view learning against view adversarial attacks](https://arxiv.org/abs/2505.04046)|[2025-IJCAI-RDML](https://github.com/Willy1005/2025-IJCAI-RDML)|\n", "2505.04788": "|[convex relaxation for robust vanishing point estimation in manhattan world](https://arxiv.org/abs/2505.04788)|[globustvp](https://github.com/wu-cvgl/globustvp)|\n", "2505.05049": "|[uncertainsam: fast and efficient uncertainty quantification of the segment anything model](https://arxiv.org/abs/2505.05049)|[UncertainSAM](https://github.com/GreenAutoML4FAS/UncertainSAM)|\n", "2505.05071": "|[fg-clip: fine-grained visual and textual alignment](https://arxiv.org/abs/2505.05071)|[fg-clip](https://github.com/360cvgroup/fg-clip)|\n", "2505.12620": "|[busterx: mllm-powered ai-generated video forgery detection and explanation](https://arxiv.org/abs/2505.12620)|[busterx](https://github.com/l8cv/busterx)|\n", "2505.13300": "|[dd-ranking: rethinking the evaluation of dataset distillation](https://arxiv.org/abs/2505.13300)|[dd-ranking](https://github.com/nus-hpc-ai-lab/dd-ranking)|\n", "2505.14074": "|[recreating neural activity during speech production with language and speech model embeddings](https://arxiv.org/abs/2505.14074)|[llm_brain_representations](https://github.com/owaismujtaba/llm_brain_representations)|\n", "2505.14100": "|[unlocking the power of sam 2 for few-shot segmentation](https://arxiv.org/abs/2505.14100)|[fssam](https://github.com/sam1224/fssam)|\n", "2505.14707": "|[crypticbio: a large multimodal dataset for visually confusing biodiversity](https://arxiv.org/abs/2505.14707)|[crypticbio](https://github.com/georgianagmanolache/crypticbio)|\n", "2505.14708": "|[draftattention: fast video diffusion via low-resolution attention guidance](https://arxiv.org/abs/2505.14708)|[draft-attention](https://github.com/shawnricecake/draft-attention)|\n", "2505.14709": "|[fastcar: cache attentive replay for fast auto-regressive video generation on the edge](https://arxiv.org/abs/2505.14709)|[fast-car](https://github.com/shawnricecake/fast-car)|\n", "2505.14714": "|[kgalign: joint semantic-structural knowledge encoding for multimodal fake news detection](https://arxiv.org/abs/2505.14714)|[kgalign](https://github.com/latuanvinh1998/kgalign)|\n", "2505.14717": "|[aneumo: a large-scale multimodal aneurysm dataset with computational fluid dynamics simulations and deep learning benchmarks](https://arxiv.org/abs/2505.14717)|[aneumo](https://github.com/xigui-li/aneumo)|\n", "2505.14747": "|[lod1 3d city model from lidar: the impact of segmentation accuracy on quality of urban 3d modeling and morphology extraction](https://arxiv.org/abs/2505.14747)|[LiDAR-3D-Building-Modeling](https://github.com/FatemehCh97/LiDAR-3D-Building-Modeling)|\n", "2505.14846": "|[open-set semi-supervised learning for long-tailed medical datasets](https://arxiv.org/abs/2505.14846)|[openltr](https://github.com/daniyanaj/openltr)|\n", "2505.14931": "|[colors matter: ai-driven exploration of human feature colors](https://arxiv.org/abs/2505.14931)|[Color-Matters-AI-Driven-Exploration-of-Human-Feature-Coloration](https://github.com/AiTaif7/Color-Matters-AI-Driven-Exploration-of-Human-Feature-Coloration)|\n", "2505.14948": "|[programmatic video prediction using large language models](https://arxiv.org/abs/2505.14948)|[ProgGen](https://github.com/metro-smiles/ProgGen)|\n", "2505.14951": "|[multimae meets earth observation: pre-training multi-modal multi-task masked autoencoders for earth observation tasks](https://arxiv.org/abs/2505.14951)|[multimae-meets-eo](https://github.com/josesosajs/multimae-meets-eo)|\n", "2505.14983": "|[toward informed av decision-making: computational model of well-being and trust in mobility](https://arxiv.org/abs/2505.14983)|[wellbeing-trust-model](https://github.com/honda-research-institute/wellbeing-trust-model)|\n", "2505.15031": "|[are the confidence scores of reviewers consistent with the review content? evidence from top conference proceedings in ai](https://arxiv.org/abs/2505.15031)|[confidence_score](https://github.com/njust-winchy/confidence_score)|\n", "2505.15075": "|[traveling across languages: benchmarking cross-lingual consistency in multimodal llms](https://arxiv.org/abs/2505.15075)|[traveling-across-languages](https://github.com/nlp-waseda/traveling-across-languages)|\n", "2505.15111": "|[ipad: iterative proposal-centric end-to-end autonomous driving](https://arxiv.org/abs/2505.15111)|[iPad](https://github.com/Kguo-cs/iPad)|\n", "2505.15120": "|[lung nodule-ssm: self-supervised lung nodule detection and classification in thoracic ct images](https://arxiv.org/abs/2505.15120)|[lung-nodule-ssm-self-supervised-lung-nodule-detection-and-classification](https://github.com/emeraldsnrpu/lung-nodule-ssm-self-supervised-lung-nodule-detection-and-classification)|\n", "2505.15133": "|[deepkd: a deeply decoupled and denoised knowledge distillation trainer](https://arxiv.org/abs/2505.15133)|[deepkd](https://github.com/haiduo/deepkd)|\n", "2505.15145": "|[cinetechbench: a benchmark for cinematographic technique understanding and generation](https://arxiv.org/abs/2505.15145)|[cinetechbench](https://github.com/pris-cv/cinetechbench)|\n", "2505.15184": "|[auxdet: auxiliary metadata matters for omni-domain infrared small target detection](https://arxiv.org/abs/2505.15184)|[auxdet](https://github.com/grokcv/auxdet)|\n", "2505.15185": "|[monosplat: generalizable 3d gaussian splatting from monocular depth foundation models](https://arxiv.org/abs/2505.15185)|[monosplat](https://github.com/cuhk-aim-group/monosplat)|\n", "2505.15217": "|[multimodal conditional information bottleneck for generalizable ai-generated image detection](https://arxiv.org/abs/2505.15217)|[infofd](https://github.com/ant0ny44/infofd)|\n", "2505.15232": "|[dc-scene: data-centric learning for 3d scene understanding](https://arxiv.org/abs/2505.15232)|[dc-scene](https://github.com/aigeeksgroup/dc-scene)|\n", "2505.15234": "|[sama-unet: enhancing medical image segmentation with self-adaptive mamba-like attention and causal-resonance learning](https://arxiv.org/abs/2505.15234)|[SAMA-UNet](https://github.com/sqbqamar/SAMA-UNet)|\n", "2505.15270": "|[scaling diffusion transformers efficiently via $\\mu$p](https://arxiv.org/abs/2505.15270)|[Scaling-Diffusion-Transformers-muP](https://github.com/ML-GSAI/Scaling-Diffusion-Transformers-muP)|\n", "2505.15272": "|[diffprob: data pruning for face recognition](https://arxiv.org/abs/2505.15272)|[DiffProb](https://github.com/EduardaCaldeira/DiffProb)|\n", "2505.15282": "|[exploring in-image machine translation with real-world background](https://arxiv.org/abs/2505.15282)|[debackx](https://github.com/bithlp/debackx)|\n", "2505.15284": "|[kernel pca for out-of-distribution detection: non-linear kernel selections and approximations](https://arxiv.org/abs/2505.15284)|[ood-kpca-extension](https://github.com/fanghenshaometeor/ood-kpca-extension)|\n", "2505.15325": "|[softhgnn: soft hypergraph neural networks for general visual recognition](https://arxiv.org/abs/2505.15325)|[SoftHGNN](https://github.com/Mengqi-Lei/SoftHGNN)|\n", "2505.15364": "|[mhanet: multi-scale hybrid attention network for auditory attention detection](https://arxiv.org/abs/2505.15364)|[mhanet](https://github.com/fchest/mhanet)|\n", "2505.15379": "|[the p$^3$ dataset: pixels, points and polygons for multimodal building vectorization](https://arxiv.org/abs/2505.15379)|[pixelspointspolygons](https://github.com/raphaelsulzer/pixelspointspolygons)|\n", "2505.15435": "|[timecausality: evaluating the causal ability in time dimension for vision language models](https://arxiv.org/abs/2505.15435)|[timecausality](https://github.com/zeqing-wang/timecausality)|\n", "2505.15506": "|[prompt tuning vision language models with margin regularizer for few-shot learning under distribution shifts](https://arxiv.org/abs/2505.15506)|[promptmargin](https://github.com/debarshigit/promptmargin)|\n", "2505.15545": "|[seg_3d_by_pc2d: multi-view projection for domain generalization and adaptation in 3d semantic segmentation](https://arxiv.org/abs/2505.15545)|[ia4markings](https://github.com/andrewcaunes/ia4markings)|\n", "2505.15576": "|[visual perturbation and adaptive hard negative contrastive learning for compositional reasoning in vision-language models](https://arxiv.org/abs/2505.15576)|[ahnpl](https://github.com/nynu-bdai/ahnpl)|\n", "2505.15581": "|[uwsam: segment anything model guided underwater instance segmentation and a large-scale benchmark dataset](https://arxiv.org/abs/2505.15581)|[uiis10k](https://github.com/liamlian0727/uiis10k)|\n", "2505.15596": "|[exploring llm-generated feedback for economics essays: how teaching assistants evaluate and envision its use](https://arxiv.org/abs/2505.15596)|[aied2025-exploring-llm-generated-feedback-for-economics-essay](https://github.com/um-lifelong-learning-lab/aied2025-exploring-llm-generated-feedback-for-economics-essay)|\n", "2505.15628": "|[snap: a benchmark for testing the effects of capture conditions on fundamental vision tasks](https://arxiv.org/abs/2505.15628)|[snap](https://github.com/ykotseruba/snap)|\n", "2505.15637": "|[oral imaging for malocclusion issues assessments: omni dataset, deep learning baselines and benchmarking](https://arxiv.org/abs/2505.15637)|[omni](https://github.com/roundfacej/omni)|\n", "2505.15644": "|[fragfake: a dataset for fine-grained detection of edited images with vision language models](https://arxiv.org/abs/2505.15644)|[FragFake](https://github.com/Vincent-HKUSTGZ/FragFake)|\n", "2505.15649": "|[the devil is in fine-tuning and long-tailed problems:a new benchmark for scene text detection](https://arxiv.org/abs/2505.15649)|[ltb](https://github.com/pd162/ltb)|\n", "2505.15809": "|[mmada: multimodal large diffusion language models](https://arxiv.org/abs/2505.15809)|[mmada](https://github.com/gen-verse/mmada)|\n", "2505.15816": "|[streamline without sacrifice -- squeeze out computation redundancy in lmm](https://arxiv.org/abs/2505.15816)|[proxyv](https://github.com/penghao-wu/proxyv)|\n", "2505.15818": "|[instructsam: a training-free framework for instruction-oriented remote sensing object recognition](https://arxiv.org/abs/2505.15818)|[InstructSAM](https://github.com/VoyagerXvoyagerx/InstructSAM)|\n"}, "2025-05-23": {"2308.10800": "|[fact-checking information from large language models can decrease headline discernment](https://arxiv.org/abs/2308.10800)|[ai_fact_checking](https://github.com/osome-iu/ai_fact_checking)|\n", "2311.02960": "|[understanding deep representation learning via layerwise feature compression and discrimination](https://arxiv.org/abs/2311.02960)|[pnc_dln](https://github.com/heimine/pnc_dln)|\n", "2408.15966": "|[more text, less point: towards 3d data-efficient point-language understanding](https://arxiv.org/abs/2408.15966)|[greenplm](https://github.com/tangyuan96/greenplm)|\n", "2409.01109": "|[sood-imagenet: a large-scale dataset for semantic out-of-distribution image classification and semantic segmentation](https://arxiv.org/abs/2409.01109)|[SOODImageNet](https://github.com/bach05/SOODImageNet)|\n", "2409.01175": "|[logit scaling for out-of-distribution detection](https://arxiv.org/abs/2409.01175)|[lts](https://github.com/andrijazz/lts)|\n", "2410.19552": "|[geollava: efficient fine-tuned vision-language models for temporal change detection in remote sensing](https://arxiv.org/abs/2410.19552)|[GeoLLaVA](https://github.com/HosamGen/GeoLLaVA)|\n", "2411.03948": "|[long-form text-to-music generation with adaptive prompts: a case study in tabletop role-playing games soundtracks](https://arxiv.org/abs/2411.03948)|[babel-bardo](https://github.com/felipemarra/babel-bardo)|\n", "2411.06790": "|[large-scale moral machine experiment on large language models](https://arxiv.org/abs/2411.06790)|[mmllm](https://github.com/kztakemoto/mmllm)|\n", "2411.08701": "|[trace: transformer-based risk assessment for clinical evaluation](https://arxiv.org/abs/2411.08701)|[TRACE](https://github.com/DionysisChristopoulos/TRACE)|\n", "2412.02573": "|[remote sensing spatio-temporal vision-language models: a comprehensive survey](https://arxiv.org/abs/2412.02573)|[awesome-rs-temporal-vlm](https://github.com/chen-yang-liu/awesome-rs-temporal-vlm)|\n", "2412.02575": "|[copy-move forgery detection and question answering for remote sensing image](https://arxiv.org/abs/2412.02575)|[rscmqa](https://github.com/shenyedepisa/rscmqa)|\n", "2412.04030": "|[mask of truth: model sensitivity to unexpected regions of medical images](https://arxiv.org/abs/2412.04030)|[mmc_masking_eyefundus](https://github.com/theosourget/mmc_masking_eyefundus)|\n", "2412.10255": "|[anisora: exploring the frontiers of animation video generation in the sora era](https://arxiv.org/abs/2412.10255)|[index-anisora](https://github.com/bilibili/index-anisora)|\n", "2412.19125": "|[advanced knowledge transfer: refined feature distillation for zero-shot quantization in edge computing](https://arxiv.org/abs/2412.19125)|[AKT-Advanced-knowledge-Transfer](https://github.com/Inpyo-Hong/AKT-Advanced-knowledge-Transfer)|\n", "2412.20157": "|[unirestorer: universal image restoration via adaptively estimating image degradation at proper granularity](https://arxiv.org/abs/2412.20157)|[unirestorer](https://github.com/mrluin/unirestorer)|\n", "2412.20798": "|[reconciling privacy and explainability in high-stakes: a systematic inquiry](https://arxiv.org/abs/2412.20798)|[DP](https://github.com/humblef-oo-l/DP)|\n", "2501.08575": "|[gotpr: general outdoor text-based place recognition using scene graph retrieval with openstreetmap](https://arxiv.org/abs/2501.08575)|[gotloc](https://github.com/donghwijung/gotloc)|\n", "2501.15415": "|[ocsu: optical chemical structure understanding for molecule-centric scientific discovery](https://arxiv.org/abs/2501.15415)|[OCSU](https://github.com/PharMolix/OCSU)|\n", "2501.17983": "|[efficient feature fusion for uav object detection](https://arxiv.org/abs/2501.17983)|[fmsa](https://github.com/gamepai0811/fmsa)|\n", "2502.01218": "|[provable ordering and continuity in vision-language pretraining for generalizable embodied agents](https://arxiv.org/abs/2502.01218)|[actol](https://github.com/daisy-zzz/actol)|\n", "2502.18225": "|[liver cirrhosis stage estimation from mri with deep learning](https://arxiv.org/abs/2502.18225)|[cirrhosisstage](https://github.com/junzengz/cirrhosisstage)|\n", "2503.01222": "|[retrieval-augmented perception: high-resolution image perception meets visual rag](https://arxiv.org/abs/2503.01222)|[rap](https://github.com/dreammr/rap)|\n", "2503.03637": "|[l2rdas: synthesizing 4d radar tensors for model generalization via dataset expansion](https://arxiv.org/abs/2503.03637)|[k-radar](https://github.com/kaist-avelab/k-radar)|\n", "2503.03644": "|[dongbamie: a multimodal information extraction dataset for evaluating semantic understanding of dongba pictograms](https://arxiv.org/abs/2503.03644)|[dongbamie](https://github.com/thinklis/dongbamie)|\n", "2503.09499": "|[mindgym: what matters in question synthesis for thinking-centric fine-tuning?](https://arxiv.org/abs/2503.09499)|[data-juicer](https://github.com/modelscope/data-juicer)|\n", "2503.11787": "|[eclare: efficient cross-planar learning for anisotropic resolution enhancement](https://arxiv.org/abs/2503.11787)|[eclare](https://github.com/sremedios/eclare)|\n", "2505.02567": "|[unified multimodal understanding and generation models: advances, challenges, and opportunities](https://arxiv.org/abs/2505.02567)|[awesome-unified-multimodal-models](https://github.com/aidc-ai/awesome-unified-multimodal-models)|\n", "2505.10049": "|[advances in radiance field for dynamic scene: from neural field to gaussian field](https://arxiv.org/abs/2505.10049)|[dynamic-radiation-field-paper-list](https://github.com/moonflo/dynamic-radiation-field-paper-list)|\n", "2505.10250": "|[adhmr: aligning diffusion-based human mesh recovery via direct preference optimization](https://arxiv.org/abs/2505.10250)|[adhmr](https://github.com/shenwenhao01/adhmr)|\n", "2505.10473": "|[consistent quantity-quality control across scenes for deployment-aware gaussian splatting](https://arxiv.org/abs/2505.10473)|[ControlGS](https://github.com/zhang-fengdi/ControlGS)|\n", "2505.12007": "|[multi-modal collaborative optimization and expansion network for event-assisted single-eye expression recognition](https://arxiv.org/abs/2505.12007)|[MCO-E-Net](https://github.com/hrdhrd/MCO-E-Net)|\n", "2505.12081": "|[visionreasoner: unified visual perception and reasoning via reinforcement learning](https://arxiv.org/abs/2505.12081)|[easyr1](https://github.com/hiyouga/easyr1)|\n", "2505.14068": "|[place recognition: a comprehensive review, current challenges and future directions](https://arxiv.org/abs/2505.14068)|[sota-place-recognitioner](https://github.com/cv4ra/sota-place-recognitioner)|\n", "2505.15222": "|[continuous representation methods, theories, and applications: an overview and perspectives](https://arxiv.org/abs/2505.15222)|[continuous-representation-zoo](https://github.com/yisiluo/continuous-representation-zoo)|\n", "2505.15358": "|[objective bicycle occlusion level classification using a deformable parts-based model](https://arxiv.org/abs/2505.15358)|[Bicycle_Occlusion_Level](https://github.com/angelmangubat/Bicycle_Occlusion_Level)|\n", "2505.15441": "|[stronger vits with octic equivariance](https://arxiv.org/abs/2505.15441)|[octic-vits](https://github.com/davnords/octic-vits)|\n", "2505.15810": "|[gui-g1: understanding r1-zero-like training for visual grounding in gui agents](https://arxiv.org/abs/2505.15810)|[gui-g1](https://github.com/yuqi-zhou/gui-g1)|\n", "2505.15867": "|[scenir: visual semantic clarity through unsupervised scene graph retrieval](https://arxiv.org/abs/2505.15867)|[scenir-icml2025](https://github.com/nickhaidos/scenir-icml2025)|\n", "2505.15870": "|[satellites reveal mobility: a commuting origin-destination flow generator for global cities](https://arxiv.org/abs/2505.15870)|[generate-od-pubtools](https://github.com/tsinghua-fib-lab/generate-od-pubtools)|\n", "2505.15928": "|[viqagent: zero-shot video question answering via agent with open-vocabulary grounding validation](https://arxiv.org/abs/2505.15928)|[viqagent](https://github.com/t-montes/viqagent)|\n", "2505.16029": "|[learning better representations for crowded pedestrians in offboard lidar-camera 3d tracking-by-detection](https://arxiv.org/abs/2505.16029)|[pcp-mv](https://github.com/nicholasli1995/pcp-mv)|\n", "2505.16104": "|[hierarchical safety realignment: lightweight restoration of safety in pruned large vision-language models](https://arxiv.org/abs/2505.16104)|[hsr](https://github.com/theshineyue/hsr)|\n", "2505.16161": "|[deep learning-driven ultra-high-definition image restoration: a survey](https://arxiv.org/abs/2505.16161)|[uhd-image-restoration-survey](https://github.com/wlydlut/uhd-image-restoration-survey)|\n", "2505.16165": "|[re-trip : reflectivity instance augmented triangle descriptor for 3d place recognition](https://arxiv.org/abs/2505.16165)|[re-trip](https://github.com/pyc5714/re-trip)|\n", "2505.16175": "|[quickvideo: real-time long video understanding with system algorithm co-design](https://arxiv.org/abs/2505.16175)|[quickvideo](https://github.com/tiger-ai-lab/quickvideo)|\n", "2505.16264": "|[linea: fast and accurate line detection using scalable transformers](https://arxiv.org/abs/2505.16264)|[LINEA](https://github.com/SebastianJanampa/LINEA)|\n", "2505.16282": "|[arpo:end-to-end policy optimization for gui agents with experience replay](https://arxiv.org/abs/2505.16282)|[arpo](https://github.com/dvlab-research/arpo)|\n", "2505.16313": "|[accelerating targeted hard-label adversarial attacks in low-query black-box settings](https://arxiv.org/abs/2505.16313)|[tea](https://github.com/mdppml/tea)|\n", "2505.16321": "|[efficient motion prompt learning for robust visual tracking](https://arxiv.org/abs/2505.16321)|[motion-prompt-tracking](https://github.com/zj5559/motion-prompt-tracking)|\n", "2505.16335": "|[fpqvar: floating point quantization for visual autoregressive model with fpga hardware co-design](https://arxiv.org/abs/2505.16335)|[fpqvar](https://github.com/pku-sec-lab/fpqvar)|\n", "2505.16360": "|[style transfer with diffusion models for synthetic-to-real domain adaptation](https://arxiv.org/abs/2505.16360)|[cactif](https://github.com/echigot/cactif)|\n", "2505.16376": "|[decafnet: delegate and conquer for efficient temporal grounding in long videos](https://arxiv.org/abs/2505.16376)|[cvpr2025-decafnet](https://github.com/zijialewislu/cvpr2025-decafnet)|\n", "2505.16402": "|[advreal: adversarial patch generation framework with application to adversarial safety evaluation of object detection systems](https://arxiv.org/abs/2505.16402)|[advreal](https://github.com/huangyh98/advreal)|\n", "2505.16411": "|[mitigating hallucinations in vision-language models through image-guided head suppression](https://arxiv.org/abs/2505.16411)|[spin](https://github.com/yueche77/spin)|\n", "2505.16416": "|[circle-rope: cone-like decoupled rotary positional embedding for large vision-language models](https://arxiv.org/abs/2505.16416)|[circlerope](https://github.com/lose4578/circlerope)|\n", "2505.16441": "|[ranked entropy minimization for continual test-time adaptation](https://arxiv.org/abs/2505.16441)|[rem](https://github.com/pilshan/rem)|\n", "2505.16470": "|[benchmarking retrieval-augmented multimomal generation for document question answering](https://arxiv.org/abs/2505.16470)|[mmdocrag](https://github.com/mmdocrag/mmdocrag)|\n", "2505.16495": "|[alto: adaptive-length tokenizer for autoregressive mask generation](https://arxiv.org/abs/2505.16495)|[altollm](https://github.com/yayafengzi/altollm)|\n", "2505.16579": "|[bridging the dynamic perception gap: training-free draft chain-of-thought for dynamic multimodal spatial reasoning](https://arxiv.org/abs/2505.16579)|[d2r](https://github.com/cratileo/d2r)|\n", "2505.16625": "|[background matters: a cross-view bidirectional modeling framework for semi-supervised medical image segmentation](https://arxiv.org/abs/2505.16625)|[cvbm](https://github.com/caoluyang0830/cvbm)|\n", "2505.16650": "|[unsupervised network anomaly detection with autoencoders and traffic images](https://arxiv.org/abs/2505.16650)|[image-based-network-traffic-anomaly-detection](https://github.com/michaelneri/image-based-network-traffic-anomaly-detection)|\n", "2505.16658": "|[zero-shot hyperspectral pansharpening using hysteresis-based tuning for spectral quality control](https://arxiv.org/abs/2505.16658)|[rho-pnn](https://github.com/giu-guarino/rho-pnn)|\n", "2505.16663": "|[conav: collaborative cross-modal reasoning for embodied navigation](https://arxiv.org/abs/2505.16663)|[CoNav](https://github.com/oceanhao/CoNav)|\n", "2505.16673": "|[r1-sharevl: incentivizing reasoning capability of multimodal large language models via share-grpo](https://arxiv.org/abs/2505.16673)|[r1-sharevl](https://github.com/hjyao00/r1-sharevl)|\n", "2505.16685": "|[on the use of graphs for satellite image time series](https://arxiv.org/abs/2505.16685)|[graph4sits](https://github.com/corentin-dfg/graph4sits)|\n", "2505.16740": "|[robust vision-based runway detection through conformal prediction and conformal map](https://arxiv.org/abs/2505.16740)|[conformal_runway_detection](https://github.com/alyasltd/conformal_runway_detection)|\n", "2505.16778": "|[single domain generalization for few-shot counting via universal representation matching](https://arxiv.org/abs/2505.16778)|[urm](https://github.com/jbr97/urm)|\n", "2505.16792": "|[repa works until it doesn't: early-stopped, holistic alignment supercharges diffusion training](https://arxiv.org/abs/2505.16792)|[haste](https://github.com/nus-hpc-ai-lab/haste)|\n", "2505.16793": "|[reobench: benchmarking robustness of earth observation foundation models](https://arxiv.org/abs/2505.16793)|[reobench](https://github.com/lx709/reobench)|\n", "2505.16815": "|[perceptual quality assessment for embodied ai](https://arxiv.org/abs/2505.16815)|[embodiediqa](https://github.com/lcysyzxdxc/embodiediqa)|\n", "2505.16850": "|[atr-bench: a federated learning benchmark for adaptation, trust, and reasoning](https://arxiv.org/abs/2505.16850)|[atr-bench](https://github.com/tajamul21/atr-bench)|\n", "2505.16864": "|[training-free efficient video generation via dynamic token carving](https://arxiv.org/abs/2505.16864)|[jenga](https://github.com/dvlab-research/jenga)|\n", "2505.16902": "|[realengine: simulating autonomous driving in realistic context](https://arxiv.org/abs/2505.16902)|[realengine](https://github.com/fudan-zvg/realengine)|\n", "2505.16916": "|[backdoor cleaning without external guidance in mllm fine-tuning](https://arxiv.org/abs/2505.16916)|[bye](https://github.com/xuankunrong/bye)|\n", "2505.16974": "|[openseg-r: improving open-vocabulary segmentation via step-by-step visual reasoning](https://arxiv.org/abs/2505.16974)|[openseg-r](https://github.com/hanzy1996/openseg-r)|\n", "2505.16977": "|[incorporating visual correspondence into diffusion model for virtual try-on](https://arxiv.org/abs/2505.16977)|[spm-diff](https://github.com/hidream-ai/spm-diff)|\n", "2505.16985": "|[extremely simple multimodal outlier synthesis for out-of-distribution detection and segmentation](https://arxiv.org/abs/2505.16985)|[featuremixing](https://github.com/mona4399/featuremixing)|\n", "2505.17008": "|[deep mineralogical segmentation of thin section images based on qemscan maps](https://arxiv.org/abs/2505.17008)|[deep-mineralogical-segmentation](https://github.com/ltracegeo/deep-mineralogical-segmentation)|\n", "2505.17011": "|[learning adaptive and temporally causal video tokenization in a 1d latent space](https://arxiv.org/abs/2505.17011)|[adaptok](https://github.com/visionxlab/adaptok)|\n", "2505.17012": "|[spatialscore: towards unified evaluation for multimodal spatial understanding](https://arxiv.org/abs/2505.17012)|[SpatialScore](https://github.com/haoningwu3639/SpatialScore)|\n", "2505.17017": "|[delving into rl for image generation with cot: a study on dpo vs. grpo](https://arxiv.org/abs/2505.17017)|[image-generation-cot](https://github.com/ziyuguo99/image-generation-cot)|\n", "2505.17018": "|[sophiavl-r1: reinforcing mllms reasoning with thinking reward](https://arxiv.org/abs/2505.17018)|[sophiavl-r1](https://github.com/kxfan2002/sophiavl-r1)|\n", "2505.17019": "|[let androids dream of electric sheep: a human-like image implication understanding and reasoning framework](https://arxiv.org/abs/2505.17019)|[let-androids-dream-of-electric-sheep](https://github.com/ming-zch/let-androids-dream-of-electric-sheep)|\n", "2505.17020": "|[crosslmm: decoupling long video sequences from lmms via dual cross-attention mechanisms](https://arxiv.org/abs/2505.17020)|[crosslmm](https://github.com/shilinyan99/crosslmm)|\n", "2505.17021": "|[arb: a comprehensive arabic multimodal reasoning benchmark](https://arxiv.org/abs/2505.17021)|[arb](https://github.com/mbzuai-oryx/arb)|\n", "2505.17022": "|[got-r1: unleashing reasoning capability of mllm for visual generation with reinforcement learning](https://arxiv.org/abs/2505.17022)|[got-r1](https://github.com/gogoduan/got-r1)|\n"}, "2025-05-24": {}, "2025-05-25": {}, "2025-05-26": {"2207.13560": "|[d3c2-net: dual-domain deep convolutional coding network for compressive sensing](https://arxiv.org/abs/2207.13560)|[d3c2-net](https://github.com/lwq20020127/d3c2-net)|\n", "2403.19924": "|[scenetracker: long-term scene flow estimation network](https://arxiv.org/abs/2403.19924)|[scenetracker](https://github.com/wwsource/scenetracker)|\n", "2410.15618": "|[erasing undesirable concepts in diffusion models with adversarial preservation](https://arxiv.org/abs/2410.15618)|[erasing-adversarial-preservation](https://github.com/tuananhbui89/erasing-adversarial-preservation)|\n", "2411.16598": "|[diffbreak: is diffusion-based purification robust?](https://arxiv.org/abs/2411.16598)|[DiffBreak](https://github.com/andrekassis/DiffBreak)|\n", "2411.19715": "|[forensics adapter: unleashing clip for generalizable face forgery detection](https://arxiv.org/abs/2411.19715)|[forensicsadapter](https://github.com/ouc-vas/forensicsadapter)|\n", "2412.12453": "|[multimodal classification and out-of-distribution detection for multimodal intent understanding](https://arxiv.org/abs/2412.12453)|[mintood](https://github.com/thuiar/mintood)|\n", "2501.18950": "|[fantastic targets for concept erasure in diffusion models and where to find them](https://arxiv.org/abs/2501.18950)|[adaptive-guided-erasure](https://github.com/tuananhbui89/adaptive-guided-erasure)|\n", "2502.11651": "|[mmxu: a multi-modal and multi-x-ray understanding dataset for disease progression](https://arxiv.org/abs/2502.11651)|[mmxu](https://github.com/linjiemu/mmxu)|\n", "2502.19260": "|[emt: a visual multi-task benchmark dataset for autonomous driving](https://arxiv.org/abs/2502.19260)|[emt-dataset](https://github.com/av-lab/emt-dataset)|\n", "2503.07435": "|[open-set gait recognition from sparse mmwave radar point clouds](https://arxiv.org/abs/2503.07435)|[OpenSetGaitRecognition_PCAA](https://github.com/rmazzier/OpenSetGaitRecognition_PCAA)|\n", "2503.22679": "|[q-insight: understanding image quality via visual reinforcement learning](https://arxiv.org/abs/2503.22679)|[q-insight](https://github.com/lwq20020127/q-insight)|\n", "2504.19838": "|[llm-powered gui agents in phone automation: surveying progress and prospects](https://arxiv.org/abs/2504.19838)|[awesome-llm-powered-phone-gui-agents](https://github.com/phonellm/awesome-llm-powered-phone-gui-agents)|\n", "2505.01476": "|[costfilter-ad: enhancing anomaly detection through matching cost filtering](https://arxiv.org/abs/2505.01476)|[costfilter-ad](https://github.com/zhe-sapi/costfilter-ad)|\n", "2505.05528": "|[x-transfer attacks: towards super transferable adversarial attacks on clip](https://arxiv.org/abs/2505.05528)|[XTransferBench](https://github.com/HanxunH/XTransferBench)|\n", "2505.10541": "|[exploring implicit visual misunderstandings in multimodal large language models through attention analysis](https://arxiv.org/abs/2505.10541)|[stme](https://github.com/welldonepf/stme)|\n", "2505.10595": "|[arfc-wahnet: adaptive receptive field convolution and wavelet-attentive hierarchical network for infrared small target detection](https://arxiv.org/abs/2505.10595)|[arfc-wahnet](https://github.com/leaf2001/arfc-wahnet)|\n", "2505.11454": "|[humanibench: a human-centric framework for large multimodal models evaluation](https://arxiv.org/abs/2505.11454)|[humanibench](https://github.com/vectorinstitute/humanibench)|\n", "2505.14151": "|[reactdiff: latent diffusion for facial reaction generation](https://arxiv.org/abs/2505.14151)|[reactdiff](https://github.com/hunan-tiger/reactdiff)|\n", "2505.15425": "|[on the robustness of medical vision-language models: are they truly generalizable?](https://arxiv.org/abs/2505.15425)|[robustmedclip](https://github.com/biomedia-mbzuai/robustmedclip)|\n", "2505.16809": "|[hypergraph tversky-aware domain incremental learning for brain tumor segmentation with missing modalities](https://arxiv.org/abs/2505.16809)|[rehydil](https://github.com/reeive/rehydil)|\n", "2505.16839": "|[lavida: a large diffusion language model for multimodal understanding](https://arxiv.org/abs/2505.16839)|[lavida](https://github.com/jacklishufan/lavida)|\n", "2505.16854": "|[think or not? selective reasoning via reinforcement learning for vision-language models](https://arxiv.org/abs/2505.16854)|[ton](https://github.com/kokolerk/ton)|\n", "2505.17104": "|[p2p: automated paper-to-poster generation and fine-grained benchmark](https://arxiv.org/abs/2505.17104)|[P2P](https://github.com/multimodal-art-projection/P2P)|\n", "2505.17114": "|[raven: query-guided representation alignment for question answering over audio, video, embedded sensors, and natural language](https://arxiv.org/abs/2505.17114)|[raven](https://github.com/bashlab/raven)|\n", "2505.17241": "|[generative ai and creativity: a systematic literature review and meta-analysis](https://arxiv.org/abs/2505.17241)|[meta-analysis-llms-creativity](https://github.com/sm2982/meta-analysis-llms-creativity)|\n", "2505.17423": "|[vibe: video-to-text information bottleneck evaluation for tl;dr](https://arxiv.org/abs/2505.17423)|[task-aware-tldr-public](https://github.com/utaustin-swarmlab/task-aware-tldr-public)|\n", "2505.17440": "|[veattack: downstream-agnostic vision encoder attack against large vision language models](https://arxiv.org/abs/2505.17440)|[veattack-lvlm](https://github.com/hfmei/veattack-lvlm)|\n", "2505.17475": "|[posebh: prototypical multi-dataset training beyond human pose estimation](https://arxiv.org/abs/2505.17475)|[PoseBH](https://github.com/uyoung-jeong/PoseBH)|\n", "2505.17479": "|[twin-2k-500: a dataset for building digital twins of over 2,000 people based on their answers to over 500 questions](https://arxiv.org/abs/2505.17479)|[digital-twin-simulation](https://github.com/tianyipeng-lab/digital-twin-simulation)|\n", "2505.17528": "|[dect-based space-squeeze method for multi-class classification of metastatic lymph nodes in breast cancer](https://arxiv.org/abs/2505.17528)|[projects](https://github.com/pigejianghai/projects)|\n", "2505.17551": "|[center-aware residual anomaly synthesis for multi-class industrial anomaly detection](https://arxiv.org/abs/2505.17551)|[CRAS](https://github.com/cqylunlun/CRAS)|\n", "2505.17556": "|[wildfire spread forecasting with deep learning](https://arxiv.org/abs/2505.17556)|[wildfirespread](https://github.com/orion-ai-lab/wildfirespread)|\n", "2505.17581": "|[modem: a morton-order degradation estimation mechanism for adverse weather image recovery](https://arxiv.org/abs/2505.17581)|[modem](https://github.com/hainuo-wang/modem)|\n", "2505.17591": "|[minkunext-si: improving point cloud-based place recognition including spherical coordinates and lidar intensity](https://arxiv.org/abs/2505.17591)|[minkunext-si](https://github.com/judithv/minkunext-si)|\n", "2505.17683": "|[dual attention residual u-net for accurate brain ultrasound segmentation in ivh detection](https://arxiv.org/abs/2505.17683)|[brainimgsegment](https://github.com/danyuan001/brainimgsegment)|\n", "2505.17739": "|[feasible action space reduction for quantifying causal responsibility in continuous spatial interactions](https://arxiv.org/abs/2505.17739)|[continuousfear](https://github.com/dai-lab-herald/continuousfear)|\n", "2505.17771": "|[topopoint: enhance topology reasoning via endpoint detection in autonomous driving](https://arxiv.org/abs/2505.17771)|[topopoint](https://github.com/franpin/topopoint)|\n", "2505.17807": "|[temporal consistency constrained transferable adversarial attacks with background mixup for action recognition](https://arxiv.org/abs/2505.17807)|[bmtc_transferattackvid](https://github.com/mlvccn/bmtc_transferattackvid)|\n", "2505.17883": "|[fastcav: efficient computation of concept activation vectors for explaining deep neural networks](https://arxiv.org/abs/2505.17883)|[fastcav](https://gitlab.com/dlr-dw/fastcav)|\n", "2505.17884": "|[track anything annotate: video annotation and dataset generation of computer vision models](https://arxiv.org/abs/2505.17884)|[track-anything-annotate](https://github.com/lnikioffic/track-anything-annotate)|\n", "2505.17908": "|[comfymind: toward general-purpose generation via tree-based planning and reactive feedback](https://arxiv.org/abs/2505.17908)|[ComfyMind](https://github.com/EnVision-Research/ComfyMind)|\n", "2505.17911": "|[object-level cross-view geo-localization with location enhancement and multi-head cross attention](https://arxiv.org/abs/2505.17911)|[ocgnet](https://github.com/zheyangh/ocgnet)|\n", "2505.17915": "|[promptable cancer segmentation using minimal expert-curated data](https://arxiv.org/abs/2505.17915)|[promptable-cancer-segmentation](https://github.com/lynnkaram/promptable-cancer-segmentation)|\n", "2505.18015": "|[semsegbench & detecbench: benchmarking reliability and generalization beyond classification](https://arxiv.org/abs/2505.18015)|[benchmarking_reliability_generalization](https://github.com/shashankskagnihotri/benchmarking_reliability_generalization)|\n", "2505.18025": "|[3d face reconstruction error decomposed: a modular benchmark for fair and fast method evaluation](https://arxiv.org/abs/2505.18025)|[M3DFB](https://github.com/sariyanidi/M3DFB)|\n", "2505.18028": "|[knot so simple: a minimalistic environment for spatial reasoning](https://arxiv.org/abs/2505.18028)|[knotgym](https://github.com/lil-lab/knotgym)|\n", "2505.18035": "|[camme: adaptive deepfake image detection with multi-modal cross-attention](https://arxiv.org/abs/2505.18035)|[camme](https://github.com/magnet300/camme)|\n", "2505.18153": "|[ren: fast and efficient region encodings from patch-based image encoders](https://arxiv.org/abs/2505.18153)|[ren](https://github.com/savya08/ren)|\n"}, "2025-05-27": {"2208.11450": "|[vistanet: visual spoken textual additive net for interpretable multimodal emotion recognition](https://arxiv.org/abs/2208.11450)|[mmemorec](https://github.com/mintelligence-group/mmemorec)|\n", "2302.03675": "|[auditing gender presentation differences in text-to-image models](https://arxiv.org/abs/2302.03675)|[GEP_data](https://github.com/SALT-NLP/GEP_data)|\n", "2303.13111": "|[boosting convolution with efficient mlp-permutation for volumetric medical image segmentation](https://arxiv.org/abs/2303.13111)|[phnet](https://github.com/xiaofang007/phnet)|\n", "2309.08482": "|[ycb-ev 1.1: event-vision dataset for 6dof object pose estimation](https://arxiv.org/abs/2309.08482)|[ycbev](https://github.com/paroj/ycbev)|\n", "2309.14072": "|[boir: box-supervised instance representation for multi-person pose estimation](https://arxiv.org/abs/2309.14072)|[BoIR](https://github.com/uyoung-jeong/BoIR)|\n", "2312.03187": "|[fergi: automatic scoring of user preferences for text-to-image generation from spontaneous facial expression reaction](https://arxiv.org/abs/2312.03187)|[fergi](https://github.com/shuangquanfeng/fergi)|\n", "2402.07945": "|[screenagent: a vision language model-driven computer control agent](https://arxiv.org/abs/2402.07945)|[screenagent](https://github.com/niuzaisheng/screenagent)|\n", "2403.01944": "|[fourier-basis functions to bridge augmentation gap: rethinking frequency augmentation in image classification](https://arxiv.org/abs/2403.01944)|[afa-augment](https://github.com/nis-research/afa-augment)|\n", "2403.05433": "|[part-aware prompted segment anything model for adaptive segmentation](https://arxiv.org/abs/2403.05433)|[P2SAM](https://github.com/Zch0414/P2SAM)|\n", "2405.10148": "|[specdetr: a transformer-based hyperspectral point object detection network](https://arxiv.org/abs/2405.10148)|[specdetr](https://github.com/zhaoxuli123/specdetr)|\n", "2406.02539": "|[parrot: multilingual visual instruction tuning](https://arxiv.org/abs/2406.02539)|[parrot](https://github.com/aidc-ai/parrot)|\n", "2406.14206": "|[live video captioning](https://arxiv.org/abs/2406.14206)|[lvc](https://github.com/gramuah/lvc)|\n", "2407.13120": "|[hppp: halpern-type preconditioned proximal point algorithms and applications to image restoration](https://arxiv.org/abs/2407.13120)|[HPPP](https://github.com/zsc15/HPPP)|\n", "2408.04523": "|[depth any canopy: leveraging depth foundation models for canopy height estimation](https://arxiv.org/abs/2408.04523)|[depth-any-canopy](https://github.com/DarthReca/depth-any-canopy)|\n", "2408.07040": "|[kan you see it? kans and sentinel for effective and explainable crop field segmentation](https://arxiv.org/abs/2408.07040)|[crop-field-segmentation-ukan](https://github.com/darthreca/crop-field-segmentation-ukan)|\n", "2408.08396": "|[level up your tutorials: vlms for game tutorials quality assessment](https://arxiv.org/abs/2408.08396)|[level-up-your-tutorials](https://github.com/DarthReca/level-up-your-tutorials)|\n", "2408.09126": "|[barbie: text to barbie-style 3d avatars](https://arxiv.org/abs/2408.09126)|[Barbie](https://github.com/XiaokunSun/Barbie)|\n", "2408.10872": "|[v-roast: visual road assessment. can vlm be a road safety assessor using the irap standard?](https://arxiv.org/abs/2408.10872)|[V-RoAst](https://github.com/PongNJ/V-RoAst)|\n", "2408.14584": "|[diagen: semantically diverse image augmentation with generative models for few-shot learning](https://arxiv.org/abs/2408.14584)|[diagen](https://github.com/visinf/diagen)|\n", "2408.14744": "|[rsteller: scaling up visual language modeling in remote sensing with rich linguistic semantics from openly available data and large language models](https://arxiv.org/abs/2408.14744)|[rsteller](https://github.com/slytheringe/rsteller)|\n", "2409.01814": "|[segmenting object affordances: reproducibility and sensitivity to scale](https://arxiv.org/abs/2409.01814)|[aff-seg](https://github.com/apicis/aff-seg)|\n", "2409.19833": "|[hazydet: open-source benchmark for drone-view object detection with depth-cues in hazy scenes](https://arxiv.org/abs/2409.19833)|[hazydet](https://github.com/grokcv/hazydet)|\n", "2410.02640": "|[rdeic: accelerating diffusion-based extreme image compression with relay residual diffusion](https://arxiv.org/abs/2410.02640)|[rdeic](https://github.com/huai-chang/rdeic)|\n", "2410.03728": "|[exploring quic dynamics: a large-scale dataset for encrypted traffic analysis](https://arxiv.org/abs/2410.03728)|[VisQUIC](https://github.com/robshahla/VisQUIC)|\n", "2410.03809": "|[radio-opaque artefacts in digital mammography: automatic detection and analysis of downstream effects](https://arxiv.org/abs/2410.03809)|[mammo-artifacts](https://github.com/biomedia-mira/mammo-artifacts)|\n", "2410.04479": "|[sitcom: step-wise triple-consistent diffusion sampling for inverse problems](https://arxiv.org/abs/2410.04479)|[SITCOM](https://github.com/sjames40/SITCOM)|\n", "2410.08613": "|[cross-modal bidirectional interaction model for referring remote sensing image segmentation](https://arxiv.org/abs/2410.08613)|[crobim](https://github.com/hit-sirs/crobim)|\n", "2410.08695": "|[dynamic multimodal evaluation with flexible complexity by vision-language bootstrapping](https://arxiv.org/abs/2410.08695)|[DME](https://github.com/yangyue5114/DME)|\n", "2410.09032": "|[alberta wells dataset: pinpointing oil and gas wells from satellite imagery](https://arxiv.org/abs/2410.09032)|[Alberta_Wells_Dataset](https://github.com/RolnickLab/Alberta_Wells_Dataset)|\n", "2410.12557": "|[one step diffusion via shortcut models](https://arxiv.org/abs/2410.12557)|[shortcut-models](https://github.com/kvfrans/shortcut-models)|\n", "2410.22101": "|[hyperspectral imaging-based perception in autonomous driving scenarios: benchmarking baseline semantic segmentation models](https://arxiv.org/abs/2410.22101)|[HSI_SemanticSegmentationModels_AD_ADAS](https://github.com/imadalishah/HSI_SemanticSegmentationModels_AD_ADAS)|\n", "2411.12919": "|[robust multi-coil mri reconstruction via self-supervised denoising](https://arxiv.org/abs/2411.12919)|[gsure-diffusion-mri](https://github.com/utcsilab/gsure-diffusion-mri)|\n", "2411.14974": "|[3d convex splatting: radiance field rendering with 3d smooth convexes](https://arxiv.org/abs/2411.14974)|[convex-splatting](https://github.com/convexsplatting/convex-splatting)|\n", "2411.17335": "|[versatilemotion: a unified framework for motion synthesis and comprehension](https://arxiv.org/abs/2411.17335)|[MotionLLaMA](https://github.com/ZeyuLing/MotionLLaMA)|\n", "2411.17761": "|[openad: open-world autonomous driving benchmark for 3d object detection](https://arxiv.org/abs/2411.17761)|[OpenAD](https://github.com/VDIGPKU/OpenAD)|\n", "2412.00784": "|[edtformer: an efficient decoder transformer for visual place recognition](https://arxiv.org/abs/2412.00784)|[edtformer](https://github.com/tong-jin01/edtformer)|\n", "2412.03318": "|[domain-agnostic stroke lesion segmentation using physics-constrained synthetic data](https://arxiv.org/abs/2412.03318)|[qsynth](https://github.com/liamchalcroft/qsynth)|\n", "2412.12974": "|[attentive eraser: unleashing diffusion model's object removal potential via self-attention redirection guidance](https://arxiv.org/abs/2412.12974)|[attentiveeraser](https://github.com/anonym0u3/attentiveeraser)|\n", "2412.14819": "|[multi-level embedding and alignment network with consistency and invariance learning for cross-view geo-localization](https://arxiv.org/abs/2412.14819)|[mean](https://github.com/ischenawei/mean)|\n", "2412.18525": "|[explanatory instructions: towards unified vision tasks understanding and zero-shot generalization](https://arxiv.org/abs/2412.18525)|[Understanding_Vision_Tasks](https://github.com/SEU-VIPGroup/Understanding_Vision_Tasks)|\n", "2501.01275": "|[hybridtrack: a hybrid approach for robust multi-object tracking](https://arxiv.org/abs/2501.01275)|[hybridtrack](https://github.com/leandro-svg/hybridtrack)|\n", "2501.04561": "|[openomni: advancing open-source omnimodal large language models with progressive multimodal alignment and real-time self-aware emotional speech synthesis](https://arxiv.org/abs/2501.04561)|[openomni](https://github.com/rainbowluocs/openomni)|\n", "2501.12524": "|[efficient lung ultrasound severity scoring using dedicated feature extractor](https://arxiv.org/abs/2501.12524)|[medivlad](https://github.com/guojiaqi-1020/medivlad)|\n", "2501.13898": "|[pointobb-v3: expanding performance boundaries of single point-supervised oriented object detection](https://arxiv.org/abs/2501.13898)|[pointobb-v3](https://github.com/zpywhu/pointobb-v3)|\n", "2501.18984": "|[context matters: query-aware dynamic long sequence modeling of gigapixel images](https://arxiv.org/abs/2501.18984)|[querent](https://github.com/dddavid4real/querent)|\n", "2502.00869": "|[staf: sinusoidal trainable activation functions for implicit neural representation](https://arxiv.org/abs/2502.00869)|[staf](https://github.com/alirezamorsali/staf)|\n", "2502.01247": "|[polynomial, trigonometric, and tropical activations](https://arxiv.org/abs/2502.01247)|[torchortho](https://github.com/K-H-Ismail/torchortho)|\n", "2502.03686": "|[variational control for guidance in diffusion models](https://arxiv.org/abs/2502.03686)|[oc-guidance](https://github.com/czi-ai/oc-guidance)|\n", "2502.08279": "|[what is that talk about? a video-to-text summarization dataset for scientific presentations](https://arxiv.org/abs/2502.08279)|[vista](https://github.com/dongqi-me/vista)|\n", "2502.11381": "|[without paired labeled data: end-to-end self-supervised learning for drone-view geo-localization](https://arxiv.org/abs/2502.11381)|[dmnil](https://github.com/ischenawei/dmnil)|\n", "2503.11187": "|[fastvid: dynamic density pruning for fast video large language models](https://arxiv.org/abs/2503.11187)|[fastvid](https://github.com/lunarshen/fastvid)|\n", "2503.13377": "|[time-r1: post-training large vision language model for temporal video grounding](https://arxiv.org/abs/2503.13377)|[timezero](https://github.com/www-ye/timezero)|\n", "2504.09724": "|[a survey on efficient vision-language models](https://arxiv.org/abs/2504.09724)|[efficient-vision-language-models-a-survey](https://github.com/mpsc-umbc/efficient-vision-language-models-a-survey)|\n", "2504.10174": "|[llava-reid: selective multi-image questioner for interactive person re-identification](https://arxiv.org/abs/2504.10174)|[llava-reid](https://github.com/xlearning-scu/llava-reid)|\n", "2504.13548": "|[beyond one-hot labels: semantic mixing for model calibration](https://arxiv.org/abs/2504.13548)|[csm](https://github.com/e-galois/csm)|\n", "2504.13617": "|[compile scene graphs with reinforcement learning](https://arxiv.org/abs/2504.13617)|[r1-sgg](https://github.com/gpt4vision/r1-sgg)|\n", "2504.16728": "|[iris: interactive research ideation system for accelerating scientific discovery](https://arxiv.org/abs/2504.16728)|[iris-interactive-research-ideation-system](https://github.com/anikethh/iris-interactive-research-ideation-system)|\n", "2504.17670": "|[dimer: disentangled mesh reconstruction model](https://arxiv.org/abs/2504.17670)|[DiMeR](https://github.com/lutao2021/DiMeR)|\n", "2504.18317": "|[task-oriented communications for visual navigation with edge-aerial collaboration in low altitude economy](https://arxiv.org/abs/2504.18317)|[TOC-Edge-Aerial](https://github.com/fangzr/TOC-Edge-Aerial)|\n", "2505.04119": "|[gaprompt: geometry-aware point cloud prompt for 3d vision model](https://arxiv.org/abs/2505.04119)|[icml2025-gaprompt](https://github.com/zhoujiahuan1991/icml2025-gaprompt)|\n", "2505.04121": "|[vision graph prompting via semantic low-rank decomposition](https://arxiv.org/abs/2505.04121)|[icml2025-vgp](https://github.com/zhoujiahuan1991/icml2025-vgp)|\n", "2505.08614": "|[waveguard: robust deepfake detection and source tracing via dual-tree complex wavelet and graph neural networks](https://arxiv.org/abs/2505.08614)|[waveguard](https://github.com/vpsg-research/waveguard)|\n", "2505.11131": "|[one image is worth a thousand words: a usability preservable text-image collaborative erasing framework](https://arxiv.org/abs/2505.11131)|[co-erasing](https://github.com/ferry-li/co-erasing)|\n", "2505.12266": "|[pmq-ve: progressive multi-frame quantization for video enhancement](https://arxiv.org/abs/2505.12266)|[pmq-ve](https://github.com/xiaobigfeng/pmq-ve)|\n", "2505.12513": "|[globalgeotree: a multi-granular vision-language dataset for global tree species classification](https://arxiv.org/abs/2505.12513)|[globalgeotree](https://github.com/muyang99/globalgeotree)|\n", "2505.12728": "|[flash: latent-aware semi-autoregressive speculative decoding for multimodal tasks](https://arxiv.org/abs/2505.12728)|[flashsd](https://github.com/zihuaevan/flashsd)|\n", "2505.13061": "|[3d visual illusion depth estimation](https://arxiv.org/abs/2505.13061)|[3d-visual-illusion-depth-estimation](https://github.com/yaochengtang/3d-visual-illusion-depth-estimation)|\n", "2505.13740": "|[improving compositional generation with diffusion models using lift scores](https://arxiv.org/abs/2505.13740)|[complift](https://github.com/rainorangelemon/complift)|\n", "2505.14362": "|[deepeyes: incentivizing \"thinking with images\" via reinforcement learning](https://arxiv.org/abs/2505.14362)|[deepeyes](https://github.com/visual-agent/deepeyes)|\n", "2505.15235": "|[x-grm: large gaussian reconstruction model for sparse-view x-rays to computed tomography](https://arxiv.org/abs/2505.15235)|[x-grm](https://github.com/cuhk-aim-group/x-grm)|\n", "2505.15660": "|[exploring the limits of vision-language-action manipulations in cross-task generalization](https://arxiv.org/abs/2505.15660)|[X-ICM](https://github.com/jiaming-zhou/X-ICM)|\n", "2505.16882": "|[tracking the flight: exploring a computational framework for analyzing escape responses in plains zebra (equus quagga)](https://arxiv.org/abs/2505.16882)|[zebras-stitching](https://github.com/neuroinformatics-unit/zebras-stitching)|\n", "2505.16990": "|[dimple: discrete diffusion multimodal large language model with parallel decoding](https://arxiv.org/abs/2505.16990)|[dimple](https://github.com/yu-rp/dimple)|\n", "2505.18156": "|[injectlab: a tactical framework for adversarial threat modeling against large language models](https://arxiv.org/abs/2505.18156)|[injectlab](https://github.com/ahow2004/injectlab)|\n", "2505.18175": "|[evaluation in eeg emotion recognition: state-of-the-art review and unified framework](https://arxiv.org/abs/2505.18175)|[eegain](https://github.com/emotionlab/eegain)|\n", "2505.18197": "|[a novel benchmark and dataset for efficient 3d gaussian splatting with gaussian point cloud compression](https://arxiv.org/abs/2505.18197)|[GausPcc](https://github.com/Wangkkklll/GausPcc)|\n", "2505.18412": "|[rehabilitation exercise quality assessment and feedback generation using large language models with prompt engineering](https://arxiv.org/abs/2505.18412)|[exercisellm](https://github.com/jessicaxtang/exercisellm)|\n", "2505.18423": "|[cenet: context enhancement network for medical image segmentation](https://arxiv.org/abs/2505.18423)|[cenet](https://github.com/xmindflow/cenet)|\n", "2505.18445": "|[omniconsistency: learning style-agnostic consistency from paired stylization data](https://arxiv.org/abs/2505.18445)|[omniconsistency](https://github.com/showlab/omniconsistency)|\n", "2505.18469": "|[honestface: towards honest face restoration with one-step diffusion model](https://arxiv.org/abs/2505.18469)|[honestface](https://github.com/jkwang28/honestface)|\n", "2505.18479": "|[syn3dtxt: embedding 3d cues for scene text generation](https://arxiv.org/abs/2505.18479)|[syntxt-gen](https://github.com/theohsiung/syntxt-gen)|\n", "2505.18487": "|[grounding bodily awareness in visual representations for efficient policy learning](https://arxiv.org/abs/2505.18487)|[icon](https://github.com/henrywjl/icon)|\n", "2505.18521": "|[improved immiscible diffusion: accelerate diffusion training by reducing its miscibility](https://arxiv.org/abs/2505.18521)|[immiscible-diffusion](https://github.com/yhli123/immiscible-diffusion)|\n", "2505.18525": "|[tk-mamba: marrying kan with mamba for text-driven 3d medical image segmentation](https://arxiv.org/abs/2505.18525)|[tk-mamba](https://github.com/yhy-whu/tk-mamba)|\n", "2505.18536": "|[reinforcement fine-tuning powers reasoning capability of multimodal large language models](https://arxiv.org/abs/2505.18536)|[awesome-rl-based-reasoning-mllms](https://github.com/sun-haoyuan23/awesome-rl-based-reasoning-mllms)|\n", "2505.18546": "|[reflectgan: modeling vegetation effects for soil carbon estimation from satellite imagery](https://arxiv.org/abs/2505.18546)|[reflectgan](https://github.com/dristidatta/reflectgan)|\n", "2505.18547": "|[diffusion blend: inference-time multi-preference alignment for diffusion models](https://arxiv.org/abs/2505.18547)|[db-2025](https://github.com/bluewoods127/db-2025)|\n", "2505.18561": "|[thinkvideo: high-quality reasoning video segmentation with chain of thoughts](https://arxiv.org/abs/2505.18561)|[thinkvideo](https://github.com/danielshkao/thinkvideo)|\n", "2505.18568": "|[learning without isolation: pathway protection for continual learning](https://arxiv.org/abs/2505.18568)|[lwi](https://github.com/chenzk202212/lwi)|\n", "2505.18582": "|[on denoising walking videos for gait recognition](https://arxiv.org/abs/2505.18582)|[opengait](https://github.com/shiqiyu/opengait)|\n", "2505.18586": "|[guiding the experts: semantic priors for efficient and focused moe routing](https://arxiv.org/abs/2505.18586)|[guiding-experts](https://github.com/0930mcx/guiding-experts)|\n", "2505.18614": "|[mavl: a multilingual audio-video lyrics dataset for animated song translation](https://arxiv.org/abs/2505.18614)|[MAVL](https://github.com/k1064190/MAVL)|\n", "2505.18652": "|[why not replace? sustaining long-term visual localization via handcrafted-learned feature collaboration on cpu](https://arxiv.org/abs/2505.18652)|[orb_slam3_localization](https://github.com/linyicheng1/orb_slam3_localization)|\n", "2505.18663": "|[dvd-quant: data-free video diffusion transformers quantization](https://arxiv.org/abs/2505.18663)|[dvd-quant](https://github.com/lhxcs/dvd-quant)|\n", "2505.18668": "|[chartgalaxy: a dataset for infographic chart understanding and generation](https://arxiv.org/abs/2505.18668)|[chartgalaxy](https://github.com/chartgalaxy/chartgalaxy)|\n", "2505.18700": "|[gre suite: geo-localization inference via fine-tuned vision-language models and enhanced reasoning chains](https://arxiv.org/abs/2505.18700)|[gre](https://github.com/thorin215/gre)|\n", "2505.18730": "|[align beyond prompts: evaluating world knowledge alignment in text-to-image generation](https://arxiv.org/abs/2505.18730)|[abp](https://github.com/smile365317/abp)|\n", "2505.18775": "|[omnigenbench: a benchmark for omnipotent multimodal generation across 50+ tasks](https://arxiv.org/abs/2505.18775)|[omnigenbench](https://github.com/emilia113/omnigenbench)|\n", "2505.18787": "|[think twice before adaptation: improving adaptability of deepfake detection via online test-time adaptation](https://arxiv.org/abs/2505.18787)|[t2a-think-twice-before-adaptation](https://github.com/honghanh2104/t2a-think-twice-before-adaptation)|\n", "2505.18809": "|[vorta: efficient video diffusion via routing sparse attention](https://arxiv.org/abs/2505.18809)|[vorta](https://github.com/wenhao728/vorta)|\n", "2505.18829": "|[litecua: computer as mcp server for computer-use agent on aios](https://arxiv.org/abs/2505.18829)|[aios](https://github.com/agiresearch/aios)|\n", "2505.18884": "|[lore: lagrangian-optimized robust embeddings for visual encoders](https://arxiv.org/abs/2505.18884)|[clip_benchmark](https://github.com/laion-ai/clip_benchmark)|\n", "2505.18899": "|[beyond domain randomization: event-inspired perception for visually robust adversarial imitation from videos](https://arxiv.org/abs/2505.18899)|[eb-laifo](https://github.com/vittoriogiammarino/eb-laifo)|\n", "2505.18902": "|[unsupervised cell segmentation by fast gaussian processes](https://arxiv.org/abs/2505.18902)|[cell_segmentation](https://github.com/uncertaintyquantification/cell_segmentation)|\n", "2505.18915": "|[are vision language models ready for clinical diagnosis? a 3d medical benchmark for tumor-centric visual question answering](https://arxiv.org/abs/2505.18915)|[deeptumorvqa](https://github.com/schuture/deeptumorvqa)|\n", "2505.18956": "|[how do images align and complement lidar? towards a harmonized multi-modal 3d panoptic segmentation](https://arxiv.org/abs/2505.18956)|[ial](https://github.com/impl-lab/ial)|\n", "2505.18983": "|[amorlip: efficient language-image pretraining via amortization](https://arxiv.org/abs/2505.18983)|[amorlip](https://github.com/haotiansun14/amorlip)|\n", "2505.18985": "|[strict: stress test of rendering images containing text](https://arxiv.org/abs/2505.18985)|[strict-bench](https://github.com/tianyu-z/strict-bench)|\n", "2505.18989": "|[spars: self-play adversarial reinforcement learning for segmentation of liver tumours](https://arxiv.org/abs/2505.18989)|[spars](https://github.com/catalinatan/spars)|\n", "2505.19000": "|[veripo: cultivating long reasoning in video-llms via verifier-gudied iterative policy optimization](https://arxiv.org/abs/2505.19000)|[veripo](https://github.com/hitsz-tmg/veripo)|\n", "2505.19015": "|[can multimodal large language models understand spatial relations?](https://arxiv.org/abs/2505.19015)|[spatialmqa](https://github.com/ziyan-xiaoyu/spatialmqa)|\n", "2505.19028": "|[infochartqa: a benchmark for multimodal question answering on infographic charts](https://arxiv.org/abs/2505.19028)|[infochartqa](https://github.com/cooldawnant/infochartqa)|\n", "2505.19031": "|[medical large vision language models with multi-image visual ability](https://arxiv.org/abs/2505.19031)|[med-mim](https://github.com/xikai97/med-mim)|\n", "2505.19065": "|[mmp-2k: a benchmark multi-labeled macro photography image quality assessment database](https://arxiv.org/abs/2505.19065)|[mmp-2k](https://github.com/future-iqa/mmp-2k)|\n", "2505.19076": "|[chartsketcher: reasoning with multimodal feedback and reflection for chart understanding](https://arxiv.org/abs/2505.19076)|[chartsketcher](https://github.com/muyehuang/chartsketcher)|\n", "2505.19084": "|[jodi: unification of visual generation and understanding via joint modeling](https://arxiv.org/abs/2505.19084)|[jodi](https://github.com/vipl-genun/jodi)|\n", "2505.19094": "|[satori-r1: incentivizing multimodal reasoning with spatial grounding and verifiable rewards](https://arxiv.org/abs/2505.19094)|[satori-r1](https://github.com/justairr/satori-r1)|\n", "2505.19120": "|[freqformer: image-demoir\\'eing transformer via efficient frequency decomposition](https://arxiv.org/abs/2505.19120)|[freqformer](https://github.com/xyliu339/freqformer)|\n", "2505.19147": "|[shifting ai efficiency from model-centric to data-centric compression](https://arxiv.org/abs/2505.19147)|[awesome-token-level-model-compression](https://github.com/xuyang-liu16/awesome-token-level-model-compression)|\n", "2505.19148": "|[dista-net: dynamic closely-spaced infrared small target unmixing](https://arxiv.org/abs/2505.19148)|[grokcso](https://github.com/grokcv/grokcso)|\n", "2505.19159": "|[a joint learning framework with feature reconstruction and prediction for incomplete satellite image time series in agricultural semantic segmentation](https://arxiv.org/abs/2505.19159)|[joint_frp](https://github.com/wangyuze-csu/joint_frp)|\n", "2505.19161": "|[benchmarking laparoscopic surgical image restoration and beyond](https://arxiv.org/abs/2505.19161)|[surgical-image-restoration](https://github.com/pjlallen/surgical-image-restoration)|\n", "2505.19190": "|[i2moe: interpretable multimodal interaction-aware mixture-of-experts](https://arxiv.org/abs/2505.19190)|[i2moe](https://github.com/raina-xin/i2moe)|\n", "2505.19196": "|[step-level reward for free in rl-based t2i diffusion model fine-tuning](https://arxiv.org/abs/2505.19196)|[coca](https://github.com/lil-shake/coca)|\n", "2505.19208": "|[domain and task-focused example selection for data-efficient contrastive medical image segmentation](https://arxiv.org/abs/2505.19208)|[polycl](https://github.com/tbwa233/polycl)|\n", "2505.19218": "|[advancing video self-supervised learning via image foundation models](https://arxiv.org/abs/2505.19218)|[advise-video-ssl](https://github.com/jingwwu/advise-video-ssl)|\n", "2505.19225": "|[meditok: a unified tokenizer for medical image synthesis and interpretation](https://arxiv.org/abs/2505.19225)|[meditok](https://github.com/masaaki-75/meditok)|\n", "2505.19235": "|[corematching: a co-adaptive sparse inference framework with token and neuron pruning for comprehensive acceleration of vision-language models](https://arxiv.org/abs/2505.19235)|[2025-icml-corematching](https://github.com/wangqinsi1/2025-icml-corematching)|\n", "2505.19249": "|[rgc-bent: a novel dataset for bent radio galaxy classification](https://arxiv.org/abs/2505.19249)|[rgc-bent](https://github.com/mirsazzathossain/rgc-bent)|\n", "2505.19264": "|[improving novel view synthesis of 360$^\\circ$ scenes in extremely sparse views by jointly training hemisphere sampled synthetic images](https://arxiv.org/abs/2505.19264)|[hemisparsegs](https://github.com/angchen-dev/hemisparsegs)|\n", "2505.19319": "|[holistic white-light polyp classification via alignment-free dense distillation of auxiliary optical chromoendoscopy](https://arxiv.org/abs/2505.19319)|[add](https://github.com/huster-hq/add)|\n", "2505.19434": "|[cstrack: enhancing rgb-x tracking via compact spatiotemporal features](https://arxiv.org/abs/2505.19434)|[cstrack](https://github.com/xiaokunfeng/cstrack)|\n", "2505.19455": "|[mm-prompt: cross-modal prompt tuning for continual visual question answering](https://arxiv.org/abs/2505.19455)|[cvqa](https://github.com/xli04/cvqa)|\n", "2505.19503": "|[locality-aware zero-shot human-object interaction detection](https://arxiv.org/abs/2505.19503)|[lain](https://github.com/oreochocolate/lain)|\n", "2505.19536": "|[flowcut: rethinking redundancy via information flow for efficient vision-language models](https://arxiv.org/abs/2505.19536)|[flowcut](https://github.com/tungchintao/flowcut)|\n", "2505.19546": "|[smart-pc: skeletal model adaptation for robust test-time training in point clouds](https://arxiv.org/abs/2505.19546)|[smart-pc](https://github.com/alibahri94/smart-pc)|\n", "2505.19564": "|[k-buffers: a plug-in method for enhancing neural fields with multiple buffers](https://arxiv.org/abs/2505.19564)|[k-buffers](https://github.com/renhaofan/k-buffers)|\n", "2505.19571": "|[vtbench: comprehensive benchmark suite towards real-world virtual try-on models](https://arxiv.org/abs/2505.19571)|[vtbench](https://github.com/huuxiaobin/vtbench)|\n", "2505.19611": "|[align and surpass human camouflaged perception: visual refocus reinforcement fine-tuning](https://arxiv.org/abs/2505.19611)|[vrrf](https://github.com/huuxiaobin/vrrf)|\n", "2505.19618": "|[rotation-equivariant self-supervised method in image denoising](https://arxiv.org/abs/2505.19618)|[adarenet](https://github.com/liuhanze623/adarenet)|\n", "2505.19638": "|[hf-vton: high-fidelity virtual try-on via consistent geometric and semantic alignment](https://arxiv.org/abs/2505.19638)|[hf-vton](https://github.com/mmlph/hf-vton)|\n", "2505.19652": "|[sacm: seeg-audio contrastive matching for chinese speech decoding](https://arxiv.org/abs/2505.19652)|[SACM](https://github.com/WangHongbinary/SACM)|\n", "2505.19659": "|[langdaug: langevin data augmentation for multi-source domain generalization in medical image segmentation](https://arxiv.org/abs/2505.19659)|[langdaug](https://github.com/backpropagator/langdaug)|\n", "2505.19692": "|[drivecamsim: generalizable camera simulation via explicit camera modeling for autonomous driving](https://arxiv.org/abs/2505.19692)|[drivecamsim](https://github.com/swc-17/drivecamsim)|\n", "2505.19742": "|[haodiff: human-aware one-step diffusion via dual-prompt guidance](https://arxiv.org/abs/2505.19742)|[haodiff](https://github.com/gobunu/haodiff)|\n", "2505.19779": "|[advancements in medical image classification through fine-tuning natural domain foundation models](https://arxiv.org/abs/2505.19779)|[medical-transfer-learning](https://github.com/sajjad-sh33/medical-transfer-learning)|\n", "2505.19793": "|[depth-guided bundle sampling for efficient generalizable neural radiance field reconstruction](https://arxiv.org/abs/2505.19793)|[gdb-nerf](https://github.com/klmav-cuc/gdb-nerf)|\n", "2505.19799": "|[a regularization-guided equivariant approach for image restoration](https://arxiv.org/abs/2505.19799)|[eq-reg](https://github.com/yulu919/eq-reg)|\n", "2505.19805": "|[translation-equivariance of normalization layers and aliasing in convolutional neural networks](https://arxiv.org/abs/2505.19805)|[normalization-layers](https://github.com/jscanvic/normalization-layers)|\n", "2505.19812": "|[efficient multi-modal long context learning for training-free adaptation](https://arxiv.org/abs/2505.19812)|[emloc](https://github.com/zehong-ma/emloc)|\n", "2505.19813": "|[golf-nrt: integrating global context and local geometry for few-shot view synthesis](https://arxiv.org/abs/2505.19813)|[golf-nrt](https://github.com/klmav-cuc/golf-nrt)|\n", "2505.19863": "|[fruitnerf++: a generalized multi-fruit counting method utilizing contrastive learning and neural radiance fields](https://arxiv.org/abs/2505.19863)|[fruitnerfpp](https://github.com/meyerls/fruitnerfpp)|\n", "2505.19877": "|[vad-r1: towards video anomaly reasoning via perception-to-cognition chain-of-thought](https://arxiv.org/abs/2505.19877)|[vad-r1](https://github.com/wbfwonderful/vad-r1)|\n", "2505.19889": "|[omnifall: a unified staged-to-wild benchmark for human fall detection](https://arxiv.org/abs/2505.19889)|[omnifall-experiments](https://github.com/simplexsigil/omnifall-experiments)|\n", "2505.19972": "|[phi: bridging domain shift in long-term action quality assessment via progressive hierarchical instruction](https://arxiv.org/abs/2505.19972)|[phi_aqa](https://github.com/zhoukanglei/phi_aqa)|\n", "2505.19995": "|[optimizing edge ai models on hpc systems with the edge in the loop](https://arxiv.org/abs/2505.19995)|[hpc2edge](https://github.com/flanders-make-vzw/hpc2edge)|\n", "2505.20024": "|[reasonplan: unified scene prediction and decision reasoning for closed-loop autonomous driving](https://arxiv.org/abs/2505.20024)|[reasonplan](https://github.com/liuxueyi/reasonplan)|\n", "2505.20038": "|[towards video to piano music generation with chain-of-perform support benchmarks](https://arxiv.org/abs/2505.20038)|[video-to-audio-and-piano](https://github.com/acappemin/video-to-audio-and-piano)|\n", "2505.20049": "|[data-free class-incremental gesture recognition with prototype-guided pseudo feature replay](https://arxiv.org/abs/2505.20049)|[pgpfr-3](https://github.com/sunao-101/pgpfr-3)|\n", "2505.20053": "|[multimodal llm-guided semantic correction in text-to-image diffusion](https://arxiv.org/abs/2505.20053)|[ppad](https://github.com/hellozicky/ppad)|\n", "2505.20107": "|[refining few-step text-to-multiview diffusion via reinforcement learning](https://arxiv.org/abs/2505.20107)|[mvc-zigal](https://github.com/ziyizhang27/mvc-zigal)|\n", "2505.20124": "|[tuna: comprehensive fine-grained temporal understanding evaluation on dense dynamic videos](https://arxiv.org/abs/2505.20124)|[TUNA](https://github.com/friedrichor/TUNA)|\n", "2505.20126": "|[ob3d: a new dataset for benchmarking omnidirectional 3d reconstruction using blender](https://arxiv.org/abs/2505.20126)|[omnidirectional_blender_3d_dataset](https://github.com/gsisaoki/omnidirectional_blender_3d_dataset)|\n", "2505.20138": "|[fairtalk: facilitating balanced participation in video conferencing by implicit visualization of predicted turn-grabbing intention](https://arxiv.org/abs/2505.20138)|[fairtalk](https://github.com/omron-sinicx/fairtalk)|\n", "2505.20152": "|[hard negative contrastive learning for fine-grained geometric understanding in large multimodal models](https://arxiv.org/abs/2505.20152)|[mmgeolm](https://github.com/thu-keg/mmgeolm)|\n", "2505.20156": "|[hunyuanvideo-avatar: high-fidelity audio-driven human animation for multiple characters](https://arxiv.org/abs/2505.20156)|[hunyuanvideo-avatar](https://github.com/tencent-hunyuan/hunyuanvideo-avatar)|\n", "2505.20255": "|[anicrafter: customizing realistic human-centric animation via avatar-background conditioning in video diffusion models](https://arxiv.org/abs/2505.20255)|[anicrafter](https://github.com/myniuuu/anicrafter)|\n", "2505.20256": "|[omni-r1: reinforcement learning for omnimodal reasoning via two-system collaboration](https://arxiv.org/abs/2505.20256)|[omni-r1](https://github.com/aim-uofa/omni-r1)|\n", "2505.20275": "|[imgedit: a unified image editing dataset and benchmark](https://arxiv.org/abs/2505.20275)|[imgedit](https://github.com/pku-yuangroup/imgedit)|\n", "2505.20277": "|[omnicharacter: towards immersive role-playing agents with seamless speech-language personality interaction](https://arxiv.org/abs/2505.20277)|[damo-convai](https://github.com/alibabaresearch/damo-convai)|\n", "2505.20279": "|[vlm-3r: vision-language models augmented with instruction-aligned 3d reconstruction](https://arxiv.org/abs/2505.20279)|[VLM-3R](https://github.com/VITA-Group/VLM-3R)|\n", "2505.20288": "|[hierarchical masked autoregressive models with low-resolution token pivots](https://arxiv.org/abs/2505.20288)|[himar](https://github.com/hidream-ai/himar)|\n", "2505.20291": "|[visualized text-to-image retrieval](https://arxiv.org/abs/2505.20291)|[visualize-then-retrieve](https://github.com/xiaowu0162/visualize-then-retrieve)|\n", "2505.20297": "|[disa: diffusion step annealing in autoregressive image generation](https://arxiv.org/abs/2505.20297)|[disa](https://github.com/qinyu-allen-zhao/disa)|\n", "2505.20298": "|[mangavqa and mangalmm: a benchmark and specialized model for multimodal manga understanding](https://arxiv.org/abs/2505.20298)|[mangalmm](https://github.com/manga109/mangalmm)|\n"}, "2025-05-28": {"2008.12065": "|[propensity-to-pay: machine learning for estimating prediction uncertainty](https://arxiv.org/abs/2008.12065)|[Propensity-to-Pay](https://github.com/mdabashar/Propensity-to-Pay)|\n", "2212.13462": "|[mvtn: learning multi-view transformations for 3d understanding](https://arxiv.org/abs/2212.13462)|[mvtorch](https://github.com/ajhamdi/mvtorch)|\n", "2403.05701": "|[are large language models aligned with people's social intuitions for human-robot interactions?](https://arxiv.org/abs/2403.05701)|[llms-for-social-robotics](https://github.com/lwachowiak/llms-for-social-robotics)|\n", "2405.00604": "|[toward unified practices in trajectory prediction research on bird's-eye-view datasets](https://arxiv.org/abs/2405.00604)|[dronalize](https://github.com/westny/dronalize)|\n", "2405.20791": "|[metags: a meta-learned gaussian-phong model for out-of-distribution 3d scene relighting](https://arxiv.org/abs/2405.20791)|[GS-Phong](https://github.com/ymhe12/GS-Phong)|\n", "2406.03143": "|[zeropur: succinct training-free adversarial purification](https://arxiv.org/abs/2406.03143)|[auto-attack](https://github.com/fra31/auto-attack)|\n", "2406.06039": "|[diving into underwater: segment anything model guided underwater salient instance segmentation and a large-scale dataset](https://arxiv.org/abs/2406.06039)|[usis10k](https://github.com/liamlian0727/usis10k)|\n", "2406.14862": "|[latentexplainer: explaining latent representations in deep generative models with multimodal large language models](https://arxiv.org/abs/2406.14862)|[latentexplainer](https://github.com/mengdanzhu/latentexplainer)|\n", "2407.20114": "|[fico-itr: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis](https://arxiv.org/abs/2407.20114)|[fico-itr](https://github.com/mikelwl/fico-itr)|\n", "2408.08105": "|[multimodal causal reasoning benchmark: challenging vision large language models to discern causal links across modalities](https://arxiv.org/abs/2408.08105)|[mucr](https://github.com/zhiyuan-li-john/mucr)|\n", "2408.15605": "|[es-ptam: event-based stereo parallel tracking and mapping](https://arxiv.org/abs/2408.15605)|[es-ptam](https://github.com/tub-rip/es-ptam)|\n", "2409.03358": "|[mousesis: a frames-and-events dataset for space-time instance segmentation of mice](https://arxiv.org/abs/2409.03358)|[mousesis](https://github.com/tub-rip/mousesis)|\n", "2410.03549": "|[multi-modal atmospheric sensing to augment wearable imu-based hand washing detection](https://arxiv.org/abs/2410.03549)|[wearPuck](https://github.com/kristofvl/wearPuck)|\n", "2410.09403": "|[many heads are better than one: improved scientific idea generation by a llm-based multi-agent system](https://arxiv.org/abs/2410.09403)|[virtual-scientists](https://github.com/open-sciencelab/virtual-scientists)|\n", "2410.22881": "|[sfa-unet: more attention to multi-scale contrast and contextual information in infrared small object segmentation](https://arxiv.org/abs/2410.22881)|[sfa_unet](https://github.com/imadalishah/sfa_unet)|\n", "2411.13112": "|[surds: benchmarking spatial understanding and reasoning in driving scenarios with vision language models](https://arxiv.org/abs/2411.13112)|[drive-mllm](https://github.com/xiandaguo/drive-mllm)|\n", "2412.18038": "|[aa-sgan: adversarially augmented social gan with synthetic data](https://arxiv.org/abs/2412.18038)|[aa-sgan](https://github.com/mirkozaff/aa-sgan)|\n", "2501.11153": "|[efficient frame extraction: a novel approach through frame similarity and surgical tool tracking for video segmentation](https://arxiv.org/abs/2501.11153)|[kinematics-afr](https://github.com/leonlha/kinematics-afr)|\n", "2501.13710": "|[yolo11-jde: fast and accurate multi-object tracking with self-supervised re-id](https://arxiv.org/abs/2501.13710)|[yolo11-jde](https://github.com/inakierregueab/yolo11-jde)|\n", "2502.12110": "|[a-mem: agentic memory for llm agents](https://arxiv.org/abs/2502.12110)|[a-mem](https://github.com/agiresearch/a-mem)|\n", "2502.19459": "|[artgs: building interactable replicas of complex articulated objects via gaussian splatting](https://arxiv.org/abs/2502.19459)|[ArtGS](https://github.com/YuLiu-LY/ArtGS)|\n", "2503.02857": "|[deepfake-eval-2024: a multi-modal in-the-wild benchmark of deepfakes circulated in 2024](https://arxiv.org/abs/2503.02857)|[deepfake-eval-2024](https://github.com/nuriachandra/deepfake-eval-2024)|\n", "2503.10042": "|[how do multimodal large language models handle complex multimodal reasoning? placing them in an extensible escape game](https://arxiv.org/abs/2503.10042)|[EscapeCraft](https://github.com/THUNLP-MT/EscapeCraft)|\n", "2503.13107": "|[clearsight: visual signal enhancement for object hallucination mitigation in multimodal large language models](https://arxiv.org/abs/2503.13107)|[ClearSight](https://github.com/ustc-hyin/ClearSight)|\n", "2504.02826": "|[envisioning beyond the pixels: benchmarking reasoning-informed visual editing](https://arxiv.org/abs/2504.02826)|[risebench](https://github.com/phoenixz810/risebench)|\n", "2504.14717": "|[tapip3d: tracking any point in persistent 3d geometry](https://arxiv.org/abs/2504.14717)|[tapip3d](https://github.com/zbw001/tapip3d)|\n", "2505.10464": "|[hwa-unetr: hierarchical window aggregate unetr for 3d multimodal gastric lesion segmentation](https://arxiv.org/abs/2505.10464)|[hwa-unetr](https://github.com/jeming-creater/hwa-unetr)|\n", "2505.10610": "|[mmlongbench: benchmarking long-context vision-language models effectively and thoroughly](https://arxiv.org/abs/2505.10610)|[mmlongbench](https://github.com/edinburghnlp/mmlongbench)|\n", "2505.12155": "|[softpq: robust instance segmentation evaluation via soft matching and tunable thresholds](https://arxiv.org/abs/2505.12155)|[SoftPQ](https://github.com/rkarmaka/SoftPQ)|\n", "2505.12499": "|[contrastive alignment with semantic gap-aware corrections in text-video retrieval](https://arxiv.org/abs/2505.12499)|[gare-text-video-retrieval](https://github.com/musicman217/gare-text-video-retrieval)|\n", "2505.13539": "|[eulearn: a 3d database for learning euler characteristics](https://arxiv.org/abs/2505.13539)|[eulearn_db](https://github.com/appliedgeometry/eulearn_db)|\n", "2505.15812": "|[leveraging the powerful attention of a pre-trained diffusion model for exemplar-based image colorization](https://arxiv.org/abs/2505.15812)|[powerful-attention](https://github.com/satoshi-kosugi/powerful-attention)|\n", "2505.17629": "|[transbench: breaking barriers for transferable graphical user interface agents in dynamic digital environments](https://arxiv.org/abs/2505.17629)|[transbench](https://github.com/buaa-irip-llm/transbench)|\n", "2505.18022": "|[remotesam: towards segment anything for earth observation](https://arxiv.org/abs/2505.18022)|[RemoteSAM](https://github.com/1e12Leon/RemoteSAM)|\n", "2505.18060": "|[semantic correspondence: unified benchmarking and a strong baseline](https://arxiv.org/abs/2505.18060)|[Semantic-Correspondence](https://github.com/Visual-AI/Semantic-Correspondence)|\n", "2505.18958": "|[cdpdnet: integrating text guidance with hybrid vision encoders for medical image segmentation](https://arxiv.org/abs/2505.18958)|[cdpdnet](https://github.com/wujiong-hub/cdpdnet)|\n", "2505.19650": "|[modality curation: building universal embeddings for advanced multimodal information retrieval](https://arxiv.org/abs/2505.19650)|[UNITE](https://github.com/friedrichor/UNITE)|\n", "2505.20322": "|[beyond prompt engineering: robust behavior control in llms via steering target atoms](https://arxiv.org/abs/2505.20322)|[steer-target-atoms](https://github.com/zjunlp/steer-target-atoms)|\n", "2505.20353": "|[fastcache: fast caching for diffusion transformer through learnable linear approximation](https://arxiv.org/abs/2505.20353)|[fastcache-xdit](https://github.com/noakliu/fastcache-xdit)|\n", "2505.20381": "|[reamot: a benchmark and framework for reasoning-based multi-object tracking](https://arxiv.org/abs/2505.20381)|[reamot](https://github.com/chen-si-jia/reamot)|\n", "2505.20414": "|[retromotion: retrocausal motion forecasting models are instructable](https://arxiv.org/abs/2505.20414)|[future-motion](https://github.com/kit-mrt/future-motion)|\n", "2505.20426": "|[mmperspective: do mllms understand perspective? a comprehensive benchmark for perspective perception, reasoning, and robustness](https://arxiv.org/abs/2505.20426)|[MMPerspective](https://github.com/yunlong10/MMPerspective)|\n", "2505.20471": "|[weatheredit: controllable weather editing with 4d gaussian field](https://arxiv.org/abs/2505.20471)|[WeatherEdit](https://github.com/Jumponthemoon/WeatherEdit)|\n", "2505.20753": "|[understand, think, and answer: advancing visual reasoning with large multimodal models](https://arxiv.org/abs/2505.20753)|[griffon](https://github.com/jefferyzhan/griffon)|\n", "2505.20788": "|[enhancing wearable tap water audio detection through subclass annotation in the hd-epic dataset](https://arxiv.org/abs/2505.20788)|[hd-epic-tap](https://github.com/RBurchard/hd-epic-tap)|\n", "2505.20894": "|[deepconvcontext: a multi-scale approach to timeseries classification in human activity recognition](https://arxiv.org/abs/2505.20894)|[context_har](https://github.com/mariusbock/context_har)|\n", "2505.20897": "|[cross from left to right brain: adaptive text dreamer for vision-and-language navigation](https://arxiv.org/abs/2505.20897)|[adaptive-text-dreamer](https://github.com/zhangpingrui/adaptive-text-dreamer)|\n", "2505.20924": "|[label leakage in federated inertial-based human activity recognition](https://arxiv.org/abs/2505.20924)|[leakage_har](https://github.com/mariusbock/leakage_har)|\n", "2505.20981": "|[refav: towards planning-centric scenario mining](https://arxiv.org/abs/2505.20981)|[refav](https://github.com/cainand/refav)|\n", "2505.21032": "|[featinv: spatially resolved mapping from feature space to input space using conditional diffusion models](https://arxiv.org/abs/2505.21032)|[FeatInv](https://github.com/AI4HealthUOL/FeatInv)|\n", "2505.21152": "|[robis: robust binary segmentation for high-resolution industrial images](https://arxiv.org/abs/2505.21152)|[robis](https://github.com/xrli-u/robis)|\n", "2505.21262": "|[dimosr: feature modulation via multi-branch dilated convolutions for efficient image super-resolution](https://arxiv.org/abs/2505.21262)|[dimosr](https://github.com/makinyilmaz/dimosr)|\n", "2505.21375": "|[geollava-8k: scaling remote-sensing multimodal large language models to 8k resolution](https://arxiv.org/abs/2505.21375)|[GeoLLaVA-8K](https://github.com/MiliLab/GeoLLaVA-8K)|\n", "2505.21473": "|[detailflow: 1d coarse-to-fine autoregressive image generation via next-detail prediction](https://arxiv.org/abs/2505.21473)|[detailflow](https://github.com/byteflow-ai/detailflow)|\n", "2505.21497": "|[paper2poster: towards multimodal poster automation from scientific papers](https://arxiv.org/abs/2505.21497)|[paper2poster](https://github.com/paper2poster/paper2poster)|\n"}, "2025-05-29": {"2207.12163": "|[multi-scale raft: combining hierarchical concepts for learning-based optical flow estimation](https://arxiv.org/abs/2207.12163)|[ms_raft](https://github.com/cv-stuttgart/ms_raft)|\n", "2210.16900": "|[high resolution multi-scale raft (robust vision challenge 2022)](https://arxiv.org/abs/2210.16900)|[MS_RAFT_plus](https://github.com/cv-stuttgart/MS_RAFT_plus)|\n", "2311.02661": "|[ccmr: high resolution optical flow estimation via coarse-to-fine context-guided motion reasoning](https://arxiv.org/abs/2311.02661)|[ccmr](https://github.com/cv-stuttgart/ccmr)|\n", "2311.18083": "|[meta co-training: two views are better than one](https://arxiv.org/abs/2311.18083)|[meta-co-training](https://github.com/jayrothenberger/meta-co-training)|\n", "2402.02933": "|[intrinsic user-centric interpretability through global mixture of experts](https://arxiv.org/abs/2402.02933)|[interpretcc](https://github.com/epfl-ml4ed/interpretcc)|\n", "2405.11985": "|[mtvqa: benchmarking multilingual text-centric visual question answering](https://arxiv.org/abs/2405.11985)|[MTVQA](https://github.com/bytedance/MTVQA)|\n", "2407.08555": "|[slord: structural low-rank descriptors for shape consistency in vertebrae segmentation](https://arxiv.org/abs/2407.08555)|[slord-verse](https://github.com/alexyouxin/slord-verse)|\n", "2407.19696": "|[cross-layer feature pyramid transformer for small object detection in aerial images](https://arxiv.org/abs/2407.19696)|[cfpt](https://github.com/duzw9311/cfpt)|\n", "2409.07973": "|[sparse r-cnn obb: ship target detection in sar images based on oriented sparse proposals](https://arxiv.org/abs/2409.07973)|[sparse-r-cnn-obb](https://github.com/ka-mirul/sparse-r-cnn-obb)|\n", "2409.19291": "|[clip-moe: towards building mixture of experts for clip with diversified multiplet upcycling](https://arxiv.org/abs/2409.19291)|[CLIP-MoE](https://github.com/OpenSparseLLMs/CLIP-MoE)|\n", "2410.13084": "|[boxr: body and head motion optimization framework for extended reality](https://arxiv.org/abs/2410.13084)|[boxr](https://github.com/rtenlab/boxr)|\n", "2411.01749": "|[multi-task geometric estimation of depth and surface normal from monocular 360{\\deg} images](https://arxiv.org/abs/2411.01749)|[360mtlgeometricestimation](https://github.com/huangkun101230/360mtlgeometricestimation)|\n", "2502.00563": "|[complex wavelet mutual information loss: a multi-scale loss function for semantic segmentation](https://arxiv.org/abs/2502.00563)|[CWMI](https://github.com/lurenhaothu/CWMI)|\n", "2502.00619": "|[distribution-aware fairness learning in medical image segmentation from a control-theoretic perspective](https://arxiv.org/abs/2502.00619)|[dmoe](https://github.com/tvseg/dmoe)|\n", "2502.05749": "|[unidb: a unified diffusion bridge framework via stochastic optimal control](https://arxiv.org/abs/2502.05749)|[unidb](https://github.com/unidb-soc/unidb)|\n", "2502.11190": "|[relearn: unlearning via learning for large language models](https://arxiv.org/abs/2502.11190)|[unlearn](https://github.com/zjunlp/unlearn)|\n", "2502.11882": "|[leveraging dual process theory in language agent framework for real-time simultaneous human-ai collaboration](https://arxiv.org/abs/2502.11882)|[dpt-agent](https://github.com/sjtu-marl/dpt-agent)|\n", "2502.12579": "|[chats: combining human-aligned optimization and test-time sampling for text-to-image generation](https://arxiv.org/abs/2502.12579)|[CHATS](https://github.com/AIDC-AI/CHATS)|\n", "2503.04838": "|[combined physics and event camera simulator for slip detection](https://arxiv.org/abs/2503.04838)|[event_slip](https://github.com/tub-rip/event_slip)|\n", "2503.07265": "|[wise: a world knowledge-informed semantic evaluation for text-to-image generation](https://arxiv.org/abs/2503.07265)|[wise](https://github.com/pku-yuangroup/wise)|\n", "2505.04229": "|[a weak supervision learning approach towards an equitable mobility estimation](https://arxiv.org/abs/2505.04229)|[equitable_mobility_estimation](https://github.com/societal-computing/equitable_mobility_estimation)|\n", "2505.12363": "|[towards visuospatial cognition via hierarchical fusion of visual experts](https://arxiv.org/abs/2505.12363)|[vica](https://github.com/nkkbr/vica)|\n", "2505.14664": "|[akrmap: adaptive kernel regression for trustworthy visualization of cross-modal embeddings](https://arxiv.org/abs/2505.14664)|[akrmap](https://github.com/yilinye/akrmap)|\n", "2505.16832": "|[from eduvisbench to eduvisagent: a benchmark and multi-agent framework for reasoning-driven pedagogical visualization](https://arxiv.org/abs/2505.16832)|[eduvisbench](https://github.com/aiming-lab/eduvisbench)|\n", "2505.17002": "|[paeff: precise alignment and enhanced gated feature fusion for face-voice association](https://arxiv.org/abs/2505.17002)|[paeff](https://github.com/hannabdul/paeff)|\n", "2505.17937": "|[survival games: human-llm strategic showdowns under severe resource scarcity](https://arxiv.org/abs/2505.17937)|[survival-games](https://github.com/hong123123/survival-games)|\n", "2505.20641": "|[see through the dark: learning illumination-affined representations for nighttime occupancy prediction](https://arxiv.org/abs/2505.20641)|[liar](https://github.com/yanzq95/liar)|\n", "2505.21136": "|[sageattention2++: a more efficient implementation of sageattention2](https://arxiv.org/abs/2505.21136)|[SageAttention](https://github.com/thu-ml/SageAttention)|\n", "2505.21544": "|[vision meets language: a rag-augmented yolov8 framework for coffee disease diagnosis and farmer assistance](https://arxiv.org/abs/2505.21544)|[A-RAG-Augmented-YOLOv8-Framework](https://github.com/semanto-mondal/A-RAG-Augmented-YOLOv8-Framework)|\n", "2505.21582": "|[aitee -- agentic tutor for electrical engineering](https://arxiv.org/abs/2505.21582)|[aitee-dataset](https://github.com/cknievel/aitee-dataset)|\n", "2505.21592": "|[taylor expansion-based kolmogorov-arnold network for blind image quality assessment](https://arxiv.org/abs/2505.21592)|[kan4iqa](https://github.com/cuc-chen/kan4iqa)|\n", "2505.21620": "|[videomarkbench: benchmarking robustness of video watermarking](https://arxiv.org/abs/2505.21620)|[videomarkbench](https://github.com/zhengyuan-jiang/videomarkbench)|\n", "2505.21634": "|[laparoscopic image desmoking using the u-net with new loss function and integrated differentiable wiener filter](https://arxiv.org/abs/2505.21634)|[imagedesmoke](https://github.com/chengyuyang-njit/imagedesmoke)|\n", "2505.21925": "|[renderformer: transformer-based neural rendering of triangle meshes with global illumination](https://arxiv.org/abs/2505.21925)|[renderformer](https://github.com/microsoft/renderformer)|\n", "2505.21932": "|[higher-order group synchronization](https://arxiv.org/abs/2505.21932)|[CHMP](https://github.com/Addieduncan/CHMP)|\n", "2505.21954": "|[unitalk: towards universal active speaker detection in real world scenarios](https://arxiv.org/abs/2505.21954)|[UniTalk-ASD-code](https://github.com/plnguyen2908/UniTalk-ASD-code)|\n", "2505.21973": "|[towards structure-aware model for multi-modal knowledge graph completion](https://arxiv.org/abs/2505.21973)|[TSAM](https://github.com/2391134843/TSAM)|\n", "2505.22228": "|[gomatching++: parameter- and data-efficient arbitrary-shaped video text spotting and benchmarking](https://arxiv.org/abs/2505.22228)|[gomatching](https://github.com/hxyz-123/gomatching)|\n", "2505.22334": "|[advancing multimodal reasoning via reinforcement learning with cold start](https://arxiv.org/abs/2505.22334)|[easyr1](https://github.com/hiyouga/easyr1)|\n", "2505.22438": "|[synonymous variational inference for perceptual image compression](https://arxiv.org/abs/2505.22438)|[SynonymousImageCompression](https://github.com/ZJLiang6412/SynonymousImageCompression)|\n", "2505.22453": "|[unsupervised post-training for multi-modal llm reasoning via grpo](https://arxiv.org/abs/2505.22453)|[easyr1](https://github.com/hiyouga/easyr1)|\n", "2505.22664": "|[zero-shot vision encoder grafting via llm surrogates](https://arxiv.org/abs/2505.22664)|[zero](https://github.com/facebookresearch/zero)|\n"}, "2025-05-30": {"2303.09117": "|[cross-modal causal intervention for medical report generation](https://arxiv.org/abs/2303.09117)|[vlci](https://github.com/wissingchen/vlci)|\n", "2307.07333": "|[syntable: a synthetic data generation pipeline for unseen object amodal instance segmentation of cluttered tabletop scenes](https://arxiv.org/abs/2307.07333)|[syntable](https://github.com/ngzhili/syntable)|\n", "2309.10815": "|[panopticnerf-360: panoramic 3d-to-2d label transfer in urban scenes](https://arxiv.org/abs/2309.10815)|[panopticnerf](https://github.com/fuxiao0719/panopticnerf)|\n", "2312.03207": "|[satellite imagery and ai: a new era in ocean conservation, from research to deployment and impact (version. 2.0)](https://arxiv.org/abs/2312.03207)|[vessel-detection-sentinels](https://github.com/allenai/vessel-detection-sentinels)|\n", "2401.13330": "|[nachos: neural architecture search for hardware constrained early exit neural networks](https://arxiv.org/abs/2401.13330)|[nas](https://github.com/ai-tech-research-lab/nas)|\n", "2404.08008": "|[sample-efficient human evaluation of large language models via maximum discrepancy competition](https://arxiv.org/abs/2404.08008)|[mad-eval](https://github.com/weiji-feng/mad-eval)|\n", "2405.20032": "|[promptus: can prompts streaming replace video streaming with stable diffusion](https://arxiv.org/abs/2405.20032)|[Promptus](https://github.com/JiangkaiWu/Promptus)|\n", "2406.09546": "|[qmamba: on first exploration of vision mamba for image quality assessment](https://arxiv.org/abs/2406.09546)|[qmamba](https://github.com/bingo-g/qmamba)|\n", "2407.09946": "|[low-rank interconnected adaptation across layers](https://arxiv.org/abs/2407.09946)|[lily](https://github.com/yibozhong/lily)|\n", "2407.11500": "|[an ai system for continuous knee osteoarthritis severity grading using self-supervised anomaly detection with limited data](https://arxiv.org/abs/2407.11500)|[ss-fewsome_disease_severity_knee_osteoarthritis](https://github.com/niamhbelton/ss-fewsome_disease_severity_knee_osteoarthritis)|\n", "2409.04003": "|[dreamforge: motion-aware autoregressive video generation for multi-view driving scenes](https://arxiv.org/abs/2409.04003)|[DriveArena](https://github.com/PJLab-ADG/DriveArena)|\n", "2410.10112": "|[can we predict performance of large models across vision-language tasks?](https://arxiv.org/abs/2410.10112)|[crosspred-lvlm](https://github.com/qinyu-allen-zhao/crosspred-lvlm)|\n", "2411.06503": "|[diffusion sampling correction via approximately 10 parameters](https://arxiv.org/abs/2411.06503)|[PAS](https://github.com/onefly123/PAS)|\n", "2412.00175": "|[circumventing shortcuts in audio-visual deepfake detection datasets with unsupervised learning](https://arxiv.org/abs/2412.00175)|[avh-align](https://github.com/bit-ml/avh-align)|\n", "2412.10908": "|[do large language vision models understand 3d shapes?](https://arxiv.org/abs/2412.10908)|[testing-large-vision-language-models-lvlm-on-visual-questions](https://github.com/sagieppel/testing-large-vision-language-models-lvlm-on-visual-questions)|\n", "2412.15819": "|[robustness-enhanced myoelectric control with gan-based open-set recognition](https://arxiv.org/abs/2412.15819)|[paper_code_robustness_enhanced_myoelectric_control](https://github.com/cwdao/paper_code_robustness_enhanced_myoelectric_control)|\n", "2412.16197": "|[generalizable representation learning for fmri-based neurological disorder identification](https://arxiv.org/abs/2412.16197)|[MeTSK](https://github.com/wenhui0206/MeTSK)|\n", "2501.01482": "|[an unsupervised method for mri recovery: deep image prior with structured sparsity](https://arxiv.org/abs/2501.01482)|[discus](https://github.com/osu-mr/discus)|\n", "2501.05874": "|[videorag: retrieval-augmented generation over video corpus](https://arxiv.org/abs/2501.05874)|[videorag](https://github.com/starsuzi/videorag)|\n", "2501.18463": "|[a benchmark and evaluation for real-world out-of-distribution detection using vision-language models](https://arxiv.org/abs/2501.18463)|[ood-x-benchmarks](https://github.com/hoshi23/ood-x-benchmarks)|\n", "2502.00264": "|[beyond the permutation symmetry of transformers: the role of rotation for model fusion](https://arxiv.org/abs/2502.00264)|[rotationsymmetry](https://github.com/zhengzaiyi/rotationsymmetry)|\n", "2502.11638": "|[safeguarding ai in medical imaging: post-hoc out-of-distribution detection with normalizing flows](https://arxiv.org/abs/2502.11638)|[medoodflow](https://github.com/dlotfi/medoodflow)|\n", "2502.15538": "|[sotopia-$\\omega$: dynamic strategy injection learning and social instruction following evaluation for social agents](https://arxiv.org/abs/2502.15538)|[SOTOPIA-Omega](https://github.com/WYRipple/SOTOPIA-Omega)|\n", "2502.16359": "|[audio visual segmentation through text embeddings](https://arxiv.org/abs/2502.16359)|[av2t-sam](https://github.com/bok-bok/av2t-sam)|\n", "2503.05214": "|[gaussian random fields as an abstract representation of patient metadata for multimodal medical image segmentation](https://arxiv.org/abs/2503.05214)|[multimodal-grf](https://github.com/mmu-dermatology-research/multimodal-grf)|\n", "2503.13330": "|[leavs: an llm-based labeler for abdominal ct supervision](https://arxiv.org/abs/2503.13330)|[LEAVS](https://github.com/rsummers11/LEAVS)|\n", "2503.23509": "|[referdino-plus: 2nd solution for 4th pvuw mevis challenge at cvpr 2025](https://arxiv.org/abs/2503.23509)|[referdino-plus](https://github.com/isee-laboratory/referdino-plus)|\n", "2503.24129": "|[it's a (blind) match! towards vision-language correspondence without parallel data](https://arxiv.org/abs/2503.24129)|[itsamatch](https://github.com/dominik-schnaus/itsamatch)|\n", "2504.03553": "|[agentic knowledgeable self-awareness](https://arxiv.org/abs/2504.03553)|[knowself](https://github.com/zjunlp/knowself)|\n", "2504.13169": "|[generate, but verify: reducing hallucination in vision-language models with retrospective resampling](https://arxiv.org/abs/2504.13169)|[reverse_vlm](https://github.com/tsunghan-wu/reverse_vlm)|\n", "2504.21336": "|[unibiomed: a universal foundation model for grounded biomedical image interpretation](https://arxiv.org/abs/2504.21336)|[UniBiomed](https://github.com/Luffy03/UniBiomed)|\n", "2505.16091": "|[oscar: one-step diffusion codec for image compression across multiple bit-rates](https://arxiv.org/abs/2505.16091)|[oscar](https://github.com/jp-guo/oscar)|\n", "2505.17955": "|[diffusion classifiers understand compositionality, but conditions apply](https://arxiv.org/abs/2505.17955)|[diffusion-classifiers-compositionality](https://github.com/eugene6923/diffusion-classifiers-compositionality)|\n", "2505.18424": "|[how we won the isles'24 challenge by preprocessing](https://arxiv.org/abs/2505.18424)|[ISLES2024](https://github.com/KurtLabUW/ISLES2024)|\n", "2505.19256": "|[polypose: localizing deformable anatomy in 3d from sparse 2d x-ray images using polyrigid transforms](https://arxiv.org/abs/2505.19256)|[polypose](https://github.com/eigenvivek/polypose)|\n", "2505.19328": "|[bah dataset for ambivalence/hesitancy recognition in videos for behavioural change](https://arxiv.org/abs/2505.19328)|[bah-dataset](https://github.com/sbelharbi/bah-dataset)|\n", "2505.20569": "|[retrieval visual contrastive decoding to mitigate object hallucinations in large vision-language models](https://arxiv.org/abs/2505.20569)|[rvcd](https://github.com/jihoonlee9898/rvcd)|\n", "2505.21070": "|[minute-long videos with dual parallelisms](https://arxiv.org/abs/2505.21070)|[dualparal](https://github.com/dualparal-project/dualparal)|\n", "2505.21144": "|[fastface: tuning identity preservation in distilled diffusion via guidance and attention](https://arxiv.org/abs/2505.21144)|[FastFace](https://github.com/ControlGenAI/FastFace)|\n", "2505.21956": "|[cross-modal rag: sub-dimensional retrieval-augmented text-to-image generation](https://arxiv.org/abs/2505.21956)|[cross-modal-rag](https://github.com/mengdanzhu/cross-modal-rag)|\n", "2505.22353": "|[vme: a satellite imagery dataset and benchmark for detecting vehicles in the middle east and beyond](https://arxiv.org/abs/2505.22353)|[VME_CDSI_dataset_benchmark](https://github.com/nalemadi/VME_CDSI_dataset_benchmark)|\n", "2505.22421": "|[geodrive: 3d geometry-informed driving world model with precise action control](https://arxiv.org/abs/2505.22421)|[geodrive](https://github.com/antonioo-c/geodrive)|\n", "2505.22705": "|[hidream-i1: a high-efficient image generative foundation model with sparse diffusion transformer](https://arxiv.org/abs/2505.22705)|[hidream-i1](https://github.com/hidream-ai/hidream-i1)|\n", "2505.22809": "|[first steps towards overhearing llm agents: a case study with dungeons & dragons gameplay](https://arxiv.org/abs/2505.22809)|[overhearing_agents](https://github.com/zhudotexe/overhearing_agents)|\n", "2505.22850": "|[improving contrastive learning for referring expression counting](https://arxiv.org/abs/2505.22850)|[c-rex](https://github.com/cvlab-stonybrook/c-rex)|\n", "2505.22863": "|[large language models for depression recognition in spoken language integrating psychological knowledge](https://arxiv.org/abs/2505.22863)|[depression-detection](https://github.com/myxp-lyp/depression-detection)|\n", "2505.22869": "|[cfp-gen: combinatorial functional protein generation via diffusion language models](https://arxiv.org/abs/2505.22869)|[cfpgen](https://github.com/yinjunbo/cfpgen)|\n", "2505.22938": "|[fast isotropic median filtering](https://arxiv.org/abs/2505.22938)|[fast-isotropic-median-filter](https://github.com/google/fast-isotropic-median-filter)|\n", "2505.22977": "|[hypermotion: dit-based pose-guided human image animation of complex motions](https://arxiv.org/abs/2505.22977)|[Hyper-Motion](https://github.com/vivoCameraResearch/Hyper-Motion)|\n", "2505.23008": "|[synthetic document question answering in hungarian](https://arxiv.org/abs/2505.23008)|[hudocvqa](https://github.com/snova-jonathanl/hudocvqa)|\n", "2505.23012": "|[spatio-temporal joint density driven learning for skeleton-based action recognition](https://arxiv.org/abs/2505.23012)|[stjd-spatio-temporal-joint-density-driven-learning-for-skeleton-based-action-recognition](https://github.com/shanakarg/stjd-spatio-temporal-joint-density-driven-learning-for-skeleton-based-action-recognition)|\n", "2505.23027": "|[diverse prototypical ensembles improve robustness to subpopulation shift](https://arxiv.org/abs/2505.23027)|[dpe4subpop](https://github.com/minhto2802/dpe4subpop)|\n", "2505.23040": "|[deep modeling and optimization of medical image classification](https://arxiv.org/abs/2505.23040)|[skincancersimulation](https://github.com/aipmlab/skincancersimulation)|\n", "2505.23043": "|[are unified vision-language models necessary: generalization across understanding and generation](https://arxiv.org/abs/2505.23043)|[generalization_unified_vlm](https://github.com/majordavidzhang/generalization_unified_vlm)|\n", "2505.23045": "|[multi-sourced compositional generalization in visual question answering](https://arxiv.org/abs/2505.23045)|[mscg](https://github.com/nevermorelch/mscg)|\n", "2505.23068": "|[urwkv: unified rwkv model with multi-state perspective for low-light image restoration](https://arxiv.org/abs/2505.23068)|[urwkv](https://github.com/fzu-n/urwkv)|\n", "2505.23093": "|[lemore: learn more details for lightweight semantic segmentation](https://arxiv.org/abs/2505.23093)|[lemore](https://github.com/miannaeem-lab/lemore)|\n", "2505.23134": "|[zero-to-hero: zero-shot initialization empowering reference-based video appearance editing](https://arxiv.org/abs/2505.23134)|[zero2hero](https://github.com/tonniia/zero2hero)|\n", "2505.23143": "|[interpreting chest x-rays like a radiologist: a benchmark with clinical reasoning](https://arxiv.org/abs/2505.23143)|[cxrtrek](https://github.com/guanjinquan/cxrtrek)|\n", "2505.23145": "|[flowalign: trajectory-regularized, inversion-free flow-based image editing](https://arxiv.org/abs/2505.23145)|[flowalign](https://github.com/flowalign/flowalign)|\n", "2505.23155": "|[prefm: online audio-visual event parsing via predictive future modeling](https://arxiv.org/abs/2505.23155)|[prefm](https://github.com/xiaoyu-1123/prefm)|\n", "2505.23173": "|[pseudo multi-source domain generalization: bridging the gap between single and multi-source domain generalization](https://arxiv.org/abs/2505.23173)|[pseudodomainbed](https://github.com/s-enmt/pseudodomainbed)|\n", "2505.23180": "|[proximal algorithm unrolling: flexible and efficient reconstruction networks for single-pixel imaging](https://arxiv.org/abs/2505.23180)|[proxunroll](https://github.com/pwangcs/proxunroll)|\n", "2505.23183": "|[unsupervised word-level quality estimation for machine translation through the lens of annotators (dis)agreement](https://arxiv.org/abs/2505.23183)|[labl](https://github.com/gsarti/labl)|\n", "2505.23214": "|[samamba: adaptive state space modeling with hierarchical vision for infrared small target detection](https://arxiv.org/abs/2505.23214)|[samamba](https://github.com/zhengshuchen/samamba)|\n", "2505.23253": "|[unitex: universal high fidelity generative texturing for 3d shapes](https://arxiv.org/abs/2505.23253)|[unitex](https://github.com/yixunliang/unitex)|\n", "2505.23271": "|[lada: scalable label-specific clip adapter for continual learning](https://arxiv.org/abs/2505.23271)|[lada](https://github.com/maolinluo/lada)|\n", "2505.23280": "|[holistic large-scale scene reconstruction via mixed gaussian splatting](https://arxiv.org/abs/2505.23280)|[mixgs](https://github.com/azhuantou/mixgs)|\n", "2505.23290": "|[wav2sem: plug-and-play audio semantic decoupling for 3d speech-driven facial animation](https://arxiv.org/abs/2505.23290)|[wav2sem](https://github.com/wslh852/wav2sem)|\n", "2505.23313": "|[adversarial semantic and label perturbation attack for pedestrian attribute recognition](https://arxiv.org/abs/2505.23313)|[openpar](https://github.com/event-ahu/openpar)|\n", "2505.23343": "|[diffusion sampling path tells more: an efficient plug-and-play strategy for sample filtering](https://arxiv.org/abs/2505.23343)|[cfg-rejection](https://github.com/wsx20003/cfg-rejection)|\n", "2505.23353": "|[synthetic generation and latent projection denoising of rim lesions in multiple sclerosis](https://arxiv.org/abs/2505.23353)|[prlx-gan](https://github.com/agr78/prlx-gan)|\n", "2505.23359": "|[videoreasonbench: can mllms perform vision-centric complex video reasoning?](https://arxiv.org/abs/2505.23359)|[video_reason_bench](https://github.com/llyx97/video_reason_bench)|\n", "2505.23380": "|[unirl: self-improving unified multimodal models via supervised and reinforcement learning](https://arxiv.org/abs/2505.23380)|[unirl](https://github.com/showlab/unirl)|\n", "2505.23406": "|[video editing for audio-visual dubbing](https://arxiv.org/abs/2505.23406)|[edidub-results](https://github.com/edidub/edidub-results)|\n", "2505.23439": "|[viton-drr: details retention virtual try-on via non-rigid registration](https://arxiv.org/abs/2505.23439)|[viton-drr-main](https://github.com/minqili/viton-drr-main)|\n", "2505.23469": "|[a divide-and-conquer approach for global orientation of non-watertight scene-level point clouds using 0-1 integer optimization](https://arxiv.org/abs/2505.23469)|[dacpo](https://github.com/zd-lee/dacpo)|\n", "2505.23475": "|[timepoint: accelerated time series alignment via self-supervised keypoint and descriptor learning](https://arxiv.org/abs/2505.23475)|[timepoint](https://github.com/bgu-cs-vil/timepoint)|\n", "2505.23481": "|[physicsnerf: physics-guided 3d reconstruction from sparse views](https://arxiv.org/abs/2505.23481)|[physicsnerf](https://github.com/anonymous-researcher-01/physicsnerf)|\n", "2505.23484": "|[vcapsbench: a large-scale fine-grained benchmark for video caption quality evaluation](https://arxiv.org/abs/2505.23484)|[vcapsbench](https://github.com/gxym/vcapsbench)|\n", "2505.23504": "|[vau-r1: advancing video anomaly understanding via reinforcement fine-tuning](https://arxiv.org/abs/2505.23504)|[vau-r1](https://github.com/gvclab/vau-r1)|\n", "2505.23525": "|[hallo4: high-fidelity dynamic portrait animation via direct preference optimization and temporal motion modulation](https://arxiv.org/abs/2505.23525)|[hallo4](https://github.com/xyz123xyz456/hallo4)|\n", "2505.23595": "|[deepchest: dynamic gradient-free task weighting for effective multi-task learning in chest x-ray classification](https://arxiv.org/abs/2505.23595)|[deepchest-mtl](https://github.com/youssefkhalil320/deepchest-mtl)|\n", "2505.23606": "|[muddit: liberating generation beyond text-to-image with a unified discrete diffusion model](https://arxiv.org/abs/2505.23606)|[muddit](https://github.com/m-e-agi-lab/muddit)|\n", "2505.23651": "|[merge-friendly post-training quantization for multi-target domain adaptation](https://arxiv.org/abs/2505.23651)|[hdrq](https://github.com/ewsn1593/hdrq)|\n", "2505.23660": "|[d-ar: diffusion via autoregressive models](https://arxiv.org/abs/2505.23660)|[d-ar](https://github.com/showlab/d-ar)|\n", "2505.23693": "|[vf-eval: evaluating multimodal llms for generating feedback on aigc videos](https://arxiv.org/abs/2505.23693)|[vf-eval](https://github.com/sighingsnow/vf-eval)|\n", "2505.23704": "|[cldtracker: a comprehensive language description for visual tracking](https://arxiv.org/abs/2505.23704)|[cldtracker](https://github.com/hamadya/cldtracker)|\n", "2505.23742": "|[magref: masked guidance for any-reference video generation](https://arxiv.org/abs/2505.23742)|[magref](https://github.com/magref-video/magref)|\n", "2505.23745": "|[to trust or not to trust your vision-language model's prediction](https://arxiv.org/abs/2505.23745)|[trustvlm](https://github.com/epfl-imos/trustvlm)|\n", "2505.23752": "|[thinkgeo: evaluating tool-augmented agents for remote sensing tasks](https://arxiv.org/abs/2505.23752)|[thinkgeo](https://github.com/mbzuai-oryx/thinkgeo)|\n", "2505.23757": "|[impromptu vla: open weights and open data for driving vision-language-action models](https://arxiv.org/abs/2505.23757)|[impromptu-vla](https://github.com/ahydchh/impromptu-vla)|\n", "2505.23759": "|[puzzled by puzzles: when vision-language models can't take a hint](https://arxiv.org/abs/2505.23759)|[visual_puzzles](https://github.com/kyunnilee/visual_puzzles)|\n", "2505.23762": "|[zerogui: automating online gui learning at zero human cost](https://arxiv.org/abs/2505.23762)|[zerogui](https://github.com/opengvlab/zerogui)|\n", "2505.23769": "|[textregion: text-aligned region tokens from frozen image-text models](https://arxiv.org/abs/2505.23769)|[TextRegion](https://github.com/avaxiao/TextRegion)|\n"}, "2025-05-31": {}, "2025-06-01": {}, "2025-06-02": {"2308.06453": "|[multi-label knowledge distillation](https://arxiv.org/abs/2308.06453)|[l2d](https://github.com/penghui-yang/l2d)|\n", "2309.00287": "|[fast diffusion em: a diffusion model for blind inverse problems with application to deconvolution](https://arxiv.org/abs/2309.00287)|[fastdiffusionem](https://github.com/claroche-r/fastdiffusionem)|\n", "2309.15818": "|[show-1: marrying pixel and latent diffusion models for text-to-video generation](https://arxiv.org/abs/2309.15818)|[show-1](https://github.com/showlab/show-1)|\n", "2312.02219": "|[behind the magic, merlim: multi-modal evaluation benchmark for large image-language models](https://arxiv.org/abs/2312.02219)|[merlim](https://github.com/ojedaf/merlim)|\n", "2404.18919": "|[theatergen: character management with llm for consistent multi-turn image generation](https://arxiv.org/abs/2404.18919)|[theatergen](https://github.com/donahowe/theatergen)|\n", "2405.14979": "|[craftsman3d: high-fidelity mesh generation with 3d native generation and interactive geometry refiner](https://arxiv.org/abs/2405.14979)|[craftsman](https://github.com/wyysf-98/craftsman)|\n", "2406.01388": "|[autostudio: crafting consistent subjects in multi-turn interactive image generation](https://arxiv.org/abs/2406.01388)|[AutoStudio](https://github.com/donahowe/AutoStudio)|\n", "2406.11317": "|[guicourse: from general vision language models to versatile gui agents](https://arxiv.org/abs/2406.11317)|[guicourse](https://github.com/yiye3/guicourse)|\n", "2408.05211": "|[vita: towards open-source interactive omni multimodal llm](https://arxiv.org/abs/2408.05211)|[VITA](https://github.com/VITA-MLLM/VITA)|\n", "2408.09429": "|[reefknot: a comprehensive benchmark for relation hallucination evaluation, analysis and mitigation in multimodal large language models](https://arxiv.org/abs/2408.09429)|[Reefknot](https://github.com/JackChen-seu/Reefknot)|\n", "2408.13877": "|[camouflaged object tracking: a benchmark](https://arxiv.org/abs/2408.13877)|[hiptrack-mls](https://github.com/openat25/hiptrack-mls)|\n", "2409.01249": "|[adversarial pruning: a survey and benchmark of pruning methods for adversarial robustness](https://arxiv.org/abs/2409.01249)|[adversarialpruningbenchmark](https://github.com/pralab/adversarialpruningbenchmark)|\n", "2409.07541": "|[enact: entropy-based clustering of attention input for reducing the computational needs of object detection transformers](https://arxiv.org/abs/2409.07541)|[enact](https://github.com/gsavathrakis/enact)|\n", "2410.03311": "|[scaling large motion models with million-level human motions](https://arxiv.org/abs/2410.03311)|[being-m0](https://github.com/beingbeyond/being-m0)|\n", "2410.03782": "|[dawin: training-free dynamic weight interpolation for robust adaptation](https://arxiv.org/abs/2410.03782)|[dawin](https://github.com/naver-ai/dawin)|\n", "2410.07599": "|[adventurer: optimizing vision mamba architecture designs for efficiency](https://arxiv.org/abs/2410.07599)|[Adventurer](https://github.com/wangf3014/Adventurer)|\n", "2410.17885": "|[theorem-validated reverse chain-of-thought problem generation for geometric reasoning](https://arxiv.org/abs/2410.17885)|[r-cot](https://github.com/dle666/r-cot)|\n", "2410.22366": "|[one-step is enough: sparse autoencoders for text-to-image diffusion models](https://arxiv.org/abs/2410.22366)|[sdxl-unbox](https://github.com/surkovv/sdxl-unbox)|\n", "2411.06160": "|[expansion quantization network: an efficient micro-emotion annotation and detection framework](https://arxiv.org/abs/2411.06160)|[Expansion-Quantization-Network-EQN](https://github.com/yeaso/Expansion-Quantization-Network-EQN)|\n", "2411.14207": "|[harp: a large-scale higher-order ambisonic room impulse response dataset](https://arxiv.org/abs/2411.14207)|[harp](https://github.com/whojavumusic/harp)|\n", "2411.16725": "|[$\\textit{revelio}$: interpreting and leveraging semantic information in diffusion models](https://arxiv.org/abs/2411.16725)|[revelio](https://github.com/revelio-diffusion/revelio)|\n", "2412.00686": "|[lvlm-count: enhancing the counting ability of large vision-language models](https://arxiv.org/abs/2412.00686)|[lvlm-count](https://github.com/mrghofrani/lvlm-count)|\n", "2412.01506": "|[structured 3d latents for scalable and versatile 3d generation](https://arxiv.org/abs/2412.01506)|[TRELLIS](https://github.com/Microsoft/TRELLIS)|\n", "2412.06014": "|[post-hoc probabilistic vision-language models](https://arxiv.org/abs/2412.06014)|[BayesVLM](https://github.com/AaltoML/BayesVLM)|\n", "2412.08922": "|[nested hash layer: a plug-and-play module for multiple-length hash code learning](https://arxiv.org/abs/2412.08922)|[nhl](https://github.com/hly1998/nhl)|\n", "2412.15032": "|[dctdiff: intriguing properties of image generative modeling in the dct space](https://arxiv.org/abs/2412.15032)|[dctdiff](https://github.com/forever208/dctdiff)|\n", "2412.15712": "|[contrastive learning for task-independent speechllm-pretraining](https://arxiv.org/abs/2412.15712)|[contr-pretraining](https://github.com/maikezuefle/contr-pretraining)|\n", "2412.20662": "|[enhancing table recognition with vision llms: a benchmark and neighbor-guided toolchain reasoner](https://arxiv.org/abs/2412.20662)|[ngtr](https://github.com/lqzxt/ngtr)|\n", "2502.05173": "|[videorope: what makes for good video rotary position embedding?](https://arxiv.org/abs/2502.05173)|[videorope](https://github.com/wiselnn570/videorope)|\n", "2503.00741": "|[lesiondiffusion: towards text-controlled general lesion synthesis](https://arxiv.org/abs/2503.00741)|[lesiondiffusion](https://github.com/hengruitiansjtu/lesiondiffusion)|\n", "2503.18767": "|[good keypoints for the two-view geometry estimation problem](https://arxiv.org/abs/2503.18767)|[BoNeSS-ST](https://github.com/KonstantinPakulev/BoNeSS-ST)|\n", "2503.20771": "|[disentangled source-free personalization for facial expression recognition with neutral target data](https://arxiv.org/abs/2503.20771)|[DSFDA-for-Pain-Assessment](https://github.com/MasoumehSharafi/DSFDA-for-Pain-Assessment)|\n", "2504.01014": "|[animegamer: infinite anime life simulation with next game state prediction](https://arxiv.org/abs/2504.01014)|[animegamer](https://github.com/tencentarc/animegamer)|\n", "2504.07934": "|[sota with less: mcts-guided sample selection for data-efficient visual reasoning self-improvement](https://arxiv.org/abs/2504.07934)|[thinklite-vl](https://github.com/si0wang/thinklite-vl)|\n", "2504.11992": "|[analysis of pseudo-labeling for online source-free universal domain adaptation](https://arxiv.org/abs/2504.11992)|[planalysis](https://github.com/pascalschlachter/planalysis)|\n", "2504.15815": "|[what's the difference? supporting users in identifying the effects of prompt and model changes through token patterns](https://arxiv.org/abs/2504.15815)|[spotlight](https://github.com/mainlp/spotlight)|\n", "2504.16181": "|[clip-it: clip-based pairing for histology images classification](https://arxiv.org/abs/2504.16181)|[ModalityPairing](https://github.com/BanafshehKarimian/ModalityPairing)|\n", "2505.02746": "|[using knowledge graphs to harvest datasets for efficient clip model training](https://arxiv.org/abs/2505.02746)|[entitynet](https://github.com/lmb-freiburg/entitynet)|\n", "2505.05528": "|[x-transfer attacks: towards super transferable adversarial attacks on clip](https://arxiv.org/abs/2505.05528)|[XTransferBench](https://github.com/HanxunH/XTransferBench)|\n", "2505.06685": "|[emotion-qwen: training hybrid experts for unified emotion and general vision-language understanding](https://arxiv.org/abs/2505.06685)|[emotion-qwen](https://github.com/24davidhuang/emotion-qwen)|\n", "2505.10238": "|[mtvcrafter: 4d motion tokenization for open-world human image animation](https://arxiv.org/abs/2505.10238)|[mtvcrafter](https://github.com/dingyanb/mtvcrafter)|\n", "2505.11404": "|[patho-r1: a multimodal reinforcement learning-based pathology expert reasoner](https://arxiv.org/abs/2505.11404)|[patho-r1](https://github.com/wenchuan-zhang/patho-r1)|\n", "2505.17013": "|[when are concepts erased from diffusion models?](https://arxiv.org/abs/2505.17013)|[diffusionconcepterasure](https://github.com/kevinlu4588/diffusionconcepterasure)|\n", "2505.17550": "|[t2vunlearning: a concept erasing method for text-to-video diffusion models](https://arxiv.org/abs/2505.17550)|[t2vunlearning](https://github.com/vdigpku/t2vunlearning)|\n", "2505.22111": "|[autoregression-free video prediction using diffusion model for mitigating error propagation](https://arxiv.org/abs/2505.22111)|[arfree](https://github.com/kowoonho/arfree)|\n", "2505.22465": "|[single domain generalization for alzheimer's detection from 3d mris with pseudo-morphological augmentations and contrastive learning](https://arxiv.org/abs/2505.22465)|[sdg-alzheimer](https://github.com/zobia111/sdg-alzheimer)|\n", "2505.22815": "|[imts is worth time $\\times$ channel patches: visual masked autoencoders for irregular multivariate time series prediction](https://arxiv.org/abs/2505.22815)|[vimts](https://github.com/whu-hzy/vimts)|\n", "2505.22918": "|[re-ttention: ultra sparse visual generation via attention statistical reshape](https://arxiv.org/abs/2505.22918)|[re-ttention](https://github.com/cccrrrccc/re-ttention)|\n", "2505.23018": "|[emotiontalk: an interactive chinese multimodal emotion dataset with rich annotations](https://arxiv.org/abs/2505.23018)|[emotiontalk](https://github.com/nku-hlt/emotiontalk)|\n", "2505.23558": "|[qwen look again: guiding vision-language reasoning models to re-attention visual information](https://arxiv.org/abs/2505.23558)|[look_again](https://github.com/liar406/look_again)|\n", "2505.23734": "|[zpressor: bottleneck-aware compression for scalable feed-forward 3dgs](https://arxiv.org/abs/2505.23734)|[ZPressor](https://github.com/ziplab/ZPressor)|\n", "2505.23856": "|[omniguard: an efficient approach for ai safety moderation across modalities](https://arxiv.org/abs/2505.23856)|[omniguard](https://github.com/vsahil/omniguard)|\n", "2505.23941": "|[vision language models are biased](https://arxiv.org/abs/2505.23941)|[vlms-are-biased](https://github.com/anvo25/vlms-are-biased)|\n", "2505.24053": "|[3dgeer: exact and efficient volumetric rendering with 3d gaussians](https://arxiv.org/abs/2505.24053)|[3DGEER](https://github.com/zixunh/3DGEER)|\n", "2505.24182": "|[seeing is not reasoning: mvpbench for graph-based evaluation of multi-path visual physical cot](https://arxiv.org/abs/2505.24182)|[MVPBench](https://github.com/CSU-JPG/MVPBench)|\n", "2505.24210": "|[stork: improving the fidelity of mid-nfe sampling for diffusion and flow matching models](https://arxiv.org/abs/2505.24210)|[stork](https://github.com/zt220501/stork)|\n", "2505.24216": "|[shuffle patchmix augmentation with confidence-margin weighted pseudo-labels for enhanced source-free domain adaptation](https://arxiv.org/abs/2505.24216)|[SPM](https://github.com/PrasannaPulakurthi/SPM)|\n", "2505.24255": "|[effects of theory of mind and prosocial beliefs on steering human-aligned behaviors of llms in ultimatum games](https://arxiv.org/abs/2505.24255)|[ultimatumtom](https://github.com/stealth-py/ultimatumtom)|\n", "2505.24301": "|[category-aware eeg image generation based on wavelet transform and contrast semantic loss](https://arxiv.org/abs/2505.24301)|[dwt_eeg_reconstruction](https://github.com/zes0v0inn/dwt_eeg_reconstruction)|\n", "2505.24421": "|[pymeal: a multi-encoder augmentation-aware learning for robust and generalizable medical image translation](https://arxiv.org/abs/2505.24421)|[pymeal](https://github.com/ai-vbrain/pymeal)|\n", "2505.24605": "|[model-guided network with cluster-based operators for spatio-spectral super-resolution](https://arxiv.org/abs/2505.24605)|[jssunet](https://github.com/tami-uib/jssunet)|\n", "2505.24623": "|[hyperbolic dataset distillation](https://arxiv.org/abs/2505.24623)|[Awesome-Dataset-Distillation](https://github.com/Guang000/Awesome-Dataset-Distillation)|\n", "2505.24693": "|[conformal prediction for zero-shot models](https://arxiv.org/abs/2505.24693)|[clip-conformal](https://github.com/jusiro/clip-conformal)|\n", "2505.24746": "|[tackling view-dependent semantics in 3d language gaussian splatting](https://arxiv.org/abs/2505.24746)|[laga](https://github.com/sjtu-deepvisionlab/laga)|\n", "2505.24796": "|[tc-gs: a faster gaussian splatting module utilizing tensor cores](https://arxiv.org/abs/2505.24796)|[3dgstensorcore](https://github.com/tensorcore3dgs/3dgstensorcore)|\n", "2505.24816": "|[cl-lora: continual low-rank adaptation for rehearsal-free class-incremental learning](https://arxiv.org/abs/2505.24816)|[cl-lora](https://github.com/jiangpenghe/cl-lora)|\n", "2505.24824": "|[segmenting france across four centuries](https://arxiv.org/abs/2505.24824)|[frax4](https://github.com/archiel19/frax4)|\n", "2505.24862": "|[vistorybench: comprehensive benchmark suite for story visualization](https://arxiv.org/abs/2505.24862)|[vistorybench](https://github.com/vistorybench/vistorybench)|\n", "2505.24869": "|[silvr: a simple language-based video reasoning framework](https://arxiv.org/abs/2505.24869)|[silvr](https://github.com/ceezh/silvr)|\n"}, "2025-06-03": {"2203.14523": "|[translation consistent semi-supervised segmentation for 3d medical images](https://arxiv.org/abs/2203.14523)|[tracoco](https://github.com/yyliu01/tracoco)|\n", "2207.06418": "|[open high-resolution satellite imagery: the worldstrat dataset -- with application to super-resolution](https://arxiv.org/abs/2207.06418)|[worldstrat](https://github.com/worldstrat/worldstrat)|\n", "2307.00438": "|[towards resource-efficient streaming of large-scale medical image datasets for deep learning](https://arxiv.org/abs/2307.00438)|[openjphpy](https://github.com/BioIntelligence-Lab/openjphpy)|\n", "2307.07873": "|[why does little robustness help? a further step towards understanding adversarial transferability](https://arxiv.org/abs/2307.07873)|[transferattacksurrogates](https://github.com/cgcl-codes/transferattacksurrogates)|\n", "2312.05984": "|[accurate differential operators for hybrid neural fields](https://arxiv.org/abs/2312.05984)|[hnf-derivatives](https://github.com/justachetan/hnf-derivatives)|\n", "2312.11556": "|[starvector: generating scalable vector graphics code from images and text](https://arxiv.org/abs/2312.11556)|[vtracer](https://github.com/visioncortex/vtracer)|\n", "2402.00045": "|[detecting multimedia generated by large ai models: a survey](https://arxiv.org/abs/2402.00045)|[detect-laim-generated-multimedia-survey](https://github.com/purdue-m2/detect-laim-generated-multimedia-survey)|\n", "2403.04024": "|[enhancing chest x-ray datasets with privacy-preserving large language models and multi-type annotations: a data-driven approach for improved classification](https://arxiv.org/abs/2403.04024)|[CADLab](https://github.com/rsummers11/CADLab)|\n", "2403.09055": "|[semanticdraw: towards real-time interactive content creation from image diffusion models](https://arxiv.org/abs/2403.09055)|[semantic-draw](https://github.com/ironjr/semantic-draw)|\n", "2404.07029": "|[generative inpainting of incomplete euclidean distance matrices of trajectories generated by a fractional brownian motion](https://arxiv.org/abs/2404.07029)|[fbm-inpainting-benchmark](https://github.com/alobashev/fbm-inpainting-benchmark)|\n", "2404.10242": "|[masked autoencoders for microscopy are scalable learners of cellular biology](https://arxiv.org/abs/2404.10242)|[maes_microscopy](https://github.com/recursionpharma/maes_microscopy)|\n", "2404.17230": "|[objectadd: adding objects into image via a training-free diffusion modification fashion](https://arxiv.org/abs/2404.17230)|[objectadd](https://github.com/potato-kitty/objectadd)|\n", "2405.09138": "|[opengait: a comprehensive benchmark study for gait recognition towards better practicality](https://arxiv.org/abs/2405.09138)|[opengait](https://github.com/shiqiyu/opengait)|\n", "2406.04343": "|[flash3d: feed-forward generalisable 3d scene reconstruction from a single image](https://arxiv.org/abs/2406.04343)|[flash3d](https://github.com/eldar/flash3d)|\n", "2406.14567": "|[dragposer: motion reconstruction from variable sparse tracking signals via latent space optimization](https://arxiv.org/abs/2406.14567)|[DragPoser](https://github.com/UPC-ViRVIG/DragPoser)|\n", "2407.07171": "|[ittakestwo: leveraging peer representations for semi-supervised lidar semantic segmentation](https://arxiv.org/abs/2407.07171)|[it2](https://github.com/yyliu01/it2)|\n", "2408.05868": "|[lawa: using latent space for in-generation image watermarking](https://arxiv.org/abs/2408.05868)|[LaWa](https://github.com/vbdi/LaWa)|\n", "2408.09153": "|[are clip features all you need for universal synthetic image origin attribution?](https://arxiv.org/abs/2408.09153)|[universalattribution](https://github.com/ciodar/universalattribution)|\n", "2408.09181": "|[padetbench: towards benchmarking physical attacks against object detection](https://arxiv.org/abs/2408.09181)|[padetbench](https://github.com/jiaweilian/padetbench)|\n", "2408.17081": "|[stochastic layer-wise shuffle for improving vision mamba training](https://arxiv.org/abs/2408.17081)|[shufflemamba](https://github.com/huangzizheng01/shufflemamba)|\n", "2409.09724": "|[mfclip: multi-modal fine-grained clip for generalizable diffusion face forgery detection](https://arxiv.org/abs/2409.09724)|[mfclip](https://github.com/jenine-321/mfclip)|\n", "2409.11316": "|[msdnet: multi-scale decoder for few-shot semantic segmentation via transformer-guided prototyping](https://arxiv.org/abs/2409.11316)|[msdnet](https://github.com/amirrezafateh/msdnet)|\n", "2409.17110": "|[morphoseg: an uncertainty-aware deep learning method for biomedical segmentation of complex cellular morphologies](https://arxiv.org/abs/2409.17110)|[morphoseg](https://github.com/ranchogoose/morphoseg)|\n", "2409.19365": "|[conditional image synthesis with diffusion models: a survey](https://arxiv.org/abs/2409.19365)|[awesome-conditional-diffusion-models](https://github.com/zju-pi/awesome-conditional-diffusion-models)|\n", "2410.01517": "|[uw-gs: distractor-aware 3d gaussian splatting for enhanced underwater scene reconstruction](https://arxiv.org/abs/2410.01517)|[uw-gs](https://github.com/wanghaoran16/uw-gs)|\n", "2410.01723": "|[harmonica: harmonizing training and inference for better feature caching in diffusion transformer acceleration](https://arxiv.org/abs/2410.01723)|[harmonica](https://github.com/modeltc/harmonica)|\n", "2410.03860": "|[mdmp: multi-modal diffusion for supervised motion predictions with uncertainty](https://arxiv.org/abs/2410.03860)|[mdmp](https://github.com/leob03/mdmp)|\n", "2410.08145": "|[insight over sight: exploring the vision-knowledge conflicts in multimodal llms](https://arxiv.org/abs/2410.08145)|[ConflictVIS](https://github.com/xyliu-cs/ConflictVIS)|\n", "2410.12613": "|[exploring model kinship for merging large language models](https://arxiv.org/abs/2410.12613)|[ModelKinship](https://github.com/zjunlp/ModelKinship)|\n", "2410.18477": "|[monge-ampere regularization for learning arbitrary shapes from point clouds](https://arxiv.org/abs/2410.18477)|[s2df](https://github.com/chuanxiang-yang/s2df)|\n", "2411.05902": "|[autoregressive models in vision: a survey](https://arxiv.org/abs/2411.05902)|[autoregressive-models-in-vision-survey](https://github.com/chaofantao/autoregressive-models-in-vision-survey)|\n", "2411.10958": "|[sageattention2: efficient attention with thorough outlier smoothing and per-thread int4 quantization](https://arxiv.org/abs/2411.10958)|[SageAttention](https://github.com/thu-ml/SageAttention)|\n", "2411.17605": "|[distractor-free generalizable 3d gaussian splatting](https://arxiv.org/abs/2411.17605)|[dggs](https://github.com/bbbbby-99/dggs)|\n", "2411.18263": "|[tsd-sr: one-step diffusion with target score distillation for real-world image super-resolution](https://arxiv.org/abs/2411.18263)|[TSD-SR](https://github.com/Microtreei/TSD-SR)|\n", "2412.01617": "|[if eleanor rigby had met chatgpt: a study on loneliness in a post-llm world](https://arxiv.org/abs/2412.01617)|[EleanorRigby](https://github.com/adewynter/EleanorRigby)|\n", "2412.03318": "|[domain-agnostic stroke lesion segmentation using physics-constrained synthetic data](https://arxiv.org/abs/2412.03318)|[qsynth](https://github.com/liamchalcroft/qsynth)|\n", "2412.18277": "|[towards modality generalization: a benchmark and prospective analysis](https://arxiv.org/abs/2412.18277)|[ModalBed](https://github.com/Xiaohao-Liu/ModalBed)|\n", "2412.20070": "|[exploring compositional generalization of multimodal llms for medical imaging](https://arxiv.org/abs/2412.20070)|[med-mat](https://github.com/freedomintelligence/med-mat)|\n", "2501.02669": "|[generalizing from simple to hard visual reasoning: can we mitigate modality imbalance in vlms?](https://arxiv.org/abs/2501.02669)|[vlm_s2h](https://github.com/princeton-pli/vlm_s2h)|\n", "2501.08282": "|[llava-st: a multimodal large language model for fine-grained spatial-temporal understanding](https://arxiv.org/abs/2501.08282)|[llava-st](https://github.com/appletea233/llava-st)|\n", "2501.15757": "|[efficiency bottlenecks of convolutional kolmogorov-arnold networks: a comprehensive scrutiny with imagenet, alexnet, lenet and tabular classification](https://arxiv.org/abs/2501.15757)|[study-of-convolutional-kolmogorov-arnold-networks](https://github.com/ashimdahal/study-of-convolutional-kolmogorov-arnold-networks)|\n", "2501.15994": "|[real-time brain tumor detection in intraoperative ultrasound using yolo11: from model training to deployment in the operating room](https://arxiv.org/abs/2501.15994)|[brain_tumor_detection_ultrasound](https://github.com/smcch/brain_tumor_detection_ultrasound)|\n", "2502.00408": "|[segment anything for histopathology](https://arxiv.org/abs/2502.00408)|[patho-sam](https://github.com/computational-cell-analytics/patho-sam)|\n", "2502.00418": "|[parameter efficient fine-tuning of segment anything model for biomedical imaging](https://arxiv.org/abs/2502.00418)|[peft-sam](https://github.com/computational-cell-analytics/peft-sam)|\n", "2502.04192": "|[pixfoundation: are we heading in the right direction with pixel-level vision foundation models?](https://arxiv.org/abs/2502.04192)|[pixfoundation](https://github.com/msiam/pixfoundation)|\n", "2502.05206": "|[safety at scale: a comprehensive survey of large model safety](https://arxiv.org/abs/2502.05206)|[awesome-large-model-safety](https://github.com/xingjunm/awesome-large-model-safety)|\n", "2502.06029": "|[ditask: multi-task fine-tuning with diffeomorphic transformations](https://arxiv.org/abs/2502.06029)|[DiTASK](https://github.com/ipsitmantri/DiTASK)|\n", "2502.11196": "|[how do llms acquire new knowledge? a knowledge circuits perspective on continual pre-training](https://arxiv.org/abs/2502.11196)|[dynamicknowledgecircuits](https://github.com/zjunlp/dynamicknowledgecircuits)|\n", "2502.15798": "|[maxsup: overcoming representation collapse in label smoothing](https://arxiv.org/abs/2502.15798)|[maximum-suppression-regularization](https://github.com/zhouyuxuanyx/maximum-suppression-regularization)|\n", "2502.17019": "|[erwin: a tree-based hierarchical transformer for large-scale physical systems](https://arxiv.org/abs/2502.17019)|[erwin](https://github.com/maxxxzdn/erwin)|\n", "2502.17358": "|[dis-co: discovering copyrighted content in vlms training data](https://arxiv.org/abs/2502.17358)|[dis-co](https://github.com/avduarte333/dis-co)|\n", "2503.00071": "|[i see what you mean: co-speech gestures for reference resolution in multimodal dialogue](https://arxiv.org/abs/2503.00071)|[MultimodalReferenceResolution](https://github.com/EsamGhaleb/MultimodalReferenceResolution)|\n", "2503.13509": "|[mentalchat16k: a benchmark dataset for conversational mental health assistance](https://arxiv.org/abs/2503.13509)|[MentalChat16K](https://github.com/ChiaPatricia/MentalChat16K)|\n", "2503.14012": "|[legnet: lightweight edge-gaussian driven network for low-quality remote sensing image object detection](https://arxiv.org/abs/2503.14012)|[legnet](https://github.com/lwcver/legnet)|\n", "2503.18147": "|[pht-cad: efficient cad parametric primitive analysis with progressive hierarchical tuning](https://arxiv.org/abs/2503.18147)|[PHT-CAD](https://github.com/yuwen-chen616/PHT-CAD)|\n", "2503.18938": "|[adaworld: learning adaptable world models with latent actions](https://arxiv.org/abs/2503.18938)|[adaworld](https://github.com/little-podi/adaworld)|\n", "2503.20756": "|[ads-edit: a multimodal knowledge editing dataset for autonomous driving systems](https://arxiv.org/abs/2503.20756)|[easyedit](https://github.com/zjunlp/easyedit)|\n", "2504.03561": "|[synworld: virtual scenario synthesis for agentic action knowledge refinement](https://arxiv.org/abs/2504.03561)|[synworld](https://github.com/zjunlp/synworld)|\n", "2504.07089": "|[omnicaptioner: one captioner to rule them all](https://arxiv.org/abs/2504.07089)|[omnicaptioner](https://github.com/alpha-innovator/omnicaptioner)|\n", "2504.07093": "|[flashdepth: real-time streaming video depth estimation at 2k resolution](https://arxiv.org/abs/2504.07093)|[FlashDepth](https://github.com/Eyeline-Research/FlashDepth)|\n", "2504.09712": "|[the structural safety generalization problem](https://arxiv.org/abs/2504.09712)|[the-ssg-problem](https://github.com/juliusbroomfield/the-ssg-problem)|\n", "2504.13861": "|[3mdbench: medical multimodal multi-agent dialogue benchmark](https://arxiv.org/abs/2504.13861)|[3mdbench](https://github.com/univanxx/3mdbench)|\n", "2505.08273": "|[irrmap: a large-scale comprehensive dataset for irrigation method mapping](https://arxiv.org/abs/2505.08273)|[irrmap](https://github.com/nibir088/irrmap)|\n", "2505.12499": "|[contrastive alignment with semantic gap-aware corrections in text-video retrieval](https://arxiv.org/abs/2505.12499)|[gare-text-video-retrieval](https://github.com/musicman217/gare-text-video-retrieval)|\n", "2505.14318": "|[radar: enhancing radiology report generation with supplementary knowledge injection](https://arxiv.org/abs/2505.14318)|[Radar](https://github.com/wjhou/Radar)|\n", "2505.16175": "|[quickvideo: real-time long video understanding with system algorithm co-design](https://arxiv.org/abs/2505.16175)|[quickvideo](https://github.com/tiger-ai-lab/quickvideo)|\n", "2505.18022": "|[remotesam: towards segment anything for earth observation](https://arxiv.org/abs/2505.18022)|[RemoteSAM](https://github.com/1e12Leon/RemoteSAM)|\n", "2505.18668": "|[chartgalaxy: a dataset for infographic chart understanding and generation](https://arxiv.org/abs/2505.18668)|[chartgalaxy](https://github.com/chartgalaxy/chartgalaxy)|\n", "2505.20279": "|[vlm-3r: vision-language models augmented with instruction-aligned 3d reconstruction](https://arxiv.org/abs/2505.20279)|[VLM-3R](https://github.com/VITA-Group/VLM-3R)|\n", "2505.23566": "|[uni-mumer: unified multi-task fine-tuning of vision-language model for handwritten mathematical expression recognition](https://arxiv.org/abs/2505.23566)|[uni-mumer](https://github.com/bflameswift/uni-mumer)|\n", "2505.23590": "|[jigsaw-r1: a study of rule-based visual reinforcement learning with jigsaw puzzles](https://arxiv.org/abs/2505.23590)|[jigsaw-r1](https://github.com/zifuwanggg/jigsaw-r1)|\n", "2505.23661": "|[openuni: a simple baseline for unified multimodal understanding and generation](https://arxiv.org/abs/2505.23661)|[openuni](https://github.com/wusize/openuni)|\n", "2505.23694": "|[da-vpt: semantic-guided visual prompt tuning for vision transformers](https://arxiv.org/abs/2505.23694)|[da-vpt](https://github.com/noahsark/da-vpt)|\n", "2505.24705": "|[rt-x net: rgb-thermal cross attention network for low-light image enhancement](https://arxiv.org/abs/2505.24705)|[rt-xnet](https://github.com/jhakrraman/rt-xnet)|\n", "2506.00325": "|[towards effective and efficient adversarial defense with diffusion models for robust visual tracking](https://arxiv.org/abs/2506.00325)|[DiffDf](https://github.com/pgao-lab/DiffDf)|\n", "2506.01091": "|[promptvfx: text-driven fields for open-world 3d gaussian animation](https://arxiv.org/abs/2506.01091)|[promptvfx](https://github.com/3Dwe-ai/promptvfx)|\n", "2506.01391": "|[agentcpm-gui: building mobile-use agents with reinforcement fine-tuning](https://arxiv.org/abs/2506.01391)|[AgentCPM-GUI](https://github.com/OpenBMB/AgentCPM-GUI)|\n", "2506.01482": "|[automatic stage lighting control: is it a rule-driven process or generative task?](https://arxiv.org/abs/2506.01482)|[Skip-BART](https://github.com/RS2002/Skip-BART)|\n", "2506.01806": "|[ridgeformer: mutli-stage contrastive training for fine-grained cross-domain fingerprint recognition](https://arxiv.org/abs/2506.01806)|[Ridgeformer](https://github.com/KNITPhoenix/Ridgeformer)|\n", "2506.01923": "|[taxadiffusion: progressively trained diffusion model for fine-grained species generation](https://arxiv.org/abs/2506.01923)|[TaxaDiffusion](https://github.com/aminK8/TaxaDiffusion)|\n"}, "2025-06-04": {"2301.00555": "|[scene structure guidance network: unfolding graph partitioning into pixel-wise feature learning](https://arxiv.org/abs/2301.00555)|[ssgnet](https://github.com/jsshin98/ssgnet)|\n", "2309.13570": "|[robust 6dof pose estimation against depth noise and a comprehensive evaluation on a mobile dataset](https://arxiv.org/abs/2309.13570)|[dttd2](https://github.com/augcog/dttd2)|\n", "2310.05026": "|[low-resolution self-attention for semantic segmentation](https://arxiv.org/abs/2310.05026)|[lrformer](https://github.com/yuhuan-wu/lrformer)|\n", "2310.08367": "|[mcu: an evaluation framework for open-ended game agents](https://arxiv.org/abs/2310.08367)|[mcu](https://github.com/craftjarvis/mcu)|\n", "2401.11311": "|[a novel benchmark for few-shot semantic segmentation in the era of foundation models](https://arxiv.org/abs/2401.11311)|[foundation_fewshot](https://github.com/redabensaidds/foundation_fewshot)|\n", "2403.04523": "|[t-tame: trainable attention mechanism for explaining convolutional networks and vision transformers](https://arxiv.org/abs/2403.04523)|[T-TAME](https://github.com/IDT-ITI/T-TAME)|\n", "2404.03998": "|[phiswid: physics-inspired underwater image dataset synthesized from rgb-d images](https://arxiv.org/abs/2404.03998)|[phismid-phiswid](https://github.com/reina0112/phismid-phiswid)|\n", "2405.15228": "|[learning from true-false labels via multi-modal prompt retrieving](https://arxiv.org/abs/2405.15228)|[tmp](https://github.com/tranquilxu/tmp)|\n", "2406.03747": "|[oralbbnet: spatially guided dental segmentation of panoramic x-rays with bounding box priors](https://arxiv.org/abs/2406.03747)|[Instance_seg_teeth](https://github.com/devichand579/Instance_seg_teeth)|\n", "2406.14239": "|[leyolo, new embedded architecture for object detection](https://arxiv.org/abs/2406.14239)|[LeYOLO](https://github.com/LilianHollard/LeYOLO)|\n", "2408.15127": "|[t-fake: synthesizing thermal images for facial landmarking](https://arxiv.org/abs/2408.15127)|[tfake](https://github.com/phflot/tfake)|\n", "2409.05819": "|[gasp: gaussian splatting for physic-based simulations](https://arxiv.org/abs/2409.05819)|[gasp](https://github.com/waczjoan/gasp)|\n", "2409.16967": "|[scalable multi-robot informative path planning for target mapping via deep reinforcement learning](https://arxiv.org/abs/2409.16967)|[marl_ipp](https://github.com/accgen99/marl_ipp)|\n", "2410.01574": "|[adversarial robustness of ai-generated image detectors in the real world](https://arxiv.org/abs/2410.01574)|[aigi-break](https://github.com/smavali/aigi-break)|\n", "2410.04417": "|[sparsevlm: visual token sparsification for efficient vision-language model inference](https://arxiv.org/abs/2410.04417)|[sparsevlms](https://github.com/gumpest/sparsevlms)|\n", "2410.16602": "|[foundation models for remote sensing and earth observation: a survey](https://arxiv.org/abs/2410.16602)|[awesome-rsfms](https://github.com/xiaoaoran/awesome-rsfms)|\n", "2410.21088": "|[shallow diffuse: robust and invisible watermarking through low-dimensional subspaces in diffusion models](https://arxiv.org/abs/2410.21088)|[shallow-diffuse](https://github.com/liwd190019/shallow-diffuse)|\n", "2411.05698": "|[visual-tcav: concept-based attribution and saliency maps for post-hoc explainability in image classification](https://arxiv.org/abs/2411.05698)|[Visual-TCAV](https://github.com/DataSciencePolimi/Visual-TCAV)|\n", "2412.13541": "|[spatio-temporal fuzzy-oriented multi-modal meta-learning for fine-grained emotion recognition](https://arxiv.org/abs/2412.13541)|[st-f2m](https://github.com/wangjingyao07/st-f2m)|\n", "2501.13106": "|[videollama 3: frontier multimodal foundation models for image and video understanding](https://arxiv.org/abs/2501.13106)|[videollama3](https://github.com/damo-nlp-sg/videollama3)|\n", "2501.18913": "|[rethinking diffusion posterior sampling: from conditional score estimator to maximizing a posterior](https://arxiv.org/abs/2501.18913)|[rethinking-diffusion-posterior-sampling-from-conditional-score-estimator-to-maximizing-a-posterior](https://github.com/tongdaxu/rethinking-diffusion-posterior-sampling-from-conditional-score-estimator-to-maximizing-a-posterior)|\n", "2502.04328": "|[ola: pushing the frontiers of omni-modal language model](https://arxiv.org/abs/2502.04328)|[ola](https://github.com/ola-omni/ola)|\n", "2502.12110": "|[a-mem: agentic memory for llm agents](https://arxiv.org/abs/2502.12110)|[a-mem](https://github.com/agiresearch/a-mem)|\n", "2502.12562": "|[sea: low-resource safety alignment for multimodal large language models via synthetic embeddings](https://arxiv.org/abs/2502.12562)|[sea](https://github.com/zeronlp/sea)|\n", "2502.14753": "|[medvae: efficient automated interpretation of medical images with large-scale generalizable autoencoders](https://arxiv.org/abs/2502.14753)|[medvae](https://github.com/stanfordmimi/medvae)|\n", "2502.18017": "|[vidorag: visual document retrieval-augmented generation via dynamic iterative reasoning agents](https://arxiv.org/abs/2502.18017)|[ViDoRAG](https://github.com/Alibaba-NLP/ViDoRAG)|\n", "2503.10080": "|[bayesian prompt flow learning for zero-shot anomaly detection](https://arxiv.org/abs/2503.10080)|[Bayes-PFL](https://github.com/xiaozhen228/Bayes-PFL)|\n", "2503.18052": "|[scenesplat: gaussian splatting-based scene understanding with vision-language pretraining](https://arxiv.org/abs/2503.18052)|[scenesplat](https://github.com/unique1i/scenesplat)|\n", "2503.24135": "|[pixelcam: pixel class activation mapping for histology image classification and roi localization](https://arxiv.org/abs/2503.24135)|[pixelcam](https://github.com/alexisguichemerrecode/pixelcam)|\n", "2504.04332": "|[impersona: evaluating individual level lm impersonation](https://arxiv.org/abs/2504.04332)|[impersona](https://github.com/princeton-nlp/impersona)|\n", "2504.13077": "|[effective dual-region augmentation for reduced reliance on large amounts of labeled data](https://arxiv.org/abs/2504.13077)|[Foreground-Background-Augmentation](https://github.com/PrasannaPulakurthi/Foreground-Background-Augmentation)|\n", "2504.14906": "|[omniaudio: generating spatial audio from 360-degree video](https://arxiv.org/abs/2504.14906)|[omniaudio](https://github.com/liuhuadai/omniaudio)|\n", "2504.19475": "|[prisma: an open source toolkit for mechanistic interpretability in vision and video](https://arxiv.org/abs/2504.19475)|[vit-prisma](https://github.com/prisma-multimodal/vit-prisma)|\n", "2505.04185": "|[s3d: sketch-driven 3d model generation](https://arxiv.org/abs/2505.04185)|[s3d](https://github.com/hailsong/s3d)|\n", "2505.11282": "|[mtevent: a multi-task event camera dataset for 6d pose estimation and moving object detection](https://arxiv.org/abs/2505.11282)|[mtevent_toolkit](https://github.com/shrutarv/mtevent_toolkit)|\n", "2505.19028": "|[infochartqa: a benchmark for multimodal question answering on infographic charts](https://arxiv.org/abs/2505.19028)|[infochartqa](https://github.com/cooldawnant/infochartqa)|\n", "2505.20156": "|[hunyuanvideo-avatar: high-fidelity audio-driven human animation for multiple characters](https://arxiv.org/abs/2505.20156)|[hunyuanvideo-avatar](https://github.com/tencent-hunyuan/hunyuanvideo-avatar)|\n", "2505.20292": "|[opens2v-nexus: a detailed benchmark and million-scale dataset for subject-to-video generation](https://arxiv.org/abs/2505.20292)|[ConsisID](https://github.com/PKU-YuanGroup/ConsisID)|\n", "2505.20322": "|[beyond prompt engineering: robust behavior control in llms via steering target atoms](https://arxiv.org/abs/2505.20322)|[steer-target-atoms](https://github.com/zjunlp/steer-target-atoms)|\n", "2505.22019": "|[vrag-rl: empower vision-perception-based rag for visually rich information understanding via iterative reasoning with reinforcement learning](https://arxiv.org/abs/2505.22019)|[vrag](https://github.com/alibaba-nlp/vrag)|\n", "2506.02214": "|[is pmbok guide the right fit for ai? re-evaluating project management in the face of artificial intelligence projects](https://arxiv.org/abs/2506.02214)|[geti](https://github.com/open-edge-platform/geti)|\n", "2506.02312": "|[dual encoding feature filtering generalized attention unet for retinal vessel segmentation](https://arxiv.org/abs/2506.02312)|[DEFFA-Unet](https://github.com/TauhidScu/DEFFA-Unet)|\n", "2506.02380": "|[eyenavgs: a 6-dof navigation dataset and record-n-replay software for real-world 3dgs scenes in vr](https://arxiv.org/abs/2506.02380)|[EyeNavGS_Software](https://github.com/symmru/EyeNavGS_Software)|\n", "2506.02514": "|[to embody or not: the effect of embodiment on user perception of llm-based conversational agents](https://arxiv.org/abs/2506.02514)|[to-embody-or-not](https://github.com/amaai-lab/to-embody-or-not)|\n", "2506.02736": "|[genea-slam2: dynamic slam with autoencoder-preprocessed genetic keypoints resampling and depth variance-guided dynamic region removal](https://arxiv.org/abs/2506.02736)|[GeneA-SLAM2](https://github.com/qingshufan/GeneA-SLAM2)|\n", "2506.02794": "|[physgaia: a physics-aware dataset of multi-body interactions for dynamic novel view synthesis](https://arxiv.org/abs/2506.02794)|[physgaia](https://github.com/mjmjeong/physgaia)|\n", "2506.02893": "|[dense match summarization for faster two-view estimation](https://arxiv.org/abs/2506.02893)|[DMS](https://github.com/jastermark/DMS)|\n", "2506.02895": "|[voltex: food volume estimation using text-guided segmentation and neural surface reconstruction](https://arxiv.org/abs/2506.02895)|[voltex](https://github.com/gcvcg/voltex)|\n", "2506.02911": "|[cell-o1: training llms to solve single-cell reasoning puzzles with reinforcement learning](https://arxiv.org/abs/2506.02911)|[cell-o1](https://github.com/ncbi-nlp/cell-o1)|\n", "2506.03097": "|[egovlm: policy optimization for egocentric video understanding](https://arxiv.org/abs/2506.03097)|[videgovlm](https://github.com/adityavavre/videgovlm)|\n"}, "2025-06-05": {"2204.03688": "|[dad-3dheads: a large-scale dense, accurate and diverse dataset for 3d head alignment from a single image](https://arxiv.org/abs/2204.03688)|[DAD-3DHeads](https://github.com/PinataFarms/DAD-3DHeads)|\n", "2406.13358": "|[multi-scale restoration of missing data in optical time-series images with masked spatial-temporal attention network](https://arxiv.org/abs/2406.13358)|[MS2TAN](https://github.com/CUG-BEODL/MS2TAN)|\n", "2406.16039": "|[cholecinstanceseg: a tool instance segmentation dataset for laparoscopic surgery](https://arxiv.org/abs/2406.16039)|[cholec_instance_seg](https://github.com/labdeeman7/cholec_instance_seg)|\n", "2407.11784": "|[data-juicer sandbox: a feedback-driven suite for multimodal data-model co-development](https://arxiv.org/abs/2407.11784)|[data-juicer](https://github.com/modelscope/data-juicer)|\n", "2407.18437": "|[mixed non-linear quantization for vision transformers](https://arxiv.org/abs/2407.18437)|[mixed-non-linear-quantization](https://gitlab.com/ones-ai/mixed-non-linear-quantization)|\n", "2408.05159": "|[easyinv: toward fast and better ddim inversion](https://arxiv.org/abs/2408.05159)|[easyinv](https://github.com/potato-kitty/easyinv)|\n", "2411.05561": "|[objective drives the consistency of representational similarity across datasets](https://arxiv.org/abs/2411.05561)|[similarity_consistency](https://github.com/lciernik/similarity_consistency)|\n", "2412.06141": "|[mmedpo: aligning medical vision-language models with clinical-aware multimodal preference optimization](https://arxiv.org/abs/2412.06141)|[mmedpo](https://github.com/aiming-lab/mmedpo)|\n", "2412.07169": "|[rate-in: information-driven adaptive dropout rates for improved inference-time uncertainty estimation](https://arxiv.org/abs/2412.07169)|[rate-in](https://github.com/code-supplement-25/rate-in)|\n", "2412.09586": "|[gaze-lle: gaze target estimation via large-scale learned encoders](https://arxiv.org/abs/2412.09586)|[gazelle](https://github.com/fkryan/gazelle)|\n", "2412.10573": "|[exechecker: where did i go wrong?](https://arxiv.org/abs/2412.10573)|[ExeChecker](https://github.com/EvenGu/ExeChecker)|\n", "2501.05790": "|[understanding impact of human feedback via influence functions](https://arxiv.org/abs/2501.05790)|[if_rlhf](https://github.com/mintaywon/if_rlhf)|\n", "2502.00698": "|[mm-iq: benchmarking human-like abstraction and reasoning in multimodal models](https://arxiv.org/abs/2502.00698)|[MMIQ](https://github.com/AceCHQ/MMIQ)|\n", "2502.07782": "|[a flag decomposition for hierarchical datasets](https://arxiv.org/abs/2502.07782)|[FD](https://github.com/nmank/FD)|\n", "2502.15167": "|[m3-agiqa: multimodal, multi-round, multi-aspect ai-generated image quality assessment](https://arxiv.org/abs/2502.15167)|[M3-AGIQA](https://github.com/strawhatboy/M3-AGIQA)|\n", "2502.18197": "|[vct: training consistency models with variational noise coupling](https://arxiv.org/abs/2502.18197)|[vct](https://github.com/sony/vct)|\n", "2503.02101": "|[generalized diffusion detector: mining robust features from diffusion models for domain-generalized detection](https://arxiv.org/abs/2503.02101)|[Generalized-Diffusion-Detector](https://github.com/heboyong/Generalized-Diffusion-Detector)|\n", "2503.10042": "|[escapecraft: a 3d room escape environment for benchmarking complex multimodal reasoning ability](https://arxiv.org/abs/2503.10042)|[EscapeCraft](https://github.com/THUNLP-MT/EscapeCraft)|\n", "2503.18223": "|[mammalps: a multi-view video behavior monitoring dataset of wild mammals in the swiss alps](https://arxiv.org/abs/2503.18223)|[mammalps](https://github.com/eceo-epfl/mammalps)|\n", "2505.05470": "|[flow-grpo: training flow matching models via online rl](https://arxiv.org/abs/2505.05470)|[flow_grpo](https://github.com/yifan123/flow_grpo)|\n", "2505.12532": "|[exploring sparsity for parameter efficient fine tuning using wavelets](https://arxiv.org/abs/2505.12532)|[sparse_peft](https://github.com/bilican/sparse_peft)|\n", "2505.14151": "|[reactdiff: latent diffusion for facial reaction generation](https://arxiv.org/abs/2505.14151)|[reactdiff](https://github.com/hunan-tiger/reactdiff)|\n", "2505.16836": "|[fact-r1: towards explainable video misinformation detection with deep reasoning](https://arxiv.org/abs/2505.16836)|[fact-r1](https://github.com/zfr00/fact-r1)|\n", "2505.23161": "|[implicit inversion turns clip into a decoder](https://arxiv.org/abs/2505.23161)|[implicit-inversion](https://github.com/omnai-lab/implicit-inversion)|\n", "2505.23637": "|[comparing the effects of persistence barcodes aggregation and feature concatenation on medical imaging](https://arxiv.org/abs/2505.23637)|[barcode_aggregation_vs_feature_concatenation](https://github.com/dashtiali/barcode_aggregation_vs_feature_concatenation)|\n", "2506.01950": "|[dualmap: online open-vocabulary semantic mapping for natural language navigation in dynamic changing scenes](https://arxiv.org/abs/2506.01950)|[dualmap](https://github.com/eku127/dualmap)|\n", "2506.02896": "|[flysearch: exploring how vision-language models explore](https://arxiv.org/abs/2506.02896)|[flysearch](https://github.com/gmum/flysearch)|\n", "2506.03310": "|[the reader is the metric: how textual features and reader profiles explain conflicting evaluations of ai creative writing](https://arxiv.org/abs/2506.03310)|[the-reader-is-the-metric](https://github.com/grmarco/the-reader-is-the-metric)|\n", "2506.03385": "|[from reality to recognition: evaluating visualization analogies for novice chart comprehension](https://arxiv.org/abs/2506.03385)|[analogyvis](https://github.com/hivelabuoft/analogyvis)|\n", "2506.03478": "|[facial appearance capture at home with patch-level reflectance prior](https://arxiv.org/abs/2506.03478)|[dora](https://github.com/yxuhan/dora)|\n", "2506.03530": "|[how far are we from predicting missing modalities with foundation models?](https://arxiv.org/abs/2506.03530)|[afm2](https://github.com/guanzhou-ke/afm2)|\n", "2506.03594": "|[splart: articulation estimation and part-level reconstruction with 3d gaussian splatting](https://arxiv.org/abs/2506.03594)|[splart](https://github.com/ripl/splart)|\n", "2506.03662": "|[zero-shot temporal interaction localization for egocentric videos](https://arxiv.org/abs/2506.03662)|[egoloc](https://github.com/irmvlab/egoloc)|\n", "2506.03735": "|[generating pedagogically meaningful visuals for math word problems: a new benchmark and analysis of text-to-image models](https://arxiv.org/abs/2506.03735)|[math2visual](https://github.com/eth-lre/math2visual)|\n", "2506.03831": "|[conformer-based ultrasound-to-speech conversion](https://arxiv.org/abs/2506.03831)|[conformer_UTS](https://github.com/ibrahimkhaliloglu/conformer_UTS)|\n", "2506.04016": "|[dreaming up scale invariance via inverse renormalization group](https://arxiv.org/abs/2506.04016)|[upscaling_ising](https://github.com/adam-rancon/upscaling_ising)|\n", "2506.04043": "|[think like a person before responding: a multi-faceted evaluation of persona-guided llms for countering hate](https://arxiv.org/abs/2506.04043)|[woah-2025](https://github.com/mikelkn/woah-2025)|\n", "2506.04211": "|[diffusion domain teacher: diffusion guided domain adaptive object detector](https://arxiv.org/abs/2506.04211)|[Diffusion-Domain-Teacher](https://github.com/heboyong/Diffusion-Domain-Teacher)|\n", "2506.04218": "|[pseudo-simulation for autonomous driving](https://arxiv.org/abs/2506.04218)|[navsim](https://github.com/autonomousvision/navsim)|\n"}, "2025-06-06": {"2003.01052": "|[how to choose the most appropriate centrality measure? a decision tree approach](https://arxiv.org/abs/2003.01052)|[centralities_dec_tree](https://github.com/dagubanov/centralities_dec_tree)|\n", "2305.08989": "|[lovit: long video transformer for surgical phase recognition](https://arxiv.org/abs/2305.08989)|[LoViT](https://github.com/MRUIL/LoViT)|\n", "2306.06963": "|[feature fusion from head to tail for long-tailed visual recognition](https://arxiv.org/abs/2306.06963)|[h2t](https://github.com/keke921/h2t)|\n", "2308.16139": "|[medshapenet -- a large-scale dataset of 3d medical shapes for computer vision](https://arxiv.org/abs/2308.16139)|[medshapenet-feedback](https://github.com/jianningli/medshapenet-feedback)|\n", "2310.17451": "|[generating by understanding: neural visual generation with logical symbol groundings](https://arxiv.org/abs/2310.17451)|[abdgen](https://github.com/future-item/abdgen)|\n", "2402.02906": "|[viewfusion: learning composable diffusion models for novel view synthesis](https://arxiv.org/abs/2402.02906)|[view-fusion](https://github.com/bronemos/view-fusion)|\n", "2404.14829": "|[revisiting neural networks for continual learning: an architectural perspective](https://arxiv.org/abs/2404.14829)|[archcraft](https://github.com/byyx666/archcraft)|\n", "2405.10723": "|[eddeep: fast eddy-current distortion correction for diffusion mri with deep learning](https://arxiv.org/abs/2405.10723)|[eddeep](https://github.com/CIG-UCL/eddeep)|\n", "2410.20898": "|[david and goliath: small one-step model beats large diffusion with score post-training](https://arxiv.org/abs/2410.20898)|[diff_instruct_star](https://github.com/pkulwj1994/diff_instruct_star)|\n", "2412.04954": "|[gla-ai4biomed at rrg24: visual instruction-tuned adaptation for radiology report generation](https://arxiv.org/abs/2412.04954)|[RRG-BioNLP-ACL2024](https://github.com/Glasgow-AI4BioMed/RRG-BioNLP-ACL2024)|\n", "2412.10510": "|[defame: dynamic evidence-based fact-checking with multimodal experts](https://arxiv.org/abs/2412.10510)|[defame](https://github.com/multimodal-ai-lab/defame)|\n", "2412.12974": "|[attentive eraser: unleashing diffusion model's object removal potential via self-attention redirection guidance](https://arxiv.org/abs/2412.12974)|[attentiveeraser](https://github.com/anonym0u3/attentiveeraser)|\n", "2501.00321": "|[ocrbench v2: an improved benchmark for evaluating large multimodal models on visual text localization and reasoning](https://arxiv.org/abs/2501.00321)|[multimodalocr](https://github.com/yuliang-liu/multimodalocr)|\n", "2501.05460": "|[efficiently serving large multimodal models using epd disaggregation](https://arxiv.org/abs/2501.05460)|[epdserve](https://github.com/vbdi/epdserve)|\n", "2501.07182": "|[unveiling voices: a co-hashtag analysis of tiktok discourse on the 2023 israel-palestine crisis](https://arxiv.org/abs/2501.07182)|[gaza-tiktok](https://github.com/rozinhasin/gaza-tiktok)|\n", "2502.10872": "|[corotational hinge-based thin plates/shells](https://arxiv.org/abs/2502.10872)|[libThinPlateShells](https://github.com/liangqx-hku/libThinPlateShells)|\n", "2502.17327": "|[anytop: character animation diffusion with any topology](https://arxiv.org/abs/2502.17327)|[anytop](https://github.com/anytop2025/anytop)|\n", "2503.11315": "|[mms-llama: efficient llm-based audio-visual speech recognition with minimal multimodal speech tokens](https://arxiv.org/abs/2503.11315)|[MMS-LLaMA](https://github.com/JeongHun0716/MMS-LLaMA)|\n", "2504.16062": "|[foresightnav: learning scene imagination for efficient exploration](https://arxiv.org/abs/2504.16062)|[foresight-nav](https://github.com/uzh-rpg/foresight-nav)|\n", "2504.18053": "|[dream: disentangling risks to enhance safety alignment in multimodal large language models](https://arxiv.org/abs/2504.18053)|[dream](https://github.com/kizna1ver/dream)|\n", "2505.04788": "|[convex relaxation for robust vanishing point estimation in manhattan world](https://arxiv.org/abs/2505.04788)|[globustvp](https://github.com/wu-cvgl/globustvp)|\n", "2505.13427": "|[mm-prm: enhancing multimodal mathematical reasoning with scalable step-level supervision](https://arxiv.org/abs/2505.13427)|[mm-prm](https://github.com/modalminds/mm-prm)|\n", "2505.14068": "|[place recognition meet multiple modalitie: a comprehensive review, current challenges and future directions](https://arxiv.org/abs/2505.14068)|[sota-place-recognitioner](https://github.com/cv4ra/sota-place-recognitioner)|\n", "2505.18614": "|[mavl: a multilingual audio-video lyrics dataset for animated song translation](https://arxiv.org/abs/2505.18614)|[MAVL](https://github.com/k1064190/MAVL)|\n", "2505.19536": "|[flowcut: rethinking redundancy via information flow for efficient vision-language models](https://arxiv.org/abs/2505.19536)|[flowcut](https://github.com/tungchintao/flowcut)|\n", "2505.20277": "|[omnicharacter: towards immersive role-playing agents with seamless speech-language personality interaction](https://arxiv.org/abs/2505.20277)|[damo-convai](https://github.com/alibabaresearch/damo-convai)|\n", "2505.21932": "|[higher-order group synchronization](https://arxiv.org/abs/2505.21932)|[CHMP](https://github.com/Addieduncan/CHMP)|\n", "2505.24195": "|[wikigap: promoting epistemic equity by surfacing knowledge gaps between english wikipedia and other language editions](https://arxiv.org/abs/2505.24195)|[wikigap](https://github.com/aw814/wikigap)|\n", "2506.02444": "|[svimo: synchronized diffusion for video and motion generation in hand-object interaction scenarios](https://arxiv.org/abs/2506.02444)|[SViMo_code](https://github.com/Droliven/SViMo_code)|\n", "2506.03614": "|[vlms can aggregate scattered training patches](https://arxiv.org/abs/2506.03614)|[visual-stitching](https://github.com/zhziszz/visual-stitching)|\n", "2506.03951": "|[rethinking the stability-plasticity trade-off in continual learning from an architectural perspective](https://arxiv.org/abs/2506.03951)|[Dual-Arch](https://github.com/byyx666/Dual-Arch)|\n", "2506.03956": "|[adapt before continual learning](https://arxiv.org/abs/2506.03956)|[ACL_code](https://github.com/byyx666/ACL_code)|\n", "2506.04283": "|[ssimbad: sigma scaling with ssim-guided balanced diffusion for animeface colorization](https://arxiv.org/abs/2506.04283)|[ssimbad-sigma-scaling-with-ssim-guided-balanced-diffusion-for-animeface-colorization](https://github.com/giventicket/ssimbad-sigma-scaling-with-ssim-guided-balanced-diffusion-for-animeface-colorization)|\n", "2506.04444": "|[photoreal scene reconstruction from an egocentric device](https://arxiv.org/abs/2506.04444)|[egocentric_splats](https://github.com/facebookresearch/egocentric_splats)|\n", "2506.04453": "|[gradient inversion attacks on parameter-efficient fine-tuning](https://arxiv.org/abs/2506.04453)|[peftleak](https://github.com/info-ucr/peftleak)|\n", "2506.04755": "|[truth in the few: high-value data selection for efficient multi-modal reasoning](https://arxiv.org/abs/2506.04755)|[rap](https://github.com/leo-ssl/rap)|\n", "2506.04842": "|[mineinsight: a multi-sensor dataset for humanitarian demining robotics in off-road environments](https://arxiv.org/abs/2506.04842)|[mineinsight](https://github.com/mariomlz99/mineinsight)|\n", "2506.04867": "|[llms for sensory-motor control: combining in-context and iterative learning](https://arxiv.org/abs/2506.04867)|[llm-robotics-article](https://github.com/jtyska/llm-robotics-article)|\n", "2506.05204": "|[oggsplat: open gaussian growing for generalizable reconstruction with expanded field-of-view](https://arxiv.org/abs/2506.05204)|[OGGSplat](https://github.com/Yanbo-23/OGGSplat)|\n", "2506.05274": "|[from play to replay: composed video retrieval for temporally fine-grained videos](https://arxiv.org/abs/2506.05274)|[tf-covr](https://github.com/ucf-crcv/tf-covr)|\n"}, "2025-06-07": {}, "2025-06-08": {}, "2025-06-09": {"2303.14005": "|[category query learning for human-object interaction classification](https://arxiv.org/abs/2303.14005)|[cql](https://github.com/charles-xie/cql)|\n", "2307.12813": "|[described object detection: liberating object detection with flexible expressions](https://arxiv.org/abs/2307.12813)|[d-cube](https://github.com/shikras/d-cube)|\n", "2310.12570": "|[da-transunet: integrating spatial and channel dual attention with transformer u-net for medical image segmentation](https://arxiv.org/abs/2310.12570)|[da-transunet](https://github.com/sun-1024/da-transunet)|\n", "2402.16021": "|[tmt: tri-modal translation between speech, image, and text by processing different modalities as different languages](https://arxiv.org/abs/2402.16021)|[tmt](https://github.com/ms-dot-k/tmt)|\n", "2403.15238": "|[weep: a method for spatial interpretation of weakly supervised cnn models in computational pathology](https://arxiv.org/abs/2403.15238)|[weep](https://github.com/rantalainengroup/weep)|\n", "2406.05113": "|[llavaguard: an open vlm-based framework for safeguarding vision datasets and models](https://arxiv.org/abs/2406.05113)|[llavaguard](https://github.com/ml-research/llavaguard)|\n", "2406.10737": "|[dpcore: dynamic prompt coreset for continual test-time adaptation](https://arxiv.org/abs/2406.10737)|[DPCore](https://github.com/zybeich/DPCore)|\n", "2407.05703": "|[hilbertmamba: local-global reciprocal network for uterine fibroid segmentation in ultrasound videos](https://arxiv.org/abs/2407.05703)|[lgrnet](https://github.com/bio-mlhui/lgrnet)|\n", "2408.17253": "|[visionts: visual masked autoencoders are free-lunch zero-shot time series forecasters](https://arxiv.org/abs/2408.17253)|[visionts](https://github.com/keytoyze/visionts)|\n", "2410.01744": "|[leopard: a vision language model for text-rich multi-image tasks](https://arxiv.org/abs/2410.01744)|[leopard](https://github.com/jill0001/leopard)|\n", "2410.18677": "|[enhancing pretraining efficiency for medical image segmentation via transferability metrics](https://arxiv.org/abs/2410.18677)|[MedSegPretrainImageNet](https://github.com/aielte-research/MedSegPretrainImageNet)|\n", "2412.01496": "|[fr\\'echet radiomic distance (frd): a versatile metric for comparing medical imaging datasets](https://arxiv.org/abs/2412.01496)|[RaD](https://github.com/mazurowski-lab/RaD)|\n", "2412.06329": "|[normalizing flows are capable generative models](https://arxiv.org/abs/2412.06329)|[ml-tarflow](https://github.com/apple/ml-tarflow)|\n", "2412.13540": "|[benchmarking and improving large vision-language models for fundamental visual graph understanding and reasoning](https://arxiv.org/abs/2412.13540)|[vgcure](https://github.com/aaandy-zhu/vgcure)|\n", "2502.01850": "|[foundation model-based apple ripeness and size estimation for selective harvesting](https://arxiv.org/abs/2502.01850)|[fuji_ripeness_and_size_estimation](https://github.com/zhukeyi-stan/fuji_ripeness_and_size_estimation)|\n", "2502.05749": "|[unidb: a unified diffusion bridge framework via stochastic optimal control](https://arxiv.org/abs/2502.05749)|[unidb](https://github.com/unidb-soc/unidb)|\n", "2502.06805": "|[efficient diffusion models: a survey](https://arxiv.org/abs/2502.06805)|[efficient-diffusion-model-survey](https://github.com/aiot-mlsys-lab/efficient-diffusion-model-survey)|\n", "2502.16671": "|[mimeqa: towards socially-intelligent nonverbal foundation models](https://arxiv.org/abs/2502.16671)|[mimeqa](https://github.com/mit-mi/mimeqa)|\n", "2502.18137": "|[spargeattention: accurate and training-free sparse attention accelerating any model inference](https://arxiv.org/abs/2502.18137)|[spargeattn](https://github.com/thu-ml/spargeattn)|\n", "2503.06608": "|[gromo: plant growth modeling with multiview images](https://arxiv.org/abs/2503.06608)|[gromo-plant-growth-modeling-with-multiview-images](https://github.com/mriglab/gromo-plant-growth-modeling-with-multiview-images)|\n", "2503.10312": "|[an ensemble-based two-step framework for classification of pap smear cell images](https://arxiv.org/abs/2503.10312)|[ps3c](https://github.com/theodpzz/ps3c)|\n", "2504.02821": "|[sparse autoencoders learn monosemantic features in vision-language models](https://arxiv.org/abs/2504.02821)|[sae-for-vlm](https://github.com/explainableml/sae-for-vlm)|\n", "2504.16656": "|[skywork r1v2: multimodal hybrid reinforcement learning for reasoning](https://arxiv.org/abs/2504.16656)|[Skywork-R1V](https://github.com/SkyworkAI/Skywork-R1V)|\n", "2504.21682": "|[visual text processing: a comprehensive review and unified evaluation](https://arxiv.org/abs/2504.21682)|[survey-of-visual-text-processing](https://github.com/shuyansy/survey-of-visual-text-processing)|\n", "2505.07449": "|[ophora: a large-scale data-driven text-guided ophthalmic surgical video generation model](https://arxiv.org/abs/2505.07449)|[ophora](https://github.com/mar-cry/ophora)|\n", "2505.13088": "|[cross-modal feature fusion for robust point cloud registration with ambiguous geometry](https://arxiv.org/abs/2505.13088)|[coff](https://github.com/zhaoyiww/coff)|\n", "2505.21136": "|[sageattention2++: a more efficient implementation of sageattention2](https://arxiv.org/abs/2505.21136)|[SageAttention](https://github.com/thu-ml/SageAttention)|\n", "2506.02761": "|[rethinking machine unlearning in image generation models](https://arxiv.org/abs/2506.02761)|[igmu](https://github.com/ryliu68/igmu)|\n", "2506.03582": "|[semioccam: a robust semi-supervised image recognition network using sparse labels](https://arxiv.org/abs/2506.03582)|[SemiOccam](https://github.com/Shu1L0n9/SemiOccam)|\n", "2506.03664": "|[assessing intersectional bias in representations of pre-trained image recognition models](https://arxiv.org/abs/2506.03664)|[inntrospect](https://github.com/valeriekrug/inntrospect)|\n", "2506.04525": "|[user altruism in recommendation systems](https://arxiv.org/abs/2506.04525)|[recsys](https://github.com/mckitch24/recsys)|\n", "2506.05280": "|[unifying appearance codes and bilateral grids for driving scene gaussian splatting](https://arxiv.org/abs/2506.05280)|[bilateral-driving](https://github.com/bigcileng/bilateral-driving)|\n", "2506.05358": "|[can chatgpt perform image splicing detection? a preliminary study](https://arxiv.org/abs/2506.05358)|[LLM-Image-Splicing-Detection](https://github.com/confusedDip/LLM-Image-Splicing-Detection)|\n", "2506.05398": "|[igsm: improved geometric and sensitivity matching for finetuning pruned diffusion models](https://arxiv.org/abs/2506.05398)|[igsm-official](https://github.com/fate4869/igsm-official)|\n", "2506.05890": "|[unleashing the potential of consistency learning for detecting and grounding multi-modal media manipulation](https://arxiv.org/abs/2506.05890)|[cscl](https://github.com/liyih/cscl)|\n", "2506.06006": "|[bootstrapping world models from dynamics models in multimodal foundation models](https://arxiv.org/abs/2506.06006)|[vlm-world-model](https://github.com/yfqiu-nlp/vlm-world-model)|\n", "2506.06199": "|[3dflowaction: learning cross-embodiment manipulation from 3d flow world model](https://arxiv.org/abs/2506.06199)|[3dflowaction](https://github.com/hoyyyaard/3dflowaction)|\n"}, "2025-06-10": {"2207.06968": "|[dass: differentiable architecture search for sparse neural networks](https://arxiv.org/abs/2207.06968)|[PR-DARTS](https://github.com/HERO-MDH/PR-DARTS)|\n", "2307.06343": "|[sequential experimental design for x-ray ct using deep reinforcement learning](https://arxiv.org/abs/2307.06343)|[seqanglerl](https://github.com/tianyuan1wang/seqanglerl)|\n", "2307.12349": "|[comptr: towards diverse bi-source dense prediction tasks via a simple yet general complementary transformer](https://arxiv.org/abs/2307.12349)|[comptr](https://github.com/lartpang/comptr)|\n", "2309.06067": "|[efficient mri parallel imaging reconstruction by k-space rendering via generalized implicit neural representation](https://arxiv.org/abs/2309.06067)|[Generalized_INR](https://github.com/YuSheng-Zhou/Generalized_INR)|\n", "2309.11082": "|[dual-modal attention-enhanced text-video retrieval with triplet partial margin contrastive learning](https://arxiv.org/abs/2309.11082)|[Ant-Multi-Modal-Framework](https://github.com/alipay/Ant-Multi-Modal-Framework)|\n", "2312.13316": "|[ecamp: entity-centered context-aware medical vision language pre-training](https://arxiv.org/abs/2312.13316)|[ecamp](https://github.com/tonichopp/ecamp)|\n", "2403.05369": "|[frequency-adaptive dilated convolution for semantic segmentation](https://arxiv.org/abs/2403.05369)|[fadc](https://github.com/linwei-chen/fadc)|\n", "2403.06054": "|[decoupled data consistency with diffusion purification for image restoration](https://arxiv.org/abs/2403.06054)|[decoupled-data-consistency-with-diffusion-purification-for-image-restoration](https://github.com/morefre/decoupled-data-consistency-with-diffusion-purification-for-image-restoration)|\n", "2403.12886": "|[emovoca: speech-driven emotional 3d talking heads](https://arxiv.org/abs/2403.12886)|[EmoVOCA](https://github.com/miccunifi/EmoVOCA)|\n", "2403.20331": "|[unsolvable problem detection: robust understanding evaluation for large multimodal models](https://arxiv.org/abs/2403.20331)|[upd](https://github.com/atsumiyai/upd)|\n", "2404.18155": "|[shapemoir\\'e: channel-wise shape-guided network for image demoir\\'eing](https://arxiv.org/abs/2404.18155)|[shapemoire](https://github.com/sichengs/shapemoire)|\n", "2405.14019": "|[brainmorph: a foundational keypoint model for robust and flexible brain mri registration](https://arxiv.org/abs/2405.14019)|[brainmorph](https://github.com/alanqrwang/brainmorph)|\n", "2406.00971": "|[minigpt-reverse-designing: predicting image adjustments utilizing minigpt-4](https://arxiv.org/abs/2406.00971)|[minigpt-reverse-designing](https://github.com/vahidaz/minigpt-reverse-designing)|\n", "2406.09401": "|[mmscan: a multi-modal 3d scene dataset with hierarchical grounded language annotations](https://arxiv.org/abs/2406.09401)|[embodiedscan](https://github.com/openrobotlab/embodiedscan)|\n", "2406.17458": "|[continuous urban change detection from satellite image time series with temporal feature refinement and multi-task integration](https://arxiv.org/abs/2406.17458)|[conturbancd](https://github.com/sebastianhafner/conturbancd)|\n", "2407.09299": "|[pid: physics-informed diffusion model for infrared image generation](https://arxiv.org/abs/2407.09299)|[pid](https://github.com/fangyuanmao/pid)|\n", "2408.01076": "|[exploiting the semantic knowledge of pre-trained text-encoders for continual learning](https://arxiv.org/abs/2408.01076)|[semantically-guided-continual-learning](https://github.com/aprilsveryown/semantically-guided-continual-learning)|\n", "2408.10903": "|[beyond dialogue: a profile-dialogue alignment framework towards general role-playing language model](https://arxiv.org/abs/2408.10903)|[beyonddialogue](https://github.com/yuyouyu32/beyonddialogue)|\n", "2408.14732": "|[octfusion: octree-based diffusion models for 3d shape generation](https://arxiv.org/abs/2408.14732)|[octfusion](https://github.com/octree-nn/octfusion)|\n", "2409.01667": "|[vprochart: answering chart question through visual perception alignment agent and programmatic solution reasoning](https://arxiv.org/abs/2409.01667)|[VProChart](https://github.com/MuyeHuang/VProChart)|\n", "2409.08906": "|[gaussian is all you need: a unified framework for solving inverse problems via diffusion posterior sampling](https://arxiv.org/abs/2409.08906)|[codps](https://github.com/csiplab/codps)|\n", "2410.04811": "|[learning efficient and effective trajectories for differential equation-based image restoration](https://arxiv.org/abs/2410.04811)|[FLUX-IR](https://github.com/ZHU-Zhiyu/FLUX-IR)|\n", "2410.08646": "|[fully unsupervised dynamic mri reconstruction via diffeo-temporal equivariance](https://arxiv.org/abs/2410.08646)|[ddei](https://github.com/andrewwango/ddei)|\n", "2410.15068": "|[llm-hdr: bridging llm-based perception and self-supervision for unpaired ldr-to-hdr image reconstruction](https://arxiv.org/abs/2410.15068)|[llm-hdr](https://github.com/hrishavbakulbarua/llm-hdr)|\n", "2410.19789": "|[xeno-learning: knowledge transfer across species in deep learning-based spectral image analysis](https://arxiv.org/abs/2410.19789)|[htc](https://github.com/imsy-dkfz/htc)|\n", "2411.06528": "|[epistemic integrity in large language models](https://arxiv.org/abs/2411.06528)|[epistemic-integrity](https://github.com/complexdata-mila/epistemic-integrity)|\n", "2411.10958": "|[sageattention2: efficient attention with thorough outlier smoothing and per-thread int4 quantization](https://arxiv.org/abs/2411.10958)|[SageAttention](https://github.com/thu-ml/SageAttention)|\n", "2411.12584": "|[leveraging mllm embeddings and attribute smoothing for compositional zero-shot learning](https://arxiv.org/abs/2411.12584)|[Trident](https://github.com/xud-yan/Trident)|\n", "2411.13918": "|[quantization without tears](https://arxiv.org/abs/2411.13918)|[QwT](https://github.com/wujx2001/QwT)|\n", "2411.15729": "|[occludenet: a causal journey into mixed-view actor-centric video action recognition under occlusions](https://arxiv.org/abs/2411.15729)|[OccludeNet-Dataset](https://github.com/The-Martyr/OccludeNet-Dataset)|\n", "2411.18970": "|[fire: fixed-points of restoration priors for solving inverse problems](https://arxiv.org/abs/2411.18970)|[fire](https://github.com/matthieutrs/fire)|\n", "2411.19946": "|[delt: a simple diversity-driven earlylate training for dataset distillation](https://arxiv.org/abs/2411.19946)|[delt](https://github.com/vila-lab/delt)|\n", "2412.11716": "|[llms can simulate standardized patients via agent coevolution](https://arxiv.org/abs/2412.11716)|[evopatient](https://github.com/zjumai/evopatient)|\n", "2412.12693": "|[sphere: unveiling spatial blind spots in vision-language models through hierarchical evaluation](https://arxiv.org/abs/2412.12693)|[SPHERE-VLM](https://github.com/zwenyu/SPHERE-VLM)|\n", "2412.20047": "|[simltd: simple supervised and semi-supervised long-tailed object detection](https://arxiv.org/abs/2412.20047)|[simltd](https://github.com/lexisnexis-risk-open-source/simltd)|\n", "2501.00603": "|[dic: rethinking conv3x3 designs in diffusion models](https://arxiv.org/abs/2501.00603)|[dic](https://github.com/yuchuantian/dic)|\n", "2502.08636": "|[spatial457: a diagnostic benchmark for 6d spatial reasoning of large multimodal models](https://arxiv.org/abs/2502.08636)|[spatial457](https://github.com/xingruiwang/spatial457)|\n", "2502.11300": "|[cordial: can multimodal large language models effectively understand coherence relationships?](https://arxiv.org/abs/2502.11300)|[cordial](https://github.com/aashish2000/cordial)|\n", "2502.11494": "|[stop looking for important tokens in multimodal language models: duplication matters more](https://arxiv.org/abs/2502.11494)|[dart](https://github.com/zichenwen1/dart)|\n", "2502.12579": "|[chats: combining human-aligned optimization and test-time sampling for text-to-image generation](https://arxiv.org/abs/2502.12579)|[CHATS](https://github.com/AIDC-AI/CHATS)|\n", "2502.17793": "|[synthia: novel concept design with affordance composition](https://arxiv.org/abs/2502.17793)|[synthia](https://github.com/hyeonjeongha/synthia)|\n", "2502.20263": "|[vector-quantized vision foundation models for object-centric learning](https://arxiv.org/abs/2502.20263)|[VQ-VFM-OCL](https://github.com/Genera1Z/VQ-VFM-OCL)|\n", "2502.20650": "|[gungnir: exploiting stylistic features in images for backdoor attacks on diffusion models](https://arxiv.org/abs/2502.20650)|[gungnir](https://github.com/paoche11/gungnir)|\n", "2503.02585": "|[a hypernetwork-based approach to kan representation of audio signals](https://arxiv.org/abs/2503.02585)|[fewsound](https://github.com/gmum/fewsound)|\n", "2503.09402": "|[vlog: video-language models by generative retrieval of narration vocabulary](https://arxiv.org/abs/2503.09402)|[vlog](https://github.com/showlab/vlog)|\n", "2503.09707": "|[revisiting semi-supervised learning in the era of foundation models](https://arxiv.org/abs/2503.09707)|[SSL-Foundation-Models](https://github.com/OSU-MLB/SSL-Foundation-Models)|\n", "2503.10997": "|[rona: pragmatically diverse image captioning with coherence relations](https://arxiv.org/abs/2503.10997)|[rona](https://github.com/aashish2000/rona)|\n", "2503.11893": "|[ustyle: waterbody style transfer of underwater scenes by depth-guided feature synthesis](https://arxiv.org/abs/2503.11893)|[ustyle](https://github.com/uf-robopi/ustyle)|\n", "2503.12559": "|[adaretake: adaptive redundancy reduction to perceive longer for video-language understanding](https://arxiv.org/abs/2503.12559)|[video-flexreduc](https://github.com/sczwangxiao/video-flexreduc)|\n", "2503.13588": "|[next-scale autoregressive models are zero-shot single-image object view synthesizers](https://arxiv.org/abs/2503.13588)|[archonview](https://github.com/shiran-yuan/archonview)|\n", "2503.20047": "|[med3dvlm: an efficient vision-language model for 3d medical image analysis](https://arxiv.org/abs/2503.20047)|[med3dvlm](https://github.com/mirthai/med3dvlm)|\n", "2504.01040": "|[cal or no cal? -- real-time miscalibration detection of lidar and camera sensors](https://arxiv.org/abs/2504.01040)|[miscalibrationdetection](https://github.com/tumftm/miscalibrationdetection)|\n", "2504.07958": "|[detect anything 3d in the wild](https://arxiv.org/abs/2504.07958)|[DetAny3D](https://github.com/OpenDriveLab/DetAny3D)|\n", "2504.17728": "|[casualhdrsplat: robust high dynamic range 3d gaussian splatting from casually captured videos](https://arxiv.org/abs/2504.17728)|[casualhdrsplat](https://github.com/wu-cvgl/casualhdrsplat)|\n", "2504.20682": "|[og-hfyolo :orientation gradient guidance and heterogeneous feature fusion for deformation table cell instance segmentation](https://arxiv.org/abs/2504.20682)|[oghfyolo](https://github.com/justliulong/oghfyolo)|\n", "2505.14049": "|[learning concept-driven logical rules for interpretable and generalizable medical image classification](https://arxiv.org/abs/2505.14049)|[crl](https://github.com/obiyoag/crl)|\n", "2505.16809": "|[hypergraph tversky-aware domain incremental learning for brain tumor segmentation with missing modalities](https://arxiv.org/abs/2505.16809)|[rehydil](https://github.com/reeive/rehydil)|\n", "2505.18668": "|[chartgalaxy: a dataset for infographic chart understanding and generation](https://arxiv.org/abs/2505.18668)|[chartgalaxy](https://github.com/chartgalaxy/chartgalaxy)|\n", "2505.18700": "|[gre suite: geo-localization inference via fine-tuned vision-language models and enhanced reasoning chains](https://arxiv.org/abs/2505.18700)|[gre](https://github.com/thorin215/gre)|\n", "2505.20124": "|[tuna: comprehensive fine-grained temporal understanding evaluation on dense dynamic videos](https://arxiv.org/abs/2505.20124)|[TUNA](https://github.com/friedrichor/TUNA)|\n", "2505.24718": "|[reinforcing video reasoning with focused thinking](https://arxiv.org/abs/2505.24718)|[tw-grpo](https://github.com/longmalongma/tw-grpo)|\n", "2506.00978": "|[capaa: classifier-agnostic projector-based adversarial attack](https://arxiv.org/abs/2506.00978)|[capaa](https://github.com/zhanliqxq/capaa)|\n", "2506.03988": "|[raid: a dataset for testing the adversarial robustness of ai-generated image detectors](https://arxiv.org/abs/2506.03988)|[raid](https://github.com/pralab/raid)|\n", "2506.05660": "|[tissunet: improved extracranial tissue and cranium segmentation for children through adulthood](https://arxiv.org/abs/2506.05660)|[TissUNet](https://github.com/AIM-KannLab/TissUNet)|\n", "2506.06315": "|[an open-source python framework and synthetic ecg image datasets for digitization, lead and lead name detection, and overlapping signal segmentation](https://arxiv.org/abs/2506.06315)|[ecg-image-and-signal-dataset](https://github.com/rezakarbasi/ecg-image-and-signal-dataset)|\n", "2506.06474": "|[edge-enabled collaborative object detection for real-time multi-vehicle perception](https://arxiv.org/abs/2506.06474)|[Edge-CAV](https://github.com/EverettRichards/Edge-CAV)|\n", "2506.06664": "|[generalized trajectory scoring for end-to-end multimodal planning](https://arxiv.org/abs/2506.06664)|[gtrs](https://github.com/nvlabs/gtrs)|\n", "2506.06667": "|[flood-damagesense: multimodal mamba with multitask learning for building flood damage assessment using sar remote sensing imagery](https://arxiv.org/abs/2506.06667)|[flood-damagesense](https://github.com/violayhho/flood-damagesense)|\n", "2506.06710": "|[a systematic investigation on deep learning-based omnidirectional image and video super-resolution](https://arxiv.org/abs/2506.06710)|[survey-on-odisr-and-odvsr](https://github.com/nqian1/survey-on-odisr-and-odvsr)|\n", "2506.06771": "|[loopdb: a loop closure dataset for large scale simultaneous localization and mapping](https://arxiv.org/abs/2506.06771)|[loopdb](https://github.com/rovislab/loopdb)|\n", "2506.06906": "|[knn-defense: defense against 3d adversarial point clouds using nearest-neighbor search](https://arxiv.org/abs/2506.06906)|[3d-knn-defense](https://github.com/nimajam41/3d-knn-defense)|\n", "2506.06933": "|[rewriting the budget: a general framework for black-box attacks under cost asymmetry](https://arxiv.org/abs/2506.06933)|[asymmetric-attacks](https://github.com/mahdisalmani/asymmetric-attacks)|\n", "2506.07138": "|[learning compact vision tokens for efficient large multimodal models](https://arxiv.org/abs/2506.07138)|[LLaVA-STF](https://github.com/visresearch/LLaVA-STF)|\n", "2506.07364": "|[multiple object stitching for unsupervised representation learning](https://arxiv.org/abs/2506.07364)|[MultipleObjectStitching](https://github.com/visresearch/MultipleObjectStitching)|\n", "2506.07530": "|[bitvla: 1-bit vision-language-action models for robotics manipulation](https://arxiv.org/abs/2506.07530)|[bitvla](https://github.com/ustcwhy/bitvla)|\n", "2506.07539": "|[domain randomization for object detection in manufacturing applications using synthetic data: a comprehensive study](https://arxiv.org/abs/2506.07539)|[synmfg_code](https://github.com/jacobhenningsson95/synmfg_code)|\n", "2506.07558": "|[immersive visualization of flat surfaces using ray marching](https://arxiv.org/abs/2506.07558)|[raymarchingflatsurfaces](https://github.com/fabianlander/raymarchingflatsurfaces)|\n", "2506.07773": "|[trend-aware fashion recommendation with visual segmentation and semantic similarity](https://arxiv.org/abs/2506.07773)|[fashionrecommender](https://github.com/meddjilani/fashionrecommender)|\n", "2506.07811": "|[looking beyond visible cues: implicit video question answering via dual-clue reasoning](https://arxiv.org/abs/2506.07811)|[implicit-videoqa](https://github.com/tychen-sjtu/implicit-videoqa)|\n", "2506.07841": "|[diffusion models under low-noise regime](https://arxiv.org/abs/2506.07841)|[diffusion_low_noise_regime](https://github.com/lizardp1/diffusion_low_noise_regime)|\n", "2506.07857": "|[logosp: local-global grouping of superpoints for unsupervised semantic segmentation of 3d point clouds](https://arxiv.org/abs/2506.07857)|[logosp](https://github.com/vlar-group/logosp)|\n", "2506.07860": "|[egocentric event-based vision for ping pong ball trajectory prediction](https://arxiv.org/abs/2506.07860)|[event_based_ping_pong_ball_trajectory_prediction](https://github.com/uzh-rpg/event_based_ping_pong_ball_trajectory_prediction)|\n", "2506.07865": "|[freegave: 3d physics learning from dynamic videos by gaussian velocity](https://arxiv.org/abs/2506.07865)|[freegave](https://github.com/vlar-group/freegave)|\n", "2506.07878": "|[spatio-temporal state space model for efficient event-based optical flow](https://arxiv.org/abs/2506.07878)|[e-stmflow](https://github.com/ahmedhumais/e-stmflow)|\n", "2506.07883": "|[diffusion counterfactual generation with semantic abduction](https://arxiv.org/abs/2506.07883)|[diffusion-counterfactuals](https://github.com/rajatrasal/diffusion-counterfactuals)|\n", "2506.07905": "|[wethink: toward general-purpose vision-language reasoning via reinforcement learning](https://arxiv.org/abs/2506.07905)|[wethink](https://github.com/yangjie-cv/wethink)|\n", "2506.07917": "|[speedy deformable 3d gaussian splatting: fast rendering and compression of dynamic scenes](https://arxiv.org/abs/2506.07917)|[speede3dgs](https://github.com/tuallen/speede3dgs)|\n", "2506.07964": "|[slidecoder: layout-aware rag-enhanced hierarchical slide generation from design](https://arxiv.org/abs/2506.07964)|[slidecoder](https://github.com/vinsontang1/slidecoder)|\n", "2506.07966": "|[space-10: a comprehensive benchmark for multimodal large language models in compositional spatial intelligence](https://arxiv.org/abs/2506.07966)|[space-10](https://github.com/cuzyoung/space-10)|\n", "2506.07971": "|[cyberv: cybernetics for test-time scaling in video understanding](https://arxiv.org/abs/2506.07971)|[cyberv](https://github.com/marinero4972/cyberv)|\n", "2506.07985": "|[rethinking crowd-sourced evaluation of neuron explanations](https://arxiv.org/abs/2506.07985)|[efficient_neuron_eval](https://github.com/trustworthy-ml-lab/efficient_neuron_eval)|\n", "2506.07992": "|[pairedit: learning semantic variations for exemplar-based image editing](https://arxiv.org/abs/2506.07992)|[pairedit](https://github.com/xudonmao/pairedit)|\n", "2506.07998": "|[generative modeling of weights: generalization or memorization?](https://arxiv.org/abs/2506.07998)|[weight_memorization](https://github.com/boyazeng/weight_memorization)|\n", "2506.08013": "|[stablemtl: repurposing latent diffusion models for multi-task learning from partially annotated synthetic datasets](https://arxiv.org/abs/2506.08013)|[stablemtl](https://github.com/astra-vision/stablemtl)|\n"}, "2025-06-11": {"2208.12306": "|[multimedia generative script learning for task planning](https://arxiv.org/abs/2208.12306)|[Multimedia-Generative-Script-Learning-for-Task-Planning](https://github.com/EagleW/Multimedia-Generative-Script-Learning-for-Task-Planning)|\n", "2304.09914": "|[the face of populism: examining differences in facial emotional expressions of political leaders using machine learning](https://arxiv.org/abs/2304.09914)|[face-of-populism](https://github.com/atomashevic/face-of-populism)|\n", "2306.08730": "|[over-the-air learning-based geometry point cloud transmission](https://arxiv.org/abs/2306.08730)|[SEPT](https://github.com/aprilbian/SEPT)|\n", "2402.03896": "|[multimodal rationales for explainable visual question answering](https://arxiv.org/abs/2402.03896)|[crvqa2024](https://github.com/lik1996/crvqa2024)|\n", "2402.04416": "|[multimodal unsupervised domain generalization by retrieving across the modality gap](https://arxiv.org/abs/2402.04416)|[mudg](https://github.com/chris210634/mudg)|\n", "2411.02299": "|[grouped discrete representation for object-centric learning](https://arxiv.org/abs/2411.02299)|[GroupedDiscreteRepresentation](https://github.com/Genera1Z/GroupedDiscreteRepresentation)|\n", "2411.04125": "|[community forensics: using thousands of generators to train fake image detectors](https://arxiv.org/abs/2411.04125)|[Community-Forensics](https://github.com/JeongsooP/Community-Forensics)|\n", "2412.18063": "|[lmrpa: large language model-driven efficient robotic process automation for ocr](https://arxiv.org/abs/2412.18063)|[erpa-ocr](https://github.com/mad-sam22/erpa-ocr)|\n", "2412.18874": "|[a culturally-aware benchmark for person re-identification in modest attire](https://arxiv.org/abs/2412.18874)|[IUST_PersonReId](https://github.com/ComputerVisionIUST/IUST_PersonReId)|\n", "2501.15513": "|[tinyllava-video: towards smaller lmms for video understanding with group resampler](https://arxiv.org/abs/2501.15513)|[tinyllava-video](https://github.com/zhangxj199/tinyllava-video)|\n", "2502.15226": "|[understand user opinions of large language models via llm-powered in-the-moment user experience interviews](https://arxiv.org/abs/2502.15226)|[llm-interviewer](https://github.com/cxcscmu/llm-interviewer)|\n", "2502.17237": "|[megaloc: one retrieval to place them all](https://arxiv.org/abs/2502.17237)|[megaloc](https://github.com/gmberton/megaloc)|\n", "2503.08071": "|[gigaslam: large-scale monocular slam with hierarchical gaussian splats](https://arxiv.org/abs/2503.08071)|[GigaSLAM](https://github.com/DengKaiCQ/GigaSLAM)|\n", "2504.02473": "|[adaptive path planning for efficient object search by uavs in agricultural fields](https://arxiv.org/abs/2504.02473)|[uav_adaptive_planner](https://github.com/wur-abe/uav_adaptive_planner)|\n", "2504.06751": "|[visualization of a multidimensional point cloud as a 3d swarm of avatars](https://arxiv.org/abs/2504.06751)|[n-dim-view](https://github.com/iitis/n-dim-view)|\n", "2504.07549": "|[step: a framework for solving scientific video inverse problems with spatiotemporal diffusion priors](https://arxiv.org/abs/2504.07549)|[STeP](https://github.com/zhangbingliang2019/STeP)|\n", "2505.17017": "|[delving into rl for image generation with cot: a study on dpo vs. grpo](https://arxiv.org/abs/2505.17017)|[image-generation-cot](https://github.com/ziyuguo99/image-generation-cot)|\n", "2505.17061": "|[mixture of decoding: an attention-inspired adaptive decoding strategy to mitigate hallucinations in large vision-language models](https://arxiv.org/abs/2505.17061)|[mod](https://github.com/xlchen0205/mod)|\n", "2505.17114": "|[raven: query-guided representation alignment for question answering over audio, video, embedded sensors, and natural language](https://arxiv.org/abs/2505.17114)|[raven](https://github.com/bashlab/raven)|\n", "2505.17683": "|[dual attention residual u-net for accurate brain ultrasound segmentation in ivh detection](https://arxiv.org/abs/2505.17683)|[brainimgsegment](https://github.com/danyuan001/brainimgsegment)|\n", "2505.18956": "|[how do images align and complement lidar? towards a harmonized multi-modal 3d panoptic segmentation](https://arxiv.org/abs/2505.18956)|[ial](https://github.com/impl-lab/ial)|\n", "2505.22918": "|[re-ttention: ultra sparse visual generation via attention statistical reshape](https://arxiv.org/abs/2505.22918)|[re-ttention](https://github.com/cccrrrccc/re-ttention)|\n", "2505.23916": "|[estimation of head motion in structural mri and its impact on cortical thickness measurements in retrospective data](https://arxiv.org/abs/2505.23916)|[cortical-motion](https://github.com/neuro-ix/cortical-motion)|\n", "2506.07977": "|[oneig-bench: omni-dimensional nuanced evaluation for image generation](https://arxiv.org/abs/2506.07977)|[oneig-benchmark](https://github.com/oneig-bench/oneig-benchmark)|\n", "2506.08071": "|[cure: cultural gaps in the long tail of text-to-image systems](https://arxiv.org/abs/2506.08071)|[cure-bench](https://github.com/aniketrege/cure-bench)|\n", "2506.08189": "|[open world scene graph generation using vision language models](https://arxiv.org/abs/2506.08189)|[pix2grp_cvpr2024](https://github.com/shtuplus/pix2grp_cvpr2024)|\n", "2506.08277": "|[instruction-tuned video-audio models elucidate functional specialization in the brain](https://arxiv.org/abs/2506.08277)|[mllm_videos](https://github.com/subbareddy248/mllm_videos)|\n", "2506.08280": "|[snap-and-tune: combining deep learning and test-time optimization for high-fidelity cardiovascular volumetric meshing](https://arxiv.org/abs/2506.08280)|[deep-cardiac-volumetric-mesh](https://github.com/danpak94/deep-cardiac-volumetric-mesh)|\n", "2506.08299": "|[openrr-1k: a scalable dataset for real-world reflection removal](https://arxiv.org/abs/2506.08299)|[openrr-1k](https://github.com/caijie0620/openrr-1k)|\n", "2506.08353": "|[an adaptive method stabilizing activations for enhanced generalization](https://arxiv.org/abs/2506.08353)|[adaact](https://github.com/hseung88/adaact)|\n", "2506.08361": "|[image demoir\\'eing using dual camera fusion on mobile phones](https://arxiv.org/abs/2506.08361)|[dcid](https://github.com/mrduckk/dcid)|\n", "2506.08391": "|[second: mitigating perceptual hallucination in vision-language models via selective and contrastive decoding](https://arxiv.org/abs/2506.08391)|[second](https://github.com/aidaslab/second)|\n", "2506.08520": "|[plug-and-play linear attention for pre-trained image and video restoration models](https://arxiv.org/abs/2506.08520)|[pnp_nystra](https://github.com/srinivas-512/pnp_nystra)|\n", "2506.08591": "|[diversity-guided mlp reduction for efficient large vision transformers](https://arxiv.org/abs/2506.08591)|[DGMR](https://github.com/visresearch/DGMR)|\n", "2506.08611": "|[towards class-wise fair adversarial training via anti-bias soft label distillation](https://arxiv.org/abs/2506.08611)|[absld](https://github.com/zhaoshiji123/absld)|\n", "2506.08613": "|[samselect: a spectral index search for marine debris visualization using segment anything](https://arxiv.org/abs/2506.08613)|[samselect](https://github.com/geojoost/samselect)|\n", "2506.08618": "|[hsg-12m: a large-scale spatial multigraph dataset](https://arxiv.org/abs/2506.08618)|[hsg-12m](https://github.com/sarinstein-yan/hsg-12m)|\n", "2506.08691": "|[vrest: enhancing reasoning in large vision-language models through tree search and self-reward mechanism](https://arxiv.org/abs/2506.08691)|[vrest](https://github.com/garyjiajia/vrest)|\n", "2506.08694": "|[mosic: optimal-transport motion trajectory for dense self-supervised learning](https://arxiv.org/abs/2506.08694)|[mosic](https://github.com/smsd75/mosic)|\n", "2506.08761": "|[normalized radon cumulative distribution transforms for invariance and robustness in optimal transport based image classification](https://arxiv.org/abs/2506.08761)|[nr-cdt](https://github.com/drbeckmann/nr-cdt)|\n", "2506.08862": "|[streamsplat: towards online dynamic 3d reconstruction from uncalibrated video streams](https://arxiv.org/abs/2506.08862)|[streamsplat](https://github.com/nickwzk/streamsplat)|\n", "2506.08887": "|[discovla: discrepancy reduction in vision, language, and alignment for parameter-efficient video-text retrieval](https://arxiv.org/abs/2506.08887)|[dsicovla](https://github.com/lunarshen/dsicovla)|\n", "2506.08949": "|[sss: semi-supervised sam-2 with efficient prompting for medical imaging segmentation](https://arxiv.org/abs/2506.08949)|[sss](https://github.com/aigeeksgroup/sss)|\n", "2506.08990": "|[efficient medical vision-language alignment through adapting masked vision models](https://arxiv.org/abs/2506.08990)|[alta](https://github.com/dopaminelcy/alta)|\n", "2506.08997": "|[sdtagnet: leveraging text-annotated navigation maps for online hd map construction](https://arxiv.org/abs/2506.08997)|[sdtagnet](https://github.com/immel-f/sdtagnet)|\n", "2506.09040": "|[autoregressive semantic visual reconstruction helps vlms understand better](https://arxiv.org/abs/2506.09040)|[asvr](https://github.com/alenjandrowang/asvr)|\n", "2506.09045": "|[magcache: fast video generation with magnitude-aware cache](https://arxiv.org/abs/2506.09045)|[magcache](https://github.com/zehong-ma/magcache)|\n"}, "2025-06-12": {"2302.07944": "|[effective data augmentation with diffusion models](https://arxiv.org/abs/2302.07944)|[da-fusion](https://github.com/brandontrabucco/da-fusion)|\n", "2312.04540": "|[sim-to-real causal transfer: a metric learning approach to causally-aware interaction representations](https://arxiv.org/abs/2312.04540)|[causalsim2real](https://github.com/vita-epfl/causalsim2real)|\n", "2402.01779": "|[plug-and-play image restoration with stochastic denoising regularization](https://arxiv.org/abs/2402.01779)|[snore](https://github.com/marien-renaud/snore)|\n", "2403.16998": "|[understanding long videos with multimodal language models](https://arxiv.org/abs/2403.16998)|[mvu](https://github.com/kahnchana/mvu)|\n", "2405.11985": "|[mtvqa: benchmarking multilingual text-centric visual question answering](https://arxiv.org/abs/2405.11985)|[MTVQA](https://github.com/bytedance/MTVQA)|\n", "2406.10322": "|[liere: lie rotational positional encodings](https://arxiv.org/abs/2406.10322)|[liere](https://github.com/stanford-aimi/liere)|\n", "2408.00273": "|[ukan-ep: enhancing u-kan with efficient attention and pyramid aggregation for 3d multi-modal mri brain tumor segmentation](https://arxiv.org/abs/2408.00273)|[ukan-ep](https://github.com/tianzetang0504/ukan-ep)|\n", "2408.16355": "|[nerf-ca: dynamic reconstruction of x-ray coronary angiography with extremely sparse-views](https://arxiv.org/abs/2408.16355)|[nerf-ca](https://github.com/kirstenmaas/nerf-ca)|\n", "2410.02080": "|[emma: efficient visual alignment in multi-modal llms](https://arxiv.org/abs/2410.02080)|[emma](https://github.com/saraghazanfari/emma)|\n", "2410.14398": "|[dynamic negative guidance of diffusion models](https://arxiv.org/abs/2410.14398)|[dynamic-negative-guidance](https://github.com/felixkoulischer/dynamic-negative-guidance)|\n", "2501.04606": "|[enhancing low-cost video editing with lightweight adaptors and temporal-aware inversion](https://arxiv.org/abs/2501.04606)|[tokenflow_adapter](https://github.com/codepassionor/tokenflow_adapter)|\n", "2502.06034": "|[traveling waves integrate spatial information through time](https://arxiv.org/abs/2502.06034)|[Wave_Representations](https://github.com/anonymous123-user/Wave_Representations)|\n", "2503.04459": "|[question-aware gaussian experts for audio-visual question answering](https://arxiv.org/abs/2503.04459)|[QA-TIGER](https://github.com/AIM-SKKU/QA-TIGER)|\n", "2504.10552": "|[lemur neural network dataset: towards seamless automl](https://arxiv.org/abs/2504.10552)|[nn-vr](https://github.com/abrain-one/nn-vr)|\n", "2506.05982": "|[mca-bench: a multimodal benchmark for evaluating captcha robustness against vlm-based attacks](https://arxiv.org/abs/2506.05982)|[mca-bench](https://github.com/noheadwuzonglin/mca-bench)|\n", "2506.07400": "|[medchat: a multi-agent framework for multimodal diagnosis with large language models](https://arxiv.org/abs/2506.07400)|[medchat](https://github.com/purdue-m2/medchat)|\n", "2506.07986": "|[rethinking cross-modal interaction in multimodal diffusion transformers](https://arxiv.org/abs/2506.07986)|[taca](https://github.com/vchitect/taca)|\n", "2506.08010": "|[vision transformers don't need trained registers](https://arxiv.org/abs/2506.08010)|[test-time-registers](https://github.com/nickjiang2378/test-time-registers)|\n", "2506.08772": "|[rs-mtdf: multi-teacher distillation and fusion for remote sensing semi-supervised semantic segmentation](https://arxiv.org/abs/2506.08772)|[semi-supervised-semantic-segmentation-with-distillation](https://github.com/earth-insights/semi-supervised-semantic-segmentation-with-distillation)|\n", "2506.08849": "|[adapting vision-language foundation model for next generation medical ultrasound image analysis](https://arxiv.org/abs/2506.08849)|[nextgen-uia](https://github.com/jinggqu/nextgen-uia)|\n", "2506.08900": "|[mirage: multimodal foundation model and benchmark for comprehensive retinal oct image analysis](https://arxiv.org/abs/2506.08900)|[mirage](https://github.com/j-morano/mirage)|\n", "2506.08908": "|[skipvar: accelerating visual autoregressive modeling via adaptive frequency-aware skipping](https://arxiv.org/abs/2506.08908)|[skipvar](https://github.com/fakerone-li/skipvar)|\n", "2506.09022": "|[do multiple instance learning models transfer?](https://arxiv.org/abs/2506.09022)|[mil-lab](https://github.com/mahmoodlab/mil-lab)|\n", "2506.09217": "|[perception characteristics distance: measuring stability and robustness of perception system in dynamic conditions under a certain decision rule](https://arxiv.org/abs/2506.09217)|[pcd_python](https://github.com/datadrivenwheels/pcd_python)|\n", "2506.09237": "|[patchguard: adversarially robust anomaly detection and localization through vision transformers and pseudo anomalies](https://arxiv.org/abs/2506.09237)|[patchgaurd](https://github.com/rohban-lab/patchgaurd)|\n", "2506.09344": "|[ming-omni: a unified multimodal model for perception and generation](https://arxiv.org/abs/2506.09344)|[ming](https://github.com/inclusionai/ming)|\n", "2506.09353": "|[davsp: safety alignment for large vision-language models via deep aligned visual safety prompt](https://arxiv.org/abs/2506.09353)|[davsp](https://github.com/zhangyitonggg/davsp)|\n", "2506.09363": "|[sage: exploring the boundaries of unsafe concept domain with semantic-augment erasing](https://arxiv.org/abs/2506.09363)|[sage](https://github.com/kevinlight831/sage)|\n", "2506.09369": "|[scalelsd: scalable deep line segment detection streamlined](https://arxiv.org/abs/2506.09369)|[scalelsd](https://github.com/ant-research/scalelsd)|\n", "2506.09385": "|[reid5o: achieving omni multi-modal person re-identification in a single model](https://arxiv.org/abs/2506.09385)|[reid5o_orbench](https://github.com/zplusdragon/reid5o_orbench)|\n", "2506.09403": "|[srpl-sfda: sam-guided reliable pseudo-labels for source-free domain adaptation in medical image segmentation](https://arxiv.org/abs/2506.09403)|[srpl-sfda](https://github.com/hilab-git/srpl-sfda)|\n", "2506.09416": "|[noise conditional variational score distillation](https://arxiv.org/abs/2506.09416)|[ncvsd](https://github.com/xypeng9903/ncvsd)|\n", "2506.09420": "|[a call for collaborative intelligence: why human-agent systems should precede ai autonomy](https://arxiv.org/abs/2506.09420)|[awesome-llm-based-human-agent-systems](https://github.com/henrypengzou/awesome-llm-based-human-agent-systems)|\n", "2506.09522": "|[revisit what you see: disclose language prior in vision tokens for efficient guided decoding of lvlms](https://arxiv.org/abs/2506.09522)|[ReVisiT](https://github.com/bscho333/ReVisiT)|\n", "2506.09626": "|[ecam: a contrastive learning approach to avoid environmental collision in trajectory forecasting](https://arxiv.org/abs/2506.09626)|[ecam](https://github.com/cvml-cfu/ecam)|\n", "2506.09650": "|[hopadiff: holistic-partial aware fourier conditioned diffusion for referring human action segmentation in multi-person scenarios](https://arxiv.org/abs/2506.09650)|[hopadiff](https://github.com/kpeng9510/hopadiff)|\n", "2506.09668": "|[cinema: conditional implicit neural multi-modal atlas for a spatio-temporal representation of the perinatal brain](https://arxiv.org/abs/2506.09668)|[cinema](https://github.com/m-dannecker/cinema)|\n", "2506.09691": "|[adding simple structure at inference improves vision-language compositionality](https://arxiv.org/abs/2506.09691)|[structure-inference-compositionality](https://github.com/imirandam/structure-inference-compositionality)|\n", "2506.09695": "|[towards practical alzheimer's disease diagnosis: a lightweight and interpretable spiking neural model](https://arxiv.org/abs/2506.09695)|[fastersnn](https://github.com/wuchangw/fastersnn)|\n", "2506.09709": "|[training-free voice conversion with factorized optimal transport](https://arxiv.org/abs/2506.09709)|[mkl-vc](https://github.com/alobashev/mkl-vc)|\n", "2506.09718": "|[non-contact health monitoring during daily personal care routines](https://arxiv.org/abs/2506.09718)|[fusionvitals](https://github.com/mcjacktang/fusionvitals)|\n", "2506.09724": "|[the four color theorem for cell instance segmentation](https://arxiv.org/abs/2506.09724)|[fcis](https://github.com/zhangye-zoe/fcis)|\n", "2506.09733": "|[atmosmj: revisiting gating mechanism for ai weather forecasting beyond the year scale](https://arxiv.org/abs/2506.09733)|[README.md](https://github.com/jmj2316/AtmosMJ/blob/main/README.md)|\n", "2506.09736": "|[vision matters: simple visual perturbations can boost multimodal math reasoning](https://arxiv.org/abs/2506.09736)|[easyr1](https://github.com/hiyouga/easyr1)|\n", "2506.09777": "|[inverting black-box face recognition systems via zero-order optimization in eigenface space](https://arxiv.org/abs/2506.09777)|[adversarialfaces](https://github.com/fusionbrainlab/adversarialfaces)|\n", "2506.09790": "|[comfyui-r1: exploring reasoning models for workflow generation](https://arxiv.org/abs/2506.09790)|[comfyui-copilot](https://github.com/aidc-ai/comfyui-copilot)|\n", "2506.09849": "|[intphys 2: benchmarking intuitive physics understanding in complex synthetic environments](https://arxiv.org/abs/2506.09849)|[intphys2](https://github.com/facebookresearch/intphys2)|\n", "2506.09881": "|[leveraging depth and language for open-vocabulary domain-generalized semantic segmentation](https://arxiv.org/abs/2506.09881)|[vireo](https://github.com/anonymouse-9c53tp182bvz/vireo)|\n", "2506.09883": "|[3d-aware vision-language models fine-tuning with geometric distillation](https://arxiv.org/abs/2506.09883)|[3d-vlm-gd](https://github.com/kaist-cvml/3d-vlm-gd)|\n", "2506.09895": "|[equicaps: predictor-free pose-aware pre-trained capsule networks](https://arxiv.org/abs/2506.09895)|[equicaps](https://github.com/aberdeenml/equicaps)|\n", "2506.09920": "|[structural-spectral graph convolution with evidential edge learning for hyperspectral image clustering](https://arxiv.org/abs/2506.09920)|[ssgco-egael](https://github.com/jhqi/ssgco-egael)|\n", "2506.09943": "|[causalvqa: a physically grounded causal reasoning benchmark for video models](https://arxiv.org/abs/2506.09943)|[causalvqa](https://github.com/facebookresearch/causalvqa)|\n", "2506.09949": "|[sampling theory for super-resolution with implicit neural representations](https://arxiv.org/abs/2506.09949)|[super_inrs](https://github.com/gregongie/super_inrs)|\n", "2506.09952": "|[unipre3d: unified pre-training of 3d point cloud models with cross-modal gaussian splatting](https://arxiv.org/abs/2506.09952)|[unipre3d](https://github.com/wangzy22/unipre3d)|\n", "2506.09953": "|[outside knowledge conversational video (okcv) dataset -- dialoguing over videos](https://arxiv.org/abs/2506.09953)|[okcv](https://github.com/c-patsch/okcv)|\n", "2506.09965": "|[reinforcing spatial reasoning in vision-language models with interwoven thinking and visual drawing](https://arxiv.org/abs/2506.09965)|[vilasr](https://github.com/antresearchnlp/vilasr)|\n", "2506.09980": "|[efficient part-level 3d object generation via dual volume packing](https://arxiv.org/abs/2506.09980)|[partpacker](https://github.com/nvlabs/partpacker)|\n", "2506.09985": "|[v-jepa 2: self-supervised video models enable understanding, prediction and planning](https://arxiv.org/abs/2506.09985)|[vjepa2](https://github.com/facebookresearch/vjepa2)|\n", "2506.09989": "|[hearing hands: generating sounds from physical interactions in 3d scenes](https://arxiv.org/abs/2506.09989)|[hearing_hands](https://github.com/dou-yiming/hearing_hands)|\n"}, "2025-06-13": {"2307.03601": "|[gpt4roi: instruction tuning large language model on region-of-interest](https://arxiv.org/abs/2307.03601)|[gpt4roi](https://github.com/jshilong/gpt4roi)|\n", "2308.07528": "|[confidence contours: uncertainty-aware annotation for medical semantic segmentation](https://arxiv.org/abs/2308.07528)|[confcontours-data](https://github.com/andre-ye/confcontours-data)|\n", "2311.03782": "|[capst: leveraging capsule networks and temporal attention for accurate model attribution in deep-fake videos](https://arxiv.org/abs/2311.03782)|[CapST](https://github.com/wasim004/CapST)|\n", "2401.00816": "|[glimpse: generalized locality for scalable and robust ct](https://arxiv.org/abs/2401.00816)|[glimpse](https://github.com/swing-research/glimpse)|\n", "2408.10688": "|[tds-clip: temporal difference side network for efficient videoaction recognition](https://arxiv.org/abs/2408.10688)|[TDS-CLIP](https://github.com/BBYL9413/TDS-CLIP)|\n", "2410.10084": "|[pointnet with kan versus pointnet with mlp for 3d classification and segmentation of point sets](https://arxiv.org/abs/2410.10084)|[pointnet_kan_graphic](https://github.com/ali-stanford/pointnet_kan_graphic)|\n", "2410.15067": "|[a survey on all-in-one image restoration: taxonomy, evaluation and future trends](https://arxiv.org/abs/2410.15067)|[all-in-one-image-restoration-survey](https://github.com/harbinzzy/all-in-one-image-restoration-survey)|\n", "2411.01796": "|[constrained human-ai cooperation: an inclusive embodied social intelligence challenge](https://arxiv.org/abs/2411.01796)|[chaic](https://github.com/umass-embodied-agi/chaic)|\n", "2501.12880": "|[advanced deep architecture pruning using single filter performance](https://arxiv.org/abs/2501.12880)|[AFCC](https://github.com/Shutshutnunte/AFCC)|\n", "2502.20490": "|[egonormia: benchmarking physical social norm understanding](https://arxiv.org/abs/2502.20490)|[egonormia](https://github.com/open-social-world/egonormia)|\n", "2506.08011": "|[play to generalize: learning to reason through game play](https://arxiv.org/abs/2506.08011)|[vigal](https://github.com/yunfeixie233/vigal)|\n", "2506.08735": "|[inceptionmamba: an efficient hybrid network with large band convolution and bottleneck mamba](https://arxiv.org/abs/2506.08735)|[inceptionmamba](https://github.com/wake1021/inceptionmamba)|\n", "2506.09042": "|[cosmos-drive-dreams: scalable synthetic driving data generation with world foundation models](https://arxiv.org/abs/2506.09042)|[cosmos-drive-dreams](https://github.com/nv-tlabs/cosmos-drive-dreams)|\n", "2506.09476": "|[urban1960satseg: unsupervised semantic segmentation of mid-20$^{th}$ century urban landscapes with satellite imageries](https://arxiv.org/abs/2506.09476)|[urban1960satseg](https://github.com/tianxiang-hao/urban1960satseg)|\n", "2506.09612": "|[consistent story generation with asymmetry zigzag sampling](https://arxiv.org/abs/2506.09612)|[asymmetry-zigzag-storydiffusion](https://github.com/mingxiao-li/asymmetry-zigzag-storydiffusion)|\n", "2506.09834": "|[mmme: a spontaneous multi-modal micro-expression dataset enabling visual-physiological fusion](https://arxiv.org/abs/2506.09834)|[mmme](https://github.com/mac0504/mmme)|\n", "2506.10036": "|[token perturbation guidance for diffusion models](https://arxiv.org/abs/2506.10036)|[token-perturbation-guidance](https://github.com/taatiteam/token-perturbation-guidance)|\n", "2506.10128": "|[vicrit: a verifiable reinforcement learning proxy task for visual perception in vlms](https://arxiv.org/abs/2506.10128)|[vicrit](https://github.com/si0wang/vicrit)|\n", "2506.10142": "|[rethinking brain tumor segmentation from the frequency domain perspective](https://arxiv.org/abs/2506.10142)|[hff](https://github.com/vinyehshaw/hff)|\n", "2506.10150": "|[when large language models are reliable for judging empathic communication](https://arxiv.org/abs/2506.10150)|[replication-data-and-code-when-LLMs-reliable-empathic-communication](https://github.com/aakriti1kumar/replication-data-and-code-when-LLMs-reliable-empathic-communication)|\n", "2506.10174": "|[retrieval of surface solar radiation through implicit albedo recovery from temporal context](https://arxiv.org/abs/2506.10174)|[hemu-dev](https://github.com/frischwood/hemu-dev)|\n", "2506.10178": "|[attention, please! revisiting attentive probing for masked image modeling](https://arxiv.org/abs/2506.10178)|[efficient-probing](https://github.com/billpsomas/efficient-probing)|\n", "2506.10182": "|[improving personalized search with regularized low-rank parameter updates](https://arxiv.org/abs/2506.10182)|[polar-vl](https://github.com/adobe-research/polar-vl)|\n", "2506.10228": "|[california crop yield benchmark: combining satellite image, climate, evapotranspiration, and soil data layers for county-level yield forecasting of over 70 crops](https://arxiv.org/abs/2506.10228)|[california-crop-yield-benchmark](https://github.com/plant-ai-biophysics-lab/california-crop-yield-benchmark)|\n", "2506.10325": "|[swdl: stratum-wise difference learning with deep laplacian pyramid for semi-supervised 3d intracranial hemorrhage segmentation](https://arxiv.org/abs/2506.10325)|[swdl](https://github.com/siat-ct-lab/swdl)|\n", "2506.10366": "|[fsatfusion: frequency-spatial attention transformer for infrared and visible image fusion](https://arxiv.org/abs/2506.10366)|[fsatfusion](https://github.com/lmmh058/fsatfusion)|\n", "2506.10386": "|[leveraging 6dof pose foundation models for mapping marine sediment burial](https://arxiv.org/abs/2506.10386)|[barrels](https://github.com/jerukan/barrels)|\n", "2506.10390": "|[dart: differentiable dynamic adaptive region tokenizer for vision transformer and mamba](https://arxiv.org/abs/2506.10390)|[dart](https://github.com/hcplab-sysu/dart)|\n", "2506.10391": "|[reconmost: multi-layer sea temperature reconstruction with observations-guided diffusion](https://arxiv.org/abs/2506.10391)|[reconmost](https://github.com/norsheep/reconmost)|\n", "2506.10452": "|[towards robust multimodal emotion recognition under missing modalities and distribution shifts](https://arxiv.org/abs/2506.10452)|[cider](https://github.com/gw-zhong/cider)|\n", "2506.10468": "|[low-barrier dataset collection with real human body for interactive per-garment virtual try-on](https://arxiv.org/abs/2506.10468)|[RTV](https://github.com/ZaiqiangWu/RTV)|\n", "2506.10550": "|[contextrefine-clip for epic-kitchens-100 multi-instance retrieval challenge 2025](https://arxiv.org/abs/2506.10550)|[contextrefine-clip](https://github.com/delcayr/contextrefine-clip)|\n", "2506.10580": "|[transformer imu calibrator: dynamic on-body imu calibration for inertial motion capture](https://arxiv.org/abs/2506.10580)|[tic](https://github.com/zuocx1996/tic)|\n", "2506.10601": "|[semantic-decoupled spatial partition guided point-supervised oriented object detection](https://arxiv.org/abs/2506.10601)|[ssp](https://github.com/antxinyuan/ssp)|\n", "2506.10609": "|[mstar: box-free multi-query scene text retrieval with attention recycling](https://arxiv.org/abs/2506.10609)|[mstar](https://github.com/yingift/mstar)|\n", "2506.10612": "|[textailor: customized text-aligned texturing via effective resampling](https://arxiv.org/abs/2506.10612)|[textailor](https://github.com/adios42/textailor)|\n", "2506.10632": "|[hessian geometry of latent space in generative models](https://arxiv.org/abs/2506.10632)|[hessian-geometry-of-diffusion-models](https://github.com/alobashev/hessian-geometry-of-diffusion-models)|\n", "2506.10890": "|[creatiposter: towards editable and controllable multi-layer graphic design generation](https://arxiv.org/abs/2506.10890)|[creatiposter](https://github.com/graphic-design-ai/creatiposter)|\n", "2506.10895": "|[air: zero-shot generative model adaptation with iterative refinement](https://arxiv.org/abs/2506.10895)|[air](https://github.com/guimeng-leo-liu/air)|\n", "2506.10967": "|[beyond attention or similarity: maximizing conditional diversity for token pruning in mllms](https://arxiv.org/abs/2506.10967)|[cdpruner](https://github.com/theia-4869/cdpruner)|\n", "2506.10977": "|[quadricformer: scene as superquadrics for 3d semantic occupancy prediction](https://arxiv.org/abs/2506.10977)|[quadricformer](https://github.com/zuosc19/quadricformer)|\n"}, "2025-06-14": {}, "2025-06-15": {}, "2025-06-16": {"2401.06122": "|[manipulating feature visualizations with gradient slingshots](https://arxiv.org/abs/2401.06122)|[grad-slingshot](https://github.com/dilyabareeva/grad-slingshot)|\n", "2405.14343": "|[efficient visual state space model for image deblurring](https://arxiv.org/abs/2405.14343)|[evssm](https://github.com/kkkls/evssm)|\n", "2408.05901": "|[efficient visual representation learning with heat conduction equation](https://arxiv.org/abs/2408.05901)|[hcnet](https://github.com/zheminzhang1/hcnet)|\n", "2409.18009": "|[control industrial automation system with large language model agents](https://arxiv.org/abs/2409.18009)|[llm4ias](https://github.com/yuchenxia/llm4ias)|\n", "2411.04746": "|[taming rectified flow for inversion and editing](https://arxiv.org/abs/2411.04746)|[rf-solver-edit](https://github.com/wangjiangshan0725/rf-solver-edit)|\n", "2411.16318": "|[one diffusion to generate them all](https://arxiv.org/abs/2411.16318)|[onediffusion](https://github.com/lehduong/onediffusion)|\n", "2412.03055": "|[real-time aiot for uav antenna interference detection via edge-cloud collaboration](https://arxiv.org/abs/2412.03055)|[edgeant](https://github.com/scnu-rislab/edgeant)|\n", "2412.21015": "|[mapqator: an extensible framework for efficient annotation of map-based qa datasets](https://arxiv.org/abs/2412.21015)|[profile](https://github.com/MapQaTor/.github/tree/main/profile)|\n", "2501.05205": "|[discovering hidden visual concepts beyond linguistic input in infant learning](https://arxiv.org/abs/2501.05205)|[discover_infant_vis](https://github.com/kexueyi/discover_infant_vis)|\n", "2503.21099": "|[learning class prototypes for unified sparse supervised 3d object detection](https://arxiv.org/abs/2503.21099)|[cpdet3d](https://github.com/zyrant/cpdet3d)|\n", "2503.23461": "|[textcrafter: accurately rendering multiple texts in complex visual scenes](https://arxiv.org/abs/2503.23461)|[textcrafter](https://github.com/nju-pcalab/textcrafter)|\n", "2504.10514": "|[colorbench: can vlms see and understand the colorful world? a comprehensive benchmark for color perception, reasoning, and robustness](https://arxiv.org/abs/2504.10514)|[colorbench](https://github.com/tianyi-lab/colorbench)|\n", "2505.02471": "|[ming-lite-uni: advancements in unified architecture for natural multimodal interaction](https://arxiv.org/abs/2505.02471)|[ming](https://github.com/inclusionai/ming)|\n", "2505.10496": "|[chexgenbench: a unified benchmark for fidelity, privacy and utility of synthetic chest radiographs](https://arxiv.org/abs/2505.10496)|[CheXGenBench](https://github.com/Raman1121/CheXGenBench)|\n", "2506.00073": "|[the automated but risky game: modeling agent-to-agent negotiations and transactions in consumer markets](https://arxiv.org/abs/2506.00073)|[A2A-NT](https://github.com/ShenzheZhu/A2A-NT)|\n", "2506.07903": "|[diffuse everything: multimodal diffusion models on arbitrary state spaces](https://arxiv.org/abs/2506.07903)|[diffuse-everything](https://github.com/kevinrojas1499/diffuse-everything)|\n", "2506.10009": "|[the iris file extension](https://arxiv.org/abs/2506.10009)|[iris-codec](https://github.com/irisdigitalpathology/iris-codec)|\n", "2506.10669": "|[pipvit: patch-based visual interpretable prototypes for retinal image analysis](https://arxiv.org/abs/2506.10669)|[pipvit](https://github.com/marziehoghbaie/pipvit)|\n", "2506.10730": "|[iqe-clip: instance-aware query embedding for zero-/few-shot anomaly detection in medical domain](https://arxiv.org/abs/2506.10730)|[iqe-clip](https://github.com/hongh0/iqe-clip)|\n", "2506.11131": "|[segment this thing: foveated tokenization for efficient point-prompted segmentation](https://arxiv.org/abs/2506.11131)|[segment_this_thing](https://github.com/facebookresearch/segment_this_thing)|\n", "2506.11133": "|[monocular 3d hand pose estimation with implicit camera alignment](https://arxiv.org/abs/2506.11133)|[handrepo](https://github.com/cpantazop/handrepo)|\n", "2506.11136": "|[jafar: jack up any feature at any resolution](https://arxiv.org/abs/2506.11136)|[jafar](https://github.com/paulcouairon/jafar)|\n", "2506.11139": "|[grids often outperform implicit neural representations](https://arxiv.org/abs/2506.11139)|[inr-benchmark](https://github.com/voilalab/inr-benchmark)|\n", "2506.11142": "|[farcluss: fuzzy adaptive rebalancing and contrastive uncertainty learning for semi-supervised semantic segmentation](https://arxiv.org/abs/2506.11142)|[FARCLUSS](https://github.com/psychofict/FARCLUSS)|\n", "2506.11252": "|[anti-aliased 2d gaussian splatting](https://arxiv.org/abs/2506.11252)|[aa-2dgs](https://github.com/maeyounes/aa-2dgs)|\n", "2506.11477": "|[fame: a lightweight spatio-temporal network for model attribution of face-swap deepfakes](https://arxiv.org/abs/2506.11477)|[FAME](https://github.com/wasim004/FAME)|\n", "2506.11543": "|[fima-q: post-training quantization for vision transformers by fisher information matrix approximation](https://arxiv.org/abs/2506.11543)|[fima-q](https://github.com/shihewang/fima-q)|\n", "2506.11661": "|[prohibited items segmentation via occlusion-aware bilayer modeling](https://arxiv.org/abs/2506.11661)|[occ](https://github.com/ryh1218/occ)|\n", "2506.11777": "|[self-supervised learning of echocardiographic video representations via online cluster distillation](https://arxiv.org/abs/2506.11777)|[discovr](https://github.com/mdivyanshu97/discovr)|\n", "2506.11823": "|[structural similarity-inspired unfolding for lightweight image super-resolution](https://arxiv.org/abs/2506.11823)|[ssiu](https://github.com/eezkni/ssiu)|\n", "2506.11827": "|[auditory-tactile congruence for synthesis of adaptive pain expressions in robopatients](https://arxiv.org/abs/2506.11827)|[submission_codes](https://github.com/nsaitarun-git/submission_codes)|\n", "2506.11989": "|[simple radiology vllm test-time scaling with thought graph traversal](https://arxiv.org/abs/2506.11989)|[Thought-Graph-Traversal](https://github.com/glerium/Thought-Graph-Traversal)|\n", "2506.12007": "|[simshift: a benchmark for adapting neural surrogates to distribution shifts](https://arxiv.org/abs/2506.12007)|[simshift](https://github.com/psetinek/simshift)|\n"}, "2025-06-17": {"2206.01397": "|[dynamic structured illumination microscopy with a neural space-time model](https://arxiv.org/abs/2206.01397)|[SpeckleFlowSIM](https://github.com/Waller-Lab/SpeckleFlowSIM)|\n", "2211.03295": "|[moganet: multi-order gated aggregation network](https://arxiv.org/abs/2211.03295)|[openmixup](https://github.com/Westlake-AI/openmixup)|\n", "2305.08295": "|[climage: human-annotated datasets for complementary-label learning](https://arxiv.org/abs/2305.08295)|[climage_dataset](https://github.com/ntucllab/climage_dataset)|\n", "2307.03948": "|[reading between the lanes: text videoqa on the road](https://arxiv.org/abs/2307.03948)|[RoadTextVQA](https://github.com/georg3tom/RoadTextVQA)|\n", "2310.05026": "|[low-resolution self-attention for semantic segmentation](https://arxiv.org/abs/2310.05026)|[lrformer](https://github.com/yuhuan-wu/lrformer)|\n", "2312.17432": "|[video understanding with large language models: a survey](https://arxiv.org/abs/2312.17432)|[awesome-llms-for-video-understanding](https://github.com/yunlong10/awesome-llms-for-video-understanding)|\n", "2403.07786": "|[physics-informed generative real-time lens-free imaging](https://arxiv.org/abs/2403.07786)|[lensgan](https://github.com/rl-arch/lensgan)|\n", "2403.09471": "|[mambatalk: efficient holistic gesture synthesis with selective state space models](https://arxiv.org/abs/2403.09471)|[MambaTalk](https://github.com/kkakkkka/MambaTalk)|\n", "2403.09605": "|[counterfactual contrastive learning: robust representations via causal image synthesis](https://arxiv.org/abs/2403.09605)|[counterfactual-contrastive](https://github.com/biomedia-mira/counterfactual-contrastive)|\n", "2404.01298": "|[noise2image: noise-enabled static scene recovery for event cameras](https://arxiv.org/abs/2404.01298)|[noise2image](https://github.com/rmcao/noise2image)|\n", "2405.19996": "|[dp-iqa: utilizing diffusion prior for blind image quality assessment in the wild](https://arxiv.org/abs/2405.19996)|[DP-IQA](https://github.com/RomGai/DP-IQA)|\n", "2405.20072": "|[faces of the mind: unveiling mental health states through facial expressions in 11,427 adolescents](https://arxiv.org/abs/2405.20072)|[FACES](https://github.com/xuxiaoooo/FACES)|\n", "2408.02966": "|[fast point cloud geometry compression with context-based residual coding and inr-based refinement](https://arxiv.org/abs/2408.02966)|[CRCIR_for_PCGC](https://github.com/hxu160/CRCIR_for_PCGC)|\n", "2408.04223": "|[videoqa in the era of llms: an empirical study](https://arxiv.org/abs/2408.04223)|[videoqa-llms](https://github.com/doc-doc/videoqa-llms)|\n", "2408.08234": "|[comparative evaluation of 3d reconstruction methods for object pose estimation](https://arxiv.org/abs/2408.08234)|[reconstruction_pose_benchmark](https://github.com/varunburde/reconstruction_pose_benchmark)|\n", "2408.11336": "|[fate: focal-modulated attention encoder for multivariate time-series forecasting](https://arxiv.org/abs/2408.11336)|[fate](https://github.com/tajamul21/fate)|\n", "2409.02335": "|[what do you see in common? learning hierarchical prototypes over tree-of-life to discover evolutionary traits](https://arxiv.org/abs/2409.02335)|[hcompnet](https://github.com/imageomics/hcompnet)|\n", "2409.10365": "|[robust image representations with counterfactual contrastive learning](https://arxiv.org/abs/2409.10365)|[counterfactual-contrastive](https://github.com/biomedia-mira/counterfactual-contrastive)|\n", "2410.03289": "|[semantic segmentation based quality control of histopathology whole slide images](https://arxiv.org/abs/2410.03289)|[wsisegqc](https://github.com/abhijeetptl5/wsisegqc)|\n", "2410.11842": "|[moh: multi-head attention as mixture-of-head attention](https://arxiv.org/abs/2410.11842)|[moh](https://github.com/skyworkai/moh)|\n", "2410.21955": "|[activesplat: high-fidelity scene reconstruction through active gaussian splatting](https://arxiv.org/abs/2410.21955)|[ActiveSplat](https://github.com/Li-Yuetao/ActiveSplat)|\n", "2412.02099": "|[accdiffusion v2: towards more accurate higher-resolution diffusion extrapolation](https://arxiv.org/abs/2412.02099)|[accdiffusion_v2](https://github.com/lzhxmu/accdiffusion_v2)|\n", "2412.05479": "|[latte: learning to think with vision specialists](https://arxiv.org/abs/2412.05479)|[taco](https://github.com/salesforceairesearch/taco)|\n", "2412.16619": "|[topology-aware 3d gaussian splatting: leveraging persistent homology for optimized structural integrity](https://arxiv.org/abs/2412.16619)|[topology-gs](https://github.com/amadeusstq/topology-gs)|\n", "2412.20522": "|[maskgaussian: adaptive 3d gaussian representation from probabilistic masks](https://arxiv.org/abs/2412.20522)|[maskgaussian](https://github.com/kaikai23/maskgaussian)|\n", "2501.00942": "|[efficient unsupervised shortcut learning detection and mitigation in transformers](https://arxiv.org/abs/2501.00942)|[Shortcut-Detection-Mitigation-Transformers](https://github.com/Arsu-Lab/Shortcut-Detection-Mitigation-Transformers)|\n", "2501.01120": "|[retrieval-augmented dynamic prompt tuning for incomplete multimodal learning](https://arxiv.org/abs/2501.01120)|[ragpt](https://github.com/jian-lang/ragpt)|\n", "2501.01426": "|[unifying specialized visual encoders for video language models](https://arxiv.org/abs/2501.01426)|[merv](https://github.com/princetonvisualai/merv)|\n", "2501.07017": "|[unetvl: enhancing 3d medical image segmentation with chebyshev kan powered vision-lstm](https://arxiv.org/abs/2501.07017)|[unetvl](https://github.com/tgrex6/unetvl)|\n", "2501.09935": "|[physics-informed deepct: sinogram wavelet decomposition meets masked diffusion](https://arxiv.org/abs/2501.09935)|[swarm](https://github.com/yqx7150/swarm)|\n", "2501.18500": "|[hsrmamba: contextual spatial-spectral state space model for single image hyperspectral super-resolution](https://arxiv.org/abs/2501.18500)|[hsrmamba](https://github.com/tomchenshi/hsrmamba)|\n", "2502.05066": "|[beautiful images, toxic words: understanding and addressing offensive text in generated images](https://arxiv.org/abs/2502.05066)|[toxicbench](https://github.com/sprintml/toxicbench)|\n", "2502.07225": "|[cat: contrastive adversarial training for evaluating the robustness of protective perturbations in latent diffusion models](https://arxiv.org/abs/2502.07225)|[cat](https://github.com/senp98/cat)|\n", "2502.07351": "|[multi-knowledge-oriented nighttime haze imaging enhancer for vision-driven intelligent systems](https://arxiv.org/abs/2502.07351)|[mtoie](https://github.com/ai-chen-lab/mtoie)|\n", "2503.00513": "|[inst3d-lmm: instance-aware 3d scene understanding with multi-modal instruction tuning](https://arxiv.org/abs/2503.00513)|[inst3d-lmm](https://github.com/hanxunyu/inst3d-lmm)|\n", "2503.01208": "|[watch out your album! on the inadvertent privacy memorization in multi-modal large language models](https://arxiv.org/abs/2503.01208)|[probingprivacy](https://github.com/illusionhi/probingprivacy)|\n", "2503.02357": "|[q-eval-100k: evaluating visual quality and alignment level for text-to-vision content](https://arxiv.org/abs/2503.02357)|[q-eval](https://github.com/zzc-1998/q-eval)|\n", "2503.12303": "|[will pre-training ever end? a first step toward next-generation foundation mllms via self-improving systematic cognition](https://arxiv.org/abs/2503.12303)|[SICOG](https://github.com/thunlp/SICOG)|\n", "2503.16465": "|[os-kairos: adaptive interaction for mllm-powered gui agents](https://arxiv.org/abs/2503.16465)|[os-kairos](https://github.com/wuzheng02/os-kairos)|\n", "2504.00478": "|[fssuwnet: mitigating the fragility of pre-trained models with feature enhancement for few-shot semantic segmentation in underwater images](https://arxiv.org/abs/2504.00478)|[FSSUWNet](https://github.com/lizhh268/FSSUWNet)|\n", "2504.07392": "|[id-booth: identity-consistent face generation with diffusion models](https://arxiv.org/abs/2504.07392)|[id-booth](https://github.com/dariant/id-booth)|\n", "2506.00868": "|[multiverse through deepfakes: the multifakeverse dataset of person-centric visual and conceptual manipulations](https://arxiv.org/abs/2506.00868)|[multifakeverse](https://github.com/parul-gupta/multifakeverse)|\n", "2506.03662": "|[zero-shot temporal interaction localization for egocentric videos](https://arxiv.org/abs/2506.03662)|[egoloc](https://github.com/irmvlab/egoloc)|\n", "2506.05633": "|[noninvasive precision modulation of high-level neural population activity via natural vision perturbations](https://arxiv.org/abs/2506.05633)|[directionalneuralmodulation](https://github.com/ggaziv/directionalneuralmodulation)|\n", "2506.06962": "|[ar-rag: autoregressive retrieval augmentation for image generation](https://arxiv.org/abs/2506.06962)|[AR-RAG](https://github.com/PLUM-Lab/AR-RAG)|\n", "2506.07327": "|[case: contrastive activation for saliency estimation](https://arxiv.org/abs/2506.07327)|[case-saliency](https://github.com/dwil2444/case-saliency)|\n", "2506.08185": "|[agentic surgical ai: surgeon style fingerprinting and privacy risk quantification via discrete diffusion in a vision-language-action framework](https://arxiv.org/abs/2506.08185)|[surgeon_style_fingerprinting](https://github.com/huixin-zhan-ai/surgeon_style_fingerprinting)|\n", "2506.09482": "|[marrying autoregressive transformer and diffusion with multi-reference autoregression](https://arxiv.org/abs/2506.09482)|[transdiff](https://github.com/transdiff/transdiff)|\n", "2506.10425": "|[it's not the target, it's the background: rethinking infrared small target detection via deep patch-free low-rank representations](https://arxiv.org/abs/2506.10425)|[lrrnet](https://github.com/halongbao/lrrnet)|\n", "2506.10821": "|[videodeepresearch: long video understanding with agentic tool using](https://arxiv.org/abs/2506.10821)|[videodeepresearch](https://github.com/yhy-2000/videodeepresearch)|\n", "2506.12214": "|[clip the landscape: automated tagging of crowdsourced landscape images](https://arxiv.org/abs/2506.12214)|[ClipTheLandscape](https://github.com/SpaceTimeLab/ClipTheLandscape)|\n", "2506.12258": "|[egoprivacy: what your first-person camera says about you?](https://arxiv.org/abs/2506.12258)|[ego-privacy](https://github.com/williamium3000/ego-privacy)|\n", "2506.12269": "|[icme 2025 grand challenge on video super-resolution for video conferencing](https://arxiv.org/abs/2506.12269)|[vsr-challenge](https://github.com/microsoft/vsr-challenge)|\n", "2506.12295": "|[matchplant: an open-source pipeline for uav-based single-plant detection and data extraction](https://arxiv.org/abs/2506.12295)|[MatchPlant](https://github.com/JacobWashburn-USDA/MatchPlant)|\n", "2506.12339": "|[sheetmind: an end-to-end llm-powered multi-agent framework for spreadsheet automation](https://arxiv.org/abs/2506.12339)|[excel-agent](https://github.com/colonel-aureliano/excel-agent)|\n", "2506.12348": "|[real-time per-garment virtual try-on with temporal consistency for loose-fitting garments](https://arxiv.org/abs/2506.12348)|[RTV](https://github.com/ZaiqiangWu/RTV)|\n", "2506.12356": "|[splashnet: split-and-share encoders for accurate and efficient typing with surface electromyography](https://arxiv.org/abs/2506.12356)|[splashnet](https://github.com/nhadidi/splashnet)|\n", "2506.12413": "|[domain generalization for person re-identification: a survey towards domain-agnostic person matching](https://arxiv.org/abs/2506.12413)|[awesome-domain-generalizable-person-re-id](https://github.com/perceptualai-lab/awesome-domain-generalizable-person-re-id)|\n", "2506.12430": "|[pushing the limits of safety: a technical report on the atlas challenge 2025](https://arxiv.org/abs/2506.12430)|[atlas_challenge_2025](https://github.com/ny1024/atlas_challenge_2025)|\n", "2506.12524": "|[inference-time gaze refinement for micro-expression recognition: enhancing event-based eye tracking with motion-aware post-processing](https://arxiv.org/abs/2506.12524)|[eyelorin](https://github.com/eye-tracking-for-physiological-sensing/eyelorin)|\n", "2506.12541": "|[bsa: ball sparse attention for large-scale geometries](https://arxiv.org/abs/2506.12541)|[bsa](https://github.com/britacatalin/bsa)|\n", "2506.12610": "|[oscnet v1.5: energy efficient hopfield network on cmos oscillators for image classification](https://arxiv.org/abs/2506.12610)|[oscnet](https://github.com/russrobin/oscnet)|\n", "2506.12683": "|[evaluating cell type inference in vision language models under varying visual context](https://arxiv.org/abs/2506.12683)|[vlmcce](https://github.com/a12dongithub/vlmcce)|\n", "2506.12693": "|[zero-shot denoising via neural compression: theoretical and algorithmic framework](https://arxiv.org/abs/2506.12693)|[zs-ncdenoiser](https://github.com/computational-imaging-ru/zs-ncdenoiser)|\n", "2506.12935": "|[soundmind: rl-incentivized logic reasoning for audio-language models](https://arxiv.org/abs/2506.12935)|[soundmind](https://github.com/xid32/soundmind)|\n", "2506.12992": "|[smarthome-bench: a comprehensive benchmark for video anomaly detection in smart homes using multi-modal large language models](https://arxiv.org/abs/2506.12992)|[smarthome-bench-llm](https://github.com/xinyi-0724/smarthome-bench-llm)|\n", "2506.13001": "|[personalizable long-context symbolic music infilling with midi-rwkv](https://arxiv.org/abs/2506.13001)|[midi-rwkv](https://github.com/christianazinn/midi-rwkv)|\n", "2506.13027": "|[detrpose: real-time end-to-end transformer model for multi-person pose estimation](https://arxiv.org/abs/2506.13027)|[DETRPose](https://github.com/SebastianJanampa/DETRPose)|\n", "2506.13051": "|[stress-testing multimodal foundation models for crystallographic reasoning](https://arxiv.org/abs/2506.13051)|[stresstestingmmfmincr](https://github.com/kurbanintelligencelab/stresstestingmmfmincr)|\n", "2506.13089": "|[superpoint-slam3: augmenting orb-slam3 with deep features, adaptive nms, and learning-based loop closure](https://arxiv.org/abs/2506.13089)|[superpointslam3](https://github.com/shahram95/superpointslam3)|\n", "2506.13160": "|[certdw: towards certified dataset ownership verification via conformal prediction](https://arxiv.org/abs/2506.13160)|[certdw](https://github.com/ncepuqiaoting/certdw)|\n", "2506.13260": "|[come: adding scene-centric forecasting control to occupancy world model](https://arxiv.org/abs/2506.13260)|[come](https://github.com/synsin0/come)|\n", "2506.13275": "|[the transition matrix -- a classification of navigational patterns between lms course sections](https://arxiv.org/abs/2506.13275)|[Transition-Matrix](https://github.com/TobiasHildebrandt/Transition-Matrix)|\n", "2506.13326": "|[vis-shepherd: constructing critic for llm-based data visualization generation](https://arxiv.org/abs/2506.13326)|[vis-shepherd](https://github.com/bopan3/vis-shepherd)|\n", "2506.13348": "|[texturesplat: per-primitive texture mapping for reflective gaussian splatting](https://arxiv.org/abs/2506.13348)|[texturesplat](https://github.com/maeyounes/texturesplat)|\n", "2506.13387": "|[tr2m: transferring monocular relative depth to metric depth with language descriptions and scale-oriented contrast](https://arxiv.org/abs/2506.13387)|[tr2m](https://github.com/beileicui/tr2m)|\n", "2506.13415": "|[simple is what you need for efficient and accurate medical image segmentation](https://arxiv.org/abs/2506.13415)|[simpleunet](https://github.com/frankyu5666666/simpleunet)|\n", "2506.13465": "|[sa-lut: spatial adaptive 4d look-up table for photorealistic style transfer](https://arxiv.org/abs/2506.13465)|[sa-lut](https://github.com/ry3ng/sa-lut)|\n", "2506.13516": "|[micro-macro gaussian splatting with enhanced scalability for unconstrained scene reconstruction](https://arxiv.org/abs/2506.13516)|[smw-gs](https://github.com/kidleyh/smw-gs)|\n", "2506.13642": "|[stream-omni: simultaneous multimodal interactions with large language-vision-speech model](https://arxiv.org/abs/2506.13642)|[stream-omni](https://github.com/ictnlp/stream-omni)|\n", "2506.13685": "|[an llm's apology: outsourcing awkwardness in the age of ai](https://arxiv.org/abs/2506.13685)|[flake-bench](https://github.com/cloakless/flake-bench)|\n", "2506.13750": "|[test3r: learning to reconstruct 3d at test time](https://arxiv.org/abs/2506.13750)|[test3r](https://github.com/nopqaq/test3r)|\n", "2506.13757": "|[autovla: a vision-language-action model for end-to-end autonomous driving with adaptive reasoning and reinforcement fine-tuning](https://arxiv.org/abs/2506.13757)|[AutoVLA](https://github.com/ucla-mobility/AutoVLA)|\n"}, "2025-06-19": {"2302.10719": "|[memory-augmented online video anomaly detection](https://arxiv.org/abs/2302.10719)|[movad](https://github.com/implabunipr/movad)|\n", "2309.10815": "|[panopticnerf-360: panoramic 3d-to-2d label transfer in urban scenes](https://arxiv.org/abs/2309.10815)|[panopticnerf](https://github.com/fuxiao0719/panopticnerf)|\n", "2404.18924": "|[swin2-mose: a new single image super-resolution model for remote sensing](https://arxiv.org/abs/2404.18924)|[swin2-mose](https://github.com/IMPLabUniPr/swin2-mose)|\n", "2405.14022": "|[i2i-mamba: multi-modal medical image synthesis via selective state space modeling](https://arxiv.org/abs/2405.14022)|[I2I-Mamba](https://github.com/icon-lab/I2I-Mamba)|\n", "2407.13214": "|[a curated and re-annotated peripheral blood cell dataset integrating four public resources](https://arxiv.org/abs/2407.13214)|[TXL-PBC_Dataset](https://github.com/lugan113/TXL-PBC_Dataset)|\n", "2408.09194": "|[drl-based resource allocation for motion blur resistant federated self-supervised learning in iov](https://arxiv.org/abs/2408.09194)|[drl-bfssl](https://github.com/qiongwu86/drl-bfssl)|\n", "2410.06940": "|[representation alignment for generation: training diffusion transformers is easier than you think](https://arxiv.org/abs/2410.06940)|[REPA](https://github.com/sihyun-yu/REPA)|\n", "2412.00473": "|[jailbreak large vision-language models through multi-modal linkage](https://arxiv.org/abs/2412.00473)|[mml](https://github.com/wangyu-ovo/mml)|\n", "2412.09441": "|[mos: model surgery for pre-trained model-based class-incremental learning](https://arxiv.org/abs/2412.09441)|[lamda-pilot](https://github.com/sun-hailong/lamda-pilot)|\n", "2501.01557": "|[click-calib: a robust extrinsic calibration method for surround-view systems](https://arxiv.org/abs/2501.01557)|[click_calib](https://github.com/LihaoWang1991/click_calib)|\n", "2502.17244": "|[a dataset of high-resolution plantar pressures for gait analysis across varying footwear and walking speeds](https://arxiv.org/abs/2502.17244)|[StepUP-P150](https://github.com/UNB-StepUP/StepUP-P150)|\n", "2503.08221": "|[egoblind: towards egocentric visual assistance for the blind](https://arxiv.org/abs/2503.08221)|[egoblind](https://github.com/doc-doc/egoblind)|\n", "2503.15576": "|[a bird song detector for improving bird identification through deep learning: a case study from do\u00f1ana](https://arxiv.org/abs/2503.15576)|[BIRDeep_BirdSongDetector_NeuralNetworks](https://github.com/GrunCrow/BIRDeep_BirdSongDetector_NeuralNetworks)|\n", "2503.18742": "|[sfdla: source-free document layout analysis](https://arxiv.org/abs/2503.18742)|[sfdla-dladapter](https://github.com/s3setewe/sfdla-dladapter)|\n", "2503.23131": "|[refchartqa: grounding visual answer on chart images through instruction tuning](https://arxiv.org/abs/2503.23131)|[refchartqa](https://github.com/moured/refchartqa)|\n", "2504.04893": "|[scam: a real-world typographic robustness evaluation for multimodal foundation models](https://arxiv.org/abs/2504.04893)|[scam](https://github.com/bliss-e-v/scam)|\n", "2504.08049": "|[patch distribution modeling framework adaptive cosine estimator (padim-ace) for anomaly detection and localization in synthetic aperture radar imagery](https://arxiv.org/abs/2504.08049)|[padim-ace](https://github.com/advanced-vision-and-learning-lab/padim-ace)|\n", "2505.01481": "|[videohallu: evaluating and mitigating multi-modal hallucinations on synthetic video understanding](https://arxiv.org/abs/2505.01481)|[videohallu](https://github.com/zli12321/videohallu)|\n", "2505.07449": "|[ophora: a large-scale data-driven text-guided ophthalmic surgical video generation model](https://arxiv.org/abs/2505.07449)|[ophora](https://github.com/mar-cry/ophora)|\n", "2505.14719": "|[msvit: improving spiking vision transformer using multi-scale attention fusion](https://arxiv.org/abs/2505.14719)|[msvit](https://github.com/nanhu-ai-lab/msvit)|\n", "2505.16839": "|[lavida: a large diffusion language model for multimodal understanding](https://arxiv.org/abs/2505.16839)|[lavida](https://github.com/jacklishufan/lavida)|\n", "2505.18787": "|[think twice before adaptation: improving adaptability of deepfake detection via online test-time adaptation](https://arxiv.org/abs/2505.18787)|[t2a-think-twice-before-adaptation](https://github.com/honghanh2104/t2a-think-twice-before-adaptation)|\n", "2505.19805": "|[translation-equivariance of normalization layers and aliasing in convolutional neural networks](https://arxiv.org/abs/2505.19805)|[normalization-layers](https://github.com/jscanvic/normalization-layers)|\n", "2506.08010": "|[vision transformers don't need trained registers](https://arxiv.org/abs/2506.08010)|[test-time-registers](https://github.com/nickjiang2378/test-time-registers)|\n", "2506.09042": "|[cosmos-drive-dreams: scalable synthetic driving data generation with world foundation models](https://arxiv.org/abs/2506.09042)|[cosmos-drive-dreams](https://github.com/nv-tlabs/cosmos-drive-dreams)|\n", "2506.09881": "|[leveraging depth and language for open-vocabulary domain-generalized semantic segmentation](https://arxiv.org/abs/2506.09881)|[vireo](https://github.com/anonymouse-9c53tp182bvz/vireo)|\n", "2506.13776": "|[recommendations and reporting checklist for rigorous & transparent human baselines in model evaluations](https://arxiv.org/abs/2506.13776)|[human-baselines](https://github.com/kevinlwei/human-baselines)|\n", "2506.14696": "|[yolov11-rgbt: towards a comprehensive single-stage multispectral object detection framework](https://arxiv.org/abs/2506.14696)|[yolov11-rgbt](https://github.com/wandahangfy/yolov11-rgbt)|\n", "2506.14823": "|[villa: a neuro-symbolic approach for animal monitoring](https://arxiv.org/abs/2506.14823)|[ViLLa](https://github.com/HarshaKoduri123/ViLLa)|\n", "2506.14842": "|[pictsure: pretraining embeddings matters for in-context learning image classifiers](https://arxiv.org/abs/2506.14842)|[pictsure-library](https://github.com/pictsure/pictsure-library)|\n", "2506.14907": "|[perl: permutation-enhanced reinforcement learning for interleaved vision-language reasoning](https://arxiv.org/abs/2506.14907)|[perl](https://github.com/alchemistyzz/perl)|\n", "2506.14934": "|[vision transformers for end-to-end quark-gluon jet classification from calorimeter images](https://arxiv.org/abs/2506.14934)|[particle_reconstruction](https://github.com/abrar2652/particle_reconstruction)|\n", "2506.15078": "|[enhancing vector quantization with distributional matching: a theoretical and empirical study](https://arxiv.org/abs/2506.15078)|[wasserstein-vq](https://github.com/vq-research/wasserstein-vq)|\n", "2506.15084": "|[an empirical study of bugs in data visualization libraries](https://arxiv.org/abs/2506.15084)|[dataviz-lib-bugs](https://github.com/williamlus/dataviz-lib-bugs)|\n", "2506.15154": "|[sonicverse: multi-task learning for music feature-informed captioning](https://arxiv.org/abs/2506.15154)|[sonicverse](https://github.com/amaai-lab/sonicverse)|\n", "2506.15160": "|[enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation](https://arxiv.org/abs/2506.15160)|[pointdistribution](https://github.com/agent9717/pointdistribution)|\n", "2506.15182": "|[classification of multi-parametric body mri series using deep learning](https://arxiv.org/abs/2506.15182)|[mri_classifier](https://github.com/boahk/mri_classifier)|\n", "2506.15200": "|[conquering the retina: bringing visual in-context learning to oct](https://arxiv.org/abs/2506.15200)|[thesis-visual-in-context-learning](https://github.com/negralessio/thesis-visual-in-context-learning)|\n", "2506.15218": "|[dm-fnet: unified multimodal medical image fusion via diffusion process-trained encoder-decoder](https://arxiv.org/abs/2506.15218)|[dm-fnet](https://github.com/hedan-11/dm-fnet)|\n", "2506.15228": "|[abc: adaptive bayesnet structure learning for computational scalable multi-task image compression](https://arxiv.org/abs/2506.15228)|[cbench_basic](https://github.com/worldlife123/cbench_basic)|\n", "2506.15312": "|[one-shot face sketch synthesis in the wild via generative diffusion prior and instruction tuning](https://arxiv.org/abs/2506.15312)|[os-sketch](https://github.com/hanwu3125/os-sketch)|\n", "2506.15313": "|[mapfm: foundation model-driven hd mapping with multi-task contextual learning](https://arxiv.org/abs/2506.15313)|[mapfm](https://github.com/livanoff/mapfm)|\n", "2506.15365": "|[fedwsidd: federated whole slide image classification via dataset distillation](https://arxiv.org/abs/2506.15365)|[fedwsidd](https://github.com/f1onae/fedwsidd)|\n", "2506.15368": "|[open-world object counting in videos](https://arxiv.org/abs/2506.15368)|[countvid](https://github.com/niki-amini-naieni/countvid)|\n", "2506.15442": "|[hunyuan3d 2.1: from images to high-fidelity 3d assets with production-ready pbr material](https://arxiv.org/abs/2506.15442)|[hunyuan3d-2.1](https://github.com/tencent-hunyuan/hunyuan3d-2.1)|\n", "2506.15499": "|[pixel-level certified explanations via randomized smoothing](https://arxiv.org/abs/2506.15499)|[certified-attributions](https://github.com/alaaanani/certified-attributions)|\n", "2506.15571": "|[microricci: a greedy and local ricci flow solver for self-tuning mesh smoothing](https://arxiv.org/abs/2506.15571)|[microricci](https://github.com/csplevuanh/microricci)|\n", "2506.15682": "|[evolutionary caching to accelerate your off-the-shelf diffusion model](https://arxiv.org/abs/2506.15682)|[ecad](https://github.com/aniaggarwal/ecad)|\n"}, "2025-06-18": {"2208.09677": "|[net2brain: a toolbox to compare artificial vision models with human brain responses](https://arxiv.org/abs/2208.09677)|[net2brain](https://github.com/toastydom/net2brain)|\n", "2307.10867": "|[figcaps-hf: a figure-to-caption generative framework and benchmark with human feedback](https://arxiv.org/abs/2307.10867)|[figcapshf](https://github.com/figcapshf/figcapshf)|\n", "2307.15220": "|[learning multi-modal representations by watching hundreds of surgical video lectures](https://arxiv.org/abs/2307.15220)|[peskavlp](https://github.com/camma-public/peskavlp)|\n", "2309.10472": "|[fully automated landmarking and facial segmentation on 3d photographs](https://arxiv.org/abs/2309.10472)|[3dlandmarkdetection](https://github.com/rumc3dlab/3dlandmarkdetection)|\n", "2402.05804": "|[inksight: offline-to-online handwriting conversion by teaching vision-language models to read and write](https://arxiv.org/abs/2402.05804)|[inksight](https://github.com/google-research/inksight)|\n", "2403.07601": "|[unified source-free domain adaptation](https://arxiv.org/abs/2403.07601)|[source-free-domain-adaptation](https://github.com/tntek/source-free-domain-adaptation)|\n", "2405.07392": "|[ngd-slam: towards real-time dynamic slam without gpu](https://arxiv.org/abs/2405.07392)|[NGD-SLAM](https://github.com/yuhaozhang7/NGD-SLAM)|\n", "2406.02255": "|[midicaps: a large-scale midi dataset with text captions](https://arxiv.org/abs/2406.02255)|[MidiCaps](https://github.com/AMAAI-Lab/MidiCaps)|\n", "2406.07871": "|[controllable dance generation with style-guided motion diffusion](https://arxiv.org/abs/2406.07871)|[dgsdp](https://github.com/mucunzhuzhu/dgsdp)|\n", "2406.10219": "|[pup 3d-gs: principled uncertainty pruning for 3d gaussian splatting](https://arxiv.org/abs/2406.10219)|[gaussian-splatting-pup](https://github.com/j-alex-hanson/gaussian-splatting-pup)|\n", "2409.11316": "|[msdnet: multi-scale decoder for few-shot semantic segmentation via transformer-guided prototyping](https://arxiv.org/abs/2409.11316)|[msdnet](https://github.com/amirrezafateh/msdnet)|\n", "2409.20060": "|[lightweight neural architecture search for cerebral palsy detection](https://arxiv.org/abs/2409.20060)|[AutoCP](https://github.com/DeepInMotion/AutoCP)|\n", "2410.05243": "|[navigating the digital world as humans do: universal visual grounding for gui agents](https://arxiv.org/abs/2410.05243)|[UGround](https://github.com/OSU-NLP-Group/UGround)|\n", "2411.13340": "|[whales: a multi-agent scheduling dataset for enhanced cooperation in autonomous driving](https://arxiv.org/abs/2411.13340)|[whales](https://github.com/chensiweithu/whales)|\n", "2412.04431": "|[infinity: scaling bitwise autoregressive modeling for high-resolution image synthesis](https://arxiv.org/abs/2412.04431)|[Infinity](https://github.com/FoundationVision/Infinity)|\n", "2412.15670": "|[bs-ldm: effective bone suppression in high-resolution chest x-ray images with conditional latent diffusion models](https://arxiv.org/abs/2412.15670)|[BS-LDM](https://github.com/diaoquesang/BS-LDM)|\n", "2501.10604": "|[when language and vision meet road safety: leveraging multimodal large language models for video-based traffic accident analysis](https://arxiv.org/abs/2501.10604)|[seeunsafe](https://github.com/ai4ce/seeunsafe)|\n", "2501.10970": "|[the alternative annotator test for llm-as-a-judge: how to statistically justify replacing human annotators with llms](https://arxiv.org/abs/2501.10970)|[alttest](https://github.com/nitaytech/alttest)|\n", "2502.00404": "|[exploring linear attention alternative for single image super-resolution](https://arxiv.org/abs/2502.00404)|[omnirwkvsr](https://github.com/question110/omnirwkvsr)|\n", "2502.09779": "|[automated muscle and fat segmentation in computed tomography for comprehensive body composition analysis](https://arxiv.org/abs/2502.09779)|[CT-Muscle-and-Fat-Segmentation](https://github.com/mazurowski-lab/CT-Muscle-and-Fat-Segmentation)|\n", "2502.13174": "|[diverse topology optimization using modulated neural fields](https://arxiv.org/abs/2502.13174)|[Generative-Topology-Optimization](https://github.com/ml-jku/Generative-Topology-Optimization)|\n", "2502.19834": "|[knowledge bridger: towards training-free missing modality completion](https://arxiv.org/abs/2502.19834)|[knowledge-bridger](https://github.com/guanzhou-ke/knowledge-bridger)|\n", "2503.12553": "|[niagara: normal-integrated geometric affine field for scene reconstruction from a single view](https://arxiv.org/abs/2503.12553)|[Niagara](https://github.com/xianzuwu/Niagara)|\n", "2505.05540": "|[benchmarking vision, language, & action models in procedurally generated, open ended action environments](https://arxiv.org/abs/2505.05540)|[MultiNet](https://github.com/ManifoldRG/MultiNet)|\n", "2505.05657": "|[arraydps: unsupervised blind speech separation with a diffusion prior](https://arxiv.org/abs/2505.05657)|[arraydps](https://github.com/arraydps/arraydps)|\n", "2505.11099": "|[hymamba: mamba with hybrid geometry-feature coupling for efficient point cloud classification](https://arxiv.org/abs/2505.11099)|[hybrid-emba3d](https://github.com/l1277471578/hybrid-emba3d)|\n", "2505.11404": "|[patho-r1: a multimodal reinforcement learning-based pathology expert reasoner](https://arxiv.org/abs/2505.11404)|[patho-r1](https://github.com/wenchuan-zhang/patho-r1)|\n", "2505.20612": "|[roboflow100-vl: a multi-domain object detection benchmark for vision-language models](https://arxiv.org/abs/2505.20612)|[rf100-vl](https://github.com/roboflow/rf100-vl)|\n", "2505.23145": "|[flowalign: trajectory-regularized, inversion-free flow-based image editing](https://arxiv.org/abs/2505.23145)|[flowalign](https://github.com/flowalign/flowalign)|\n", "2505.24164": "|[mixed-r1: unified reward perspective for reasoning capability in multimodal large language models](https://arxiv.org/abs/2505.24164)|[mixed-r1](https://github.com/xushilin1/mixed-r1)|\n", "2506.01391": "|[agentcpm-gui: building mobile-use agents with reinforcement fine-tuning](https://arxiv.org/abs/2506.01391)|[AgentCPM-GUI](https://github.com/OpenBMB/AgentCPM-GUI)|\n", "2506.01413": "|[incentivizing reasoning for advanced instruction-following of large language models](https://arxiv.org/abs/2506.01413)|[raif](https://github.com/yuleiqin/raif)|\n", "2506.07917": "|[speedy deformable 3d gaussian splatting: fast rendering and compression of dynamic scenes](https://arxiv.org/abs/2506.07917)|[speede3dgs](https://github.com/tuallen/speede3dgs)|\n", "2506.08915": "|[inherently faithful attention maps for vision transformers](https://arxiv.org/abs/2506.08915)|[ifam](https://github.com/ananthu-aniraj/ifam)|\n", "2506.09081": "|[flagevalmm: a flexible framework for comprehensive multimodal model evaluation](https://arxiv.org/abs/2506.09081)|[flagevalmm](https://github.com/flageval-baai/flagevalmm)|\n", "2506.11154": "|[slrnet: a real-time lstm-based sign language recognition system](https://arxiv.org/abs/2506.11154)|[SLRNet](https://github.com/Khushi-739/SLRNet)|\n", "2506.13277": "|[seqpe: transformer with sequential position encoding](https://arxiv.org/abs/2506.13277)|[seqpe](https://github.com/ghrua/seqpe)|\n", "2506.13444": "|[self-supervised enhancement for depth from a lightweight tof sensor with monocular images](https://arxiv.org/abs/2506.13444)|[selftof](https://github.com/denyingmxd/selftof)|\n", "2506.13657": "|[lecture video visual objects (lvvo) dataset: a benchmark for visual object detection in educational videos](https://arxiv.org/abs/2506.13657)|[lvvo_dataset](https://github.com/dipayan1109033/lvvo_dataset)|\n", "2506.13807": "|[brats orchestrator : democratizing and disseminating state-of-the-art brain tumor image analysis](https://arxiv.org/abs/2506.13807)|[brats](https://github.com/brainlesion/brats)|\n", "2506.14035": "|[simpledoc: multi-modal document understanding with dual-cue page retrieval and iterative refinement](https://arxiv.org/abs/2506.14035)|[simpledoc](https://github.com/ag2ai/simpledoc)|\n", "2506.14107": "|[d\u00e9j\u00e0 vu: efficient video-language query engine with learning-based inter-frame computation reuse](https://arxiv.org/abs/2506.14107)|[dejavu](https://github.com/casys-kaist/dejavu)|\n", "2506.14130": "|[kdmos:knowledge distillation for motion segmentation](https://arxiv.org/abs/2506.14130)|[kdmos](https://github.com/scnu-rislab/kdmos)|\n", "2506.14136": "|[interpreting biomedical vlms on high-imbalance out-of-distributions: an insight into biomedclip on radiology](https://arxiv.org/abs/2506.14136)|[biovlm_eval_cxr](https://github.com/nafiz95/biovlm_eval_cxr)|\n", "2506.14356": "|[eva02-at: egocentric video-language understanding with spatial-temporal rotary positional embeddings and symmetric optimization](https://arxiv.org/abs/2506.14356)|[eva02-at](https://github.com/xqwang14/eva02-at)|\n", "2506.14362": "|[hydrochronos: forecasting decades of surface water change](https://arxiv.org/abs/2506.14362)|[hydro-chronos](https://github.com/darthreca/hydro-chronos)|\n", "2506.14404": "|[causally steered diffusion for automated video counterfactual generation](https://arxiv.org/abs/2506.14404)|[counterfactual-video-generation](https://github.com/nysp78/counterfactual-video-generation)|\n", "2506.14451": "|[adapting lightweight vision language models for radiological visual question answering](https://arxiv.org/abs/2506.14451)|[medm](https://github.com/adishourya/medm)|\n", "2506.14473": "|[foundation model insights and a multi-model approach for superior fine-grained one-shot subset selection](https://arxiv.org/abs/2506.14473)|[ram-apl](https://github.com/zhijingwan/ram-apl)|\n", "2506.14511": "|[mol: joint estimation of micro-expression, optical flow, and landmark via transformer-graph-style convolution](https://arxiv.org/abs/2506.14511)|[mol](https://github.com/cyf-cuber/mol)|\n", "2506.14582": "|[busting the paper ballot: voting meets adversarial machine learning](https://arxiv.org/abs/2506.14582)|[busting-the-ballot](https://github.com/votercenter/busting-the-ballot)|\n", "2506.14596": "|[posegraf: geometric-reinforced adaptive fusion for monocular 3d human pose estimation](https://arxiv.org/abs/2506.14596)|[posegraf](https://github.com/icitylab/posegraf)|\n", "2506.14605": "|[unsupervised imaging inverse problems with diffusion distribution matching](https://arxiv.org/abs/2506.14605)|[ddm4ip](https://github.com/inria-thoth/ddm4ip)|\n", "2506.14629": "|[vistext-mosquito: a multimodal dataset and benchmark for ai-based mosquito breeding site detection and reasoning](https://arxiv.org/abs/2506.14629)|[vistext-mosquito](https://github.com/adnanul-islam-jisun/vistext-mosquito)|\n", "2506.14642": "|[3dgs-ieval-15k: a large-scale image quality evaluation database for 3d gaussian-splatting](https://arxiv.org/abs/2506.14642)|[3dgs-ieval-15k](https://github.com/yukexing/3dgs-ieval-15k)|\n", "2506.14765": "|[scaling-up the pretraining of the earth observation foundation model phileo to the majortom dataset](https://arxiv.org/abs/2506.14765)|[PhilEO-MajorTOM](https://github.com/ESA-PhiLab/PhilEO-MajorTOM)|\n"}, "2025-06-20": {"2504.21774": "|[is intermediate fusion all you need for uav-based collaborative perception?](https://arxiv.org/abs/2504.21774)|[lif](https://github.com/uestchjw/lif)|\n", "2505.04623": "|[echoink-r1: exploring audio-visual reasoning in multimodal llms via reinforcement learning](https://arxiv.org/abs/2505.04623)|[echoink](https://github.com/harryhsing/echoink)|\n"}, "2025-06-21": {}, "2025-06-22": {}, "2025-06-23": {"2211.05781": "|[demystify transformers & convolutions in modern image deep networks](https://arxiv.org/abs/2211.05781)|[stm-evaluation](https://github.com/opengvlab/stm-evaluation)|\n", "2401.16991": "|[category-wise fine-tuning: resisting incorrect pseudo-labels in multi-label image classification with partial labels](https://arxiv.org/abs/2401.16991)|[category-wise-fine-tuning](https://github.com/maxium0526/category-wise-fine-tuning)|\n", "2403.01306": "|[icc: quantifying image caption concreteness for multimodal dataset curation](https://arxiv.org/abs/2403.01306)|[icc_code](https://github.com/moranyanuka/icc_code)|\n", "2403.02566": "|[enhancing weakly supervised 3d medical image segmentation through probabilistic-aware learning](https://arxiv.org/abs/2403.02566)|[pw4medseg](https://github.com/runminjiang/pw4medseg)|\n", "2404.13953": "|[360vots: visual object tracking and segmentation in omnidirectional videos](https://arxiv.org/abs/2404.13953)|[360vot](https://github.com/huajianup/360vot)|\n", "2404.15564": "|[guided absolutegrad: magnitude of gradients matters to explanation's localization and saliency](https://arxiv.org/abs/2404.15564)|[guided-absolutegrad](https://github.com/youyinnn/guided-absolutegrad)|\n", "2405.11536": "|[robmot: robust 3d multi-object tracking by observational noise and state estimation drift mitigation on lidar pointcloud](https://arxiv.org/abs/2405.11536)|[RobMOT](https://github.com/MohamedNagyMostafa/RobMOT)|\n", "2406.06967": "|[dual thinking and logical processing -- are multi-modal large language models closing the gap with human vision ?](https://arxiv.org/abs/2406.06967)|[dual_thinking](https://github.com/kailasdayanandan/dual_thinking)|\n", "2406.07851": "|[a labeled array distance metric for measuring image segmentation quality](https://arxiv.org/abs/2406.07851)|[see-segment](https://github.com/see-insight/see-segment)|\n", "2407.17734": "|[cost-effective instruction learning for pathology vision and language analysis](https://arxiv.org/abs/2407.17734)|[clover](https://github.com/jlinekai/clover)|\n", "2409.13609": "|[mapper: multimodal prior-guided parameter efficient tuning for referring expression comprehension](https://arxiv.org/abs/2409.13609)|[mapper](https://github.com/liuting20/mapper)|\n", "2410.14769": "|[medical artificial intelligence for early detection of lung cancer: a survey](https://arxiv.org/abs/2410.14769)|[awesome-lung-cancer-detection](https://github.com/caiguohui123/awesome-lung-cancer-detection)|\n", "2410.23623": "|[on learning multi-modal forgery representation for diffusion generated video detection](https://arxiv.org/abs/2410.23623)|[mm-det](https://github.com/sparklexfantasy/mm-det)|\n", "2411.07940": "|[automatic dataset shift identification to support safe deployment of medical imaging ai](https://arxiv.org/abs/2411.07940)|[shift_identification](https://github.com/biomedia-mira/shift_identification)|\n", "2411.15397": "|[efficient online inference of vision transformers by training-free tokenization](https://arxiv.org/abs/2411.15397)|[visual-word-tokenizer](https://github.com/wearepal/visual-word-tokenizer)|\n", "2412.14195": "|[a multimodal dataset for understanding the impact of mobile phones on remote online virtual education](https://arxiv.org/abs/2412.14195)|[improve](https://github.com/bidalab/improve)|\n", "2412.16402": "|[the landscape of college-level data visualization courses, and the benefits of incorporating statistical thinking](https://arxiv.org/abs/2412.16402)|[teaching-data-viz](https://github.com/ryurko/teaching-data-viz)|\n", "2501.00912": "|[autopresent: designing structured visuals from scratch](https://arxiv.org/abs/2501.00912)|[AutoPresent](https://github.com/para-lost/AutoPresent)|\n", "2501.08924": "|[learning joint denoising, demosaicing, and compression from the raw natural image noise dataset](https://arxiv.org/abs/2501.08924)|[rawnind_jddc](https://gitlab.com/trougnouf/rawnind_jddc)|\n", "2501.11260": "|[a survey of world models for autonomous driving](https://arxiv.org/abs/2501.11260)|[wmad-benchmarks](https://github.com/fengzicai/wmad-benchmarks)|\n", "2502.01816": "|[low-resource video super-resolution using memory, wavelets, and deformable convolutions](https://arxiv.org/abs/2502.01816)|[RCDM](https://github.com/kavi1388/RCDM)|\n", "2502.04599": "|[fuzzy linkography: automatic graphical summarization of creative activity traces](https://arxiv.org/abs/2502.04599)|[fuzzy-linkography](https://github.com/mkremins/fuzzy-linkography)|\n", "2502.05142": "|[chest x-ray foundation model with global and local representations integration](https://arxiv.org/abs/2502.05142)|[chexfound](https://github.com/rpidial/chexfound)|\n", "2502.05731": "|[visual text mining with progressive taxonomy construction for environmental studies](https://arxiv.org/abs/2502.05731)|[GreenMine](https://github.com/SamLee-dedeboy/GreenMine)|\n", "2502.09507": "|[when and how does clip enable domain and compositional generalization?](https://arxiv.org/abs/2502.09507)|[understanding-clip-ood](https://github.com/lmb-freiburg/understanding-clip-ood)|\n", "2502.21049": "|[synthesizing individualized aging brains in health and disease with generative models and parallel transport](https://arxiv.org/abs/2502.21049)|[inbrainsyn](https://github.com/fjr9516/inbrainsyn)|\n", "2503.19740": "|[surg-3m: a dataset and foundation model for perception in surgical settings](https://arxiv.org/abs/2503.19740)|[surg-3m](https://github.com/visurg-ai/surg-3m)|\n", "2504.12696": "|[collaborative perception datasets for autonomous driving: a review](https://arxiv.org/abs/2504.12696)|[collaborative-perception-datasets-for-autonomous-driving](https://github.com/frankwnb/collaborative-perception-datasets-for-autonomous-driving)|\n", "2504.13180": "|[perceptionlm: open-access data and models for detailed visual understanding](https://arxiv.org/abs/2504.13180)|[perception_models](https://github.com/facebookresearch/perception_models)|\n", "2505.20981": "|[refav: towards planning-centric scenario mining](https://arxiv.org/abs/2505.20981)|[refav](https://github.com/cainand/refav)|\n", "2506.01444": "|[variance-based defense against blended backdoor attacks](https://arxiv.org/abs/2506.01444)|[BackdoorBench](https://github.com/Orange-OpenSource/BackdoorBench)|\n", "2506.06561": "|[lamp-cap: personalized figure caption generation with multimodal figure profiles](https://arxiv.org/abs/2506.06561)|[lamp-cap](https://github.com/crowd-ai-lab/lamp-cap)|\n", "2506.09965": "|[reinforcing spatial reasoning in vision-language models with interwoven thinking and visual drawing](https://arxiv.org/abs/2506.09965)|[vilasr](https://github.com/antresearchnlp/vilasr)|\n", "2506.10730": "|[iqe-clip: instance-aware query embedding for zero-/few-shot anomaly detection in medical domain](https://arxiv.org/abs/2506.10730)|[iqe-clip](https://github.com/hongh0/iqe-clip)|\n", "2506.11140": "|[autonomous computer vision development with agentic ai](https://arxiv.org/abs/2506.11140)|[OpenManus-SimpleMind](https://github.com/jink-ucla/OpenManus-SimpleMind)|\n", "2506.11302": "|[tardis stride: a spatio-temporal road image dataset and world model for autonomy](https://arxiv.org/abs/2506.11302)|[tardis](https://github.com/tera-ai/tardis)|\n", "2506.12400": "|[perceptual-gs: scene-adaptive perceptual densification for gaussian splatting](https://arxiv.org/abs/2506.12400)|[perceptual-gs](https://github.com/eezkni/perceptual-gs)|\n", "2506.13045": "|[a comprehensive survey on continual learning in generative models](https://arxiv.org/abs/2506.13045)|[awesome-continual-learning-in-generative-models](https://github.com/ghy0501/awesome-continual-learning-in-generative-models)|\n", "2506.14243": "|[cross-modal geometric hierarchy fusion: an implicit-submap driven framework for resilient 3d place recognition](https://arxiv.org/abs/2506.14243)|[CMGHF](https://github.com/HBLT-hub/CMGHF)|\n", "2506.14777": "|[webxaii: an open-source web framework to study human-xai interaction](https://arxiv.org/abs/2506.14777)|[webxaii](https://github.com/pajean/webxaii)|\n", "2506.15258": "|[privacy-preserving chest x-ray classification in latent space with homomorphically encrypted neural inference](https://arxiv.org/abs/2506.15258)|[latent-he](https://github.com/jongdory/latent-he)|\n", "2506.15564": "|[show-o2: improved native unified multimodal models](https://arxiv.org/abs/2506.15564)|[show-o](https://github.com/showlab/show-o)|\n", "2506.15591": "|[one-step diffusion for detail-rich and temporally consistent video super-resolution](https://arxiv.org/abs/2506.15591)|[dloral](https://github.com/yjsunnn/dloral)|\n", "2506.15711": "|[shadow defense against gradient inversion attack in federated learning](https://arxiv.org/abs/2506.15711)|[ShadowDef](https://github.com/tekap404/ShadowDef)|\n", "2506.15860": "|[user-guided force-directed graph layout](https://arxiv.org/abs/2506.15860)|[uggly](https://github.com/sciluna/uggly)|\n", "2506.15940": "|[polyline path masked attention for vision transformer](https://arxiv.org/abs/2506.15940)|[ppma](https://github.com/zhongchenzhao/ppma)|\n", "2506.15980": "|[advanced sign language video generation with compressed and quantized multi-condition tokenization](https://arxiv.org/abs/2506.15980)|[signvip](https://github.com/umnooob/signvip)|\n", "2506.15988": "|[adversarial attacks and detection in visual place recognition for safer robot navigation](https://arxiv.org/abs/2506.15988)|[aarapsiproject](https://github.com/QVPR/aarapsiproject)|\n", "2506.16017": "|[endomust: monocular depth estimation for robotic endoscopy via end-to-end multi-step self-supervised training](https://arxiv.org/abs/2506.16017)|[endomust](https://github.com/baymaxshao/endomust)|\n", "2506.16073": "|[td3net: a temporal densely connected multi-dilated convolutional network for lipreading](https://arxiv.org/abs/2506.16073)|[td3net-a-temporal-densely-connected-multi-dilated-convolutional-network-for-lipreading](https://github.com/leebh-kor/td3net-a-temporal-densely-connected-multi-dilated-convolutional-network-for-lipreading)|\n", "2506.16141": "|[grpo-care: consistency-aware reinforcement learning for multimodal reasoning](https://arxiv.org/abs/2506.16141)|[grpo-care](https://github.com/tencentarc/grpo-care)|\n", "2506.16209": "|[videogan-based trajectory proposal for automated vehicles](https://arxiv.org/abs/2506.16209)|[video-gan-trajectories](https://github.com/ajmariani/video-gan-trajectories)|\n", "2506.16265": "|[dense 3d displacement estimation for landslide monitoring via fusion of tls point clouds and embedded rgb images](https://arxiv.org/abs/2506.16265)|[fusion4landslide](https://github.com/zhaoyiww/fusion4landslide)|\n", "2506.16349": "|[watermarking autoregressive image generation](https://arxiv.org/abs/2506.16349)|[wmar](https://github.com/facebookresearch/wmar)|\n", "2506.16353": "|[mambahash: visual state space deep hashing model for large-scale image retrieval](https://arxiv.org/abs/2506.16353)|[mambahash](https://github.com/shuaichaochao/mambahash)|\n", "2506.16371": "|[agc-drive: a large-scale dataset for real-world aerial-ground collaboration in driving scenarios](https://arxiv.org/abs/2506.16371)|[agc-drive](https://github.com/percepx/agc-drive)|\n", "2506.16401": "|[trajscenellm: a multimodal perspective on semantic gps trajectory analysis](https://arxiv.org/abs/2506.16401)|[trajscenellm](https://github.com/februarysea/trajscenellm)|\n", "2506.16504": "|[hunyuan3d 2.5: towards high-fidelity 3d assets generation with ultimate details](https://arxiv.org/abs/2506.16504)|[hunyuan3d-2](https://github.com/tencent/hunyuan3d-2)|\n", "2506.16572": "|[diffo: single-step diffusion for image compression at ultra-low bitrates](https://arxiv.org/abs/2506.16572)|[diffo](https://github.com/freemasti/diffo)|\n", "2506.16643": "|[see what i mean? expressiveness and clarity in robot display design](https://arxiv.org/abs/2506.16643)|[huamn_cozmo_interaction](https://github.com/mattufts/huamn_cozmo_interaction)|\n", "2506.16728": "|[few-shot generalized category discovery with retrieval-guided decision boundary enhancement](https://arxiv.org/abs/2506.16728)|[fsgcd](https://github.com/ryh1218/fsgcd)|\n", "2506.16743": "|[noise-informed diffusion-generated image detection with anomaly attention](https://arxiv.org/abs/2506.16743)|[nasa-swin](https://github.com/weinanguan/nasa-swin)|\n", "2506.16819": "|[loupe: a generalizable and adaptive framework for image forgery detection](https://arxiv.org/abs/2506.16819)|[loupe](https://github.com/kamichanw/loupe)|\n", "2506.16842": "|[camera calibration via circular patterns: a comprehensive framework with measurement uncertainty and unbiased projection model](https://arxiv.org/abs/2506.16842)|[discocal](https://github.com/chaehyeonsong/discocal)|\n", "2506.16856": "|[parkformer: a transformer-based parking policy with goal embedding and pedestrian-aware control](https://arxiv.org/abs/2506.16856)|[parkformer](https://github.com/little-snail-f/parkformer)|\n", "2506.16940": "|[lunarloc: segment-based global localization on the moon](https://arxiv.org/abs/2506.16940)|[lunarloc-data](https://github.com/mit-acl/lunarloc-data)|\n", "2506.16960": "|[visual-instructed degradation diffusion for all-in-one image restoration](https://arxiv.org/abs/2506.16960)|[defusion](https://github.com/luowyang/defusion)|\n", "2506.16962": "|[enhancing step-by-step and verifiable medical reasoning in mllms](https://arxiv.org/abs/2506.16962)|[chiron-o1](https://github.com/manglu097/chiron-o1)|\n", "2506.17113": "|[mexa: towards general multimodal reasoning with dynamic multi-expert aggregation](https://arxiv.org/abs/2506.17113)|[mexa](https://github.com/yui010206/mexa)|\n", "2506.17119": "|[rgbtrack: fast, robust depth-free 6d pose estimation and tracking](https://arxiv.org/abs/2506.17119)|[rgbtrack](https://github.com/greatenanoymous/rgbtrack)|\n", "2506.17159": "|[co-seg++: mutual prompt-guided collaborative learning for versatile medical segmentation](https://arxiv.org/abs/2506.17159)|[co-seg-plus](https://github.com/xq141839/co-seg-plus)|\n", "2506.17186": "|[yasmot: yet another stereo image multi-object tracker](https://arxiv.org/abs/2506.17186)|[yasmot](https://github.com/ketil-malde/yasmot)|\n", "2506.17196": "|[detecting llm-generated short answers and effects on learner performance](https://arxiv.org/abs/2506.17196)|[ai-detection](https://github.com/shambhavib20/ai-detection)|\n", "2506.17202": "|[unifork: exploring modality alignment for unified multimodal understanding and generation](https://arxiv.org/abs/2506.17202)|[unifork](https://github.com/tliby/unifork)|\n", "2506.17213": "|[long-term traffic simulation with interleaved autoregressive motion and scenario generation](https://arxiv.org/abs/2506.17213)|[infgen](https://github.com/orangesodahub/infgen)|\n", "2506.17218": "|[machine mental imagery: empower multimodal reasoning with latent visual tokens](https://arxiv.org/abs/2506.17218)|[mirage](https://github.com/umass-embodied-agi/mirage)|\n"}, "2025-06-24": {"2303.11536": "|[indeterminate probability theory](https://arxiv.org/abs/2303.11536)|[ipnn](https://github.com/starfruit007/ipnn)|\n", "2307.09997": "|[tunes: a temporal u-net with self-attention for video-based surgical phase recognition](https://arxiv.org/abs/2307.09997)|[tunes](https://gitlab.com/nct_tso_public/tunes)|\n", "2308.06712": "|[multi-level compositional feature augmentation for unbiased scene graph generation](https://arxiv.org/abs/2308.06712)|[cfa](https://github.com/hkust-longgroup/cfa)|\n", "2311.10873": "|[multi-entity video transformers for fine-grained video representation learning](https://arxiv.org/abs/2311.10873)|[video_rep_learning](https://github.com/facebookresearch/video_rep_learning)|\n", "2401.04585": "|[eda-dm: enhanced distribution alignment for post-training quantization of diffusion models](https://arxiv.org/abs/2401.04585)|[EDA-DM](https://github.com/BienLuky/EDA-DM)|\n", "2402.19186": "|[disentangling representations of retinal images with generative models](https://arxiv.org/abs/2402.19186)|[disentangling-retinal-images](https://github.com/berenslab/disentangling-retinal-images)|\n", "2403.06567": "|[leveraging foundation models for content-based image retrieval in radiology](https://arxiv.org/abs/2403.06567)|[foundation-models-for-cbmir](https://github.com/mic-dkfz/foundation-models-for-cbmir)|\n", "2404.14249": "|[clip-gs: clip-informed gaussian splatting for view-consistent 3d indoor semantic understanding](https://arxiv.org/abs/2404.14249)|[clip-gs](https://github.com/gbliao/clip-gs)|\n", "2405.03177": "|[transformer-based rgb-t tracking with channel and spatial feature fusion](https://arxiv.org/abs/2405.03177)|[cstnet](https://github.com/liyunfenglyf/cstnet)|\n", "2405.07332": "|[potatogans: utilizing generative adversarial networks, instance segmentation, and explainable ai for enhanced potato disease identification and classification](https://arxiv.org/abs/2405.07332)|[ExplainableAI-PotatoGAN-Cutting-Edge-Disease-Identification-for-Potatoes](https://github.com/Mukaffi28/ExplainableAI-PotatoGAN-Cutting-Edge-Disease-Identification-for-Potatoes)|\n", "2405.14239": "|[harmony: a joint self-supervised and weakly-supervised framework for learning general purpose visual representations](https://arxiv.org/abs/2405.14239)|[harmony](https://github.com/mohammedsb/harmony)|\n", "2407.09174": "|[dart: an automated end-to-end object detection pipeline with data diversification, open-vocabulary bounding box annotation, pseudo-label review, and model training](https://arxiv.org/abs/2407.09174)|[dart](https://github.com/chen-xin-94/dart)|\n", "2408.09886": "|[improved baselines with synchronized encoding for universal medical image segmentation](https://arxiv.org/abs/2408.09886)|[sam-unet](https://github.com/hhankyangg/sam-unet)|\n", "2409.06821": "|[sam2rad: a segmentation model for medical images with learnable prompts](https://arxiv.org/abs/2409.06821)|[sam2radiology](https://github.com/aswahd/sam2radiology)|\n", "2410.06437": "|[locovr: multiuser indoor locomotion dataset in virtual reality](https://arxiv.org/abs/2410.06437)|[locovr](https://github.com/kt2024-hal/locovr)|\n", "2410.12557": "|[one step diffusion via shortcut models](https://arxiv.org/abs/2410.12557)|[shortcut-models](https://github.com/kvfrans/shortcut-models)|\n", "2410.13864": "|[unidrive: towards universal driving perception across camera configurations](https://arxiv.org/abs/2410.13864)|[unidrive](https://github.com/ywyeli/unidrive)|\n", "2410.22366": "|[one-step is enough: sparse autoencoders for text-to-image diffusion models](https://arxiv.org/abs/2410.22366)|[sdxl-unbox](https://github.com/surkovv/sdxl-unbox)|\n", "2411.02747": "|[efficient feature aggregation and scale-aware regression for monocular 3d object detection](https://arxiv.org/abs/2411.02747)|[MonoASRH](https://github.com/WYFDUT/MonoASRH)|\n", "2411.19479": "|[flare: toward universal dataset purification against backdoor attacks](https://arxiv.org/abs/2411.19479)|[backdoor-toolbox](https://github.com/vtu81/backdoor-toolbox)|\n", "2412.19637": "|[reneg: learning negative embedding with reward guidance](https://arxiv.org/abs/2412.19637)|[ReNeg](https://github.com/AMD-AIG-AIMA/ReNeg)|\n", "2501.04975": "|[v2c-cbm: building concept bottlenecks with vision-to-concept tokenizer](https://arxiv.org/abs/2501.04975)|[v2c-cbm](https://github.com/riverback/v2c-cbm)|\n", "2501.16879": "|[ultra-high resolution multimodal mri densely labelled holistic structural brain atlas](https://arxiv.org/abs/2501.16879)|[hypothalamus_seg](https://github.com/BBillot/hypothalamus_seg)|\n", "2501.17690": "|[segmentation-aware generative reinforcement network (grn) for tissue layer segmentation in 3-d ultrasound images for chronic low-back pain (clbp) assessment](https://arxiv.org/abs/2501.17690)|[GRN](https://github.com/Francisdadada/GRN)|\n", "2502.09620": "|[exploring the potential of encoder-free architectures in 3d lmms](https://arxiv.org/abs/2502.09620)|[enel](https://github.com/ivan-tang-3d/enel)|\n", "2503.01103": "|[direct discriminative optimization: your likelihood-based visual generative model is secretly a gan discriminator](https://arxiv.org/abs/2503.01103)|[ddo](https://github.com/nvlabs/ddo)|\n", "2503.01837": "|[multi-stage manipulation with demonstration-augmented reward, policy, and world model learning](https://arxiv.org/abs/2503.01837)|[demo3](https://github.com/adrialopezescoriza/demo3)|\n", "2503.18665": "|[boosting virtual agent learning and reasoning: a step-wise, multi-dimensional, and generalist reward model with benchmark](https://arxiv.org/abs/2503.18665)|[similar-v1](https://github.com/galery23/similar-v1)|\n", "2503.23980": "|[salt: a flexible semi-automatic labeling tool for general lidar point clouds with cross-scene adaptability and 4d consistency](https://arxiv.org/abs/2503.23980)|[SALT](https://github.com/Cavendish518/SALT)|\n", "2504.07491": "|[kimi-vl technical report](https://arxiv.org/abs/2504.07491)|[kimi-vl](https://github.com/moonshotai/kimi-vl)|\n", "2504.17761": "|[step1x-edit: a practical framework for general image editing](https://arxiv.org/abs/2504.17761)|[step1x-edit](https://github.com/stepfun-ai/step1x-edit)|\n", "2505.07001": "|[hallucination-aware multimodal benchmark for gastrointestinal image analysis with large vision-language models](https://arxiv.org/abs/2505.07001)|[hallucination-aware-vlm](https://github.com/bhattarailab/hallucination-aware-vlm)|\n", "2505.17590": "|[cgs-gan: 3d consistent gaussian splatting gans for high resolution human head synthesis](https://arxiv.org/abs/2505.17590)|[cgs-gan](https://github.com/fraunhoferhhi/cgs-gan)|\n", "2505.19319": "|[holistic white-light polyp classification via alignment-free dense distillation of auxiliary optical chromoendoscopy](https://arxiv.org/abs/2505.19319)|[add](https://github.com/huster-hq/add)|\n", "2505.20897": "|[cross from left to right brain: adaptive text dreamer for vision-and-language navigation](https://arxiv.org/abs/2505.20897)|[adaptive-text-dreamer](https://github.com/zhangpingrui/adaptive-text-dreamer)|\n", "2505.21777": "|[memorization to generalization: emergence of diffusion models from associative memory](https://arxiv.org/abs/2505.21777)|[Diffusion-Models-and-Associative-Memory](https://github.com/Lemon-cmd/Diffusion-Models-and-Associative-Memory)|\n", "2505.23481": "|[physicsnerf: physics-guided 3d reconstruction from sparse views](https://arxiv.org/abs/2505.23481)|[physicsnerf](https://github.com/anonymous-researcher-01/physicsnerf)|\n", "2506.11142": "|[farcluss: fuzzy adaptive rebalancing and contrastive uncertainty learning for semi-supervised semantic segmentation](https://arxiv.org/abs/2506.11142)|[FARCLUSS](https://github.com/psychofict/FARCLUSS)|\n", "2506.12524": "|[inference-time gaze refinement for micro-expression recognition: enhancing event-based eye tracking with motion-aware post-processing](https://arxiv.org/abs/2506.12524)|[eyelorin](https://github.com/eye-tracking-for-physiological-sensing/eyelorin)|\n", "2506.13642": "|[stream-omni: simultaneous multimodal interactions with large language-vision-speech model](https://arxiv.org/abs/2506.13642)|[stream-omni](https://github.com/ictnlp/stream-omni)|\n", "2506.15698": "|[global context-aware representation learning for spatially resolved transcriptomics](https://arxiv.org/abs/2506.15698)|[spotscape](https://github.com/yunhak0/spotscape)|\n", "2506.16262": "|[r3evision: a survey on robust rendering, restoration, and enhancement for 3d low-level vision](https://arxiv.org/abs/2506.16262)|[awesome-3d-low-level-vision](https://github.com/cmlab-korea/awesome-3d-low-level-vision)|\n", "2506.16318": "|[segment anything for satellite imagery: a strong baseline and a regional dataset for automatic field delineation](https://arxiv.org/abs/2506.16318)|[eras-dataset](https://github.com/cscribano/eras-dataset)|\n", "2506.16784": "|[textbrats: text-guided volumetric brain tumor segmentation with innovative dataset development and fusion module exploration](https://arxiv.org/abs/2506.16784)|[textbrats](https://github.com/jupitern52/textbrats)|\n", "2506.16796": "|[realsr-r1: reinforcement learning for real-world image super-resolution with vision-language chain-of-thought](https://arxiv.org/abs/2506.16796)|[realsr-r1](https://github.com/junboooo/realsr-r1)|\n", "2506.17101": "|[multi-label scene classification for autonomous vehicles: acquiring and accumulating knowledge from diverse datasets](https://arxiv.org/abs/2506.17101)|[kaa-cal](https://github.com/kelisbu/kaa-cal)|\n", "2506.17220": "|[emergent temporal correspondences from video diffusion transformers](https://arxiv.org/abs/2506.17220)|[DiffTrack](https://github.com/cvlab-kaist/DiffTrack)|\n"}, "2025-06-25": {"2308.16075": "|[impact of visual context on noisy multimodal nmt: an empirical study for english to indian languages](https://arxiv.org/abs/2308.16075)|[indicmmt](https://github.com/babangain/indicmmt)|\n", "2310.08785": "|[deltaspace: a semantic-aligned feature space for flexible text-guided image editing](https://arxiv.org/abs/2310.08785)|[deltaedit](https://github.com/yueming6568/deltaedit)|\n", "2403.07494": "|[semgauss-slam: dense semantic gaussian splatting slam](https://arxiv.org/abs/2403.07494)|[SemGauss-SLAM](https://github.com/IRMVLab/SemGauss-SLAM)|\n", "2403.12029": "|[align and distill: unifying and improving domain adaptive object detection](https://arxiv.org/abs/2403.12029)|[aldi](https://github.com/justinkay/aldi)|\n", "2405.00239": "|[igconda-pet: weakly-supervised pet anomaly detection using implicitly-guided attention-conditional counterfactual diffusion modeling -- a multi-center, multi-cancer, and multi-tracer study](https://arxiv.org/abs/2405.00239)|[igconda-pet](https://github.com/ahxmeds/igconda-pet)|\n", "2410.02643": "|[why sample space matters: keyframe sampling optimization for lidar-based place recognition](https://arxiv.org/abs/2410.02643)|[opt-key](https://github.com/ltu-rai/opt-key)|\n", "2410.23478": "|[collage: decomposable rapid prototyping for information extraction on scientific pdfs](https://arxiv.org/abs/2410.23478)|[ht-max](https://github.com/gsireesh/ht-max)|\n", "2501.01023": "|[hadamard attention recurrent transformer: a strong baseline for stereo matching transformer](https://arxiv.org/abs/2501.01023)|[hart](https://github.com/zyangchen/hart)|\n", "2501.06533": "|[divtrackee versus dyntracker: promoting diversity in anti-facial recognition against dynamic fr strategy](https://arxiv.org/abs/2501.06533)|[divtrackee](https://github.com/fiora6/divtrackee)|\n", "2502.02514": "|[privacy attacks on image autoregressive models](https://arxiv.org/abs/2502.02514)|[privacy_attacks_against_iars](https://github.com/sprintml/privacy_attacks_against_iars)|\n", "2502.10156": "|[fusionforce: end-to-end differentiable neural-symbolic layer for trajectory prediction](https://arxiv.org/abs/2502.10156)|[monoforce](https://github.com/ctu-vras/monoforce)|\n", "2502.18185": "|[vesselsam: leveraging sam for aortic vessel segmentation with atrouslora](https://arxiv.org/abs/2502.18185)|[atrouslora](https://github.com/adnan-cas/atrouslora)|\n", "2502.21320": "|[tomoselfdeq: self-supervised deep equilibrium learning for sparse-angle ct reconstruction](https://arxiv.org/abs/2502.21320)|[TomoSelfDEQ](https://github.com/sedaboni/TomoSelfDEQ)|\n", "2505.04229": "|[a weak supervision learning approach towards an equitable mobility estimation](https://arxiv.org/abs/2505.04229)|[equitable_mobility_estimation](https://github.com/societal-computing/equitable_mobility_estimation)|\n", "2505.09529": "|[contactless cardiac pulse monitoring using event cameras](https://arxiv.org/abs/2505.09529)|[contactless_cardiac_pulse_monitoring_using_event_cameras](https://github.com/c3imaging/contactless_cardiac_pulse_monitoring_using_event_cameras)|\n", "2505.12280": "|[temporal-spectral-spatial unified remote sensing dense prediction](https://arxiv.org/abs/2505.12280)|[official_tssun](https://github.com/walking-shadow/official_tssun)|\n", "2506.05199": "|[grounding beyond detection: enhancing contextual understanding in embodied 3d grounding](https://arxiv.org/abs/2506.05199)|[deground](https://github.com/zyn213/deground)|\n", "2506.09399": "|[improving out-of-distribution detection via dynamic covariance calibration](https://arxiv.org/abs/2506.09399)|[ooddcc](https://github.com/workerbcd/ooddcc)|\n", "2506.12006": "|[crossmoda challenge: evolution of cross-modality domain adaptation techniques for vestibular schwannoma and cochlea segmentation from 2021 to 2023](https://arxiv.org/abs/2506.12006)|[cmda2022.superpolymerization](https://github.com/fiy2w/cmda2022.superpolymerization)|\n", "2506.15201": "|[privacy-shielded image compression: defending against exploitation from vision-language pretrained models](https://arxiv.org/abs/2506.15201)|[psic](https://github.com/jiayinxu5499/psic)|\n", "2506.17885": "|[cloud-aware sar fusion for enhanced optical sensing in space missions](https://arxiv.org/abs/2506.17885)|[Cloud-Removal](https://github.com/thoailt/Cloud-Removal)|\n", "2506.18335": "|[rethinking decoder design: improving biomarker segmentation using depth-to-space restoration and residual linear attention](https://arxiv.org/abs/2506.18335)|[mcads-decoder](https://github.com/saadwazir/mcads-decoder)|\n", "2506.18810": "|[concisehint: boosting efficient reasoning via continuous concise hints during generation](https://arxiv.org/abs/2506.18810)|[ConciseHint](https://github.com/tsa18/ConciseHint)|\n"}, "2025-06-26": {"2109.00317": "|[bvmatch: lidar-based place recognition using bird's-eye view images](https://arxiv.org/abs/2109.00317)|[bvmatch](https://github.com/zjuluolun/bvmatch)|\n", "2302.14325": "|[bevplace: learning lidar-based place recognition using bird's eye view images](https://arxiv.org/abs/2302.14325)|[bevplace](https://github.com/zjuluolun/bevplace)|\n", "2401.13934": "|[mambamorph: a mamba-based framework for medical mr-ct deformable registration](https://arxiv.org/abs/2401.13934)|[mambamorph](https://github.com/guo-stone/mambamorph)|\n", "2403.08059": "|[fluorosam: a language-promptable foundation model for flexible x-ray image segmentation](https://arxiv.org/abs/2403.08059)|[fluorosam](https://github.com/arcadelab/fluorosam)|\n", "2408.05894": "|[glyphpattern: an abstract pattern recognition benchmark for vision-language models](https://arxiv.org/abs/2408.05894)|[GlyphPattern](https://github.com/Wellesley-EASEL-lab/GlyphPattern)|\n", "2410.18362": "|[waffle: finetuning multi-modal model for automated front-end development](https://arxiv.org/abs/2410.18362)|[Waffle](https://github.com/lt-asset/Waffle)|\n", "2411.10504": "|[usp-gaussian: unifying spike-based image reconstruction, pose correction and gaussian splatting](https://arxiv.org/abs/2411.10504)|[usp-gaussian](https://github.com/chenkang455/usp-gaussian)|\n", "2501.17726": "|[vicca: visual interpretation and comprehension of chest x-ray anomalies in generated report without human feedback](https://arxiv.org/abs/2501.17726)|[vicca](https://github.com/sayeh1994/vicca)|\n", "2503.05319": "|[robust multimodal learning for ophthalmic disease grading via disentangled representation](https://arxiv.org/abs/2503.05319)|[robust-multimodal-learning-for-ophthalmic-disease-grading-via-disentangled-representation](https://github.com/xinkunwang111/robust-multimodal-learning-for-ophthalmic-disease-grading-via-disentangled-representation)|\n", "2503.19777": "|[lposs: label propagation over patches and pixels for open-vocabulary semantic segmentation](https://arxiv.org/abs/2503.19777)|[lposs](https://github.com/vladan-stojnic/lposs)|\n", "2505.12434": "|[videorft: incentivizing video reasoning capability in mllms via reinforced fine-tuning](https://arxiv.org/abs/2505.12434)|[videorft](https://github.com/qiwang98/videorft)|\n", "2505.23018": "|[emotiontalk: an interactive chinese multimodal emotion dataset with rich annotations](https://arxiv.org/abs/2505.23018)|[emotiontalk](https://github.com/nku-hlt/emotiontalk)|\n", "2505.24862": "|[vistorybench: comprehensive benchmark suite for story visualization](https://arxiv.org/abs/2505.24862)|[vistorybench](https://github.com/vistorybench/vistorybench)|\n", "2506.20152": "|[loss-aware automatic selection of structured pruning criteria for deep neural network acceleration](https://arxiv.org/abs/2506.20152)|[laasp](https://github.com/ghimiredhikura/laasp)|\n", "2506.20355": "|[practical insights on the effect of different encodings, ans\u00e4tze and measurements in quantum and hybrid convolutional neural networks](https://arxiv.org/abs/2506.20355)|[QML-Satellite-Image-Classification](https://github.com/uriballo/QML-Satellite-Image-Classification)|\n"}, "2025-06-27": {"2211.05770": "|[efficient image generation with variadic attention heads](https://arxiv.org/abs/2211.05770)|[StyleNAT](https://github.com/SHI-Labs/StyleNAT)|\n", "2402.03666": "|[quest: low-bit diffusion model quantization via efficient selective finetuning](https://arxiv.org/abs/2402.03666)|[QuEST](https://github.com/hatchetProject/QuEST)|\n", "2403.14684": "|[self-regulated neurogenesis for online data-incremental learning](https://arxiv.org/abs/2403.14684)|[focil](https://github.com/muratonuryildirim/focil)|\n", "2406.09838": "|[climateiqa: a new dataset and benchmark to advance vision-language models in meteorology anomalies analysis](https://arxiv.org/abs/2406.09838)|[Climate-Zoo](https://github.com/AlexJJJChen/Climate-Zoo)|\n", "2408.17443": "|[hermes: temporal-coherent long-form understanding with episodes and semantics](https://arxiv.org/abs/2408.17443)|[HERMES](https://github.com/joslefaure/HERMES)|\n", "2409.13568": "|[tackling fluffy clouds: robust field boundary delineation across global agricultural landscapes with sentinel-1 and sentinel-2 time series](https://arxiv.org/abs/2409.13568)|[tfcl](https://github.com/feevos/tfcl)|\n", "2409.18017": "|[transferring disentangled representations: bridging the gap between synthetic and real images](https://arxiv.org/abs/2409.18017)|[transfer_disentanglement](https://github.com/JacopoDapueto/transfer_disentanglement)|\n", "2410.08082": "|[tomie: towards explicit exoskeleton for the reconstruction of complicated 3d human avatars](https://arxiv.org/abs/2410.08082)|[ToMiE](https://github.com/Yifever20002/ToMiE)|\n", "2411.02136": "|[advanced computer vision for extracting georeferenced vehicle trajectories from drone imagery](https://arxiv.org/abs/2411.02136)|[stabilo](https://github.com/rfonod/stabilo)|\n", "2411.08272": "|[lbonet: supervised spectral descriptors for shape analysis](https://arxiv.org/abs/2411.08272)|[LBONet](https://github.com/yioguz/LBONet)|\n", "2411.12558": "|[recall and refine: a simple but effective source-free open-set domain adaptation framework](https://arxiv.org/abs/2411.12558)|[RRDA](https://github.com/ismailnejjar/RRDA)|\n", "2411.14133": "|[gasp: efficient black-box generation of adversarial suffixes for jailbreaking llms](https://arxiv.org/abs/2411.14133)|[GASP](https://github.com/TrustMLRG/GASP)|\n", "2411.18309": "|[mvketr: chest ct report generation with multi-view perception and knowledge enhancement](https://arxiv.org/abs/2411.18309)|[MvKeTR](https://github.com/xiweideng/MvKeTR)|\n", "2501.03717": "|[materialist: physically based editing using single-image inverse rendering](https://arxiv.org/abs/2501.03717)|[materialist](https://github.com/lez-s/materialist)|\n", "2501.18637": "|[machine learning of microstructure--property relationships in materials leveraging microstructure representation from foundational vision transformers](https://arxiv.org/abs/2501.18637)|[micropropvit](https://github.com/materials-informatics-az/micropropvit)|\n", "2503.04065": "|[pp-docbee: improving multimodal document understanding through a bag of tricks](https://arxiv.org/abs/2503.04065)|[PaddleMIX](https://github.com/PaddlePaddle/PaddleMIX)|\n", "2503.11175": "|[zero-tig: temporal consistency-aware zero-shot illumination-guided low-light video enhancement](https://arxiv.org/abs/2503.11175)|[Zero-TIG](https://github.com/liyinibristol/Zero-TIG)|\n", "2503.13952": "|[simworld: a unified benchmark for simulator-conditioned scene generation via world model](https://arxiv.org/abs/2503.13952)|[simworld](https://github.com/li-zn-h/simworld)|\n", "2503.15676": "|[high temporal consistency through semantic similarity propagation in semi-supervised video semantic segmentation for autonomous flight](https://arxiv.org/abs/2503.15676)|[ssp](https://github.com/fraunhoferivi/ssp)|\n", "2503.18104": "|[challenging dataset and multi-modal gated mixture of experts model for remote sensing copy-move forgery understanding](https://arxiv.org/abs/2503.18104)|[cm-mmoe](https://github.com/shenyedepisa/cm-mmoe)|\n", "2504.15404": "|[context aware grounded teacher for source free object detection](https://arxiv.org/abs/2504.15404)|[Grounded_Teacher](https://github.com/Tajamul21/Grounded_Teacher)|\n", "2505.00482": "|[jointdit: enhancing rgb-depth joint modeling with diffusion transformers](https://arxiv.org/abs/2505.00482)|[JointDiT-code](https://github.com/ByungKi-K/JointDiT-code)|\n", "2505.07449": "|[ophora: a large-scale data-driven text-guided ophthalmic surgical video generation model](https://arxiv.org/abs/2505.07449)|[ophora](https://github.com/mar-cry/ophora)|\n", "2505.14414": "|[diving into the fusion of monocular priors for generalized stereo matching](https://arxiv.org/abs/2505.14414)|[Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching](https://github.com/YaoChengTang/Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching)|\n", "2506.01923": "|[taxadiffusion: progressively trained diffusion model for fine-grained species generation](https://arxiv.org/abs/2506.01923)|[TaxaDiffusion](https://github.com/aminK8/TaxaDiffusion)|\n", "2506.07977": "|[oneig-bench: omni-dimensional nuanced evaluation for image generation](https://arxiv.org/abs/2506.07977)|[oneig-benchmark](https://github.com/oneig-bench/oneig-benchmark)|\n", "2506.18575": "|[2d triangle splatting for direct differentiable mesh training](https://arxiv.org/abs/2506.18575)|[triangle-splatting](https://github.com/GaodeRender/triangle-splatting)|\n"}, "2025-06-28": {}, "2025-06-29": {}, "2025-06-30": {"2109.05721": "|[adnet: leveraging error-bias towards normal direction in face alignment](https://arxiv.org/abs/2109.05721)|[ADNet](https://github.com/huangyangyu/ADNet)|\n", "2301.12276": "|[protoseg: interpretable semantic segmentation with prototypical parts](https://arxiv.org/abs/2301.12276)|[proto-segmentation](https://github.com/gmum/proto-segmentation)|\n", "2307.09727": "|[samconvex: fast discrete optimization for ct registration using self-supervised anatomical embedding and correlation pyramid](https://arxiv.org/abs/2307.09727)|[samconvex](https://github.com/alibaba-damo-academy/samconvex)|\n", "2403.15011": "|[cell tracking according to biological needs -- strong mitosis-aware multi-hypothesis tracker with aleatoric uncertainty](https://arxiv.org/abs/2403.15011)|[biologicalneeds](https://github.com/timok93/biologicalneeds)|\n", "2403.20035": "|[ultralight vm-unet: parallel vision mamba significantly reduces parameters for skin lesion segmentation](https://arxiv.org/abs/2403.20035)|[UltraLight-VM-UNet](https://github.com/wurenkai/UltraLight-VM-UNet)|\n", "2405.04997": "|[bridging the gap between saliency prediction and image quality assessment](https://arxiv.org/abs/2405.04997)|[sacid](https://github.com/alexkkir/sacid)|\n", "2405.12105": "|[end-to-end full-page optical music recognition for pianoform sheet music](https://arxiv.org/abs/2405.12105)|[SMT-plusplus](https://github.com/antoniorv6/SMT-plusplus)|\n", "2407.06136": "|[mamba-fscil: dynamic adaptation with selective state space model for few-shot class-incremental learning](https://arxiv.org/abs/2407.06136)|[mamba-fscil](https://github.com/xiaojieli0903/mamba-fscil)|\n", "2407.19812": "|[image-text matching for large-scale book collections](https://arxiv.org/abs/2407.19812)|[library-dataset](https://github.com/llabres/library-dataset)|\n", "2409.17792": "|[reblurring-guided single image defocus deblurring: a learning framework with misaligned training pairs](https://arxiv.org/abs/2409.17792)|[reblurring-guided-jdrl](https://github.com/ssscrystal/reblurring-guided-jdrl)|\n", "2410.06020": "|[qt-dog: quantization-aware training for domain generalization](https://arxiv.org/abs/2410.06020)|[QT-DoG](https://github.com/saqibjaved1/QT-DoG)|\n", "2412.03177": "|[patchdpo: patch-level dpo for finetuning-free personalized image generation](https://arxiv.org/abs/2412.03177)|[patchdpo](https://github.com/hqhqaq/patchdpo)|\n", "2412.04783": "|[knn-mmd: cross domain wireless sensing via local distribution alignment](https://arxiv.org/abs/2412.04783)|[KNN-MMD](https://github.com/RS2002/KNN-MMD)|\n", "2503.15465": "|[fp4dit: towards effective floating point quantization for diffusion transformers](https://arxiv.org/abs/2503.15465)|[fp4dit](https://github.com/cccrrrccc/fp4dit)|\n", "2503.17966": "|[real-world remote sensing image dehazing: benchmark and baseline](https://arxiv.org/abs/2503.17966)|[rrshid](https://github.com/lwcver/rrshid)|\n", "2503.19367": "|[vgat: a cancer survival analysis framework transitioning from generative visual question answering to genomic reconstruction](https://arxiv.org/abs/2503.19367)|[vgat](https://github.com/czzzzzzzzzzzzzzzzz/vgat)|\n", "2505.02567": "|[unified multimodal understanding and generation models: advances, challenges, and opportunities](https://arxiv.org/abs/2505.02567)|[awesome-unified-multimodal-models](https://github.com/aidc-ai/awesome-unified-multimodal-models)|\n", "2505.13232": "|[starft: robust fine-tuning of zero-shot models via spuriosity alignment](https://arxiv.org/abs/2505.13232)|[starft](https://github.com/alinlab/starft)|\n", "2506.08010": "|[vision transformers don't need trained registers](https://arxiv.org/abs/2506.08010)|[test-time-registers](https://github.com/nickjiang2378/test-time-registers)|\n", "2506.14473": "|[foundation model insights and a multi-model approach for superior fine-grained one-shot subset selection](https://arxiv.org/abs/2506.14473)|[ram-apl](https://github.com/zhijingwan/ram-apl)|\n"}, "2025-07-01": {"2106.06887": "|[the spatio-temporal poisson point process: a simple model for the alignment of event camera data](https://arxiv.org/abs/2106.06887)|[Event-ST-PPP](https://github.com/pbideau/Event-ST-PPP)|\n", "2112.06193": "|[gunnel: guided mixup augmentation and multi-model fusion for aquatic animal segmentation](https://arxiv.org/abs/2112.06193)|[mask-mixup](https://github.com/lmquan2000/mask-mixup)|\n", "2303.10428": "|[rca: region conditioned adaptation for visual abductive reasoning](https://arxiv.org/abs/2303.10428)|[rpa](https://github.com/lunaproject22/rpa)|\n", "2312.01431": "|[d$^2$st-adapter: disentangled-and-deformable spatio-temporal adapter for few-shot action recognition](https://arxiv.org/abs/2312.01431)|[d2st-adapter](https://github.com/qizhongtan/d2st-adapter)|\n", "2402.02242": "|[parameter-efficient fine-tuning for pre-trained vision models: a survey and benchmark](https://arxiv.org/abs/2402.02242)|[awesome-parameter-efficient-transfer-learning](https://github.com/synbol/awesome-parameter-efficient-transfer-learning)|\n", "2403.04444": "|[disentangled diffusion-based 3d human pose estimation with hierarchical spatial and temporal denoiser](https://arxiv.org/abs/2403.04444)|[DDHPose](https://github.com/Andyen512/DDHPose)|\n", "2403.10798": "|[object retrieval for visual question answering with outside knowledge](https://arxiv.org/abs/2403.10798)|[ms-ugcml](https://github.com/dengyuhai/ms-ugcml)|\n", "2403.11052": "|[unveiling and mitigating memorization in text-to-image diffusion models through cross attention](https://arxiv.org/abs/2403.11052)|[memattn](https://github.com/renjie3/memattn)|\n", "2404.03446": "|[sp$^2$ot: semantic-regularized progressive partial optimal transport for imbalanced clustering](https://arxiv.org/abs/2404.03446)|[SPPOT](https://github.com/rhfeiyang/SPPOT)|\n", "2406.15303": "|[aem: attention entropy maximization for multiple instance learning based whole slide image classification](https://arxiv.org/abs/2406.15303)|[aem](https://github.com/dazhangyu123/aem)|\n", "2407.06109": "|[perldiff: controllable street view synthesis using perspective-layout diffusion models](https://arxiv.org/abs/2407.06109)|[perldiff](https://github.com/labshuhanggu/perldiff)|\n", "2408.15256": "|[improving ontology requirements engineering with ontochat and participatory prompting](https://arxiv.org/abs/2408.15256)|[ontochat](https://github.com/king-s-knowledge-graph-lab/ontochat)|\n", "2409.17777": "|[harnessing shared relations via multimodal mixup contrastive learning for multimodal classification](https://arxiv.org/abs/2409.17777)|[M3CoL](https://github.com/RaghavSinghal10/M3CoL)|\n", "2409.18860": "|[lw2g: learning whether to grow for prompt-based continual learning](https://arxiv.org/abs/2409.18860)|[lw2g](https://github.com/raian08/lw2g)|\n", "2410.01697": "|[enhancing adversarial robustness through multi-objective representation learning](https://arxiv.org/abs/2410.01697)|[MOREL](https://github.com/salomonhotegni/MOREL)|\n", "2410.09432": "|[fedex-lora: exact aggregation for federated and efficient fine-tuning of foundation models](https://arxiv.org/abs/2410.09432)|[fedex-lora](https://github.com/RaghavSinghal10/fedex-lora)|\n", "2411.15240": "|[foundation models for wearable movement data in mental health research](https://arxiv.org/abs/2411.15240)|[pretrained-actigraphy-transformer](https://github.com/njacobsonlab/pretrained-actigraphy-transformer)|\n", "2411.15397": "|[efficient online inference of vision transformers by training-free tokenization](https://arxiv.org/abs/2411.15397)|[visual-word-tokenizer](https://github.com/wearepal/visual-word-tokenizer)|\n", "2411.18066": "|[gls: geometry-aware 3d language gaussian splatting](https://arxiv.org/abs/2411.18066)|[gls](https://github.com/jiaxiongq/gls)|\n", "2412.04062": "|[zipar: parallel auto-regressive image generation through spatial locality](https://arxiv.org/abs/2412.04062)|[ZipAR](https://github.com/ThisisBillhe/ZipAR)|\n", "2412.05515": "|[video2reward: generating reward function from videos for legged robot behavior learning](https://arxiv.org/abs/2412.05515)|[Video2Reward](https://github.com/Alvin-Zeng/Video2Reward)|\n", "2412.10718": "|[grid: omni visual generation](https://arxiv.org/abs/2412.10718)|[grid](https://github.com/should-ai-lab/grid)|\n", "2412.19326": "|[task preference optimization: improving multimodal large language models with vision task alignment](https://arxiv.org/abs/2412.19326)|[tpo](https://github.com/opengvlab/tpo)|\n", "2412.19628": "|[recconv: efficient recursive convolutions for multi-frequency representations](https://arxiv.org/abs/2412.19628)|[recnext](https://github.com/suous/recnext)|\n", "2501.05460": "|[efficiently serving large multimodal models using epd disaggregation](https://arxiv.org/abs/2501.05460)|[epdserve](https://github.com/vbdi/epdserve)|\n", "2501.08983": "|[compositional generative model of unbounded 4d cities](https://arxiv.org/abs/2501.08983)|[CityDreamer4D](https://github.com/hzxie/CityDreamer4D)|\n", "2502.08769": "|[cluster and predict latent patches for improved masked image modeling](https://arxiv.org/abs/2502.08769)|[capi](https://github.com/facebookresearch/capi)|\n", "2502.12080": "|[humangif: single-view human diffusion with generative prior](https://arxiv.org/abs/2502.12080)|[humangif](https://github.com/skhu101/humangif)|\n", "2502.21085": "|[bst: badminton stroke-type transformer for skeleton-based action recognition in racket sports](https://arxiv.org/abs/2502.21085)|[BST-Badminton-Stroke-type-Transformer](https://github.com/Va6lue/BST-Badminton-Stroke-type-Transformer)|\n", "2503.00071": "|[i see what you mean: co-speech gestures for reference resolution in multimodal dialogue](https://arxiv.org/abs/2503.00071)|[MultimodalReferenceResolution](https://github.com/EsamGhaleb/MultimodalReferenceResolution)|\n", "2503.00410": "|[high dynamic range video compression: a large-scale benchmark dataset and a learned bit-depth scalable compression algorithm](https://arxiv.org/abs/2503.00410)|[hdr-learned-video-coding](https://github.com/sdkinda/hdr-learned-video-coding)|\n", "2503.06132": "|[usp: unified self-supervised pretraining for image generation and understanding](https://arxiv.org/abs/2503.06132)|[usp](https://github.com/cxxgtxy/usp)|\n", "2503.06520": "|[seg-zero: reasoning-chain guided segmentation via cognitive reinforcement](https://arxiv.org/abs/2503.06520)|[Seg-Zero](https://github.com/dvlab-research/Seg-Zero)|\n", "2503.06671": "|[emulating self-attention with convolution for efficient image super-resolution](https://arxiv.org/abs/2503.06671)|[ESC](https://github.com/dslisleedh/ESC)|\n", "2503.08101": "|[accelerate 3d object detection models via zero-shot attention key pruning](https://arxiv.org/abs/2503.08101)|[tg_gbc](https://github.com/iseri27/tg_gbc)|\n", "2503.11167": "|[neurons: emulating the human visual cortex improves fidelity and interpretability in fmri-to-video reconstruction](https://arxiv.org/abs/2503.11167)|[neurons](https://github.com/xmed-lab/neurons)|\n", "2503.13377": "|[time-r1: post-training large vision language model for temporal video grounding](https://arxiv.org/abs/2503.13377)|[timezero](https://github.com/www-ye/timezero)|\n", "2503.15127": "|[a comparative study of human motion models in reinforcement learning algorithms for social robot navigation](https://arxiv.org/abs/2503.15127)|[Social-Navigation-PyEnvs](https://github.com/TommasoVandermeer/Social-Navigation-PyEnvs)|\n", "2503.15426": "|[visual position prompt for mllm based visual grounding](https://arxiv.org/abs/2503.15426)|[vpp-llava](https://github.com/waynetomas/vpp-llava)|\n", "2503.17262": "|[unsupervised joint learning of optical flow and intensity with event cameras](https://arxiv.org/abs/2503.17262)|[e2fai](https://github.com/tub-rip/e2fai)|\n", "2504.11134": "|[visual re-ranking with non-visual side information](https://arxiv.org/abs/2504.11134)|[gcsa](https://github.com/ghanning/gcsa)|\n", "2504.19938": "|[mesh-learner: texturing mesh with spherical harmonics](https://arxiv.org/abs/2504.19938)|[mesh-learner](https://github.com/hku-mars/mesh-learner)|\n", "2505.18561": "|[thinkvideo: high-quality reasoning video segmentation with chain of thoughts](https://arxiv.org/abs/2505.18561)|[thinkvideo](https://github.com/danielshkao/thinkvideo)|\n", "2505.20471": "|[weatheredit: controllable weather editing with 4d gaussian field](https://arxiv.org/abs/2505.20471)|[WeatherEdit](https://github.com/Jumponthemoon/WeatherEdit)|\n", "2506.16398": "|[hyperpath: knowledge-guided hyperbolic semantic hierarchy modeling for wsi analysis](https://arxiv.org/abs/2506.16398)|[hyperpath](https://github.com/lambert-hpx/hyperpath)|\n"}, "2025-07-02": {"2308.02587": "|[synthesising rare cataract surgery samples with guided diffusion models](https://arxiv.org/abs/2308.02587)|[catasynth](https://github.com/meclabtuda/catasynth)|\n", "2403.00268": "|[improving acne image grading with label distribution smoothing](https://arxiv.org/abs/2403.00268)|[acne-lds](https://github.com/openface-io/acne-lds)|\n", "2404.09158": "|[streaknet-arch: an anti-scattering network-based architecture for underwater carrier lidar-radar imaging](https://arxiv.org/abs/2404.09158)|[streaknet](https://github.com/bestanhongjun/streaknet)|\n", "2405.05769": "|[exploring text-guided single image editing for remote sensing images](https://arxiv.org/abs/2405.05769)|[remote_sensing_image_editing](https://github.com/hit-philiphan/remote_sensing_image_editing)|\n", "2406.00772": "|[unsupervised contrastive analysis for anomaly detection in brain mris via conditional diffusion models](https://arxiv.org/abs/2406.00772)|[unsupervised-contrastive-cond-diff](https://github.com/cristianopatricio/unsupervised-contrastive-cond-diff)|\n", "2407.14153": "|[de-lightsam: modality-decoupled lightweight sam for generalizable medical segmentation](https://arxiv.org/abs/2407.14153)|[esp-medsam](https://github.com/xq141839/esp-medsam)|\n", "2410.05255": "|[bridging sft and dpo for diffusion model alignment with self-sampling preference optimization](https://arxiv.org/abs/2410.05255)|[seppo](https://github.com/dwanzhang-ai/seppo)|\n", "2410.11281": "|[dynaclr: contrastive learning of cellular dynamics with temporal regularization](https://arxiv.org/abs/2410.11281)|[viscy](https://github.com/mehta-lab/viscy)|\n", "2411.19278": "|[omni-dc: highly robust depth completion with multiresolution depth integration](https://arxiv.org/abs/2411.19278)|[omni-dc](https://github.com/princeton-vl/omni-dc)|\n", "2412.03704": "|[scaling inference-time search with vision value model for improved visual comprehension](https://arxiv.org/abs/2412.03704)|[visvm](https://github.com/si0wang/visvm)|\n", "2501.01855": "|[uav-detr: efficient end-to-end object detection for unmanned aerial vehicle imagery](https://arxiv.org/abs/2501.01855)|[uav-detr](https://github.com/valiantdiligent/uav-detr)|\n", "2501.10736": "|[semi-supervised semantic segmentation for remote sensing images via multi-scale uncertainty consistency and cross-teacher-student attention](https://arxiv.org/abs/2501.10736)|[rs-muca](https://github.com/wangshanwen001/rs-muca)|\n", "2501.13094": "|[robust representation consistency model via contrastive denoising](https://arxiv.org/abs/2501.13094)|[rrcm](https://github.com/jiachenlei/rrcm)|\n", "2502.03628": "|[the hidden life of tokens: reducing hallucination of large vision-language models via visual information steering](https://arxiv.org/abs/2502.03628)|[VISTA](https://github.com/LzVv123456/VISTA)|\n", "2502.07707": "|[prvql: progressive knowledge-guided refinement for robust egocentric visual query localization](https://arxiv.org/abs/2502.07707)|[prvql](https://github.com/fb-reps/prvql)|\n", "2502.09653": "|[sasvi -- segment any surgical video](https://arxiv.org/abs/2502.09653)|[SASVi](https://github.com/MECLabTUDA/SASVi)|\n", "2502.14351": "|[seganypet: universal promptable segmentation from positron emission tomography images](https://arxiv.org/abs/2502.14351)|[seganypet](https://github.com/yichizhang98/seganypet)|\n", "2503.02424": "|[exploring intrinsic normal prototypes within a single image for universal anomaly detection](https://arxiv.org/abs/2503.02424)|[inp-former](https://github.com/luow23/inp-former)|\n", "2505.00703": "|[t2i-r1: reinforcing image generation with collaborative semantic-level and token-level cot](https://arxiv.org/abs/2505.00703)|[t2i-r1](https://github.com/caraj7/t2i-r1)|\n", "2505.05469": "|[generating physically stable and buildable brick structures from text](https://arxiv.org/abs/2505.05469)|[LegoGPT](https://github.com/AvaLovelace1/LegoGPT)|\n", "2506.10967": "|[beyond attention or similarity: maximizing conditional diversity for token pruning in mllms](https://arxiv.org/abs/2506.10967)|[cdpruner](https://github.com/theia-4869/cdpruner)|\n", "2506.12269": "|[icme 2025 grand challenge on video super-resolution for video conferencing](https://arxiv.org/abs/2506.12269)|[vsr-challenge](https://github.com/microsoft/vsr-challenge)|\n"}, "2025-07-03": {"2403.06759": "|[average calibration error: a differentiable loss for improved reliability in image segmentation](https://arxiv.org/abs/2403.06759)|[ace-dliris](https://github.com/cai4cai/ace-dliris)|\n", "2406.00192": "|[direct cardiac segmentation from undersampled k-space using transformers](https://arxiv.org/abs/2406.00192)|[DiSK](https://github.com/Yundi-Zhang/DiSK)|\n", "2406.00329": "|[whole heart 3d+t representation learning through sparse 2d cardiac mr images](https://arxiv.org/abs/2406.00329)|[WholeHeartRL](https://github.com/Yundi-Zhang/WholeHeartRL)|\n", "2406.03747": "|[oralbbnet: spatially guided dental segmentation of panoramic x-rays with bounding box priors](https://arxiv.org/abs/2406.03747)|[Instance_seg_teeth](https://github.com/devichand579/Instance_seg_teeth)|\n", "2406.09570": "|[improving consistency models with generator-augmented flows](https://arxiv.org/abs/2406.09570)|[consistency_gc](https://github.com/thibautissenhuth/consistency_gc)|\n", "2406.11933": "|[harnessing massive satellite imagery with efficient masked image modeling](https://arxiv.org/abs/2406.11933)|[SelectiveMAE](https://github.com/Fengxiang23/SelectiveMAE)|\n", "2406.17538": "|[three-stream temporal-shift attention network based on self-knowledge distillation for micro-expression recognition](https://arxiv.org/abs/2406.17538)|[skd-tstsan](https://github.com/guanghaozhu663/skd-tstsan)|\n", "2408.11787": "|[nusegdg: integration of heterogeneous space and gaussian kernel for domain-generalized nuclei segmentation](https://arxiv.org/abs/2408.11787)|[nusegdg](https://github.com/xq141839/nusegdg)|\n", "2410.09998": "|[slimseiz: efficient channel-adaptive seizure prediction using a mamba-enhanced network](https://arxiv.org/abs/2410.09998)|[slimseiz](https://github.com/guoruilu/slimseiz)|\n", "2410.11062": "|[cleanumamba: a compact mamba network for speech denoising using channel pruning](https://arxiv.org/abs/2410.11062)|[cleanumamba](https://github.com/lab-emi/cleanumamba)|\n", "2410.19332": "|[beyond point annotation: a weakly supervised network guided by multi-level labels generated from four-point annotation for thyroid nodule segmentation in ultrasound image](https://arxiv.org/abs/2410.19332)|[PAplusNet](https://github.com/bluehenglee/PAplusNet)|\n", "2410.20573": "|[unsupervised panoptic interpretation of latent spaces in gans using space-filling vector quantization](https://arxiv.org/abs/2410.20573)|[interpretable-gans-by-sfvq](https://github.com/mhvali/interpretable-gans-by-sfvq)|\n", "2410.22784": "|[contrastive learning and adversarial disentanglement for privacy-aware task-oriented semantic communication](https://arxiv.org/abs/2410.22784)|[clad](https://github.com/omarerak/clad)|\n", "2410.23114": "|[unified triplet-level hallucination evaluation for large vision-language models](https://arxiv.org/abs/2410.23114)|[tri-he](https://github.com/wujunjie1998/tri-he)|\n", "2412.03055": "|[real-time aiot for aav antenna interference detection via edge-cloud collaboration](https://arxiv.org/abs/2412.03055)|[edgeant](https://github.com/scnu-rislab/edgeant)|\n", "2412.11576": "|[dcbm: data-efficient visual concept bottleneck models](https://arxiv.org/abs/2412.11576)|[gcbm](https://github.com/kathpra/gcbm)|\n", "2501.04353": "|[defusion: an effective decoupling fusion network for multi-modal pregnancy prediction](https://arxiv.org/abs/2501.04353)|[dfnet](https://github.com/ou-young-1999/dfnet)|\n", "2502.04320": "|[conceptattention: diffusion transformers learn highly interpretable features](https://arxiv.org/abs/2502.04320)|[ConceptAttention](https://github.com/helblazer811/ConceptAttention)|\n", "2503.03327": "|[scalefusionnet: transformer-guided multi-scale feature fusion for skin lesion segmentation](https://arxiv.org/abs/2503.03327)|[scalefusionnet](https://github.com/sqbqamar/scalefusionnet)|\n", "2503.11054": "|[lusd: localized update score distillation for text-guided image editing](https://arxiv.org/abs/2503.11054)|[lusd](https://github.com/sincostanx/lusd)|\n", "2503.15576": "|[a bird song detector for improving bird identification through deep learning: a case study from do\u00f1ana](https://arxiv.org/abs/2503.15576)|[BIRDeep_BirdSongDetector_NeuralNetworks](https://github.com/GrunCrow/BIRDeep_BirdSongDetector_NeuralNetworks)|\n", "2503.18873": "|[efficient self-supervised adaptation for medical image analysis](https://arxiv.org/abs/2503.18873)|[apla](https://github.com/moeinsorkhei/apla)|\n", "2504.03096": "|[scaling open-vocabulary action detection](https://arxiv.org/abs/2504.03096)|[sia_act](https://github.com/siatheindochinese/sia_act)|\n", "2504.05750": "|[radiative backpropagation with non-static geometry](https://arxiv.org/abs/2504.05750)|[mitsuba-missing-term](https://github.com/mworchel/mitsuba-missing-term)|\n", "2504.09724": "|[a survey on efficient vision-language models](https://arxiv.org/abs/2504.09724)|[efficient-vision-language-models-a-survey](https://github.com/mpsc-umbc/efficient-vision-language-models-a-survey)|\n", "2504.13037": "|[towards cardiac mri foundation models: comprehensive visual-tabular representations for whole-heart assessment and beyond](https://arxiv.org/abs/2504.13037)|[vita](https://github.com/yundi-zhang/vita)|\n", "2505.03440": "|[manvr3d: a platform for human-in-the-loop cell tracking in virtual reality](https://arxiv.org/abs/2505.03440)|[manvr3d](https://github.com/scenerygraphics/manvr3d)|\n", "2505.12620": "|[busterx: mllm-powered ai-generated video forgery detection and explanation](https://arxiv.org/abs/2505.12620)|[busterx](https://github.com/l8cv/busterx)|\n", "2506.15682": "|[evolutionary caching to accelerate your off-the-shelf diffusion model](https://arxiv.org/abs/2506.15682)|[ecad](https://github.com/aniaggarwal/ecad)|\n"}, "2025-07-04": {"2303.06285": "|[deltaedit: exploring text-free training for text-driven image manipulation](https://arxiv.org/abs/2303.06285)|[deltaedit](https://github.com/yueming6568/deltaedit)|\n", "2408.07079": "|[anatomical foundation models for brain mris](https://arxiv.org/abs/2408.07079)|[anatcl](https://github.com/eidoslab/anatcl)|\n", "2410.16236": "|[llava-kd: a framework of distilling multimodal large language models](https://arxiv.org/abs/2410.16236)|[LLaVA-KD](https://github.com/Fantasyele/LLaVA-KD)|\n", "2411.02136": "|[advanced computer vision for extracting georeferenced vehicle trajectories from drone imagery](https://arxiv.org/abs/2411.02136)|[stabilo](https://github.com/rfonod/stabilo)|\n", "2411.19688": "|[sure-vqa: systematic understanding of robustness evaluation in medical vqa tasks](https://arxiv.org/abs/2411.19688)|[sure-vqa](https://github.com/iml-dkfz/sure-vqa)|\n", "2412.00420": "|[tarot: targeted data selection via optimal transport](https://arxiv.org/abs/2412.00420)|[tarot](https://github.com/vita-epfl/tarot)|\n", "2412.03349": "|[fairer analysis and demographically balanced face generation for fairer face verification](https://arxiv.org/abs/2412.03349)|[FaVFA](https://github.com/MSoumm/FaVFA)|\n", "2412.14171": "|[thinking in space: how multimodal large language models see, remember, and recall spaces](https://arxiv.org/abs/2412.14171)|[thinking-in-space](https://github.com/vision-x-nyu/thinking-in-space)|\n", "2503.03259": "|[banet: bilateral aggregation network for mobile stereo matching](https://arxiv.org/abs/2503.03259)|[banet](https://github.com/gangweix/banet)|\n", "2503.17046": "|[hapi: a model for learning robot facial expressions from human preferences](https://arxiv.org/abs/2503.17046)|[PairwiseExpressionAnnotator](https://github.com/KUCognitiveInformaticsLab/PairwiseExpressionAnnotator)|\n", "2503.17089": "|[understanding-informed bias mitigation for fair cmr segmentation](https://arxiv.org/abs/2503.17089)|[nnUNet-bias-mitigation](https://github.com/tiarnaleeKCL/nnUNet-bias-mitigation)|\n", "2504.12753": "|[stronger, steadier & superior: geometric consistency in depth vfm forges domain generalized semantic segmentation](https://arxiv.org/abs/2504.12753)|[depthforge](https://github.com/anonymouse-xzrptkvyqc/depthforge)|\n", "2504.19136": "|[pad: phase-amplitude decoupling fusion for multi-modal land cover classification](https://arxiv.org/abs/2504.19136)|[pad](https://github.com/ranfeng2/pad)|\n", "2505.06002": "|[task-adapter++: task-specific adaptation with order-aware alignment for few-shot action recognition](https://arxiv.org/abs/2505.06002)|[task-adapter-pp](https://github.com/jaulin-bage/task-adapter-pp)|\n", "2505.08601": "|[rejoining fragmented ancient bamboo slips with physics-driven deep learning](https://arxiv.org/abs/2505.08601)|[wisepanda](https://github.com/zhujinchi/wisepanda)|\n", "2505.15075": "|[traveling across languages: benchmarking cross-lingual consistency in multimodal llms](https://arxiv.org/abs/2505.15075)|[traveling-across-languages](https://github.com/nlp-waseda/traveling-across-languages)|\n", "2506.06231": "|[towards an explainable comparison and alignment of feature embeddings](https://arxiv.org/abs/2506.06231)|[embedding-comparison](https://github.com/mjalali/embedding-comparison)|\n", "2506.09612": "|[consistent story generation with asymmetry zigzag sampling](https://arxiv.org/abs/2506.09612)|[asymmetry-zigzag-storydiffusion](https://github.com/mingxiao-li/asymmetry-zigzag-storydiffusion)|\n"}, "2025-07-05": {}, "2025-07-06": {}, "2025-07-07": {"2407.14364": "|[towards assessing data replication in music generation with music similarity metrics on raw audio](https://arxiv.org/abs/2407.14364)|[mira](https://github.com/roserbatlleroca/mira)|\n", "2503.00731": "|[lightendostereo: a real-time lightweight stereo matching method for endoscopy images](https://arxiv.org/abs/2503.00731)|[lightendostereo](https://github.com/sonne-ding/lightendostereo)|\n"}, "2025-07-08": {"2106.12839": "|[visualizing graph neural networks with corgie: corresponding a graph to its embedding](https://arxiv.org/abs/2106.12839)|[CorGIE](https://github.com/zipengliu/CorGIE)|\n", "2301.01201": "|[uncertainty in real-time semantic segmentation on embedded systems](https://arxiv.org/abs/2301.01201)|[eu-seg](https://github.com/egstatsml/eu-seg)|\n", "2303.06572": "|[continual visual reinforcement learning with a life-long world model](https://arxiv.org/abs/2303.06572)|[cpl](https://github.com/jc043/cpl)|\n", "2307.00928": "|[learning differentiable logic programs for abstract visual reasoning](https://arxiv.org/abs/2307.00928)|[neumann](https://github.com/ml-research/neumann)|\n", "2307.08106": "|[polarization multi-image synthesis with birefringent metasurfaces](https://arxiv.org/abs/2307.08106)|[multi-image-synthesis](https://github.com/deanhazineh/multi-image-synthesis)|\n", "2309.08402": "|[3d sa-unet: 3d spatial attention unet with 3d atrous spatial pyramid pooling for white matter hyperintensities segmentation](https://arxiv.org/abs/2309.08402)|[wmhchallenge](https://github.com/hjkuijf/wmhchallenge)|\n", "2311.10116": "|[wildfire smoke detection system: model architecture, training mechanism, and dataset](https://arxiv.org/abs/2311.10116)|[CCPE](https://github.com/WCUSTC/CCPE)|\n", "2312.03430": "|[sharecmp: polarization-aware rgb-p semantic segmentation](https://arxiv.org/abs/2312.03430)|[sharecmp](https://github.com/lefteyex/sharecmp)|\n", "2312.14201": "|[towards better visualizing the decision basis of networks via unfold and conquer attribution guidance](https://arxiv.org/abs/2312.14201)|[UCAG](https://github.com/KU-HJH/UCAG)|\n", "2401.09596": "|[efficient generative adversarial networks using linear additive-attention transformers](https://arxiv.org/abs/2401.09596)|[LadaGAN-pytorch](https://github.com/milmor/LadaGAN-pytorch)|\n", "2402.13126": "|[vgmshield: mitigating misuse of video generative models](https://arxiv.org/abs/2402.13126)|[mmvgm](https://github.com/py85252876/mmvgm)|\n", "2403.17377": "|[self-rectifying diffusion sampling with perturbed-attention guidance](https://arxiv.org/abs/2403.17377)|[Perturbed-Attention-Guidance](https://github.com/KU-CVLAB/Perturbed-Attention-Guidance)|\n", "2403.20309": "|[instantsplat: sparse-view gaussian splatting in seconds](https://arxiv.org/abs/2403.20309)|[InstantSplat](https://github.com/NVlabs/InstantSplat)|\n", "2404.01988": "|[cooperative students: navigating unsupervised domain adaptation in nighttime object detection](https://arxiv.org/abs/2404.01988)|[cooperitive_students](https://github.com/jichengyuan/cooperitive_students)|\n", "2404.17230": "|[objectadd: adding objects into image via a training-free diffusion modification fashion](https://arxiv.org/abs/2404.17230)|[objectadd](https://github.com/potato-kitty/objectadd)|\n", "2405.15239": "|[brain3d: generating 3d objects from fmri](https://arxiv.org/abs/2405.15239)|[Brain3D](https://github.com/fudan-zvg/Brain3D)|\n", "2406.04345": "|[active stereo in the wild through virtual pattern projection](https://arxiv.org/abs/2406.04345)|[vppstereo](https://github.com/bartn8/vppstereo)|\n", "2406.06612": "|[see-2-sound: zero-shot spatial environment-to-spatial sound](https://arxiv.org/abs/2406.06612)|[see2sound](https://github.com/see2sound/see2sound)|\n", "2407.13120": "|[hppp: halpern-type preconditioned proximal point algorithms and applications to image restoration](https://arxiv.org/abs/2407.13120)|[HPPP](https://github.com/zsc15/HPPP)|\n", "2409.02426": "|[diffusion models learn low-dimensional distributions via subspace clustering](https://arxiv.org/abs/2409.02426)|[Diffusion-Model-Generalizability](https://github.com/huijieZH/Diffusion-Model-Generalizability)|\n", "2409.09721": "|[finetuning clip to reason about pairwise differences](https://arxiv.org/abs/2409.09721)|[pc_clip](https://github.com/dsam99/pc_clip)|\n", "2410.18151": "|[music102: an $d_{12}$-equivariant transformer for chord progression accompaniment](https://arxiv.org/abs/2410.18151)|[music102](https://github.com/Benzoin96485/music102)|\n", "2411.02570": "|[ti-prego: chain of thought and in-context learning for online mistake detection in procedural egocentric videos](https://arxiv.org/abs/2411.02570)|[prego](https://github.com/aleflabo/prego)|\n", "2411.10595": "|[fedali: personalized federated learning alignment with prototype layers for generalized mobile services](https://arxiv.org/abs/2411.10595)|[FedAli](https://github.com/getalp/FedAli)|\n", "2411.15098": "|[ominicontrol: minimal and universal control for diffusion transformer](https://arxiv.org/abs/2411.15098)|[OminiControl](https://github.com/Yuanshi9815/OminiControl)|\n", "2412.04954": "|[gla-ai4biomed at rrg24: visual instruction-tuned adaptation for radiology report generation](https://arxiv.org/abs/2412.04954)|[RRG-BioNLP-ACL2024](https://github.com/Glasgow-AI4BioMed/RRG-BioNLP-ACL2024)|\n", "2412.07156": "|[qcresunet: joint subject-level and voxel-level segmentation quality prediction](https://arxiv.org/abs/2412.07156)|[QCResUNet](https://github.com/sotiraslab/QCResUNet)|\n", "2412.10444": "|[boundary exploration of next best view policy in 3d robotic scanning](https://arxiv.org/abs/2412.10444)|[benbv](https://github.com/leihui6/benbv)|\n", "2412.14111": "|[event-based photometric bundle adjustment](https://arxiv.org/abs/2412.14111)|[epba](https://github.com/tub-rip/epba)|\n", "2412.14790": "|[yolov11 optimization for efficient resource utilization](https://arxiv.org/abs/2412.14790)|[yolov11](https://github.com/areeg94fahad/yolov11)|\n", "2501.01949": "|[videolifter: lifting videos to 3d with fast hierarchical stereo alignment](https://arxiv.org/abs/2501.01949)|[VideoLifter](https://github.com/VITA-Group/VideoLifter)|\n", "2501.13805": "|[mmegohand: egocentric hand pose estimation and gesture recognition with head-mounted millimeter-wave radar and imu](https://arxiv.org/abs/2501.13805)|[mmvr](https://github.com/whisperyi/mmvr)|\n", "2502.00285": "|[k nearest neighbor-guided trajectory similarity learning](https://arxiv.org/abs/2502.00285)|[TSMini](https://github.com/changyanchuan/TSMini)|\n", "2502.02029": "|[morph-ler: log-euclidean regularization for population-aware image registration](https://arxiv.org/abs/2502.02029)|[morph_ler](https://github.com/iyerkrithika21/morph_ler)|\n", "2502.05040": "|[gaussrender: learning 3d occupancy with gaussian rendering](https://arxiv.org/abs/2502.05040)|[gaussrender](https://github.com/valeoai/gaussrender)|\n", "2502.17776": "|[tip of the tongue query elicitation for simulated evaluation](https://arxiv.org/abs/2502.17776)|[llm-tot-query-elicitation](https://github.com/kimdanny/llm-tot-query-elicitation)|\n", "2502.19707": "|[weakly supervised segmentation framework for thyroid nodule based on high-confidence labels and high-rationality losses](https://arxiv.org/abs/2502.19707)|[mli-msc](https://github.com/bluehenglee/mli-msc)|\n", "2503.02410": "|[neuroverse3d: developing in-context learning universal model for neuroimaging in 3d](https://arxiv.org/abs/2503.02410)|[neu3d](https://github.com/jiesihu/neu3d)|\n", "2503.07435": "|[open-set gait recognition from sparse mmwave radar point clouds](https://arxiv.org/abs/2503.07435)|[OpenSetGaitRecognition_PCAA](https://github.com/rmazzier/OpenSetGaitRecognition_PCAA)|\n", "2503.13028": "|[beyond role-based surgical domain modeling: generalizable re-identification in the operating room](https://arxiv.org/abs/2503.13028)|[or_reid](https://github.com/wngTn/or_reid)|\n", "2503.17966": "|[real-world remote sensing image dehazing: benchmark and baseline](https://arxiv.org/abs/2503.17966)|[rrshid](https://github.com/lwcver/rrshid)|\n", "2503.20612": "|[iap: improving continual learning of vision-language models via instance-aware prompting](https://arxiv.org/abs/2503.20612)|[iap](https://github.com/ferdinandzju/iap)|\n", "2504.00047": "|[eap4emsig -- enhancing event-driven microscopy for microfluidic single-cell analysis](https://arxiv.org/abs/2504.00047)|[TensorRT](https://github.com/NVIDIA/TensorRT)|\n", "2504.15133": "|[easyedit2: an easy-to-use steering framework for editing large language models](https://arxiv.org/abs/2504.15133)|[easyedit](https://github.com/zjunlp/easyedit)|\n", "2504.20948": "|[ds_fusionnet: dynamic dual-stream fusion with bidirectional knowledge distillation for plant disease recognition](https://arxiv.org/abs/2504.20948)|[DS_FusionNet](https://github.com/YanghuiSong/DS_FusionNet)|\n", "2505.03836": "|[explainable coarse-to-fine ancient manuscript duplicates discovery](https://arxiv.org/abs/2505.03836)|[obd-finder](https://github.com/cszhanglmu/obd-finder)|\n", "2505.04921": "|[perception, reason, think, and plan: a survey on large multimodal reasoning models](https://arxiv.org/abs/2505.04921)|[awesome-large-multimodal-reasoning-models](https://github.com/hitsz-tmg/awesome-large-multimodal-reasoning-models)|\n", "2505.05163": "|[probabilistic embeddings for frozen vision-language models: uncertainty quantification with gaussian process latent variable models](https://arxiv.org/abs/2505.05163)|[GroVE](https://github.com/vaishwarya96/GroVE)|\n", "2505.08468": "|[judging the judges: can large vision-language models fairly evaluate chart comprehension and reasoning?](https://arxiv.org/abs/2505.08468)|[chart_lvlm_judge](https://github.com/tahmedge/chart_lvlm_judge)|\n", "2505.09193": "|[biecvc: gated diversification of bidirectional contexts for learned video compression](https://arxiv.org/abs/2505.09193)|[ecvc](https://github.com/jiangweibeta/ecvc)|\n", "2505.20255": "|[anicrafter: customizing realistic human-centric animation via avatar-background conditioning in video diffusion models](https://arxiv.org/abs/2505.20255)|[anicrafter](https://github.com/myniuuu/anicrafter)|\n", "2506.05336": "|[videomolmo: spatio-temporal grounding meets pointing](https://arxiv.org/abs/2506.05336)|[videomolmo](https://github.com/mbzuai-oryx/videomolmo)|\n", "2506.05344": "|[sparsemm: head sparsity emerges from visual concept responses in mllms](https://arxiv.org/abs/2506.05344)|[sparsemm](https://github.com/cr400af-a/sparsemm)|\n", "2506.08011": "|[play to generalize: learning to reason through game play](https://arxiv.org/abs/2506.08011)|[vigal](https://github.com/yunfeixie233/vigal)|\n", "2506.09695": "|[towards practical alzheimer's disease diagnosis: a lightweight and interpretable spiking neural model](https://arxiv.org/abs/2506.09695)|[fastersnn](https://github.com/wuchangw/fastersnn)|\n", "2506.10974": "|[automind: adaptive knowledgeable agent for automated data science](https://arxiv.org/abs/2506.10974)|[automind](https://github.com/innovatingai/automind)|\n"}, "2025-07-09": {"2305.09666": "|[abdomenatlas-8k: annotating 8,000 ct volumes for multi-organ segmentation in three weeks](https://arxiv.org/abs/2305.09666)|[abdomenatlas](https://github.com/mrgiovanni/abdomenatlas)|\n", "2305.12659": "|[uvosam: a mask-free paradigm for unsupervised video object segmentation via segment anything model](https://arxiv.org/abs/2305.12659)|[uvosam](https://github.com/alibaba/uvosam)|\n", "2312.12491": "|[streamdiffusion: a pipeline-level solution for real-time interactive generation](https://arxiv.org/abs/2312.12491)|[streamdiffusion](https://github.com/cumulo-autumn/streamdiffusion)|\n", "2312.17670": "|[benchmarking the cow with the topcow challenge: topology-aware anatomical segmentation of the circle of willis for cta and mra](https://arxiv.org/abs/2312.17670)|[multivesseg](https://github.com/i-vesseg/multivesseg)|\n", "2404.16302": "|[cfmw: cross-modality fusion mamba for robust object detection under adverse weather](https://arxiv.org/abs/2404.16302)|[cfmw](https://github.com/lhy-zjut/cfmw)|\n", "2406.16993": "|[are vision xlstm embedded unet more reliable in medical 3d image segmentation?](https://arxiv.org/abs/2406.16993)|[u-vixlstm](https://github.com/duttapallabi2907/u-vixlstm)|\n", "2407.16697": "|[abdomenatlas: a large-scale, detailed-annotated, & multi-center dataset for efficient transfer learning and open algorithmic benchmarking](https://arxiv.org/abs/2407.16697)|[abdomenatlas](https://github.com/mrgiovanni/abdomenatlas)|\n", "2411.01866": "|[improving trust estimation in human-robot collaboration using beta reputation at fine-grained timescales](https://arxiv.org/abs/2411.01866)|[robot-learning-human-trust](https://github.com/resuldagdanov/robot-learning-human-trust)|\n", "2411.09822": "|[advancing stroke risk prediction using a multi-modal foundation model](https://arxiv.org/abs/2411.09822)|[SSMSRPM](https://github.com/CamilleDelgrange/SSMSRPM)|\n", "2411.13918": "|[quantization without tears](https://arxiv.org/abs/2411.13918)|[QwT](https://github.com/wujx2001/QwT)|\n", "2411.17616": "|[towards stabilized and efficient diffusion transformers through long-skip-connections with spectral constraints](https://arxiv.org/abs/2411.17616)|[skip-dit](https://github.com/opensparsellms/skip-dit)|\n", "2411.18702": "|[random walks with tweedie: a unified view of score-based diffusion models](https://arxiv.org/abs/2411.18702)|[randomwalk_diffusion](https://github.com/wustl-cig/randomwalk_diffusion)|\n", "2412.09331": "|[physics-driven autoregressive state space models for medical image reconstruction](https://arxiv.org/abs/2412.09331)|[MambaRoll](https://github.com/icon-lab/MambaRoll)|\n", "2412.20545": "|[the impact of prompt programming on function-level code generation](https://arxiv.org/abs/2412.20545)|[codeprompteval](https://github.com/icetlab/codeprompteval)|\n", "2501.09530": "|[make yourself comfortable: nudging urban heat and noise mitigation with smartwatch-based just-in-time adaptive interventions (jitai)](https://arxiv.org/abs/2501.09530)|[make-yourself-comfortable-jitai-journal-paper](https://github.com/buds-lab/make-yourself-comfortable-jitai-journal-paper)|\n", "2503.04504": "|[anyanomaly: zero-shot customizable video anomaly detection with lvlm](https://arxiv.org/abs/2503.04504)|[Paper-AnyAnomaly](https://github.com/SkiddieAhn/Paper-AnyAnomaly)|\n", "2503.08805": "|[filter like you test: data-driven data filtering for clip pretraining](https://arxiv.org/abs/2503.08805)|[FLYT](https://github.com/formll/FLYT)|\n", "2503.12149": "|[seeing sarcasm through different eyes: analyzing multimodal sarcasm perception in large vision-language models](https://arxiv.org/abs/2503.12149)|[LVLMSarcasmAnalysis](https://github.com/CoderChen01/LVLMSarcasmAnalysis)|\n", "2503.18364": "|[mass13k: a matting-level semantic segmentation benchmark](https://arxiv.org/abs/2503.18364)|[mass13k](https://github.com/xiechenxi99/mass13k)|\n", "2503.23367": "|[fastvar: linear visual autoregressive modeling via cached token pruning](https://arxiv.org/abs/2503.23367)|[fastvar](https://github.com/csguoh/fastvar)|\n", "2505.05599": "|[enhancing satellite object localization with dilated convolutions and attention-aided spatial pooling](https://arxiv.org/abs/2505.05599)|[satellite-object-localization](https://github.com/ai-4-atmosphere-remote-sensing/satellite-object-localization)|\n", "2505.06393": "|[toward advancing license plate super-resolution in real-world scenarios: a dataset and benchmark](https://arxiv.org/abs/2505.06393)|[lpsrgan](https://github.com/valfride/lpsrgan)|\n"}, "2025-07-10": {"2304.00050": "|[batch normalization in cytometry data by knn-graph preservation](https://arxiv.org/abs/2304.00050)|[knn-res_demo](https://github.com/muhammadsaeedbatikh/knn-res_demo)|\n", "2307.14770": "|[3dportraitgan: learning one-quarter headshot 3d gans from a single-view portrait dataset with diverse body poses](https://arxiv.org/abs/2307.14770)|[3DPortraitGAN](https://github.com/oneThousand1000/3DPortraitGAN)|\n", "2311.18564": "|[leveraging local patch alignment to seam-cutting for large parallax image stitching](https://arxiv.org/abs/2311.18564)|[lpam_seam-cutting](https://github.com/tlliao/lpam_seam-cutting)|\n", "2402.16267": "|[infrared and visible image fusion with language-driven loss in clip embedding space](https://arxiv.org/abs/2402.16267)|[LDFusion](https://github.com/wyhlaowang/LDFusion)|\n", "2403.05427": "|[reply with sticker: new dataset and model for sticker retrieval](https://arxiv.org/abs/2403.05427)|[int-ra](https://github.com/hitsz-hlt/int-ra)|\n", "2407.03010": "|[cavis: context-aware video instance segmentation](https://arxiv.org/abs/2407.03010)|[CAVIS](https://github.com/Seung-Hun-Lee/CAVIS)|\n", "2407.08277": "|[stixelnext: toward monocular low-weight perception for object segmentation and free space detection](https://arxiv.org/abs/2407.08277)|[StixelNExT](https://github.com/MarcelVSHNS/StixelNExT)|\n", "2410.06405": "|[tackling the abstraction and reasoning corpus with vision transformers: the importance of 2d representation, positions, and objects](https://arxiv.org/abs/2410.06405)|[ViTARC](https://github.com/khalil-research/ViTARC)|\n", "2410.08740": "|[hespi: a pipeline for automatically detecting information from hebarium specimen sheets](https://arxiv.org/abs/2410.08740)|[hespi](https://github.com/rbturnbull/hespi)|\n", "2411.11199": "|[bvi-cr: a multi-view human dataset for volumetric video compression](https://arxiv.org/abs/2411.11199)|[bvi-cr](https://github.com/fan-aaron-zhang/bvi-cr)|\n", "2411.12510": "|[pr-endo: physically based relightable gaussian splatting for endoscopy](https://arxiv.org/abs/2411.12510)|[PR-ENDO](https://github.com/SanoScience/PR-ENDO)|\n", "2411.15802": "|[medical slice transformer: improved diagnosis and explainability on 3d medical images with dinov2](https://arxiv.org/abs/2411.15802)|[mst](https://github.com/mueller-franzes/mst)|\n", "2411.18115": "|[transformer-driven active transfer learning for cross-hyperspectral image classification](https://arxiv.org/abs/2411.18115)|[atl-sst](https://github.com/mahmad000/atl-sst)|\n", "2412.02506": "|[rover: a multi-season dataset for visual slam](https://arxiv.org/abs/2412.02506)|[rover_benchmark](https://github.com/iis-esslingen/rover_benchmark)|\n", "2412.15670": "|[bs-ldm: effective bone suppression in high-resolution chest x-ray images with conditional latent diffusion models](https://arxiv.org/abs/2412.15670)|[BS-LDM](https://github.com/diaoquesang/BS-LDM)|\n", "2501.04670": "|[are they the same? exploring visual correspondence shortcomings of multimodal llms](https://arxiv.org/abs/2501.04670)|[colva](https://github.com/zhouyiks/colva)|\n", "2501.06927": "|[culture3d: a large-scale and diverse dataset of cultural landmarks and terrains for gaussian-based scene rendering](https://arxiv.org/abs/2501.06927)|[culture3d](https://github.com/openinterx/culture3d)|\n", "2502.20853": "|[oscillation-reduced mxfp4 training for vision transformers](https://arxiv.org/abs/2502.20853)|[tetrajet-mxfp4training](https://github.com/thu-ml/tetrajet-mxfp4training)|\n", "2503.09446": "|[sparse autoencoder as a zero-shot classifier for concept erasing in text-to-image diffusion models](https://arxiv.org/abs/2503.09446)|[interpret-then-deactivate](https://github.com/nansirun/interpret-then-deactivate)|\n", "2505.08617": "|[openthinkimg: learning to think with images via visual tool reinforcement learning](https://arxiv.org/abs/2505.08617)|[openthinkimg](https://github.com/zhaochen0110/openthinkimg)|\n"}, "2025-07-11": {"1905.09226": "|[boundary learning by using weighted propagation in convolution network](https://arxiv.org/abs/1905.09226)|[WPU-Net](https://github.com/clovermini/WPU-Net)|\n", "2105.05874": "|[the federated tumor segmentation (fets) challenge](https://arxiv.org/abs/2105.05874)|[Challenge](https://github.com/FETS-AI/Challenge)|\n", "2203.07861": "|[don't get me wrong: how to apply deep visual interpretations to time series](https://arxiv.org/abs/2203.07861)|[saliency](https://github.com/crispchris/saliency)|\n", "2405.20559": "|[information-driven design of imaging systems](https://arxiv.org/abs/2405.20559)|[encodinginformation](https://github.com/waller-lab/encodinginformation)|\n", "2406.09260": "|[deep transformer network for monocular pose estimation of shipborne unmanned aerial vehicle](https://arxiv.org/abs/2406.09260)|[tnn-mo](https://github.com/fdcl-gwu/tnn-mo)|\n", "2407.17773": "|[kiva: kid-inspired visual analogies for testing large multimodal models](https://arxiv.org/abs/2407.17773)|[kiva](https://github.com/ey242/kiva)|\n", "2408.02900": "|[medtrinity-25m: a large-scale multimodal dataset with multigranular annotations for medicine](https://arxiv.org/abs/2408.02900)|[MedTrinity-25M](https://github.com/UCSC-VLAA/MedTrinity-25M)|\n", "2408.06687": "|[masked image modeling: a survey](https://arxiv.org/abs/2408.06687)|[mim-survey](https://github.com/vladhondru25/mim-survey)|\n", "2501.03575": "|[cosmos world foundation model platform for physical ai](https://arxiv.org/abs/2501.03575)|[cosmos-predict1](https://github.com/nvidia-cosmos/cosmos-predict1)|\n", "2503.05689": "|[goalflow: goal-driven flow matching for multimodal trajectories generation in end-to-end autonomous driving](https://arxiv.org/abs/2503.05689)|[goalflow](https://github.com/yvanyin/goalflow)|\n", "2503.11498": "|[open-source automatic pipeline for efficient conversion of large-scale point clouds to ifc format](https://arxiv.org/abs/2503.11498)|[cloud2bim](https://github.com/vaclavnezerka/cloud2bim)|\n", "2503.12356": "|[localized concept erasure for text-to-image diffusion models using training-free gated low-rank adaptation](https://arxiv.org/abs/2503.12356)|[GLoCE](https://github.com/Hyun1A/GLoCE)|\n", "2504.07793": "|[revisiting likelihood-based out-of-distribution detection by modeling representations](https://arxiv.org/abs/2504.07793)|[likelihood-ood](https://github.com/limchaos/likelihood-ood)|\n", "2506.08694": "|[mosic: optimal-transport motion trajectory for dense self-supervised learning](https://arxiv.org/abs/2506.08694)|[mosic](https://github.com/smsd75/mosic)|\n", "2506.08908": "|[skipvar: accelerating visual autoregressive modeling via adaptive frequency-aware skipping](https://arxiv.org/abs/2506.08908)|[skipvar](https://github.com/fakerone-li/skipvar)|\n"}, "2025-07-12": {}, "2025-07-13": {}, "2025-07-14": {"2311.10011": "|[sqlnet: scale-modulated query and localization network for few-shot class-agnostic counting](https://arxiv.org/abs/2311.10011)|[sqlnet](https://github.com/hcplab-sysu/sqlnet)|\n", "2401.16522": "|[dropout concrete autoencoder for band selection on hsi scenes](https://arxiv.org/abs/2401.16522)|[hyperspectral](https://github.com/leixuai/hyperspectral)|\n", "2501.02788": "|[glog-csunet: enhancing vision transformers with adaptable radiomic features for medical image segmentation](https://arxiv.org/abs/2501.02788)|[glog-csunet](https://github.com/haail/glog-csunet)|\n", "2502.05928": "|[clinkd: cross-modal clinical knowledge distiller for multi-task medical images](https://arxiv.org/abs/2502.05928)|[clinkd](https://github.com/overloadedhenry/clinkd)|\n", "2503.01163": "|[bandit-based prompt design strategy selection improves prompt optimizers](https://arxiv.org/abs/2503.01163)|[opts](https://github.com/shiralab/opts)|\n", "2503.07499": "|[athletepose3d: a benchmark dataset for 3d human pose estimation and kinematic validation in athletic movements](https://arxiv.org/abs/2503.07499)|[athletepose3d](https://github.com/calvinyeungck/athletepose3d)|\n", "2503.07656": "|[drivetransformer: unified transformer for scalable end-to-end autonomous driving](https://arxiv.org/abs/2503.07656)|[drivetransformer](https://github.com/thinklab-sjtu/drivetransformer)|\n", "2503.09131": "|[mp-hsir: a multi-prompt framework for universal hyperspectral image restoration](https://arxiv.org/abs/2503.09131)|[mp-hsir](https://github.com/zhehuiwu/mp-hsir)|\n", "2503.20287": "|[insvie-1m: effective instruction-based video editing with elaborate dataset construction](https://arxiv.org/abs/2503.20287)|[insvie](https://github.com/langmanbusi/insvie)|\n", "2503.22589": "|[using ai to summarize us presidential campaign tv advertisement videos, 1952-2012](https://arxiv.org/abs/2503.22589)|[ai-summarizevid](https://github.com/adambreuer/ai-summarizevid)|\n", "2504.00901": "|[a decade of deep learning for remote sensing spatiotemporal fusion: advances, challenges, and opportunities](https://arxiv.org/abs/2504.00901)|[deep-learning-spatiotemporal-fusion-survey](https://github.com/yc-cui/deep-learning-spatiotemporal-fusion-survey)|\n", "2504.13078": "|[mgt: extending virtual try-off to multi-garment scenarios](https://arxiv.org/abs/2504.13078)|[tryoffdiff](https://github.com/rizavelioglu/tryoffdiff)|\n", "2506.12430": "|[pushing the limits of safety: a technical report on the atlas challenge 2025](https://arxiv.org/abs/2506.12430)|[atlas_challenge_2025](https://github.com/ny1024/atlas_challenge_2025)|\n"}, "2025-07-15": {"2106.14490": "|[making images real again: a comprehensive survey on deep image composition](https://arxiv.org/abs/2106.14490)|[awesome-object-insertion](https://github.com/bcmi/awesome-object-insertion)|\n", "2207.10552": "|[a primer on topological data analysis to support image analysis tasks in environmental science](https://arxiv.org/abs/2207.10552)|[sffg_tda](https://github.com/zyjux/sffg_tda)|\n", "2212.08983": "|[adaptive deep learning framework for robust unsupervised underwater image enhancement](https://arxiv.org/abs/2212.08983)|[udnet](https://github.com/alzayats/udnet)|\n", "2306.11341": "|[msvd-indonesian: a benchmark for multimodal video-text tasks in indonesian](https://arxiv.org/abs/2306.11341)|[msvd-indonesian](https://github.com/willyfh/msvd-indonesian)|\n", "2312.00700": "|[wegeft: weight-generative fine-tuning for multi-faceted efficient adaptation of large models](https://arxiv.org/abs/2312.00700)|[gift](https://github.com/savadikarc/gift)|\n", "2312.10872": "|[evaluating the role of training data origin for country-scale cropland mapping in data-scarce regions: a case study of nigeria](https://arxiv.org/abs/2312.10872)|[nigeria-crop-mask](https://github.com/joaquin-gajardo/nigeria-crop-mask)|\n", "2403.03309": "|[learning zero-shot material states segmentation, by implanting natural image patterns in synthetic data](https://arxiv.org/abs/2403.03309)|[matseg](https://github.com/sagieppel/matseg)|\n", "2403.06759": "|[average calibration error: a differentiable loss for improved reliability in image segmentation](https://arxiv.org/abs/2403.06759)|[ace-dliris](https://github.com/cai4cai/ace-dliris)|\n", "2404.13693": "|[advancing automatic photovoltaic defect detection using semi-supervised semantic segmentation of electroluminescence images](https://arxiv.org/abs/2404.13693)|[pv-s3](https://github.com/abj247/pv-s3)|\n", "2404.14435": "|[frenet-serret frame-based decomposition for part segmentation of 3d curvilinear structures](https://arxiv.org/abs/2404.14435)|[ffd4denspineem](https://github.com/vcg/ffd4denspineem)|\n", "2405.03328": "|[enhancing spatiotemporal disease progression models via latent diffusion and prior knowledge](https://arxiv.org/abs/2405.03328)|[brlp](https://github.com/lemuelpuglisi/brlp)|\n", "2405.03546": "|[ccdm: continuous conditional diffusion models for image generation](https://arxiv.org/abs/2405.03546)|[ccdm](https://github.com/ubcdingxin/ccdm)|\n", "2406.00365": "|[synthba: reliable brain age estimation across multiple mri sequences and resolutions](https://arxiv.org/abs/2406.00365)|[synthba](https://github.com/lemuelpuglisi/synthba)|\n", "2406.01069": "|[uniqa: unified vision-language pre-training for image quality and aesthetic assessment](https://arxiv.org/abs/2406.01069)|[uniqa](https://github.com/zht8506/uniqa)|\n", "2406.17709": "|[mga-net: a novel mask-guided attention neural network for precision neonatal brain imaging](https://arxiv.org/abs/2406.17709)|[mga-net](https://github.com/bahramjafrasteh/mga-net)|\n", "2408.09241": "|[re-boosting self-collaboration parallel prompt gan for unsupervised image restoration](https://arxiv.org/abs/2408.09241)|[rscp2gan](https://github.com/linxin0/rscp2gan)|\n", "2408.11447": "|[gaussianocc: fully self-supervised and efficient 3d occupancy estimation with gaussian splatting](https://arxiv.org/abs/2408.11447)|[gaussianocc](https://github.com/ganwanshui/gaussianocc)|\n", "2408.12429": "|[flexedit: marrying free-shape masks to vllm for flexible image editing](https://arxiv.org/abs/2408.12429)|[flex_edit](https://github.com/a-new-b/flex_edit)|\n", "2408.17339": "|[enhancing underwater imaging with 4-d light fields: dataset and method](https://arxiv.org/abs/2408.17339)|[lfuie](https://github.com/linlos1234/lfuie)|\n", "2409.05137": "|[readoc: a unified benchmark for realistic document structured extraction](https://arxiv.org/abs/2409.05137)|[READoc](https://github.com/icip-cas/READoc)|\n", "2409.08824": "|[pathfinder for low-altitude aircraft with binary neural network](https://arxiv.org/abs/2409.08824)|[pathfinder](https://github.com/imrl/pathfinder)|\n", "2410.09135": "|[enabling advanced land cover analytics: an integrated data extraction pipeline for predictive modeling with the dynamic world dataset](https://arxiv.org/abs/2410.09135)|[advancedlandcoveranalytics-pipeline](https://github.com/victor-radermecker/advancedlandcoveranalytics-pipeline)|\n", "2410.10563": "|[mega-bench: scaling multimodal evaluation to over 500 real-world tasks](https://arxiv.org/abs/2410.10563)|[MEGA-Bench](https://github.com/TIGER-AI-Lab/MEGA-Bench)|\n", "2411.10086": "|[corrclip: reconstructing patch correlations in clip for open-vocabulary semantic segmentation](https://arxiv.org/abs/2411.10086)|[CorrCLIP](https://github.com/zdk258/CorrCLIP)|\n", "2411.10440": "|[llava-cot: let vision language models reason step-by-step](https://arxiv.org/abs/2411.10440)|[LLaVA-CoT](https://github.com/PKU-YuanGroup/LLaVA-CoT)|\n", "2412.00947": "|[visonlyqa: large vision language models still struggle with visual perception of geometric information](https://arxiv.org/abs/2412.00947)|[visonlyqa](https://github.com/psunlpgroup/visonlyqa)|\n", "2412.03409": "|[prefixkv: adaptive prefix kv cache is what vision instruction-following models need for efficient generation](https://arxiv.org/abs/2412.03409)|[PrefixKV](https://github.com/THU-MIG/PrefixKV)|\n", "2412.14379": "|[ha-rdet: hybrid anchor rotation detector for oriented object detection](https://arxiv.org/abs/2412.14379)|[ha-rdet](https://github.com/phucnda/ha-rdet)|\n", "2501.00574": "|[videochat-flash: hierarchical compression for long-context video modeling](https://arxiv.org/abs/2501.00574)|[videochat-flash](https://github.com/opengvlab/videochat-flash)|\n", "2501.12386": "|[internvideo2.5: empowering video mllms with long and rich context modeling](https://arxiv.org/abs/2501.12386)|[internvideo](https://github.com/opengvlab/internvideo)|\n", "2501.17266": "|[advancing the biological plausibility and efficacy of hebbian convolutional neural networks](https://arxiv.org/abs/2501.17266)|[advancing-the-biological-plausibility-and-efficacy-of-hebbian-convolutional-neural-networks](https://github.com/julian-jn/advancing-the-biological-plausibility-and-efficacy-of-hebbian-convolutional-neural-networks)|\n", "2501.19066": "|[concept steerers: leveraging k-sparse autoencoders for test-time controllable generations](https://arxiv.org/abs/2501.19066)|[steerers](https://github.com/kim-dahye/steerers)|\n", "2502.08560": "|[brain latent progression: individual-based spatiotemporal disease progression on 3d brain mris via latent diffusion](https://arxiv.org/abs/2502.08560)|[brlp](https://github.com/lemuelpuglisi/brlp)|\n", "2502.09873": "|[compression-aware one-step diffusion model for jpeg artifact removal](https://arxiv.org/abs/2502.09873)|[codiff](https://github.com/jp-guo/codiff)|\n", "2502.21291": "|[mige: mutually enhanced multimodal instruction-based image generation and editing](https://arxiv.org/abs/2502.21291)|[mige](https://github.com/eureka-maggie/mige)|\n", "2503.05332": "|[comogaussian: continuous motion-aware gaussian splatting from motion-blurred images](https://arxiv.org/abs/2503.05332)|[comogaussian](https://github.com/jho-yonsei/comogaussian)|\n", "2503.06471": "|[online dense point tracking with streaming memory](https://arxiv.org/abs/2503.06471)|[spot](https://github.com/dqiaole/spot)|\n", "2503.06678": "|[gamma: toward generic image assessment with mixture of assessment experts](https://arxiv.org/abs/2503.06678)|[gamma](https://github.com/zht8506/gamma)|\n", "2503.12720": "|[towards open-world generation of stereo images and unsupervised matching](https://arxiv.org/abs/2503.12720)|[GenStereo](https://github.com/Qjizhi/GenStereo)|\n", "2503.16465": "|[os-kairos: adaptive interaction for mllm-powered gui agents](https://arxiv.org/abs/2503.16465)|[os-kairos](https://github.com/wuzheng02/os-kairos)|\n", "2503.24391": "|[easi3r: estimating disentangled motion from dust3r without training](https://arxiv.org/abs/2503.24391)|[easi3r](https://github.com/inception3d/easi3r)|\n", "2504.21774": "|[is intermediate fusion all you need for uav-based collaborative perception?](https://arxiv.org/abs/2504.21774)|[lif](https://github.com/uestchjw/lif)|\n", "2505.00684": "|[visual test-time scaling for gui agent grounding](https://arxiv.org/abs/2505.00684)|[regionfocus](https://github.com/tiangeluo/regionfocus)|\n", "2505.02704": "|[vgld: visually-guided linguistic disambiguation for monocular depth scale recovery](https://arxiv.org/abs/2505.02704)|[vgld](https://github.com/pakinwu/vgld)|\n", "2505.07449": "|[ophora: a large-scale data-driven text-guided ophthalmic surgical video generation model](https://arxiv.org/abs/2505.07449)|[ophora](https://github.com/mar-cry/ophora)|\n", "2505.08245": "|[large language model psychometrics: a systematic review of evaluation, validation, and enhancement](https://arxiv.org/abs/2505.08245)|[awesome-llm-psychometrics](https://github.com/valuebyte-ai/awesome-llm-psychometrics)|\n", "2505.08527": "|[leveraging segment anything model for source-free domain adaptation via dual feature guided auto-prompting](https://arxiv.org/abs/2505.08527)|[dfg](https://github.com/xmed-lab/dfg)|\n", "2505.19319": "|[holistic white-light polyp classification via alignment-free dense distillation of auxiliary optical chromoendoscopy](https://arxiv.org/abs/2505.19319)|[add](https://github.com/huster-hq/add)|\n", "2506.07966": "|[space-10: a comprehensive benchmark for multimodal large language models in compositional spatial intelligence](https://arxiv.org/abs/2506.07966)|[space-10](https://github.com/cuzyoung/space-10)|\n"}, "2025-07-16": {"2305.06110": "|[pavlok-nudge: a feedback mechanism for atomic behaviour modification with snoring usecase](https://arxiv.org/abs/2305.06110)|[pavlok-nudge-snore](https://github.com/hasan-rakibul/pavlok-nudge-snore)|\n", "2402.03666": "|[quest: low-bit diffusion model quantization via efficient selective finetuning](https://arxiv.org/abs/2402.03666)|[QuEST](https://github.com/hatchetProject/QuEST)|\n", "2402.12683": "|[torchcp: a python library for conformal prediction](https://arxiv.org/abs/2402.12683)|[torchcp](https://github.com/ml-stat-sustech/torchcp)|\n", "2404.07078": "|[vllms provide better context for emotion understanding through common sense reasoning](https://arxiv.org/abs/2404.07078)|[emocommonsense](https://github.com/nickyfot/emocommonsense)|\n", "2405.02700": "|[unveiling differences in generative models: a scalable differential clustering approach](https://arxiv.org/abs/2405.02700)|[finc](https://github.com/buyeah1109/finc)|\n", "2406.03262": "|[a comprehensive library for benchmarking multi-class visual anomaly detection](https://arxiv.org/abs/2406.03262)|[ader](https://github.com/zhangzjn/ader)|\n", "2407.06109": "|[perldiff: controllable street view synthesis using perspective-layout diffusion models](https://arxiv.org/abs/2407.06109)|[perldiff](https://github.com/labshuhanggu/perldiff)|\n", "2409.07040": "|[retinex-rawmamba: bridging demosaicing and denoising for low-light raw image enhancement](https://arxiv.org/abs/2409.07040)|[retinexrawmamba](https://github.com/cynicarlos/retinexrawmamba)|\n", "2409.16921": "|[moner: motion correction in undersampled radial mri with unsupervised neural representation](https://arxiv.org/abs/2409.16921)|[moner](https://github.com/iwuqing/moner)|\n", "2411.10061": "|[echomimicv2: towards striking, simplified, and semi-body human animation](https://arxiv.org/abs/2411.10061)|[echomimic_v2](https://github.com/antgroup/echomimic_v2)|\n", "2411.15858": "|[svtrv2: ctc beats encoder-decoder models in scene text recognition](https://arxiv.org/abs/2411.15858)|[openocr](https://github.com/topdu/openocr)|\n", "2412.02734": "|[mvctrack: boosting 3d point cloud tracking via multimodal-guided virtual cues](https://arxiv.org/abs/2412.02734)|[MVCTrack](https://github.com/StiphyJay/MVCTrack)|\n", "2412.18675": "|[tab: transformer attention bottlenecks enable user intervention and debugging in vision-language models](https://arxiv.org/abs/2412.18675)|[TAB](https://github.com/anguyen8/TAB)|\n", "2502.12110": "|[a-mem: agentic memory for llm agents](https://arxiv.org/abs/2502.12110)|[a-mem](https://github.com/agiresearch/a-mem)|\n", "2503.08836": "|[a critical analysis of the usage of dimensionality reduction in four domains](https://arxiv.org/abs/2503.08836)|[hd-vis-scripts](https://github.com/keller-mark/hd-vis-scripts)|\n", "2503.10596": "|[groundingsuite: measuring complex multi-granular pixel grounding](https://arxiv.org/abs/2503.10596)|[groundingsuite](https://github.com/hustvl/groundingsuite)|\n", "2504.12753": "|[stronger, steadier & superior: geometric consistency in depth vfm forges domain generalized semantic segmentation](https://arxiv.org/abs/2504.12753)|[depthforge](https://github.com/anonymouse-xzrptkvyqc/depthforge)|\n", "2504.18397": "|[unsupervised visual chain-of-thought reasoning via preference optimization](https://arxiv.org/abs/2504.18397)|[uv-cot](https://github.com/kesenzhao/uv-cot)|\n", "2504.18398": "|[partition map-based fast block partitioning for vvc inter coding](https://arxiv.org/abs/2504.18398)|[ipm](https://github.com/ustc-ivclab/ipm)|\n", "2504.21356": "|[nexus-gen: unified image understanding, generation, and editing via prefilled autoregression in shared embedding space](https://arxiv.org/abs/2504.21356)|[nexus-gen](https://github.com/modelscope/nexus-gen)|\n", "2505.15075": "|[traveling across languages: benchmarking cross-lingual consistency in multimodal llms](https://arxiv.org/abs/2505.15075)|[traveling-across-languages](https://github.com/nlp-waseda/traveling-across-languages)|\n", "2505.16658": "|[zero-shot hyperspectral pansharpening using hysteresis-based tuning for spectral quality control](https://arxiv.org/abs/2505.16658)|[rho-pnn](https://github.com/giu-guarino/rho-pnn)|\n", "2505.23145": "|[flowalign: trajectory-regularized, inversion-free flow-based image editing](https://arxiv.org/abs/2505.23145)|[flowalign](https://github.com/flowalign/flowalign)|\n"}, "2025-07-17": {"2309.10527": "|[spot: scalable 3d pre-training via occupancy prediction for learning transferable 3d representations](https://arxiv.org/abs/2309.10527)|[3dtrans](https://github.com/pjlab-adg/3dtrans)|\n", "2404.05102": "|[lhu-net: a lean hybrid u-net for cost-efficient, high-performance volumetric segmentation](https://arxiv.org/abs/2404.05102)|[lhunet](https://github.com/xmindflow/lhunet)|\n", "2404.09158": "|[streaknet-arch: an anti-scattering network-based architecture for underwater carrier lidar-radar imaging](https://arxiv.org/abs/2404.09158)|[streaknet](https://github.com/bestanhongjun/streaknet)|\n", "2408.02426": "|[boosting memory efficiency in transfer learning for high-resolution medical image classification](https://arxiv.org/abs/2408.02426)|[fpt](https://github.com/yijinhuang/fpt)|\n", "2409.06490": "|[uavdb: point-guided masks for uav detection and segmentation](https://arxiv.org/abs/2409.06490)|[uavdb](https://github.com/wish44165/uavdb)|\n", "2409.15615": "|[kiss-matcher: fast and robust point cloud registration revisited](https://arxiv.org/abs/2409.15615)|[kiss-matcher](https://github.com/mit-spark/kiss-matcher)|\n", "2410.06405": "|[tackling the abstraction and reasoning corpus with vision transformers: the importance of 2d representation, positions, and objects](https://arxiv.org/abs/2410.06405)|[ViTARC](https://github.com/khalil-research/ViTARC)|\n", "2411.10745": "|[bridging the skeleton-text modality gap: diffusion-powered modality alignment for zero-shot skeleton-based action recognition](https://arxiv.org/abs/2411.10745)|[TDSM](https://github.com/KAIST-VICLab/TDSM)|\n", "2411.17240": "|[boost 3d reconstruction using diffusion-based monocular camera calibration](https://arxiv.org/abs/2411.17240)|[dm-calib](https://github.com/junyuandeng/dm-calib)|\n", "2412.06771": "|[proactive agents for multi-turn text-to-image generation under uncertainty](https://arxiv.org/abs/2412.06771)|[proactive_t2i_agents](https://github.com/google-deepmind/proactive_t2i_agents)|\n", "2501.15151": "|[spikedet: better firing patterns for accurate and energy-efficient object detection with spiking neuron networks](https://arxiv.org/abs/2501.15151)|[spikssd](https://github.com/yimeng-fan/spikssd)|\n", "2503.11167": "|[neurons: emulating the human visual cortex improves fidelity and interpretability in fmri-to-video reconstruction](https://arxiv.org/abs/2503.11167)|[neurons](https://github.com/xmed-lab/neurons)|\n", "2503.12335": "|[gs-i$^{3}$: gaussian splatting for surface reconstruction from illumination-inconsistent images](https://arxiv.org/abs/2503.12335)|[gs-3i](https://github.com/tfwang-9527/gs-3i)|\n", "2503.15426": "|[visual position prompt for mllm based visual grounding](https://arxiv.org/abs/2503.15426)|[vpp-llava](https://github.com/waynetomas/vpp-llava)|\n", "2503.17237": "|[strong baseline: multi-uav tracking via yolov12 with bot-sort-reid](https://arxiv.org/abs/2503.17237)|[yolov12-bot-sort-reid](https://github.com/wish44165/yolov12-bot-sort-reid)|\n", "2504.10267": "|[trade-offs in privacy-preserving eye tracking through iris obfuscation: a benchmarking study](https://arxiv.org/abs/2504.10267)|[Iris-Obfuscation-Benchmark](https://gitlab.lrz.de/hctl/Iris-Obfuscation-Benchmark)|\n", "2505.05470": "|[flow-grpo: training flow matching models via online rl](https://arxiv.org/abs/2505.05470)|[flow_grpo](https://github.com/yifan123/flow_grpo)|\n", "2505.07530": "|[fluxsynid: a framework for identity-controlled synthetic face generation with document and live images](https://arxiv.org/abs/2505.07530)|[FLUXSynID](https://github.com/Raul2718/FLUXSynID)|\n", "2505.09092": "|[openlka: an open dataset of lane keeping assist from recent car models under real-world driving conditions](https://arxiv.org/abs/2505.09092)|[openlka](https://github.com/openlka/openlka)|\n"}, "2025-07-18": {"2301.00618": "|[an event-based algorithm for simultaneous 6-dof camera pose tracking and mapping](https://arxiv.org/abs/2301.00618)|[eorb_slam](https://github.com/m-dayani/eorb_slam)|\n", "2311.18149": "|[stf: spatial temporal fusion for trajectory prediction](https://arxiv.org/abs/2311.18149)|[STF-Spatial-Temporal-Fusion-for-Trajectory-Prediction](https://github.com/pengqianhan/STF-Spatial-Temporal-Fusion-for-Trajectory-Prediction)|\n", "2410.14987": "|[seas: few-shot industrial anomaly image generation with separation and sharing fine-tuning](https://arxiv.org/abs/2410.14987)|[SeaS](https://github.com/HUST-SLOW/SeaS)|\n", "2410.23114": "|[unified triplet-level hallucination evaluation for large vision-language models](https://arxiv.org/abs/2410.23114)|[tri-he](https://github.com/wujunjie1998/tri-he)|\n", "2411.01866": "|[improving trust estimation in human-robot collaboration using beta reputation at fine-grained timescales](https://arxiv.org/abs/2411.01866)|[robot-learning-human-trust](https://github.com/resuldagdanov/robot-learning-human-trust)|\n", "2411.09502": "|[golden noise for diffusion models: a learning framework](https://arxiv.org/abs/2411.09502)|[golden-noise-for-diffusion-models](https://github.com/xie-lab-ml/golden-noise-for-diffusion-models)|\n", "2412.02197": "|[cascaded multi-scale attention for enhanced multi-scale feature extraction and interaction with low-resolution images](https://arxiv.org/abs/2412.02197)|[cmsa](https://github.com/xyonglu/cmsa)|\n", "2412.04106": "|[mrgen: segmentation data engine for underrepresented mri modalities](https://arxiv.org/abs/2412.04106)|[MRGen](https://github.com/haoningwu3639/MRGen)|\n", "2501.14048": "|[sidda: sinkhorn dynamic domain adaptation for image classification with equivariant neural networks](https://arxiv.org/abs/2501.14048)|[gcnn_da](https://github.com/deepskies/gcnn_da)|\n", "2501.19034": "|[xrf v2: a dataset for action summarization with wi-fi signals, and imus in phones, watches, earbuds, and glasses](https://arxiv.org/abs/2501.19034)|[xrfv2](https://github.com/aiotgroup/xrfv2)|\n", "2502.10088": "|[enhancing patient acceptance of robotic ultrasound through conversational virtual agent and immersive visualizations](https://arxiv.org/abs/2502.10088)|[Robotic-US-with-Virtual-Agent](https://github.com/stytim/Robotic-US-with-Virtual-Agent)|\n", "2502.14908": "|[segsub: evaluating robustness to knowledge conflicts and hallucinations in vision-language models](https://arxiv.org/abs/2502.14908)|[SegSub](https://github.com/CASOS-IDeaS-CMU/SegSub)|\n", "2506.11133": "|[monocular 3d hand pose estimation with implicit camera alignment](https://arxiv.org/abs/2506.11133)|[handrepo](https://github.com/cpantazop/handrepo)|\n", "2506.12610": "|[oscnet v1.5: energy efficient hopfield network on cmos oscillators for image classification](https://arxiv.org/abs/2506.12610)|[oscnet](https://github.com/russrobin/oscnet)|\n"}, "2025-07-19": {}, "2025-07-20": {}}