{"2025-04-15": {"2408.07817": "|[myogestic: emg interfacing framework for decoding multiple spared degrees of freedom of the hand in individuals with neural lesions](https://arxiv.org/abs/2408.07817)|[MyoGestic](https://github.com/NsquaredLab/MyoGestic)|\n", "2408.10397": "|[webcam-based pupil diameter prediction benefits from upscaling](https://arxiv.org/abs/2408.10397)|[webcam-based-pupil-diameter-estimation](https://github.com/vijulshah/webcam-based-pupil-diameter-estimation)|\n", "2412.00905": "|[ref-gs: directional factorization for 2d gaussian splatting](https://arxiv.org/abs/2412.00905)|[Ref-GS](https://github.com/YoujiaZhang/Ref-GS)|\n", "2503.03953": "|[geoden: a visual exploration tool for analysing the geographic spread of dengue serotypes](https://arxiv.org/abs/2503.03953)|[GeoDEN](https://github.com/geohai/GeoDEN)|\n", "2503.04707": "|[iris style transfer: enhancing iris recognition with style features and privacy preservation through neural style transfer](https://arxiv.org/abs/2503.04707)|[Iris-Style-Transfer](https://gitlab.lrz.de/hctl/Iris-Style-Transfer)|\n", "2504.07210": "|[mesa: text-driven terrain generation using latent diffusion and global copernicus data](https://arxiv.org/abs/2504.07210)|[MESA](https://github.com/PaulBorneP/MESA)|\n", "2504.08256": "|[rag-vr: leveraging retrieval-augmented generation for 3d question answering in vr environments](https://arxiv.org/abs/2504.08256)|[RAG-VR](https://github.com/sding11/RAG-VR)|\n", "2504.08875": "|[datamap: a portable application for visualizing high-dimensional data](https://arxiv.org/abs/2504.08875)|[datamap](https://github.com/gexijin/datamap)|\n", "2504.09213": "|[spiking neural network for intra-cortical brain signal decoding](https://arxiv.org/abs/2504.09213)|[SNN_iBCIs](https://github.com/SongYang008/SNN_iBCIs)|\n", "2504.09221": "|[cmcrd: cross-modal contrastive representation distillation for emotion recognition](https://arxiv.org/abs/2504.09221)|[cmcrd](https://github.com/kssyyy/cmcrd)|\n", "2504.09352": "|[explorer: robust collection of interactable gui elements](https://arxiv.org/abs/2504.09352)|[Explorer](https://github.com/varnelis/Explorer)|\n", "2504.09623": "|[ges3vig: incorporating pointing gestures into language-based 3d visual grounding for embodied reference understanding](https://arxiv.org/abs/2504.09623)|[ges3vig](https://github.com/atharvmane/ges3vig)|\n", "2504.09689": "|[emoagent: assessing and safeguarding human-ai interaction for mental health safety](https://arxiv.org/abs/2504.09689)|[emoagent](https://github.com/1akaman/emoagent)|\n", "2504.09697": "|[spice: a synergistic, precise, iterative, and customizable image editing workflow](https://arxiv.org/abs/2504.09697)|[spice](https://github.com/kenantang/spice)|\n", "2504.09717": "|[adapting robot's explanation for failures based on observed human behavior in human-robot collaboration](https://arxiv.org/abs/2504.09717)|[adapting-robot-explanation-for-failures](https://github.com/andreasnaoum/adapting-robot-explanation-for-failures)|\n", "2504.09734": "|[dynamik: syntactically-driven dynamic font sizing for emphasis of key information](https://arxiv.org/abs/2504.09734)|[Dynamik_experiment](https://github.com/nawta/Dynamik_experiment)|\n", "2504.09737": "|[can llm feedback enhance review quality? a randomized study of 20k reviews at iclr 2025](https://arxiv.org/abs/2504.09737)|[review_feedback_agent](https://github.com/zou-group/review_feedback_agent)|\n", "2504.09846": "|[glytwin: digital twin for glucose control in type 1 diabetes through optimal behavioral modifications using patient-centric counterfactuals](https://arxiv.org/abs/2504.09846)|[glytwin](https://github.com/arefeen06088/glytwin)|\n", "2504.09865": "|[labeling messages as ai-generated does not reduce their persuasive effects](https://arxiv.org/abs/2504.09865)|[ai-authorship-persuasion](https://github.com/i-gallegos/ai-authorship-persuasion)|\n", "2504.10134": "|[let's talk about it: making scientific computational reproducibility easy](https://arxiv.org/abs/2504.10134)|[adsketch](https://github.com/opspai/adsketch)|\n", "2504.10258": "|[xy-cut++: advanced layout ordering via hierarchical mask mechanism on a novel benchmark](https://arxiv.org/abs/2504.10258)|[PaddleXrc](https://github.com/liushuai35/PaddleXrc)|\n", "2504.10443": "|[multimodal long video modeling based on temporal dynamic context](https://arxiv.org/abs/2504.10443)|[tdc-video](https://github.com/hoar012/tdc-video)|\n"}, "2025-04-14": {"2311.08957": "|[i was blind but now i see: implementing vision-enabled dialogue in social robots](https://arxiv.org/abs/2311.08957)|[vision-enabled-dialogue](https://github.com/giubots/vision-enabled-dialogue)|\n", "2406.14567": "|[dragposer: motion reconstruction from variable sparse tracking signals via latent space optimization](https://arxiv.org/abs/2406.14567)|[DragPoser](https://github.com/UPC-ViRVIG/DragPoser)|\n", "2409.16938": "|[generative object insertion in gaussian splatting with a multi-view diffusion model](https://arxiv.org/abs/2409.16938)|[multiview_inpaint](https://github.com/jiutongbro/multiview_inpaint)|\n", "2501.08561": "|[ansr-dt: an adaptive neuro-symbolic learning and reasoning framework for digital twins](https://arxiv.org/abs/2501.08561)|[ansr-dt](https://github.com/sbhakim/ansr-dt)|\n", "2504.01153": "|[catch me if you search: when contextual web search results affect the detection of hallucinations](https://arxiv.org/abs/2504.01153)|[CatchMeIfYouSearch](https://github.com/MahjabinNahar/CatchMeIfYouSearch)|\n", "2504.07999": "|[igg: image generation informed by geodesic dynamics in deformation spaces](https://arxiv.org/abs/2504.07999)|[igg](https://github.com/nellie689/igg)|\n"}, "2025-04-13": {}, "2025-04-12": {}, "2025-04-11": {"2412.03371": "|[sgsst: scaling gaussian splatting styletransfer](https://arxiv.org/abs/2412.03371)|[SGSST](https://github.com/JianlingWANG2021/SGSST)|\n", "2412.08912": "|[reversing the damage: a qp-aware transformer-diffusion approach for 8k video restoration under codec compression](https://arxiv.org/abs/2412.08912)|[DiQP](https://github.com/alimd94/DiQP)|\n", "2502.18348": "|[towards softerware: enabling personalization of interactive data representations for users with disabilities](https://arxiv.org/abs/2502.18348)|[highcharts-a11y-prototyping](https://github.com/highcharts/highcharts-a11y-prototyping)|\n", "2504.07521": "|[why we feel: breaking boundaries in emotional reasoning with multimodal large language models](https://arxiv.org/abs/2504.07521)|[eibench](https://github.com/lum1104/eibench)|\n", "2504.07870": "|[open datasets for grid modeling and visualization: an alberta power network case](https://arxiv.org/abs/2504.07870)|[carbondistributionmap](https://github.com/bencheng2/carbondistributionmap)|\n"}, "2025-04-10": {"2409.17550": "|[a simple but strong baseline for sounding video generation: effective adaptation of audio and video diffusion models for joint generation](https://arxiv.org/abs/2409.17550)|[svg_baseline](https://github.com/sonyresearch/svg_baseline)|\n", "2412.12225": "|[dlf: disentangled-language-focused multimodal sentiment analysis](https://arxiv.org/abs/2412.12225)|[dlf](https://github.com/pwang322/dlf)|\n", "2503.05639": "|[videopainter: any-length video inpainting and editing with plug-and-play context control](https://arxiv.org/abs/2503.05639)|[VideoPainter](https://github.com/TencentARC/VideoPainter)|\n", "2504.06677": "|[setup-invariant augmented reality for teaching by demonstration with surgical robots](https://arxiv.org/abs/2504.06677)|[dv-stear_public](https://github.com/alexandrebanks6/dv-stear_public)|\n", "2504.06751": "|[visualisation of a multidimensional point cloud as a 3d swarm of avatars](https://arxiv.org/abs/2504.06751)|[n-dim-view](https://github.com/iitis/n-dim-view)|\n"}, "2025-04-16": {"2210.04723": "|[experiential explanations for reinforcement learning](https://arxiv.org/abs/2210.04723)|[experiential-explanations-rl](https://github.com/amal994/experiential-explanations-rl)|\n", "2303.01396": "|[mlanet: multi-level attention network with sub-instruction for continuous vision-and-language navigation](https://arxiv.org/abs/2303.01396)|[mla](https://github.com/ravenkiller/mla)|\n", "2402.04620": "|[cataractbot: an llm-powered expert-in-the-loop chatbot for cataract patients](https://arxiv.org/abs/2402.04620)|[byoeb](https://github.com/microsoft/byoeb)|\n", "2407.19631": "|[\"a good bot always knows its limitations\": assessing autonomous system decision-making competencies through factorized machine self-confidence](https://arxiv.org/abs/2407.19631)|[FaMSeC](https://github.com/COHRINT/FaMSeC)|\n", "2412.09353": "|[causal graphical models for vision-language compositional understanding](https://arxiv.org/abs/2412.09353)|[COGT](https://github.com/aimagelab/COGT)|\n", "2504.05862": "|[are generative ai agents effective personalized financial advisors?](https://arxiv.org/abs/2504.05862)|[LLMAdvisor_supplementary](https://github.com/TTsamurai/LLMAdvisor_supplementary)|\n", "2504.09861": "|[ethosgpt: mapping human value diversity to advance sustainable development goals (sdgs)](https://arxiv.org/abs/2504.09861)|[EthoGPT-DB](https://github.com/sunshineluyao/EthoGPT-DB)|\n", "2504.09975": "|[octgpt: octree-based multiscale autoregressive models for 3d shape generation](https://arxiv.org/abs/2504.09975)|[octgpt](https://github.com/octree-nn/octgpt)|\n", "2504.10489": "|[roamify: designing and evaluating an llm based google chrome extension for personalised itinerary planning](https://arxiv.org/abs/2504.10489)|[roamify](https://github.com/roamify-research/roamify)|\n", "2504.10739": "|[hippomm: hippocampal-inspired multimodal memory for long audiovisual event understanding](https://arxiv.org/abs/2504.10739)|[hippomm](https://github.com/linyueqian/hippomm)|\n", "2504.11349": "|[explicit and implicit representations in ai-based 3d reconstruction for radiology: a systematic literature review](https://arxiv.org/abs/2504.11349)|[ai4med](https://github.com/bean-young/ai4med)|\n"}, "2025-04-17": {"2309.12029": "|[exploring self-supervised skeleton-based action recognition in occluded environments](https://arxiv.org/abs/2309.12029)|[opstl](https://github.com/cyfml/opstl)|\n", "2403.14773": "|[streamingt2v: consistent, dynamic, and extendable long video generation from text](https://arxiv.org/abs/2403.14773)|[streamingt2v](https://github.com/picsart-ai-research/streamingt2v)|\n", "2408.14477": "|[rise-ieeg: robust to inter-subject electrodes implantation variability ieeg classifier](https://arxiv.org/abs/2408.14477)|[RISE-iEEG](https://github.com/MaryamOstadsharif/RISE-iEEG)|\n", "2502.04942": "|[wikireddit: tracing information and attention flows between online platforms](https://arxiv.org/abs/2502.04942)|[wikireddit](https://github.com/pgilders/wikireddit)|\n", "2502.06817": "|[diffusion-empowered autoprompt medsam](https://arxiv.org/abs/2502.06817)|[autopromptmedsam](https://github.com/hp-ml/autopromptmedsam)|\n", "2504.11491": "|[attention ghostunet++: enhanced segmentation of adipose tissue and liver in ct images](https://arxiv.org/abs/2504.11491)|[attention-ghostunetplusplus](https://github.com/mansoorhayat777/attention-ghostunetplusplus)|\n"}, "2025-04-18": {"2408.05667": "|[phishlang: a real-time, fully client-side phishing detection framework using mobilebert](https://arxiv.org/abs/2408.05667)|[phishlang](https://github.com/uta-sprlab/phishlang)|\n", "2409.14319": "|[scene-text grounding for text-based video question answering](https://arxiv.org/abs/2409.14319)|[vitxt-gqa](https://github.com/zhousheng97/vitxt-gqa)|\n", "2410.10291": "|[evaluating semantic variation in text-to-image synthesis: a causal perspective](https://arxiv.org/abs/2410.10291)|[semvarbench](https://github.com/zhuxiangru/semvarbench)|\n", "2501.09012": "|[multimodal llms can reason about aesthetics in zero-shot](https://arxiv.org/abs/2501.09012)|[mllm4art](https://github.com/songrise/mllm4art)|\n", "2504.07521": "|[why we feel: breaking boundaries in emotional reasoning with multimodal large language models](https://arxiv.org/abs/2504.07521)|[eibench](https://github.com/lum1104/eibench)|\n", "2504.12451": "|[one model to rig them all: diverse skeleton rigging with unirig](https://arxiv.org/abs/2504.12451)|[UniRig](https://github.com/VAST-AI-Research/UniRig)|\n", "2504.12452": "|[planglow: personalized study planning with an explainable and controllable llm-driven system](https://arxiv.org/abs/2504.12452)|[PlanGlow](https://github.com/dreamlab-24/PlanGlow)|\n", "2504.12492": "|[mobileposer: real-time full-body pose estimation and 3d human translation from imus in mobile consumer devices](https://arxiv.org/abs/2504.12492)|[MobilePoser](https://github.com/SPICExLAB/MobilePoser)|\n", "2504.12809": "|[saliency-aware diffusion reconstruction for effective invisible watermark removal](https://arxiv.org/abs/2504.12809)|[sadre](https://github.com/inzamamuldu/sadre)|\n", "2504.12900": "|[fashiondpo:fine-tune fashion outfit generation model using direct preference optimization](https://arxiv.org/abs/2504.12900)|[fashiondpo](https://github.com/yzcreator/fashiondpo)|\n"}, "2025-04-19": {}, "2025-04-20": {}, "2025-04-21": {"2502.12110": "|[a-mem: agentic memory for llm agents](https://arxiv.org/abs/2502.12110)|[a-mem](https://github.com/agiresearch/a-mem)|\n", "2504.11936": "|[mind2matter: creating 3d models from eeg signals](https://arxiv.org/abs/2504.11936)|[mind2matter](https://github.com/sddwwww/mind2matter)|\n"}, "2025-04-22": {"2406.00888": "|[aligning language models with demonstrated feedback](https://arxiv.org/abs/2406.00888)|[demonstrated-feedback](https://github.com/SALT-NLP/demonstrated-feedback)|\n", "2408.13611": "|[real-time rendering of glints in the presence of area lights](https://arxiv.org/abs/2408.13611)|[arealightglintsunityproject](https://github.com/tomix1024/arealightglintsunityproject)|\n", "2503.21088": "|[zjuklab at semeval-2025 task 4: unlearning via model merging](https://arxiv.org/abs/2503.21088)|[unlearn](https://github.com/zjunlp/unlearn)|\n", "2504.09689": "|[emoagent: assessing and safeguarding human-ai interaction for mental health safety](https://arxiv.org/abs/2504.09689)|[emoagent](https://github.com/1akaman/emoagent)|\n", "2504.13095": "|[should we tailor the talk? understanding the impact of conversational styles on preference elicitation in conversational recommender systems](https://arxiv.org/abs/2504.13095)|[umap2025-convstyles](https://github.com/iai-group/umap2025-convstyles)|\n", "2504.15101": "|[neugaze: reshaping the future bci](https://arxiv.org/abs/2504.15101)|[neugaze](https://github.com/neuspeech/neugaze)|\n", "2504.15133": "|[easyedit2: an easy-to-use steering framework for editing large language models](https://arxiv.org/abs/2504.15133)|[easyedit](https://github.com/zjunlp/easyedit)|\n"}, "2025-04-23": {"2410.02003": "|[terrainav sim: an open-source simulation of uav aerial imaging from satellite data](https://arxiv.org/abs/2410.02003)|[TerrAInav-Sim](https://github.com/JacobsSensorLab/TerrAInav-Sim)|\n", "2410.07369": "|[an undetectable watermark for generative image models](https://arxiv.org/abs/2410.07369)|[prc-watermark](https://github.com/xuandongzhao/prc-watermark)|\n", "2504.09697": "|[spice: a synergistic, precise, iterative, and customizable image editing workflow](https://arxiv.org/abs/2504.09697)|[spice](https://github.com/kenantang/spice)|\n", "2504.09865": "|[labeling messages as ai-generated does not reduce their persuasive effects](https://arxiv.org/abs/2504.09865)|[ai-authorship-persuasion](https://github.com/i-gallegos/ai-authorship-persuasion)|\n", "2504.12977": "|[a phenomenological approach to analyzing user queries in it systems using heidegger's fundamental ontology](https://arxiv.org/abs/2504.12977)|[15241370](https://zenodo.org/record/15241370)|\n"}, "2025-04-24": {"2403.13924": "|[lfs-aware surface reconstruction from unoriented 3d point clouds](https://arxiv.org/abs/2403.13924)|[lfs-aware-reconstruction](https://github.com/bizerfr/lfs-aware-reconstruction)|\n", "2405.07229": "|[mm-instructeval: zero-shot evaluation of (multimodal) large language models on multimodal reasoning tasks](https://arxiv.org/abs/2405.07229)|[MM-InstructEval](https://github.com/declare-lab/MM-InstructEval)|\n", "2407.15842": "|[diffartist: towards structure and appearance controllable image stylization](https://arxiv.org/abs/2407.15842)|[Artist](https://github.com/songrise/Artist)|\n", "2504.16323": "|[media content atlas: a pipeline to explore and investigate multidimensional media space using multimodal llms](https://arxiv.org/abs/2504.16323)|[mediacontentatlas](https://github.com/mediacontentatlas/mediacontentatlas)|\n"}, "2025-04-25": {"2504.17253": "|[dive: inverting conditional diffusion models for discriminative tasks](https://arxiv.org/abs/2504.17253)|[DIVE](https://github.com/LiYinqi/DIVE)|\n"}, "2025-04-26": {}, "2025-04-27": {}, "2025-04-28": {"2309.14786": "|[treating motion as option with output selection for unsupervised video object segmentation](https://arxiv.org/abs/2309.14786)|[tmo](https://github.com/suhwan-cho/tmo)|\n", "2310.19380": "|[transxnet: learning both global and local dynamics with a dual dynamic token mixer for visual recognition](https://arxiv.org/abs/2310.19380)|[transxnet](https://github.com/lmmmeng/transxnet)|\n", "2312.02252": "|[storygpt-v: large language models as consistent story visualizers](https://arxiv.org/abs/2312.02252)|[StoryGPT-V](https://github.com/xiaoqian-shen/StoryGPT-V)|\n", "2402.11908": "|[semantic textual similarity assessment in chest x-ray reports using a domain-specific cosine-based metric](https://arxiv.org/abs/2402.11908)|[medical-corpus-semantic-similarity-evaluation](https://github.com/sayeh1994/medical-corpus-semantic-similarity-evaluation)|\n", "2405.15638": "|[m4u: evaluating multilingual understanding and reasoning for large multimodal models](https://arxiv.org/abs/2405.15638)|[m4u](https://github.com/m4u-benchmark/m4u)|\n", "2406.18037": "|[towards synchronous memorizability and generalizability with site-modulated diffusion replay for cross-site continual segmentation](https://arxiv.org/abs/2406.18037)|[smg-learning](https://github.com/dyxu-cuhkcse/smg-learning)|\n", "2408.10581": "|[multi-view hand reconstruction with a point-embedded transformer](https://arxiv.org/abs/2408.10581)|[poem-v2](https://github.com/jubsteven/poem-v2)|\n", "2408.11748": "|[understanding depth and height perception in large visual-language models](https://arxiv.org/abs/2408.11748)|[dh-bench](https://github.com/sacrcv/dh-bench)|\n", "2409.09366": "|[mhad: multimodal home activity dataset with multi-angle videos and synchronized physiological signals](https://arxiv.org/abs/2409.09366)|[mhad-dataset](https://github.com/jdh-algo/mhad-dataset)|\n", "2410.22784": "|[contrastive learning and adversarial disentanglement for task-oriented semantic communications](https://arxiv.org/abs/2410.22784)|[clad](https://github.com/omarerak/clad)|\n", "2411.12792": "|[clic: contrastive learning framework for unsupervised image complexity representation](https://arxiv.org/abs/2411.12792)|[clic](https://github.com/xauat-liushipeng/clic)|\n", "2411.16718": "|[neuro-symbolic evaluation of text-to-video models using formal verification](https://arxiv.org/abs/2411.16718)|[NeuS-V](https://github.com/UTAustin-SwarmLab/NeuS-V)|\n", "2412.07199": "|[a parametric approach to adversarial augmentation for cross-domain iris presentation attack detection](https://arxiv.org/abs/2412.07199)|[adv-gen-irispad](https://github.com/iprobe-lab/adv-gen-irispad)|\n", "2501.10917": "|[decomposing and fusing intra- and inter-sensor spatio-temporal signal for multi-sensor wearable human activity recognition](https://arxiv.org/abs/2501.10917)|[decomposewhar](https://github.com/anakin2555/decomposewhar)|\n", "2502.19260": "|[emt: a visual multi-task benchmark dataset for autonomous driving in the arab gulf region](https://arxiv.org/abs/2502.19260)|[emt-dataset](https://github.com/av-lab/emt-dataset)|\n", "2504.03096": "|[scaling open-vocabulary action detection](https://arxiv.org/abs/2504.03096)|[sia_act](https://github.com/siatheindochinese/sia_act)|\n", "2504.14509": "|[dreamid: high-fidelity and fast diffusion-based face swapping via triplet id group learning](https://arxiv.org/abs/2504.14509)|[DreamID](https://github.com/superhero-7/DreamID)|\n", "2504.14603": "|[ufo2: the desktop agentos](https://arxiv.org/abs/2504.14603)|[UFO](https://github.com/microsoft/UFO)|\n", "2504.16656": "|[skywork r1v2: multimodal hybrid reinforcement learning for reasoning](https://arxiv.org/abs/2504.16656)|[Skywork-R1V](https://github.com/SkyworkAI/Skywork-R1V)|\n", "2504.17815": "|[visibility-uncertainty-guided 3d gaussian inpainting via scene conceptional learning](https://arxiv.org/abs/2504.17815)|[VISTA](https://github.com/Aswhalefall/VISTA)|\n", "2504.18419": "|[a multimodal hybrid late-cascade fusion network for enhanced 3d object detection](https://arxiv.org/abs/2504.18419)|[HybridLateCascadeFusion](https://github.com/CarloSgaravatti/HybridLateCascadeFusion)|\n"}, "2025-04-29": {"2109.08843": "|[memory regulation and alignment toward generalizer rgb-infrared person](https://arxiv.org/abs/2109.08843)|[MGMRA](https://github.com/Chenfeng1271/MGMRA)|\n", "2110.12915": "|[revealing unforeseen diagnostic image features with deep learning by detecting cardiovascular diseases from apical four-chamber ultrasounds](https://arxiv.org/abs/2110.12915)|[disease-detection-and-diagnostic-image-feature](https://github.com/lishinc/disease-detection-and-diagnostic-image-feature)|\n", "2211.13726": "|[lightweight event-based optical flow estimation via iterative deblurring](https://arxiv.org/abs/2211.13726)|[idnet](https://github.com/tudelft/idnet)|\n", "2304.04421": "|[local-global temporal difference learning for satellite video super-resolution](https://arxiv.org/abs/2304.04421)|[lgtd](https://github.com/xy-boy/lgtd)|\n", "2305.15956": "|[anomaly detection with conditioned denoising diffusion models](https://arxiv.org/abs/2305.15956)|[DDAD](https://github.com/arimousa/DDAD)|\n", "2310.18961": "|[anomalyclip: object-agnostic prompt learning for zero-shot anomaly detection](https://arxiv.org/abs/2310.18961)|[anomalyclip](https://github.com/zqhang/anomalyclip)|\n", "2311.01090": "|[infusion: internal diffusion for inpainting of dynamic textures and complex motion](https://arxiv.org/abs/2311.01090)|[infusion](https://github.com/ncherel/infusion)|\n", "2401.17515": "|[semantic-syntactic discrepancy in images (ssdi): learning meaning and order of features from natural images](https://arxiv.org/abs/2401.17515)|[SSDI](https://github.com/ChunTao1999/SSDI)|\n", "2402.12185": "|[chartx & chartvlm: a versatile benchmark and foundation model for complicated chart reasoning](https://arxiv.org/abs/2402.12185)|[chartvlm](https://github.com/alpha-innovator/chartvlm)|\n", "2403.09554": "|[cloud gap-filling with deep learning for improved grassland monitoring](https://arxiv.org/abs/2403.09554)|[deep-learning-for-cloud-gap-filling-on-normalized-difference-vegetation-index](https://github.com/agri-hub/deep-learning-for-cloud-gap-filling-on-normalized-difference-vegetation-index)|\n", "2403.10413": "|[real-time image segmentation via hybrid convolutional-transformer architecture search](https://arxiv.org/abs/2403.10413)|[hyctas](https://github.com/marvinyu1995/hyctas)|\n", "2403.13642": "|[h-vmunet: high-order vision mamba unet for medical image segmentation](https://arxiv.org/abs/2403.13642)|[h-vmunet](https://github.com/wurenkai/h-vmunet)|\n", "2403.20331": "|[unsolvable problem detection: robust understanding evaluation for large multimodal models](https://arxiv.org/abs/2403.20331)|[upd](https://github.com/atsumiyai/upd)|\n", "2404.08535": "|[generalized contrastive learning for multi-modal retrieval and ranking](https://arxiv.org/abs/2404.08535)|[gcl](https://github.com/marqo-ai/gcl)|\n", "2408.08784": "|[multi-task learning approach for intracranial hemorrhage prognosis](https://arxiv.org/abs/2408.08784)|[multitasklearning_ich_prognosis](https://github.com/miriamcobo/multitasklearning_ich_prognosis)|\n", "2409.08775": "|[what should we engineer in prompts? training humans in requirement-driven llm use](https://arxiv.org/abs/2409.08775)|[rope](https://github.com/mqo00/rope)|\n", "2409.09497": "|[multi-scale grouped prototypes for interpretable semantic segmentation](https://arxiv.org/abs/2409.09497)|[scaleprotoseg](https://github.com/eceo-epfl/scaleprotoseg)|\n", "2409.09649": "|[sparx: a sparse cross-layer connection mechanism for hierarchical vision mamba and transformer networks](https://arxiv.org/abs/2409.09649)|[sparx](https://github.com/lmmmeng/sparx)|\n", "2409.17993": "|[sshnet: unsupervised cross-modal homography estimation via problem reformulation and split optimization](https://arxiv.org/abs/2409.17993)|[internet](https://github.com/junchen-yu/internet)|\n", "2409.19954": "|[domain consistency representation learning for lifelong person re-identification](https://arxiv.org/abs/2409.19954)|[DCR](https://github.com/LiuShiBen/DCR)|\n", "2409.20332": "|[devil is in details: locality-aware 3d abdominal ct volume generation for self-supervised organ segmentation](https://arxiv.org/abs/2409.20332)|[Lad](https://github.com/Ryann-Ran/Lad)|\n", "2409.20407": "|[open-source periorbital segmentation dataset for ophthalmic applications](https://arxiv.org/abs/2409.20407)|[periorbital-dataset](https://github.com/aiolab/periorbital-dataset)|\n", "2410.06140": "|[estimating the number of http/3 responses in quic using deep learning](https://arxiv.org/abs/2410.06140)|[VisQUIC](https://github.com/robshahla/VisQUIC)|\n", "2410.07149": "|[towards interpreting visual information processing in vision-language models](https://arxiv.org/abs/2410.07149)|[llava-interp](https://github.com/clemneo/llava-interp)|\n", "2410.16719": "|[progressive compositionality in text-to-image generative models](https://arxiv.org/abs/2410.16719)|[evogen](https://github.com/evansh666/evogen)|\n", "2411.11927": "|[flame: frozen large language models enable data-efficient language-image pre-training](https://arxiv.org/abs/2411.11927)|[flame](https://github.com/miv-xjtu/flame)|\n", "2411.18279": "|[large language model-brained gui agents: a survey](https://arxiv.org/abs/2411.18279)|[LLM-Brained-GUI-Agents-Survey](https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey)|\n", "2412.04653": "|[hidden in the noise: two-stage robust watermarking for images](https://arxiv.org/abs/2412.04653)|[Hidden-in-the-Noise](https://github.com/Kasraarabi/Hidden-in-the-Noise)|\n", "2412.20047": "|[simltd: simple supervised and semi-supervised long-tailed object detection](https://arxiv.org/abs/2412.20047)|[simltd](https://github.com/lexisnexis-risk-open-source/simltd)|\n", "2501.01568": "|[interruption handling for conversational robots](https://arxiv.org/abs/2501.01568)|[interruption-handling-system](https://github.com/intuitivecomputing/interruption-handling-system)|\n", "2501.15579": "|[an explainable biomedical foundation model via large-scale concept-enhanced vision-language pre-training](https://arxiv.org/abs/2501.15579)|[ConceptCLIP](https://github.com/JerrryNie/ConceptCLIP)|\n", "2501.18951": "|[draw2cut: direct on-material annotations for cnc milling](https://arxiv.org/abs/2501.18951)|[Draw2Cut](https://github.com/ApisXia/Draw2Cut)|\n", "2502.02097": "|[vertenet -- a multi-context hybrid cnn transformer for accurate vertebral landmark localization in lateral spine dxa images](https://arxiv.org/abs/2502.02097)|[vertenet](https://github.com/zaidilyas89/vertenet)|\n", "2502.05173": "|[videorope: what makes for good video rotary position embedding?](https://arxiv.org/abs/2502.05173)|[videorope](https://github.com/wiselnn570/videorope)|\n", "2502.08025": "|[from brainwaves to brain scans: a robust neural network for eeg-to-fmri synthesis](https://arxiv.org/abs/2502.08025)|[e2fnet](https://github.com/kgr20/e2fnet)|\n", "2502.10872": "|[corotational hinge-based thin plates/shells](https://arxiv.org/abs/2502.10872)|[libThinPlateShells](https://github.com/liangqx-hku/libThinPlateShells)|\n", "2502.20087": "|[overlock: an overview-first-look-closely-next convnet with context-mixing dynamic kernels](https://arxiv.org/abs/2502.20087)|[overlock](https://github.com/lmmmeng/overlock)|\n", "2503.01576": "|[mri super-resolution reconstruction using efficient diffusion probabilistic model with residual shifting](https://arxiv.org/abs/2503.01576)|[res-srdiff](https://github.com/mosaf/res-srdiff)|\n", "2503.12150": "|[point-cache: test-time dynamic and hierarchical cache for robust and generalizable point cloud analysis](https://arxiv.org/abs/2503.12150)|[point-cache](https://github.com/auniquesun/point-cache)|\n", "2503.13777": "|[8-calves image dataset](https://arxiv.org/abs/2503.13777)|[8-calves](https://github.com/tonyfang04/8-calves)|\n", "2503.23452": "|[videogen-eval: agent-based system for video generation evaluation](https://arxiv.org/abs/2503.23452)|[videogen-eval](https://github.com/ailab-cvc/videogen-eval)|\n", "2504.07089": "|[omnicaptioner: one captioner to rule them all](https://arxiv.org/abs/2504.07089)|[omnicaptioner](https://github.com/alpha-innovator/omnicaptioner)|\n", "2504.07957": "|[mm-ifengine: towards multimodal instruction following](https://arxiv.org/abs/2504.07957)|[mm-ifengine](https://github.com/syuan03/mm-ifengine)|\n", "2504.11019": "|[drift open dataset: a drone-derived intelligence for traffic analysis in urban environment](https://arxiv.org/abs/2504.11019)|[the-drift](https://github.com/aixmobility/the-drift)|\n", "2504.12909": "|[real-time high-fidelity gaussian human avatars with position-based interpolation of spatially distributed mlps](https://arxiv.org/abs/2504.12909)|[mmlphuman](https://github.com/1231234zhan/mmlphuman)|\n", "2504.13499": "|[u-shape mamba: state space model for faster diffusion](https://arxiv.org/abs/2504.13499)|[U-Shape-Mamba](https://github.com/ErgastiAlex/U-Shape-Mamba)|\n", "2504.13617": "|[compile scene graphs with reinforcement learning](https://arxiv.org/abs/2504.13617)|[r1-sgg](https://github.com/gpt4vision/r1-sgg)|\n", "2504.15280": "|[seeing from another perspective: evaluating multi-view understanding in mllms](https://arxiv.org/abs/2504.15280)|[All-Angles-Bench](https://github.com/Chenyu-Wang567/All-Angles-Bench)|\n", "2504.18983": "|[mediaug: exploring visual augmentation in medical imaging](https://arxiv.org/abs/2504.18983)|[MediAug](https://github.com/AIGeeksGroup/MediAug)|\n", "2504.19546": "|[crowd detection using very-fine-resolution satellite imagery](https://arxiv.org/abs/2504.19546)|[CrowdSat-Net](https://github.com/Tong-777777/CrowdSat-Net)|\n", "2504.19863": "|[towards ball spin and trajectory analysis in table tennis broadcast videos via physically grounded synthetic-to-real transfer](https://arxiv.org/abs/2504.19863)|[SpinAndTrajectoryTableTennis](https://github.com/KieDani/SpinAndTrajectoryTableTennis)|\n"}, "2025-04-30": {"2303.01903": "|[prophet: prompting large language models with complementary answer heuristics for knowledge-based visual question answering](https://arxiv.org/abs/2303.01903)|[prophet](https://github.com/milvlg/prophet)|\n", "2306.07520": "|[instruct-reid: a multi-purpose person re-identification task with instructions](https://arxiv.org/abs/2306.07520)|[instruct-reid](https://github.com/hwz-zju/instruct-reid)|\n", "2310.18511": "|[3dcompat$^{++}$: an improved large-scale 3d vision dataset for compositional recognition](https://arxiv.org/abs/2310.18511)|[3dcompat-challenge](https://github.com/cattalyya/3dcompat-challenge)|\n", "2403.12743": "|[controllable face synthesis with semantic latent diffusion models](https://arxiv.org/abs/2403.12743)|[ldm-diffusion-sem](https://github.com/ergastialex/ldm-diffusion-sem)|\n", "2405.17790": "|[instruct-reid++: towards universal purpose instruction-guided person re-identification](https://arxiv.org/abs/2405.17790)|[instruct-reid](https://github.com/hwz-zju/instruct-reid)|\n", "2406.11357": "|[refiner: restructure retrieval content efficiently to advance question-answering capabilities](https://arxiv.org/abs/2406.11357)|[refiner-rag](https://github.com/allen-li1231/refiner-rag)|\n", "2408.13509": "|[dual-interrelated diffusion model for few-shot anomaly image generation](https://arxiv.org/abs/2408.13509)|[dualanodiff](https://github.com/yinyjin/dualanodiff)|\n", "2409.16902": "|[underwater camouflaged object tracking meets vision-language sam2](https://arxiv.org/abs/2409.16902)|[awesome-multimodal-object-tracking](https://github.com/983632847/awesome-multimodal-object-tracking)|\n", "2410.13675": "|[pose-based sign language appearance transfer](https://arxiv.org/abs/2410.13675)|[pose-anonymization](https://github.com/sign-language-processing/pose-anonymization)|\n", "2410.20084": "|[univst: a unified framework for training-free localized video style transfer](https://arxiv.org/abs/2410.20084)|[UniVST](https://github.com/QuanjianSong/UniVST)|\n", "2411.01411": "|[mapping global floods with 10 years of satellite radar data](https://arxiv.org/abs/2411.01411)|[ai4g-flood](https://github.com/microsoft/ai4g-flood)|\n", "2411.10013": "|[efficient depth estimation for unstable stereo camera systems on ar glasses](https://arxiv.org/abs/2411.10013)|[MultiHeadDepth-HomoDepth](https://github.com/UCI-ISA-Lab/MultiHeadDepth-HomoDepth)|\n", "2411.14280": "|[easyhoi: unleashing the power of large models for reconstructing hand-object interactions in the wild](https://arxiv.org/abs/2411.14280)|[EasyHOI](https://github.com/lym29/EasyHOI)|\n", "2411.17982": "|[hi-slam2: geometry-aware gaussian slam for fast monocular scene reconstruction](https://arxiv.org/abs/2411.17982)|[HI-SLAM2](https://github.com/Willyzw/HI-SLAM2)|\n", "2412.16086": "|[towards interpretable radiology report generation via concept bottlenecks using a multi-agentic rag](https://arxiv.org/abs/2412.16086)|[irr-with-cbm-rag](https://github.com/tifat58/irr-with-cbm-rag)|\n", "2501.11153": "|[efficient frame extraction: a novel approach through frame similarity and surgical tool tracking for video segmentation](https://arxiv.org/abs/2501.11153)|[kinematics-afr](https://github.com/leonlha/kinematics-afr)|\n", "2501.16326": "|[movement- and traffic-based user identification in commercial virtual reality applications: threats and opportunities](https://arxiv.org/abs/2501.16326)|[vr_user_id](https://github.com/signetlabdei/vr_user_id)|\n", "2503.00063": "|[nopain: no-box point cloud attack via optimal transport singular boundary](https://arxiv.org/abs/2503.00063)|[nopain](https://github.com/cognaclee/nopain)|\n", "2503.06698": "|[what's in a latent? leveraging diffusion latent space for domain generalization](https://arxiv.org/abs/2503.06698)|[GUIDE](https://github.com/XThomasBU/GUIDE)|\n", "2504.10143": "|[negate or embrace: on how misalignment shapes multimodal representation learning](https://arxiv.org/abs/2504.10143)|[crossmodal_mislaignment](https://github.com/yichaocai1/crossmodal_mislaignment)|\n", "2504.13754": "|[towards accurate and interpretable neuroblastoma diagnosis via contrastive multi-scale pathological image analysis](https://arxiv.org/abs/2504.13754)|[cmswinkan](https://github.com/jsliam94/cmswinkan)|\n", "2504.14582": "|[ntire 2025 challenge on image super-resolution ($\\times$4): methods and results](https://arxiv.org/abs/2504.14582)|[ntire2025_imagesr_x4](https://github.com/zhengchen1999/ntire2025_imagesr_x4)|\n", "2504.20405": "|[scope-mri: bankart lesion detection as a case study in data curation and deep learning for challenging diagnoses](https://arxiv.org/abs/2504.20405)|[scope-mri](https://github.com/sahilsethi0105/scope-mri)|\n"}, "2025-05-01": {"2305.13800": "|[generalizable synthetic image detection via language-guided contrastive learning](https://arxiv.org/abs/2305.13800)|[lasted](https://github.com/highwaywu/lasted)|\n", "2309.06129": "|[leyes: a lightweight framework for deep learning-based eye tracking using synthetic eye images](https://arxiv.org/abs/2309.06129)|[byrneetal_leyes](https://github.com/dcnieho/byrneetal_leyes)|\n", "2401.09736": "|[ddm: a metric for comparing 3d shapes using directional distance fields](https://arxiv.org/abs/2401.09736)|[dirdist](https://github.com/rsy6318/dirdist)|\n", "2403.10635": "|[medslip: medical dual-stream language-image pre-training with pathology-anatomy semantic alignment](https://arxiv.org/abs/2403.10635)|[MeDSLIP](https://github.com/Shef-AIRE/MeDSLIP)|\n", "2407.05679": "|[bevworld: a multimodal world simulator for autonomous driving via scene-level bev latents](https://arxiv.org/abs/2407.05679)|[bevworld](https://github.com/zympsyche/bevworld)|\n", "2409.15545": "|[addressing emotion bias in music emotion recognition and generation with frechet audio distance](https://arxiv.org/abs/2409.15545)|[fadtk](https://github.com/microsoft/fadtk)|\n", "2409.15551": "|[revise, reason, and recognize: llm-based emotion recognition via emotion-specific prompts and asr error correction](https://arxiv.org/abs/2409.15551)|[emotion-prompt](https://github.com/yc-li20/emotion-prompt)|\n", "2409.16920": "|[cross-lingual speech emotion recognition: humans vs. self-supervised models](https://arxiv.org/abs/2409.16920)|[crosslingual_ser](https://github.com/zhan7721/crosslingual_ser)|\n", "2409.16937": "|[semi-supervised cognitive state classification from speech with multi-view pseudo-labeling](https://arxiv.org/abs/2409.16937)|[semi-supervised-training](https://github.com/yc-li20/semi-supervised-training)|\n", "2410.16284": "|[a 3d framework for improving low-latency multi-channel live streaming](https://arxiv.org/abs/2410.16284)|[livestreaming](https://github.com/aizierjiang/livestreaming)|\n", "2411.15388": "|[a contrast-agnostic method for ultra-high resolution claustrum segmentation](https://arxiv.org/abs/2411.15388)|[claustrum_segmentation](https://github.com/chiara-mauri/claustrum_segmentation)|\n", "2411.19509": "|[ditto: motion-space diffusion for controllable realtime talking head synthesis](https://arxiv.org/abs/2411.19509)|[ditto-talkinghead](https://github.com/antgroup/ditto-talkinghead)|\n", "2412.04204": "|[pangaea: a global and inclusive benchmark for geospatial foundation models](https://arxiv.org/abs/2412.04204)|[pangaea-bench](https://github.com/vmarsocci/pangaea-bench)|\n", "2412.06314": "|[cad-unet: a capsule network-enhanced unet architecture for accurate segmentation of covid-19 lung infections from ct images](https://arxiv.org/abs/2412.06314)|[cad-unet](https://github.com/amanotooko-jie/cad-unet)|\n", "2501.16289": "|[multi-view structural convolution network for domain-invariant point cloud recognition of autonomous vehicles](https://arxiv.org/abs/2501.16289)|[mscn](https://github.com/mlmlab/mscn)|\n", "2501.17690": "|[segmentation-aware generative reinforcement network (grn) for tissue layer segmentation in 3-d ultrasound images for chronic low-back pain (clbp) assessment](https://arxiv.org/abs/2501.17690)|[GRN](https://github.com/Francisdadada/GRN)|\n", "2502.03649": "|[all-in-one image compression and restoration](https://arxiv.org/abs/2502.03649)|[all-in-one](https://github.com/zeldam1/all-in-one)|\n", "2502.06805": "|[efficient diffusion models: a survey](https://arxiv.org/abs/2502.06805)|[efficient-diffusion-model-survey](https://github.com/aiot-mlsys-lab/efficient-diffusion-model-survey)|\n", "2503.03327": "|[scalefusionnet: transformer-guided multi-scale feature fusion for skin lesion segmentation](https://arxiv.org/abs/2503.03327)|[scalefusionnet](https://github.com/sqbqamar/scalefusionnet)|\n", "2503.06669": "|[agibot world colosseo: a large-scale manipulation platform for scalable and intelligent embodied systems](https://arxiv.org/abs/2503.06669)|[agibot-world](https://github.com/opendrivelab/agibot-world)|\n", "2503.13435": "|[widerange4d: enabling high-quality 4d reconstruction with wide-range movements and scenes](https://arxiv.org/abs/2503.13435)|[widerange4d](https://github.com/gen-verse/widerange4d)|\n", "2504.09689": "|[emoagent: assessing and safeguarding human-ai interaction for mental health safety](https://arxiv.org/abs/2504.09689)|[emoagent](https://github.com/1akaman/emoagent)|\n", "2504.20114": "|[treehop: generate and filter next query embeddings efficiently for multi-hop question answering](https://arxiv.org/abs/2504.20114)|[treehop-rag](https://github.com/allen-li1231/treehop-rag)|\n", "2504.20923": "|[end-to-end audio deepfake detection from raw waveforms: a rawnet-based approach with cross-dataset evaluation](https://arxiv.org/abs/2504.20923)|[RawNetLite](https://github.com/adipiz99/RawNetLite)|\n", "2504.20948": "|[ds_fusionnet: dynamic dual-stream fusion with bidirectional knowledge distillation for plant disease recognition](https://arxiv.org/abs/2504.20948)|[DS_FusionNet](https://github.com/YanghuiSong/DS_FusionNet)|\n", "2504.21194": "|[geolocating earth imagery from iss: integrating machine learning with astronaut photography for enhanced geographic mapping](https://arxiv.org/abs/2504.21194)|[GeoMapper](https://github.com/VedikaSrivastava/GeoMapper)|\n", "2504.21263": "|[embracing collaboration over competition: condensing multiple prompts for visual in-context learning](https://arxiv.org/abs/2504.21263)|[CVPR25-Condenser](https://github.com/gimpong/CVPR25-Condenser)|\n", "2504.21435": "|[seriesbench: a benchmark for narrative-driven drama series understanding](https://arxiv.org/abs/2504.21435)|[seriesbench-cvpr2025](https://github.com/zackhxn/seriesbench-cvpr2025)|\n"}, "2025-05-02": {"2211.06841": "|[point-dae: denoising autoencoders for self-supervised point cloud learning](https://arxiv.org/abs/2211.06841)|[point-dae](https://github.com/ybzh/point-dae)|\n", "2309.08035": "|[interpretability-aware vision transformer](https://arxiv.org/abs/2309.08035)|[ia-vit](https://github.com/qiangyao1988/ia-vit)|\n", "2312.12028": "|[eyepreserve: identity-preserving iris synthesis](https://arxiv.org/abs/2312.12028)|[EyePreserve](https://github.com/CVRL/EyePreserve)|\n", "2401.03048": "|[latte: latent diffusion transformer for video generation](https://arxiv.org/abs/2401.03048)|[Latte](https://github.com/maxin-cn/Latte)|\n", "2403.16677": "|[fool: addressing the downlink bottleneck in satellite computing with neural feature compression](https://arxiv.org/abs/2403.16677)|[the-fool](https://github.com/rezafuru/the-fool)|\n", "2406.03184": "|[ouroboros3d: image-to-3d generation via 3d-aware recursive diffusion](https://arxiv.org/abs/2406.03184)|[Ouroboros3D](https://github.com/Costwen/Ouroboros3D)|\n", "2409.07284": "|[tld-ready: traffic light detection -- relevance estimation and deployment analysis](https://arxiv.org/abs/2409.07284)|[traffic-light-detection](https://github.com/kastel-mobilitylab/traffic-light-detection)|\n", "2409.08091": "|[ezigen: enhancing zero-shot personalized image generation with precise subject encoding and decoupled guidance](https://arxiv.org/abs/2409.08091)|[EZIGen](https://github.com/ZichengDuan/EZIGen)|\n", "2409.12002": "|[towards global localization using multi-modal object-instance re-identification](https://arxiv.org/abs/2409.12002)|[instance-based-loc](https://github.com/instance-based-loc/instance-based-loc)|\n", "2411.16508": "|[all languages matter: evaluating lmms on culturally diverse 100 languages](https://arxiv.org/abs/2411.16508)|[ALM-Bench](https://github.com/mbzuai-oryx/ALM-Bench)|\n", "2412.18086": "|[generating traffic scenarios via in-context learning to learn better motion planner](https://arxiv.org/abs/2412.18086)|[AutoSceneGen](https://github.com/Ezharjan/AutoSceneGen)|\n", "2501.09503": "|[anystory: towards unified single and multiple subject personalization in text-to-image generation](https://arxiv.org/abs/2501.09503)|[AnyStory](https://github.com/junjiehe96/AnyStory)|\n", "2502.18137": "|[spargeattn: accurate sparse attention accelerating any model inference](https://arxiv.org/abs/2502.18137)|[spargeattn](https://github.com/thu-ml/spargeattn)|\n", "2504.05304": "|[gaussian mixture flow matching models](https://arxiv.org/abs/2504.05304)|[gmflow](https://github.com/lakonik/gmflow)|\n", "2504.21707": "|[recursive kl divergence optimization: a dynamic framework for representation learning](https://arxiv.org/abs/2504.21707)|[RKDO-recursive-kl-divergence-optimization](https://github.com/anthonymartin/RKDO-recursive-kl-divergence-optimization)|\n", "2505.00312": "|[aware-net: adaptive weighted averaging for robust ensemble network in deepfake detection](https://arxiv.org/abs/2505.00312)|[AWARE-NET](https://github.com/recluzegeek/AWARE-NET)|\n", "2505.00502": "|[towards scalable human-aligned benchmark for text-guided image editing](https://arxiv.org/abs/2505.00502)|[HATIE](https://github.com/SuhoRyu/HATIE)|\n", "2505.00681": "|[minerva: evaluating complex video reasoning](https://arxiv.org/abs/2505.00681)|[neptune](https://github.com/google-deepmind/neptune)|\n", "2505.00684": "|[visual test-time scaling for gui agent grounding](https://arxiv.org/abs/2505.00684)|[regionfocus](https://github.com/tiangeluo/regionfocus)|\n", "2505.00703": "|[t2i-r1: reinforcing image generation with collaborative semantic-level and token-level cot](https://arxiv.org/abs/2505.00703)|[t2i-r1](https://github.com/caraj7/t2i-r1)|\n"}, "2025-05-03": {}, "2025-05-04": {}, "2025-05-05": {"2306.03271": "|[volumetric medical image segmentation through dual self-distillation in u-shaped networks](https://arxiv.org/abs/2306.03271)|[dualselfdistillation](https://github.com/soumbane/dualselfdistillation)|\n", "2310.15402": "|[towards contrast-agnostic soft segmentation of the spinal cord](https://arxiv.org/abs/2310.15402)|[contrast-agnostic-softseg-spinalcord](https://github.com/sct-pipeline/contrast-agnostic-softseg-spinalcord)|\n", "2403.02411": "|[ninformer: a network in network transformer with token mixing generated gating function](https://arxiv.org/abs/2403.02411)|[NiNformer](https://github.com/Abdullah-88/NiNformer)|\n", "2404.01330": "|[p-hologen: an end-to-end generative framework for phase-only holograms](https://arxiv.org/abs/2404.01330)|[p-hologen](https://github.com/james0223/p-hologen)|\n", "2404.17347": "|[inspectorraget: an introspection platform for rag evaluation](https://arxiv.org/abs/2404.17347)|[inspectorraget](https://github.com/ibm/inspectorraget)|\n", "2404.18624": "|[do vision & language decoders use images and text equally? how self-consistent are their explanations?](https://arxiv.org/abs/2404.18624)|[cc-shap-vlm](https://github.com/heidelberg-nlp/cc-shap-vlm)|\n", "2406.01494": "|[robust classification by coupling data mollification with label smoothing](https://arxiv.org/abs/2406.01494)|[supervised-mollification](https://github.com/markusheinonen/supervised-mollification)|\n", "2408.08518": "|[visual-friendly concept protection via selective adversarial perturbations](https://arxiv.org/abs/2408.08518)|[VCPro](https://github.com/KululuMi/VCPro)|\n", "2410.01723": "|[harmonica: harmonizing training and inference for better feature caching in diffusion transformer acceleration](https://arxiv.org/abs/2410.01723)|[harmonica](https://github.com/modeltc/harmonica)|\n", "2410.03359": "|[an enhanced harmonic densely connected hybrid transformer network architecture for chronic wound segmentation utilising multi-colour space tensor merging](https://arxiv.org/abs/2410.03359)|[hardnet-cws](https://github.com/mmu-dermatology-research/hardnet-cws)|\n", "2410.19816": "|[divshift: exploring domain-specific distribution shifts in large-scale, volunteer-collected biodiversity datasets](https://arxiv.org/abs/2410.19816)|[DivShift](https://github.com/moiexpositoalonsolab/DivShift)|\n", "2411.06224": "|[stiffgipc: advancing gpu ipc for stiff affine-deformable simulation](https://arxiv.org/abs/2411.06224)|[muda](https://github.com/mugdxy/muda)|\n", "2411.14432": "|[insight-v: exploring long-chain visual reasoning with multimodal large language models](https://arxiv.org/abs/2411.14432)|[insight-v](https://github.com/dongyh20/insight-v)|\n", "2411.16721": "|[steering away from harm: an adaptive approach to defending vision language model against jailbreaks](https://arxiv.org/abs/2411.16721)|[ASTRA](https://github.com/ASTRAL-Group/ASTRA)|\n", "2411.17662": "|[robopepp: vision-based robot pose and joint angle estimation through embedding predictive pre-training](https://arxiv.org/abs/2411.17662)|[robopepp](https://github.com/raktimgg/robopepp)|\n", "2503.05214": "|[gaussian random fields as an abstract representation of patient metadata for multimodal medical image segmentation](https://arxiv.org/abs/2503.05214)|[multimodal-grf](https://github.com/mmu-dermatology-research/multimodal-grf)|\n", "2503.12623": "|[maven: multi-modal attention for valence-arousal emotion network](https://arxiv.org/abs/2503.12623)|[maven_8th_abaw](https://github.com/vrushank-ahire/maven_8th_abaw)|\n", "2504.02782": "|[gpt-imgeval: a comprehensive benchmark for diagnosing gpt4o in image generation](https://arxiv.org/abs/2504.02782)|[gpt-imgeval](https://github.com/picotrex/gpt-imgeval)|\n", "2504.16276": "|[an automated pipeline for few-shot bird call classification: a case study with the tooth-billed pigeon](https://arxiv.org/abs/2504.16276)|[few-shot-bird-call](https://github.com/colossal-compsci/few-shot-bird-call)|\n", "2504.18317": "|[task-oriented communications for visual navigation with edge-aerial collaboration in low altitude economy](https://arxiv.org/abs/2504.18317)|[TOC-Edge-Aerial](https://github.com/fangzr/TOC-Edge-Aerial)|\n", "2505.00056": "|[clustering internet memes through template matching and multi-dimensional similarity](https://arxiv.org/abs/2505.00056)|[meme-clustering](https://github.com/tygobl/meme-clustering)|\n", "2505.00568": "|[multimodal masked autoencoder pre-training for 3d mri-based brain tumor analysis with missing modalities](https://arxiv.org/abs/2505.00568)|[bm-mae](https://github.com/lucas-rbnt/bm-mae)|\n", "2505.00740": "|[fast2comm:collaborative perception combined with prior knowledge](https://arxiv.org/abs/2505.00740)|[fast2comm](https://github.com/zhangzhengbin-tj/fast2comm)|\n", "2505.00772": "|[person detection and re-identification in open-world settings of retail stores and public spaces](https://arxiv.org/abs/2505.00772)|[personReID](https://github.com/brkljac/personReID)|\n", "2505.00866": "|[are minimal radial distortion solvers really necessary for relative pose estimation?](https://arxiv.org/abs/2505.00866)|[rdnet](https://github.com/kocurvik/rdnet)|\n", "2505.00938": "|[cdformer: cross-domain few-shot object detection transformer against feature confusion](https://arxiv.org/abs/2505.00938)|[CDFormer_code](https://github.com/LONGXUANX/CDFormer_code)|\n", "2505.01172": "|[freepca: integrating consistency information across long-short frames in training-free long video generation via principal component analysis](https://arxiv.org/abs/2505.01172)|[freepca](https://github.com/josephtitan/freepca)|\n", "2505.01224": "|[rd-uie: relation-driven state space modeling for underwater image enhancement](https://arxiv.org/abs/2505.01224)|[rd-uie](https://github.com/kkoucy/rd-uie)|\n", "2505.01225": "|[core-set selection for data-efficient land cover segmentation](https://arxiv.org/abs/2505.01225)|[data-centric-rs-classification](https://github.com/keillernogueira/data-centric-rs-classification)|\n", "2505.01257": "|[cameltrack: context-aware multi-cue exploitation for online multi-object tracking](https://arxiv.org/abs/2505.01257)|[CAMELTrack](https://github.com/TrackingLaboratory/CAMELTrack)|\n", "2505.01406": "|[vidstamp: a temporally-aware watermark for ownership and integrity in video diffusion models](https://arxiv.org/abs/2505.01406)|[vidstamp](https://github.com/spin-umass/vidstamp)|\n"}, "2025-05-06": {"2308.04369": "|[sstformer: bridging spiking neural network and memory support transformer for frame-event based recognition](https://arxiv.org/abs/2308.04369)|[sstformer](https://github.com/event-ahu/sstformer)|\n", "2402.04168": "|[informed reinforcement learning for situation-aware traffic rule exceptions](https://arxiv.org/abs/2402.04168)|[informed_rl](https://github.com/fzi-forschungszentrum-informatik/informed_rl)|\n", "2402.15388": "|[on the usability of next-generation authentication: a study on eye movement and brainwave-based mechanisms](https://arxiv.org/abs/2402.15388)|[mockup_paper](https://github.com/kit-ps/mockup_paper)|\n", "2403.07569": "|[exploring challenges in deep learning of single-station ground motion records](https://arxiv.org/abs/2403.07569)|[mage](https://github.com/caglarmert/mage)|\n", "2404.01249": "|[fireants: adaptive riemannian optimization for multi-scale diffeomorphic matching](https://arxiv.org/abs/2404.01249)|[fireants](https://github.com/rohitrango/fireants)|\n", "2405.00318": "|[covariant spatio-temporal receptive fields for spiking neural networks](https://arxiv.org/abs/2405.00318)|[nrf](https://github.com/jegp/nrf)|\n", "2405.01101": "|[enhancing person re-identification via uncertainty feature fusion method and auto-weighted measure combination](https://arxiv.org/abs/2405.01101)|[Enhancing-Person-Re-Identification-via-UFFM-and-AMC](https://github.com/chequanghuy/Enhancing-Person-Re-Identification-via-UFFM-and-AMC)|\n", "2406.07361": "|[deep implicit optimization enables robust learnable features for deformable image registration](https://arxiv.org/abs/2406.07361)|[dio](https://github.com/rohitrango/dio)|\n", "2407.02329": "|[migc++: advanced multi-instance generation controller for image synthesis](https://arxiv.org/abs/2407.02329)|[migc](https://github.com/limuloo/migc)|\n", "2407.05576": "|[care-ego: contact-aware relationship modeling for egocentric interactive hand-object segmentation](https://arxiv.org/abs/2407.05576)|[care-ego](https://github.com/yuggiehk/care-ego)|\n", "2407.12772": "|[lmms-eval: reality check on the evaluation of large multimodal models](https://arxiv.org/abs/2407.12772)|[lmms-eval](https://github.com/evolvinglmms-lab/lmms-eval)|\n", "2408.05411": "|[how does audio influence visual attention in omnidirectional videos? database and model](https://arxiv.org/abs/2408.05411)|[avs-odv](https://github.com/intmegroup/avs-odv)|\n", "2408.13431": "|[face clustering via early stopping and edge recall](https://arxiv.org/abs/2408.13431)|[fc-eser](https://github.com/jumptoliujj/fc-eser)|\n", "2408.17090": "|[fissionvae: federated non-iid image generation with latent space and decoder decomposition](https://arxiv.org/abs/2408.17090)|[fissionvae](https://github.com/rand2ai/fissionvae)|\n", "2409.07271": "|[cfcpalsy: facial image synthesis with cross-fusion cycle diffusion model for facial paralysis individuals](https://arxiv.org/abs/2409.07271)|[cfcpalsy](https://github.com/gaovix/cfcpalsy)|\n", "2409.09724": "|[mfclip: multi-modal fine-grained clip for generalizable diffusion face forgery detection](https://arxiv.org/abs/2409.09724)|[mfclip](https://github.com/jenine-321/mfclip)|\n", "2410.10821": "|[tex4d: zero-shot 4d scene texturing with video diffusion models](https://arxiv.org/abs/2410.10821)|[Tex4D](https://github.com/ZqlwMatt/Tex4D)|\n", "2411.15539": "|[large language model with region-guided referring and grounding for ct report generation](https://arxiv.org/abs/2411.15539)|[reg2rg](https://github.com/zhi-xuan-chen/reg2rg)|\n", "2411.19415": "|[amo sampler: enhancing text rendering with overshooting](https://arxiv.org/abs/2411.19415)|[amo-release](https://github.com/hxixixh/amo-release)|\n", "2412.18165": "|[parallel neural computing for scene understanding from lidar perception in autonomous racing](https://arxiv.org/abs/2412.18165)|[parallel-perception-network](https://github.com/suwesh/parallel-perception-network)|\n", "2501.04206": "|[graphite: graph-based interpretable tissue examination for enhanced explainability in breast cancer histopathology](https://arxiv.org/abs/2501.04206)|[graphite](https://github.com/raktim-mondol/graphite)|\n", "2501.10098": "|[landmarker: a toolkit for anatomical landmark localization in 2d/3d images](https://arxiv.org/abs/2501.10098)|[landmarker](https://github.com/predict-idlab/landmarker)|\n", "2501.10977": "|[smarte-vr: student monitoring and adaptive response technology for e-learning in virtual reality](https://arxiv.org/abs/2501.10977)|[smarte-vr-db](https://github.com/blancelin1/smarte-vr-db)|\n", "2502.00968": "|[code: blockwise control for denoising diffusion models](https://arxiv.org/abs/2502.00968)|[code](https://github.com/anujinho/code)|\n", "2502.01710": "|[dagnet: a dual-view attention-guided network for efficient x-ray security inspection](https://arxiv.org/abs/2502.01710)|[dagnet](https://github.com/shilonghong/dagnet)|\n", "2502.15251": "|[simhand: mining similar hands for large-scale 3d hand pose pre-training](https://arxiv.org/abs/2502.15251)|[simhand](https://github.com/ut-vision/simhand)|\n", "2502.15666": "|[almost ai, almost human: the challenge of detecting ai-polished writing](https://arxiv.org/abs/2502.15666)|[ai-polished-text](https://github.com/ShoumikSaha/ai-polished-text)|\n", "2502.20490": "|[egonormia: benchmarking physical social norm understanding](https://arxiv.org/abs/2502.20490)|[egonormia](https://github.com/open-social-world/egonormia)|\n", "2503.02910": "|[langgas: introducing language in selective zero-shot background subtraction for semi-transparent gas leak detection with a new dataset](https://arxiv.org/abs/2503.02910)|[Lang-Gas](https://github.com/weathon/Lang-Gas)|\n", "2503.06457": "|[geometric knowledge-guided localized global distribution alignment for federated learning](https://arxiv.org/abs/2503.06457)|[2025cvpr_ggeur](https://github.com/weidai-david/2025cvpr_ggeur)|\n", "2504.03471": "|[dynamic importance in diffusion u-net for enhanced image synthesis](https://arxiv.org/abs/2504.03471)|[unetreweighting](https://github.com/hytidel/unetreweighting)|\n", "2504.04519": "|[sam2mot: a novel paradigm of multi-object tracking by segmentation](https://arxiv.org/abs/2504.04519)|[SAM2MOT](https://github.com/TripleJoy/SAM2MOT)|\n", "2504.07392": "|[id-booth: identity-consistent face generation with diffusion models](https://arxiv.org/abs/2504.07392)|[id-booth](https://github.com/dariant/id-booth)|\n", "2504.11936": "|[mind2matter: creating 3d models from eeg signals](https://arxiv.org/abs/2504.11936)|[mind2matter](https://github.com/sddwwww/mind2matter)|\n", "2504.14693": "|[video-mmlu: a massive multi-discipline lecture understanding benchmark](https://arxiv.org/abs/2504.14693)|[video-mmlu](https://github.com/espere-1119-song/video-mmlu)|\n", "2504.20682": "|[og-hfyolo :orientation gradient guidance and heterogeneous feature fusion for deformation table cell instance segmentation](https://arxiv.org/abs/2504.20682)|[oghfyolo](https://github.com/justliulong/oghfyolo)|\n", "2504.20898": "|[cbm-rag: demonstrating enhanced interpretability in radiology report generation with multi-agent rag and concept bottleneck models](https://arxiv.org/abs/2504.20898)|[enhanced-interpretable-report-generation-demo](https://github.com/tifat58/enhanced-interpretable-report-generation-demo)|\n", "2504.20903": "|[modeling ai-human collaboration as a multi-agent adaptation](https://arxiv.org/abs/2504.20903)|[NKC-Multi-Agent-Models](https://github.com/saimihirj/NKC-Multi-Agent-Models)|\n", "2505.00630": "|[vision mamba in remote sensing: a comprehensive survey of techniques, applications and outlook](https://arxiv.org/abs/2505.00630)|[awesome-mamba-in-remote-sensing](https://github.com/baobao0926/awesome-mamba-in-remote-sensing)|\n", "2505.01431": "|[zs-vcos: zero-shot outperforms supervised video camouflaged object segmentation](https://arxiv.org/abs/2505.01431)|[vcos](https://github.com/weathon/vcos)|\n", "2505.01456": "|[unlearning sensitive information in multimodal llms: benchmark and attack-defense evaluation](https://arxiv.org/abs/2505.01456)|[unlok-vqa](https://github.com/vaidehi99/unlok-vqa)|\n", "2505.01476": "|[costfilter-ad: enhancing anomaly detection through matching cost filtering](https://arxiv.org/abs/2505.01476)|[costfilter-ad](https://github.com/zhe-sapi/costfilter-ad)|\n", "2505.01481": "|[videohallu: evaluating and mitigating multi-modal hallucinations for synthetic videos](https://arxiv.org/abs/2505.01481)|[videohallu](https://github.com/zli12321/videohallu)|\n", "2505.01548": "|[rethinking rgb-event semantic segmentation with a novel bidirectional motion-enhanced event representation](https://arxiv.org/abs/2505.01548)|[BRENet](https://github.com/zyaocoder/BRENet)|\n", "2505.01583": "|[tempura: temporal event masked prediction and understanding for reasoning in action](https://arxiv.org/abs/2505.01583)|[tempura](https://github.com/andy-cheng/tempura)|\n", "2505.01644": "|[a dual-task synergy-driven generalization framework for pancreatic cancer segmentation in ct scans](https://arxiv.org/abs/2505.01644)|[dual-task-seg](https://github.com/sjtubme-qianlab/dual-task-seg)|\n", "2505.01699": "|[component-based fairness in face attribute classification with bayesian network-informed meta learning](https://arxiv.org/abs/2505.01699)|[bnmr-faircompface](https://github.com/yliuaa/bnmr-faircompface)|\n", "2505.01724": "|[vistaxa: developing a taxonomy of historical visualizations](https://arxiv.org/abs/2505.01724)|[image-taxonomy-labeler](https://github.com/oldvis/image-taxonomy-labeler)|\n", "2505.01755": "|[lensnet: an end-to-end learning framework for empirical point spread function modeling and lensless imaging reconstruction](https://arxiv.org/abs/2505.01755)|[Lensnet](https://github.com/baijiesong/Lensnet)|\n", "2505.01779": "|[polar interpolants for thin-shell microstructure homogenization](https://arxiv.org/abs/2505.01779)|[polarinterpolants](https://github.com/antoine-chan-lock/polarinterpolants)|\n", "2505.01790": "|[enhancing the learning experience: using vision-language models to generate questions for educational videos](https://arxiv.org/abs/2505.01790)|[aied_2025_video_qg](https://github.com/markossta/aied_2025_video_qg)|\n", "2505.01854": "|[accelerating volumetric medical image annotation via short-long memory sam 2](https://arxiv.org/abs/2505.01854)|[slm-sam2](https://github.com/mazurowski-lab/slm-sam2)|\n", "2505.01938": "|[hybridgs: high-efficiency gaussian splatting data compression using dual-channel sparse representation and point cloud encoder](https://arxiv.org/abs/2505.01938)|[hybridgs](https://github.com/qi-yangsjtu/hybridgs)|\n", "2505.02005": "|[learning heterogeneous mixture of scene experts for large-scale neural radiance fields](https://arxiv.org/abs/2505.02005)|[Switch-NeRF](https://github.com/MiZhenxing/Switch-NeRF)|\n", "2505.02075": "|[benchmarking feature upsampling methods for vision foundation models using interactive segmentation](https://arxiv.org/abs/2505.02075)|[isegprobe](https://github.com/havrylovv/isegprobe)|\n", "2505.02159": "|[small clips, big gains: learning long-range refocused temporal information for video super-resolution](https://arxiv.org/abs/2505.02159)|[lrti-vsr](https://github.com/labshuhanggu/lrti-vsr)|\n", "2505.02179": "|[prodisc-vad: an efficient system for weakly-supervised anomaly detection in video surveillance applications](https://arxiv.org/abs/2505.02179)|[ProDisc-VAD](https://github.com/modadundun/ProDisc-VAD)|\n", "2505.02182": "|[robust ai-generated face detection with imbalanced data](https://arxiv.org/abs/2505.02182)|[sp_cup](https://github.com/purdue-m2/sp_cup)|\n", "2505.02246": "|[cricket: a self-powered chirping pixel](https://arxiv.org/abs/2505.02246)|[cricket-public](https://github.com/columbiacomputervision/cricket-public)|\n", "2505.02325": "|[teda: boosting vision-lanuage models for zero-shot 3d object retrieval via testing-time distribution alignment](https://arxiv.org/abs/2505.02325)|[teda](https://github.com/wangzhichuan123/teda)|\n", "2505.02331": "|[vaemo: efficient representation learning for visual-audio emotion with knowledge injection](https://arxiv.org/abs/2505.02331)|[VAEmo](https://github.com/MSA-LMC/VAEmo)|\n", "2505.02350": "|[sparse ellipsoidal radial basis function network for point cloud surface representation](https://arxiv.org/abs/2505.02350)|[se-rbfnet](https://github.com/lianbobo/se-rbfnet)|\n", "2505.02370": "|[superedit: rectifying and facilitating supervision for instruction-based image editing](https://arxiv.org/abs/2505.02370)|[superedit](https://github.com/bytedance/superedit)|\n", "2505.02385": "|[an arbitrary-modal fusion network for volumetric cranial nerves tract segmentation](https://arxiv.org/abs/2505.02385)|[cntseg](https://github.com/ipis-xielei/cntseg)|\n", "2505.02414": "|[quadrupedal spine control strategies: exploring correlations between system dynamic responses and human perspectives](https://arxiv.org/abs/2505.02414)|[ester](https://github.com/nickick-icrs/ester)|\n", "2505.02481": "|[finger pose estimation for under-screen fingerprint sensor](https://arxiv.org/abs/2505.02481)|[draco](https://github.com/xiongjunguan/draco)|\n", "2505.02654": "|[sim2real in endoscopy segmentation with a novel structure aware image translation](https://arxiv.org/abs/2505.02654)|[sim2real-endoscopysegmentation](https://github.com/ropertuz/sim2real-endoscopysegmentation)|\n", "2505.02705": "|[multi-view learning with context-guided receptance for image denoising](https://arxiv.org/abs/2505.02705)|[crwkv](https://github.com/seeker98/crwkv)|\n", "2505.02746": "|[using knowledge graphs to harvest datasets for efficient clip model training](https://arxiv.org/abs/2505.02746)|[entitynet](https://github.com/lmb-freiburg/entitynet)|\n", "2505.02753": "|[advancing generalizable tumor segmentation with anomaly-aware open-vocabulary attention maps and frozen foundation diffusion models](https://arxiv.org/abs/2505.02753)|[diffugts](https://github.com/yankai96/diffugts)|\n", "2505.02780": "|[beyond the monitor: mixed reality visualization and ai for enhanced digital pathology workflow](https://arxiv.org/abs/2505.02780)|[path_vis](https://github.com/jaiprakash1824/path_vis)|\n", "2505.02823": "|[musar: exploring multi-subject customization from single-subject dataset via attention routing](https://arxiv.org/abs/2505.02823)|[musar](https://github.com/guozinan126/musar)|\n", "2505.02824": "|[towards dataset copyright evasion attack against personalized text-to-image diffusion models](https://arxiv.org/abs/2505.02824)|[ceat2i](https://github.com/csyufei/ceat2i)|\n"}, "2025-05-07": {"2303.12675": "|[vecfontsdf: learning to reconstruct and synthesize high-quality vector fonts via signed distance functions](https://arxiv.org/abs/2303.12675)|[VecFontSDF](https://github.com/ymxbj/VecFontSDF)|\n", "2305.18708": "|[infrared image deturbulence restoration using degradation parameter-assisted wide & deep learning](https://arxiv.org/abs/2305.18708)|[DparNet](https://github.com/Ydo-W/DparNet)|\n", "2311.14284": "|[paragraph-to-image generation with information-enriched diffusion model](https://arxiv.org/abs/2311.14284)|[paradiffusion](https://github.com/weijiawu/paradiffusion)|\n", "2312.01581": "|[plum: improving inference efficiency by leveraging repetition-sparsity trade-off](https://arxiv.org/abs/2312.01581)|[plum](https://github.com/sachitkuhar/plum)|\n", "2401.12033": "|[momentum-sam: sharpness aware minimization without computational overhead](https://arxiv.org/abs/2401.12033)|[msam](https://github.com/marlonbecker/msam)|\n", "2403.08256": "|[ig-fiqa: improving face image quality assessment through intra-class variance guidance robust to inaccurate pseudo-labels](https://arxiv.org/abs/2403.08256)|[IG-FIQA](https://github.com/kim1102/IG-FIQA)|\n", "2407.06606": "|[tailored design of audio-visual speech recognition models using branchformers](https://arxiv.org/abs/2407.06606)|[tailored-avsr](https://github.com/david-gimeno/tailored-avsr)|\n", "2407.08277": "|[stixelnext: toward monocular low-weight perception for object segmentation and free space detection](https://arxiv.org/abs/2407.08277)|[StixelNExT](https://github.com/MarcelVSHNS/StixelNExT)|\n", "2409.07012": "|[towards predicting temporal changes in a patient's chest x-ray images based on electronic health records](https://arxiv.org/abs/2409.07012)|[ehrxdiff](https://github.com/dek924/ehrxdiff)|\n", "2411.03239": "|[decoupling fine detail and global geometry for compressed depth map super-resolution](https://arxiv.org/abs/2411.03239)|[gdnet](https://github.com/ian0926/gdnet)|\n", "2411.18279": "|[large language model-brained gui agents: a survey](https://arxiv.org/abs/2411.18279)|[LLM-Brained-GUI-Agents-Survey](https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey)|\n", "2412.04280": "|[humanedit: a high-quality human-rewarded dataset for instruction-based image editing](https://arxiv.org/abs/2412.04280)|[humanedit](https://github.com/viiika/humanedit)|\n", "2501.18630": "|[deformable beta splatting](https://arxiv.org/abs/2501.18630)|[beta-splatting](https://github.com/RongLiu-Leo/beta-splatting)|\n", "2502.07328": "|[music for all: representational bias and cross-cultural adaptability of music generation models](https://arxiv.org/abs/2502.07328)|[music4all](https://github.com/atharva20038/music4all)|\n", "2502.17648": "|[calibrefine: deep learning-based online automatic targetless lidar-camera calibration with iterative and attention-driven post-refinement](https://arxiv.org/abs/2502.17648)|[Lidar_Camera_Automatic_Calibration](https://github.com/radar-lab/Lidar_Camera_Automatic_Calibration)|\n", "2502.18225": "|[liver cirrhosis stage estimation from mri with deep learning](https://arxiv.org/abs/2502.18225)|[cirrhosisstage](https://github.com/junzengz/cirrhosisstage)|\n", "2503.03307": "|[full-dof egomotion estimation for event cameras using geometric solvers](https://arxiv.org/abs/2503.03307)|[relpose-event](https://github.com/jizhaox/relpose-event)|\n", "2503.04114": "|[organize, then vote: exploring cognitive load in quadratic survey interfaces](https://arxiv.org/abs/2503.04114)|[Quadratic-Survey-Dataset-and-Analysis](https://github.com/CrowdDynamicsLab/Quadratic-Survey-Dataset-and-Analysis)|\n", "2504.01153": "|[catch me if you search: when contextual web search results affect the detection of hallucinations](https://arxiv.org/abs/2504.01153)|[CatchMeIfYouSearch](https://github.com/MahjabinNahar/CatchMeIfYouSearch)|\n", "2504.07606": "|[heart failure prediction using modal decomposition and masked autoencoders for scarce echocardiography databases](https://arxiv.org/abs/2504.07606)|[modelflows-app](https://github.com/modelflows/modelflows-app)|\n", "2504.13754": "|[towards accurate and interpretable neuroblastoma diagnosis via contrastive multi-scale pathological image analysis](https://arxiv.org/abs/2504.13754)|[cmswinkan](https://github.com/jsliam94/cmswinkan)|\n", "2504.17761": "|[step1x-edit: a practical framework for general image editing](https://arxiv.org/abs/2504.17761)|[step1x-edit](https://github.com/stepfun-ai/step1x-edit)|\n", "2504.19244": "|[semantic-aligned learning with collaborative refinement for unsupervised vi-reid](https://arxiv.org/abs/2504.19244)|[code-for-salcr](https://github.com/franklinlingfeng/code-for-salcr)|\n", "2505.01884": "|[adversarial robustness of deep learning models for inland water body segmentation from sar images](https://arxiv.org/abs/2505.01884)|[iwseg-sar-poison](https://github.com/gvcl/iwseg-sar-poison)|\n", "2505.02048": "|[regression is all you need for medical image translation](https://arxiv.org/abs/2505.02048)|[yoda](https://github.com/deep-mi/yoda)|\n", "2505.02064": "|[rtv-bench: benchmarking mllm continuous perception, understanding and reasoning through real-time video](https://arxiv.org/abs/2505.02064)|[rtv-bench](https://github.com/ljungang/rtv-bench)|\n", "2505.02704": "|[vgld: visually-guided linguistic disambiguation for monocular depth scale recovery](https://arxiv.org/abs/2505.02704)|[vgld](https://github.com/pakinwu/vgld)|\n", "2505.02971": "|[adversarial robustness analysis of vision-language models in medical image segmentation](https://arxiv.org/abs/2505.02971)|[secure-private-ai](https://github.com/anjilab/secure-private-ai)|\n", "2505.03007": "|[ntire 2025 challenge on ugc video enhancement: methods and results](https://arxiv.org/abs/2505.03007)|[ntire25_ugc_video_enhancement](https://github.com/msu-video-group/ntire25_ugc_video_enhancement)|\n", "2505.03046": "|[sim2real transfer for vision-based grasp verification](https://arxiv.org/abs/2505.03046)|[hsr-graspsynth](https://github.com/pauamargant/hsr-graspsynth)|\n", "2505.03114": "|[path and bone-contour regularized unpaired mri-to-ct translation](https://arxiv.org/abs/2505.03114)|[pabot](https://github.com/kennysyp/pabot)|\n", "2505.03153": "|[robust fairness vision-language learning for medical image analysis](https://arxiv.org/abs/2505.03153)|[robust_fairness_for_medical_image](https://github.com/purdue-m2/robust_fairness_for_medical_image)|\n", "2505.03242": "|[seeing the abstract: translating the abstract language for vision language models](https://arxiv.org/abs/2505.03242)|[fashionact](https://github.com/davidetalon/fashionact)|\n", "2505.03299": "|[towards efficient benchmarking of foundation models in remote sensing: a capabilities encoding approach](https://arxiv.org/abs/2505.03299)|[capabilities-encoding](https://github.com/pierreadorni/capabilities-encoding)|\n", "2505.03319": "|[sd-vsum: a method and dataset for script-driven video summarization](https://arxiv.org/abs/2505.03319)|[sd-vsum](https://github.com/idt-iti/sd-vsum)|\n", "2505.03401": "|[ddatr: dynamic difference-aware temporal residual network for longitudinal radiology report generation](https://arxiv.org/abs/2505.03401)|[ddatr](https://github.com/xmed-lab/ddatr)|\n", "2505.03422": "|[liftfeat: 3d geometry-aware local feature matching](https://arxiv.org/abs/2505.03422)|[liftfeat](https://github.com/lyp-deeplearning/liftfeat)|\n", "2505.03427": "|[medarabiq: benchmarking large language models on arabic medical tasks](https://arxiv.org/abs/2505.03427)|[medarabiq](https://github.com/nyuad-cai/medarabiq)|\n", "2505.03431": "|[a fusion-guided inception network for hyperspectral image super-resolution](https://arxiv.org/abs/2505.03431)|[fusion](https://github.com/usman1021/fusion)|\n", "2505.03470": "|[blending 3d geometry and machine learning for multi-view stereopsis](https://arxiv.org/abs/2505.03470)|[GC-MVSNet-PlusPlus](https://github.com/vkvats/GC-MVSNet-PlusPlus)|\n", "2505.03480": "|[modeling musical genre trajectories through pathlet learning](https://arxiv.org/abs/2505.03480)|[music_pathlets](https://github.com/lilianmarey/music_pathlets)|\n", "2505.03494": "|[upmad-net: a brain tumor segmentation network with uncertainty guidance and adaptive multimodal feature fusion](https://arxiv.org/abs/2505.03494)|[upmad_net_brainseg](https://github.com/chenzhao2023/upmad_net_brainseg)|\n", "2505.03507": "|[modality-guided dynamic graph fusion and temporal diffusion for self-supervised rgb-t tracking](https://arxiv.org/abs/2505.03507)|[gdstrack](https://github.com/lishenglana/gdstrack)|\n", "2505.03538": "|[rail: region-aware instructive learning for semi-supervised tooth segmentation in cbct](https://arxiv.org/abs/2505.03538)|[rail](https://github.com/tournesol-saturday/rail)|\n", "2505.03539": "|[panoramic out-of-distribution segmentation](https://arxiv.org/abs/2505.03539)|[panoos](https://github.com/mengfeid/panoos)|\n", "2505.03568": "|[familiarizing with music: discovery patterns for different music discovery needs](https://arxiv.org/abs/2505.03568)|[familiarizing_with_music](https://github.com/hcai-mms/familiarizing_with_music)|\n", "2505.03581": "|[dygenc: encoding a sequence of textual scene graphs to reason and answer questions in dynamic scenes](https://arxiv.org/abs/2505.03581)|[dygenc](https://github.com/linukc/dygenc)|\n", "2505.03597": "|[fixed-length dense fingerprint representation](https://arxiv.org/abs/2505.03597)|[flare](https://github.com/yu-yy/flare)|\n", "2505.03623": "|[bounding box-guided diffusion for synthesizing industrial images and segmentation map](https://arxiv.org/abs/2505.03623)|[diffusion_labeling](https://github.com/covisionlab/diffusion_labeling)|\n", "2505.03692": "|[matching distance and geometric distribution aided learning multiview point cloud registration](https://arxiv.org/abs/2505.03692)|[mdgd](https://github.com/shi-qi-li/mdgd)|\n"}, "2025-05-08": {"2301.02008": "|[expressive speech-driven facial animation with controllable emotions](https://arxiv.org/abs/2301.02008)|[facialanimation](https://github.com/on1262/facialanimation)|\n", "2306.07971": "|[xraygpt: chest radiographs summarization using medical vision-language models](https://arxiv.org/abs/2306.07971)|[xraygpt](https://github.com/mbzuai-oryx/xraygpt)|\n", "2311.18681": "|[radialog: a large vision-language model for radiology report generation and conversational assistance](https://arxiv.org/abs/2311.18681)|[radialog](https://github.com/chantalmp/radialog)|\n", "2406.04321": "|[vidmuse: a simple video-to-music generation framework with long-short-term modeling](https://arxiv.org/abs/2406.04321)|[vidmuse](https://github.com/zeyuet/vidmuse)|\n", "2406.17774": "|[uncertainty for svbrdf acquisition using frequency analysis](https://arxiv.org/abs/2406.17774)|[svbrdf_uncertainty](https://github.com/rubenwiersma/svbrdf_uncertainty)|\n", "2407.08364": "|[scalar function topology divergence: comparing topology of 3d objects](https://arxiv.org/abs/2407.08364)|[sftd](https://github.com/ilyatrofimov/sftd)|\n", "2409.15511": "|[bayesian computation with generative diffusion models by multilevel monte carlo](https://arxiv.org/abs/2409.15511)|[mlmcfordms](https://github.com/lshaw8317/mlmcfordms)|\n", "2409.19911": "|[replace anyone in videos](https://arxiv.org/abs/2409.19911)|[unianimate-dit](https://github.com/ali-vilab/unianimate-dit)|\n", "2410.01495": "|[ov-mer: towards open-vocabulary multimodal emotion recognition](https://arxiv.org/abs/2410.01495)|[affectgpt](https://github.com/zeroqiaoba/affectgpt)|\n", "2411.04997": "|[llm2clip: powerful language model unlocks richer visual representation](https://arxiv.org/abs/2411.04997)|[LLM2CLIP](https://github.com/microsoft/LLM2CLIP)|\n", "2411.06911": "|[gaussian process emulators for few-shot segmentation in cardiac mri](https://arxiv.org/abs/2411.06911)|[gpe_4_cardiac_fss](https://gitlab.com/bruno_viti/gpe_4_cardiac_fss)|\n", "2412.03413": "|[deep learning for sea surface temperature reconstruction under cloud occlusion](https://arxiv.org/abs/2412.03413)|[sst_reconstruction](https://github.com/asperti/sst_reconstruction)|\n", "2412.04472": "|[stereo anywhere: robust zero-shot deep stereo matching even where either stereo or mono fail](https://arxiv.org/abs/2412.04472)|[stereoanywhere](https://github.com/bartn8/stereoanywhere)|\n", "2501.16566": "|[affectgpt: a new dataset, model, and benchmark for emotion understanding with multimodal large language models](https://arxiv.org/abs/2501.16566)|[affectgpt](https://github.com/zeroqiaoba/affectgpt)|\n", "2502.01547": "|[mwhisper-flamingo for multilingual audio-visual noise-robust speech recognition](https://arxiv.org/abs/2502.01547)|[whisper-flamingo](https://github.com/roudimit/whisper-flamingo)|\n", "2502.10156": "|[monoforce: learnable image-conditioned physics engine](https://arxiv.org/abs/2502.10156)|[monoforce](https://github.com/ctu-vras/monoforce)|\n", "2502.11178": "|[da-mamba: domain adaptive hybrid mamba-transformer based one-stage object detection](https://arxiv.org/abs/2502.11178)|[damamba](https://github.com/enesdoruk/damamba)|\n", "2504.02287": "|[multisensor-home: a wide-area multi-modal multi-view dataset for action recognition and transformer-based sensor fusion](https://arxiv.org/abs/2504.02287)|[multitsf](https://github.com/thanhhff/multitsf)|\n", "2504.19186": "|[lrfusionpr: a polar bev-based lidar-radar fusion network for place recognition](https://arxiv.org/abs/2504.19186)|[lrfusionpr](https://github.com/qizs-bit/lrfusionpr)|\n", "2504.20468": "|[antidote: a unified framework for mitigating lvlm hallucinations in counterfactual presupposition and object perception](https://arxiv.org/abs/2504.20468)|[antidote](https://github.com/wu0409/antidote)|\n", "2505.01880": "|[weakly-supervised audio temporal forgery localization via progressive audio-language co-learning network](https://arxiv.org/abs/2505.01880)|[LOCO](https://github.com/ItzJuny/LOCO)|\n", "2505.02406": "|[token coordinated prompt attention is needed for visual prompting](https://arxiv.org/abs/2505.02406)|[icml2025-tcpa](https://github.com/zhoujiahuan1991/icml2025-tcpa)|\n", "2505.02471": "|[ming-lite-uni: advancements in unified architecture for natural multimodal interaction](https://arxiv.org/abs/2505.02471)|[ming](https://github.com/inclusionai/ming)|\n", "2505.02567": "|[unified multimodal understanding and generation models: advances, challenges, and opportunities](https://arxiv.org/abs/2505.02567)|[awesome-unified-multimodal-models](https://github.com/aidc-ai/awesome-unified-multimodal-models)|\n", "2505.03440": "|[manvr3d: a platform for human-in-the-loop cell tracking in virtual reality](https://arxiv.org/abs/2505.03440)|[manvr3d](https://github.com/scenerygraphics/manvr3d)|\n", "2505.03631": "|[breaking annotation barriers: generalized video quality assessment via ranking-based self-supervision](https://arxiv.org/abs/2505.03631)|[LMM-PVQA](https://github.com/clh124/LMM-PVQA)|\n", "2505.03836": "|[obd-finder: explainable coarse-to-fine text-centric oracle bone duplicates discovery](https://arxiv.org/abs/2505.03836)|[obd-finder](https://github.com/cszhanglmu/obd-finder)|\n", "2505.03859": "|[deepfakes on demand: the rise of accessible non-consensual deepfake image generators](https://arxiv.org/abs/2505.03859)|[deepfakesondemand](https://github.com/WillHawkins3/deepfakesondemand)|\n", "2505.03896": "|[novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation](https://arxiv.org/abs/2505.03896)|[attukan](https://github.com/stevezs315/attukan)|\n", "2505.03912": "|[openhelix: a short survey, empirical analysis, and open-source dual-system vla model for robotic manipulation](https://arxiv.org/abs/2505.03912)|[OpenHelix](https://github.com/OpenHelix-robot/OpenHelix)|\n", "2505.04003": "|[prototype-based information compensation network for multi-source remote sensing data classification](https://arxiv.org/abs/2505.04003)|[picnet](https://github.com/oucailab/picnet)|\n", "2505.04058": "|[as3d: 2d-assisted cross-modal understanding with semantic-spatial scene graphs for 3d visual grounding](https://arxiv.org/abs/2505.04058)|[AS3D](https://github.com/onmyoji-xiao/AS3D)|\n", "2505.04095": "|[scalable aerial gnss localization for marine robots](https://arxiv.org/abs/2505.04095)|[aerial_gnss](https://github.com/stevvwen/aerial_gnss)|\n", "2505.04119": "|[gaprompt: geometry-aware point cloud prompt for 3d vision model](https://arxiv.org/abs/2505.04119)|[icml2025-vgp](https://github.com/zhoujiahuan1991/icml2025-vgp)|\n", "2505.04121": "|[vision graph prompting via semantic low-rank decomposition](https://arxiv.org/abs/2505.04121)|[icml2025-vgp](https://github.com/zhoujiahuan1991/icml2025-vgp)|\n", "2505.04185": "|[s3d: sketch-driven 3d model generation](https://arxiv.org/abs/2505.04185)|[s3d](https://github.com/hailsong/s3d)|\n", "2505.04192": "|[videopath-llava: pathology diagnostic reasoning through video instruction tuning](https://arxiv.org/abs/2505.04192)|[videopath-llava](https://github.com/trinhvg/videopath-llava)|\n", "2505.04258": "|[rgb-event fusion with self-attention for collision prediction](https://arxiv.org/abs/2505.04258)|[eva](https://github.com/pbonazzi/eva)|\n", "2505.04276": "|[hdifftg: a lightweight hybrid diffusion-transformer-gcn architecture for 3d human pose estimation](https://arxiv.org/abs/2505.04276)|[hdifftg](https://github.com/circejie/hdifftg)|\n", "2505.04369": "|[wdmamba: when wavelet degradation prior meets vision mamba for image dehazing](https://arxiv.org/abs/2505.04369)|[wdmamba](https://github.com/sunj000/wdmamba)|\n", "2505.04410": "|[declip: decoupled learning for open-vocabulary dense perception](https://arxiv.org/abs/2505.04410)|[declip](https://github.com/xiaomoguhz/declip)|\n", "2505.04526": "|[dfvo: learning darkness-free visible and infrared image disentanglement and fusion all at once](https://arxiv.org/abs/2505.04526)|[dfvo](https://github.com/davin-qi530/dfvo)|\n", "2505.04540": "|[registration of 3d point sets using exponential-based similarity matrix](https://arxiv.org/abs/2505.04540)|[esm_icp](https://github.com/aralab-unr/esm_icp)|\n", "2505.04575": "|[componential prompt-knowledge alignment for domain incremental learning](https://arxiv.org/abs/2505.04575)|[icml2025-ka-prompt](https://github.com/zhoujiahuan1991/icml2025-ka-prompt)|\n", "2505.04584": "|[slideitright: using ai to find relevant slides and provide feedback for open-ended questions](https://arxiv.org/abs/2505.04584)|[slideitright](https://github.com/zqh0421/slideitright)|\n", "2505.04623": "|[echoink-r1: exploring audio-visual reasoning in multimodal llms via reinforcement learning](https://arxiv.org/abs/2505.04623)|[echoink](https://github.com/harryhsing/echoink)|\n"}, "2025-05-09": {"2208.03571": "|[transformer-based assignment decision network for multiple object tracking](https://arxiv.org/abs/2208.03571)|[tadn-mot](https://github.com/psaltaath/tadn-mot)|\n", "2211.05781": "|[demystify transformers & convolutions in modern image deep networks](https://arxiv.org/abs/2211.05781)|[stm-evaluation](https://github.com/opengvlab/stm-evaluation)|\n", "2309.14630": "|[free discontinuity regression: with an application to the economic effects of internet shutdowns](https://arxiv.org/abs/2309.14630)|[fdr](https://github.com/davidvandijcke/fdr)|\n", "2406.06050": "|[generalizable human gaussians from single-view image](https://arxiv.org/abs/2406.06050)|[HGM](https://github.com/jinnan-chen/HGM)|\n", "2408.16859": "|[evaluating deep learning models for breast cancer classification: a comparative study](https://arxiv.org/abs/2408.16859)|[Breast-Cancer-Classification](https://github.com/saniaesk/Breast-Cancer-Classification)|\n", "2409.09085": "|[hesso: towards automatic efficient and user friendly any neural network training and pruning](https://arxiv.org/abs/2409.09085)|[only_train_once](https://github.com/microsoft/only_train_once)|\n", "2409.16111": "|[cloudtrack: scalable uav tracking with cloud semantics](https://arxiv.org/abs/2409.16111)|[CloudTrack](https://github.com/yblei/CloudTrack)|\n", "2410.03577": "|[look twice before you answer: memory-space visual retracing for hallucination mitigation in multimodal large language models](https://arxiv.org/abs/2410.03577)|[MemVR](https://github.com/1zhou-Wang/MemVR)|\n", "2410.09049": "|[scenecraft: layout-guided 3d scene generation](https://arxiv.org/abs/2410.09049)|[scenecraft](https://github.com/orangesodahub/scenecraft)|\n", "2410.12705": "|[worldcuisines: a massive-scale benchmark for multilingual and multicultural visual question answering on global cuisines](https://arxiv.org/abs/2410.12705)|[worldcuisines](https://github.com/worldcuisines/worldcuisines)|\n", "2410.16296": "|[large scale mri collection and segmentation of cirrhotic liver](https://arxiv.org/abs/2410.16296)|[cirrmri600plus](https://github.com/nubagcilab/cirrmri600plus)|\n", "2411.01742": "|[learning from convolution-based unlearnable datasets](https://arxiv.org/abs/2411.01742)|[RSK](https://github.com/aseriesof-tubes/RSK)|\n", "2412.03093": "|[expanding event modality applications through a robust clip-based encoder](https://arxiv.org/abs/2412.03093)|[Event_Modality_Application](https://github.com/EavnJeong/Event_Modality_Application)|\n", "2412.16698": "|[interact with me: joint egocentric forecasting of intent to interact, attitude and social actions](https://arxiv.org/abs/2412.16698)|[SocialEgoNet](https://github.com/biantongfei/SocialEgoNet)|\n", "2501.04597": "|[frontiernet: learning visual cues to explore](https://arxiv.org/abs/2501.04597)|[frontiernet](https://github.com/cvg/frontiernet)|\n", "2502.08821": "|[dejaivu: identifying and explaining ai art on the web in real-time with saliency maps](https://arxiv.org/abs/2502.08821)|[dejaivu](https://github.com/noodulz/dejaivu)|\n", "2503.10042": "|[how do multimodal large language models handle complex multimodal reasoning? placing them in an extensible escape game](https://arxiv.org/abs/2503.10042)|[EscapeCraft](https://github.com/THUNLP-MT/EscapeCraft)|\n", "2504.11895": "|[search is all you need for few-shot anomaly detection](https://arxiv.org/abs/2504.11895)|[visionad](https://github.com/qiqigeww/visionad)|\n", "2504.21356": "|[nexus-gen: a unified model for image understanding, generation, and editing](https://arxiv.org/abs/2504.21356)|[nexus-gen](https://github.com/modelscope/nexus-gen)|\n", "2504.21487": "|[dgsolver: diffusion generalist solver with universal posterior sampling for image restoration](https://arxiv.org/abs/2504.21487)|[dgsolver](https://github.com/mililab/dgsolver)|\n", "2505.00735": "|[leveraging depth maps and attention mechanisms for enhanced image inpainting](https://arxiv.org/abs/2505.00735)|[CSCE748_Computational-Photography](https://github.com/7201krap/CSCE748_Computational-Photography)|\n", "2505.02060": "|[transforming faces into video stories -- videoface2.0](https://arxiv.org/abs/2505.02060)|[videoface2.0](https://github.com/brkljac/videoface2.0)|\n", "2505.02393": "|[uncertainty-weighted image-event multimodal fusion for video anomaly detection](https://arxiv.org/abs/2505.02393)|[ief-vad](https://github.com/eavnjeong/ief-vad)|\n", "2505.03808": "|[ai-driven multi-source data fusion for algal bloom severity classification in small inland water bodies: leveraging sentinel-2, dem, and noaa climate data](https://arxiv.org/abs/2505.03808)|[harmfulalgalbloomdetection](https://github.com/ioannisnasios/harmfulalgalbloomdetection)|\n", "2505.03838": "|[intellicardiac: an intelligent platform for cardiac image segmentation and classification](https://arxiv.org/abs/2505.03838)|[IntelliCardiac](https://github.com/tiffany9056/IntelliCardiac)|\n", "2505.03856": "|[an active inference model of covert and overt visual attention](https://arxiv.org/abs/2505.03856)|[ainf-visual-attention](https://github.com/unizgfer-lamor/ainf-visual-attention)|\n", "2505.04046": "|[reliable disentanglement multi-view learning against view adversarial attacks](https://arxiv.org/abs/2505.04046)|[2025-IJCAI-RDML](https://github.com/Willy1005/2025-IJCAI-RDML)|\n", "2505.04066": "|[llamapie: proactive in-ear conversation assistants](https://arxiv.org/abs/2505.04066)|[LlamaPIE](https://github.com/chentuochao/LlamaPIE)|\n", "2505.04281": "|[ts-diff: two-stage diffusion model for low-light raw image enhancement](https://arxiv.org/abs/2505.04281)|[ts-diff](https://github.com/circcclek/ts-diff)|\n", "2505.04586": "|[active sampling for mri-based sequential decision making](https://arxiv.org/abs/2505.04586)|[mri_sequential_active_sampling](https://github.com/vios-s/mri_sequential_active_sampling)|\n", "2505.04590": "|[tetweave: isosurface extraction using on-the-fly delaunay tetrahedral grids for gradient-based mesh optimization](https://arxiv.org/abs/2505.04590)|[TetWeave](https://github.com/AlexandreBinninger/TetWeave)|\n", "2505.04650": "|[multimodal benchmarking and recommendation of text-to-image generation models](https://arxiv.org/abs/2505.04650)|[Evaluation_generated_images](https://github.com/kapilw25/Evaluation_generated_images)|\n", "2505.04652": "|[rethinking boundary detection in deep learning-based medical image segmentation](https://arxiv.org/abs/2505.04652)|[cto](https://github.com/xiaofang007/cto)|\n", "2505.04656": "|[meshgen: generating pbr textured mesh with render-enhanced auto-encoder and generative data augmentation](https://arxiv.org/abs/2505.04656)|[meshgen](https://github.com/heheyas/meshgen)|\n", "2505.04659": "|[gssplat: generalizable semantic gaussian splatting for novel-view synthesis in 3d scenes](https://arxiv.org/abs/2505.04659)|[gssplat](https://github.com/onmyoji-xiao/gssplat)|\n", "2505.04668": "|[sgcr: spherical gaussians for efficient 3d curve reconstruction](https://arxiv.org/abs/2505.04668)|[sgcr](https://github.com/martinyxr/sgcr)|\n", "2505.04672": "|[histo-miner: deep learning based tissue features extraction pipeline from h&e whole slide images of cutaneous squamous cell carcinoma](https://arxiv.org/abs/2505.04672)|[Histo-Miner](https://github.com/bozeklab/Histo-Miner)|\n", "2505.04720": "|[false promises in medical imaging ai? assessing validity of outperformance claims](https://arxiv.org/abs/2505.04720)|[probability-of-false-claims](https://github.com/IMSY-DKFZ/probability-of-false-claims)|\n", "2505.04788": "|[convex relaxation for robust vanishing point estimation in manhattan world](https://arxiv.org/abs/2505.04788)|[globustvp](https://github.com/wu-cvgl/globustvp)|\n", "2505.04831": "|[steerable scene generation with post training and inference-time search](https://arxiv.org/abs/2505.04831)|[steerable-scene-generation](https://github.com/nepfaff/steerable-scene-generation)|\n", "2505.04835": "|[are synthetic corruptions a reliable proxy for real-world corruptions?](https://arxiv.org/abs/2505.04835)|[benchmarking_robustness](https://github.com/shashankskagnihotri/benchmarking_robustness)|\n", "2505.04899": "|[owt: a foundational organ-wise tokenization framework for medical imaging](https://arxiv.org/abs/2505.04899)|[OWT](https://github.com/SifanSong/OWT)|\n", "2505.04917": "|[a simple detector with frame dynamics is a strong tracker](https://arxiv.org/abs/2505.04917)|[A-Simple-Detector-is-a-Strong-Tracker](https://github.com/facias914/A-Simple-Detector-is-a-Strong-Tracker)|\n", "2505.04921": "|[perception, reason, think, and plan: a survey on large multimodal reasoning models](https://arxiv.org/abs/2505.04921)|[awesome-large-multimodal-reasoning-models](https://github.com/hitsz-tmg/awesome-large-multimodal-reasoning-models)|\n", "2505.04941": "|[building-guided pseudo-label learning for cross-modal building damage mapping](https://arxiv.org/abs/2505.04941)|[Building-Guided-Pseudo-Label-Learning-for-Cross-Modal-Building-Damage-Mapping](https://github.com/Henryjiepanli/Building-Guided-Pseudo-Label-Learning-for-Cross-Modal-Building-Damage-Mapping)|\n", "2505.05001": "|[stabstitch++: unsupervised online video stitching with spatiotemporal bidirectional warps](https://arxiv.org/abs/2505.05001)|[stabstitch2](https://github.com/nie-lang/stabstitch2)|\n", "2505.05004": "|[automated thoracolumbar stump rib detection and analysis in a large ct cohort](https://arxiv.org/abs/2505.05004)|[rib-segmentation](https://github.com/Hendrik-code/rib-segmentation)|\n", "2505.05022": "|[soap: style-omniscient animatable portraits](https://arxiv.org/abs/2505.05022)|[soap](https://github.com/tingtingliao/soap)|\n", "2505.05076": "|[the city that never settles: simulation-based lidar dataset for long-term place recognition under extreme structural changes](https://arxiv.org/abs/2505.05076)|[cns_dataset](https://github.com/hyunho111/cns_dataset)|\n", "2505.05091": "|[dispbench: benchmarking disparity estimation to synthetic corruptions](https://arxiv.org/abs/2505.05091)|[benchmarking_robustness](https://github.com/shashankskagnihotri/benchmarking_robustness)|\n", "2505.05163": "|[probabilistic embeddings for frozen vision-language models: uncertainty quantification with gaussian process latent variable models](https://arxiv.org/abs/2505.05163)|[GroVE](https://github.com/vaishwarya96/GroVE)|\n", "2505.05309": "|[augmented deep contexts for spatially embedded video coding](https://arxiv.org/abs/2505.05309)|[sevc](https://github.com/esakak/sevc)|\n", "2505.05343": "|[hearing and seeing through clip: a framework for self-supervised sound source localization](https://arxiv.org/abs/2505.05343)|[ACL-SSL](https://github.com/swimmiing/ACL-SSL)|\n", "2505.05422": "|[toklip: marry visual tokens to clip for multimodal comprehension and generation](https://arxiv.org/abs/2505.05422)|[toklip](https://github.com/tencentarc/toklip)|\n", "2505.05446": "|[adaptive markup language generation for contextually-grounded visual document understanding](https://arxiv.org/abs/2505.05446)|[DocMark](https://github.com/Euphoria16/DocMark)|\n", "2505.05469": "|[generating physically stable and buildable lego designs from text](https://arxiv.org/abs/2505.05469)|[LegoGPT](https://github.com/AvaLovelace1/LegoGPT)|\n", "2505.05474": "|[3d scene generation: a survey](https://arxiv.org/abs/2505.05474)|[awesome-3d-scene-generation](https://github.com/hzxie/awesome-3d-scene-generation)|\n", "2505.05475": "|[svad: from single image to 3d avatar via synthetic data generation with video diffusion and data augmentation](https://arxiv.org/abs/2505.05475)|[SVAD](https://github.com/yc4ny/SVAD)|\n"}, "2025-05-10": {}, "2025-05-11": {}, "2025-05-12": {"2203.01207": "|[container localisation and mass estimation with an rgb-d camera](https://arxiv.org/abs/2203.01207)|[visual](https://github.com/corsmal/visual)|\n", "2303.17051": "|[towards foundation models and few-shot parameter-efficient fine-tuning for volumetric organ segmentation](https://arxiv.org/abs/2303.17051)|[fewshot-finetuning](https://github.com/jusiro/fewshot-finetuning)|\n", "2306.14070": "|[superbench: a super-resolution benchmark dataset for scientific machine learning](https://arxiv.org/abs/2306.14070)|[superbench](https://github.com/erichson/superbench)|\n", "2308.11233": "|[affordance segmentation of hand-occluded containers from exocentric images](https://arxiv.org/abs/2308.11233)|[acanet](https://github.com/SEAlab-unige/acanet)|\n", "2312.09968": "|[human perception-inspired grain segmentation refinement using conditional random fields](https://arxiv.org/abs/2312.09968)|[hierarchicalcrf](https://github.com/dorukaksoy/hierarchicalcrf)|\n", "2312.12429": "|[the endoscapes dataset for surgical scene segmentation, object detection, and critical view of safety assessment: official splits and benchmark](https://arxiv.org/abs/2312.12429)|[endoscapes](https://github.com/camma-public/endoscapes)|\n", "2404.09957": "|[how to build the best medical image segmentation algorithm using foundation models: a comprehensive empirical study with segment anything model](https://arxiv.org/abs/2404.09957)|[finetune-sam](https://github.com/mazurowski-lab/finetune-sam)|\n", "2405.13637": "|[curriculum direct preference optimization for diffusion and consistency models](https://arxiv.org/abs/2405.13637)|[curriculum-dpo](https://github.com/croitorualin/curriculum-dpo)|\n", "2407.11243": "|[representation learning and identity adversarial training for facial behavior understanding](https://arxiv.org/abs/2407.11243)|[fmae-iat](https://github.com/forever208/fmae-iat)|\n", "2412.14123": "|[anysat: one earth observation model for many resolutions, scales, and modalities](https://arxiv.org/abs/2412.14123)|[anysat](https://github.com/gastruc/anysat)|\n", "2412.20002": "|[learning an adaptive and view-invariant vision transformer for real-time uav tracking](https://arxiv.org/abs/2412.20002)|[AVTrack](https://github.com/wuyou3474/AVTrack)|\n", "2501.02704": "|[persistence of backdoor-based watermarks for neural networks: a comprehensive evaluation](https://arxiv.org/abs/2501.02704)|[dnn-watermark-persistence](https://github.com/anhtu96/dnn-watermark-persistence)|\n", "2501.03525": "|[texhoi: reconstructing textures of 3d unknown objects in monocular hand-object interaction scenes](https://arxiv.org/abs/2501.03525)|[texhoi](https://github.com/alakhag/texhoi)|\n", "2502.04521": "|[generative autoregressive transformers for model-agnostic federated mri reconstruction](https://arxiv.org/abs/2502.04521)|[FedGAT](https://github.com/icon-lab/FedGAT)|\n", "2502.06380": "|[structure-preserving contrastive learning for spatial time series](https://arxiv.org/abs/2502.06380)|[spclt](https://github.com/Yiru-Jiao/spclt)|\n", "2503.24166": "|[foundation models for seismic data processing: an extensive review](https://arxiv.org/abs/2503.24166)|[foundation-models-seismic-processing](https://codeberg.org/fuchsfa/foundation-models-seismic-processing)|\n", "2504.06751": "|[visualization of a multidimensional point cloud as a 3d swarm of avatars](https://arxiv.org/abs/2504.06751)|[n-dim-view](https://github.com/iitis/n-dim-view)|\n", "2504.08049": "|[patch distribution modeling framework adaptive cosine estimator (padim-ace) for anomaly detection and localization in synthetic aperture radar imagery](https://arxiv.org/abs/2504.08049)|[padim-ace](https://github.com/advanced-vision-and-learning-lab/padim-ace)|\n", "2505.02539": "|[marker-based extrinsic calibration method for accurate multi-camera 3d reconstruction](https://arxiv.org/abs/2505.02539)|[CalibMarker](https://github.com/Tech4DLab/CalibMarker)|\n", "2505.02835": "|[r1-reward: training multimodal reward model through stable reinforcement learning](https://arxiv.org/abs/2505.02835)|[r1_reward](https://github.com/yfzhang114/r1_reward)|\n", "2505.05049": "|[uncertainsam: fast and efficient uncertainty quantification of the segment anything model](https://arxiv.org/abs/2505.05049)|[UncertainSAM](https://github.com/GreenAutoML4FAS/UncertainSAM)|\n", "2505.05375": "|[threshold modulation for online test-time adaptation of spiking neural networks](https://arxiv.org/abs/2505.05375)|[tm-otta-snn](https://github.com/nneurotransmitterr/tm-otta-snn)|\n", "2505.05504": "|[image restoration via multi-domain learning](https://arxiv.org/abs/2505.05504)|[swformer](https://github.com/deng-ai-lab/swformer)|\n", "2505.05505": "|[apply hierarchical-chain-of-generation to complex attributes text-to-3d generation](https://arxiv.org/abs/2505.05505)|[gascol](https://github.com/wakals/gascol)|\n", "2505.05510": "|[how to train your metamorphic deep neural network](https://arxiv.org/abs/2505.05510)|[htty_neumeta](https://github.com/tsommariva/htty_neumeta)|\n", "2505.05528": "|[x-transfer attacks: towards super transferable adversarial attacks on clip](https://arxiv.org/abs/2505.05528)|[XTransferBench](https://github.com/HanxunH/XTransferBench)|\n", "2505.05599": "|[enhancing satellite object localization with dilated convolutions and attention-aided spatial pooling](https://arxiv.org/abs/2505.05599)|[satellite-object-localization](https://github.com/ai-4-atmosphere-remote-sensing/satellite-object-localization)|\n", "2505.05621": "|[a preliminary study for gpt-4o on image restoration](https://arxiv.org/abs/2505.05621)|[gpt_restoration](https://github.com/noxsine/gpt_restoration)|\n", "2505.05657": "|[unsupervised blind speech separation with a diffusion prior](https://arxiv.org/abs/2505.05657)|[arraydps](https://github.com/arraydps/arraydps)|\n", "2505.05659": "|[v-efficientnets: vector-valued efficiently scaled convolutional neural network models](https://arxiv.org/abs/2505.05659)|[v-nets](https://github.com/mevalle/v-nets)|\n", "2505.05689": "|[equivariant imaging biomarkers for robust unsupervised segmentation of histopathology](https://arxiv.org/abs/2505.05689)|[sre_unsupervised_segm](https://github.com/fyc423/sre_unsupervised_segm)|\n", "2505.05711": "|[digit: multi-dilated gated encoder and central-adjacent region integrated decoder for temporal action detection transformer](https://arxiv.org/abs/2505.05711)|[digit](https://github.com/dotori-hj/digit)|\n", "2505.05736": "|[multimodal integrated knowledge transfer to large language models through preference optimization with biomedical applications](https://arxiv.org/abs/2505.05736)|[mint-llm](https://github.com/wglab/mint-llm)|\n", "2505.05752": "|[automating infrastructure surveying: a framework for geometric measurements and compliance assessment using point cloud data](https://arxiv.org/abs/2505.05752)|[surveyautomation](https://github.com/soltanilara/surveyautomation)|\n", "2505.05812": "|[towards order of magnitude x-ray dose reduction in breast cancer imaging using phase contrast and deep denoising](https://arxiv.org/abs/2505.05812)|[quell](https://github.com/quell-devs/quell)|\n", "2505.05829": "|[accelerating diffusion transformer via increment-calibrated caching with channel-aware singular value decomposition](https://arxiv.org/abs/2505.05829)|[icc](https://github.com/ccccczzy/icc)|\n", "2505.05834": "|[dual-level fuzzy learning with patch guidance for image ordinal regression](https://arxiv.org/abs/2505.05834)|[dfpg-ord](https://github.com/zjumai/dfpg-ord)|\n", "2505.05895": "|[leveraging vision-language models for visual grounding and analysis of automotive ui](https://arxiv.org/abs/2505.05895)|[ELAM-7B](https://huggingface.co/sparks-solutions/ELAM-7B)|\n", "2505.05913": "|[dfen: dual feature equalization network for medical image segmentation](https://arxiv.org/abs/2505.05913)|[dfen](https://github.com/jianjianyin/dfen)|\n", "2505.05936": "|[cgtrack: cascade gating network with hierarchical feature aggregation for uav tracking](https://arxiv.org/abs/2505.05936)|[cgtrack](https://github.com/nightwatch-fox11/cgtrack)|\n", "2505.06002": "|[task-adapter++: task-specific adaptation with order-aware alignment for few-shot action recognition](https://arxiv.org/abs/2505.06002)|[task-adapter-pp](https://github.com/jaulin-bage/task-adapter-pp)|\n", "2505.06003": "|[from pixels to perception: interpretable predictions via instance-wise grouped feature selection](https://arxiv.org/abs/2505.06003)|[p2p](https://github.com/mvandenhi/p2p)|\n", "2505.06030": "|[why are you wrong? counterfactual explanations for language grounding with 3d objects](https://arxiv.org/abs/2505.06030)|[why-are-you-wrong](https://github.com/toprei/why-are-you-wrong)|\n", "2505.06064": "|[context informed incremental learning improves myoelectric control performance in virtual reality object manipulation tasks](https://arxiv.org/abs/2505.06064)|[ciil-emg-vr](https://github.com/biomedicalits/ciil-emg-vr)|\n", "2505.06068": "|[noise-consistent siamese-diffusion for medical image synthesis and segmentation](https://arxiv.org/abs/2505.06068)|[siamese-diffusion](https://github.com/qiukunpeng/siamese-diffusion)|\n", "2505.06107": "|[differentiating emigration from return migration of scholars using name-based nationality detection models](https://arxiv.org/abs/2505.06107)|[NameBasedNationalityDetection](https://github.com/FaezeGhorbanpour/NameBasedNationalityDetection)|\n", "2505.06120": "|[llms get lost in multi-turn conversation](https://arxiv.org/abs/2505.06120)|[lost_in_conversation](https://github.com/microsoft/lost_in_conversation)|\n", "2505.06134": "|[realistic adversarial attacks for robustness evaluation of trajectory prediction models via future state perturbation](https://arxiv.org/abs/2505.06134)|[general-framework-update-adversarial-jeroen](https://github.com/jhagenus/general-framework-update-adversarial-jeroen)|\n", "2505.06152": "|[mm-skin: enhancing dermatology vision-language model with an image-text dataset derived from textbooks](https://arxiv.org/abs/2505.06152)|[mm-skin](https://github.com/zwq803/mm-skin)|\n"}, "2025-05-13": {"2312.14999": "|[leveraging habitat information for fine-grained bird identification](https://arxiv.org/abs/2312.14999)|[reasoning](https://github.com/ngthanhtin/reasoning)|\n", "2403.05581": "|[can interpretability layouts influence human perception of offensive sentences?](https://arxiv.org/abs/2403.05581)|[user_study](https://bitbucket.org/thiago-phd/user_study)|\n", "2405.06198": "|[mapl: memory augmentation and pseudo-labeling for semi-supervised anomaly detection](https://arxiv.org/abs/2405.06198)|[mapl](https://github.com/jzc777/mapl)|\n", "2405.17456": "|[generalized compressed sensing for image reconstruction with diffusion probabilistic models](https://arxiv.org/abs/2405.17456)|[optimal-measurement](https://github.com/lingqiz/optimal-measurement)|\n", "2407.01330": "|[a lightweight udf learning framework for 3d reconstruction based on local shape functions](https://arxiv.org/abs/2407.01330)|[LoSF](https://github.com/jbHu67/LoSF)|\n", "2407.13120": "|[hppp: halpern-type preconditioned proximal point algorithms and applications to image restoration](https://arxiv.org/abs/2407.13120)|[HPPP](https://github.com/zsc15/HPPP)|\n", "2408.10919": "|[crossfi: a cross domain wi-fi sensing framework based on siamese network](https://arxiv.org/abs/2408.10919)|[CrossFi](https://github.com/RS2002/CrossFi)|\n", "2409.00638": "|[igev++: iterative multi-range geometry encoding volumes for stereo matching](https://arxiv.org/abs/2409.00638)|[igev](https://github.com/gangweix/igev)|\n", "2409.02426": "|[diffusion models learn low-dimensional distributions via subspace clustering](https://arxiv.org/abs/2409.02426)|[Diffusion-Model-Generalizability](https://github.com/huijieZH/Diffusion-Model-Generalizability)|\n", "2409.18653": "|[when sam2 meets video camouflaged object segmentation: a comprehensive evaluation and adaptation](https://arxiv.org/abs/2409.18653)|[sam2-vcos](https://github.com/zhoustan/sam2-vcos)|\n", "2410.03311": "|[scaling large motion models with million-level human motions](https://arxiv.org/abs/2410.03311)|[being-m0](https://github.com/beingbeyond/being-m0)|\n", "2411.11904": "|[geoground: a unified large vision-language model for remote sensing visual grounding](https://arxiv.org/abs/2411.11904)|[geoground](https://github.com/zytx121/geoground)|\n", "2412.01818": "|[beyond text-visual attention: exploiting visual cues for effective token pruning in vlms](https://arxiv.org/abs/2412.01818)|[fastervlm](https://github.com/theia-4869/fastervlm)|\n", "2501.00843": "|[fusionsort: fusion methods for online multi-object visual tracking](https://arxiv.org/abs/2501.00843)|[FusionSORT](https://github.com/nathanlem1/FusionSORT)|\n", "2501.16003": "|[improving tropical cyclone forecasting with video diffusion models](https://arxiv.org/abs/2501.16003)|[forecast-video-diffmodels](https://github.com/ren-creater/forecast-video-diffmodels)|\n", "2502.12110": "|[a-mem: agentic memory for llm agents](https://arxiv.org/abs/2502.12110)|[a-mem](https://github.com/agiresearch/a-mem)|\n", "2502.14908": "|[segsub: evaluating robustness to knowledge conflicts and hallucinations in vision-language models](https://arxiv.org/abs/2502.14908)|[SegSub](https://github.com/CASOS-IDeaS-CMU/SegSub)|\n", "2503.01103": "|[direct discriminative optimization: your likelihood-based visual generative model is secretly a gan discriminator](https://arxiv.org/abs/2503.01103)|[ddo](https://github.com/nvlabs/ddo)|\n", "2503.04318": "|[infl-ux: a toolkit for web-based interactive federated learning](https://arxiv.org/abs/2503.04318)|[interactive-fl-poc](https://github.com/tmaurer42/interactive-fl-poc)|\n", "2503.08507": "|[referring to any person](https://arxiv.org/abs/2503.08507)|[rexseek](https://github.com/idea-research/rexseek)|\n", "2503.15970": "|[v-naw: video-based noise-aware adaptive weighting for facial expression recognition](https://arxiv.org/abs/2503.15970)|[V-NAW](https://github.com/jungyu0413/V-NAW)|\n", "2503.16188": "|[think or not think: a study of explicit thinking in rule-based visual reinforcement fine-tuning](https://arxiv.org/abs/2503.16188)|[CLS-RL](https://github.com/minglllli/CLS-RL)|\n", "2504.11416": "|[deep learning-based bathymetry retrieval without in-situ depths using remote sensing imagery and sfm-mvs dsms with data gaps](https://arxiv.org/abs/2504.11416)|[swin-bathyunet](https://github.com/pagraf/swin-bathyunet)|\n", "2504.12157": "|[focusedad: character-centric movie audio description](https://arxiv.org/abs/2504.12157)|[focusedad](https://github.com/thorin215/focusedad)|\n", "2504.13617": "|[compile scene graphs with reinforcement learning](https://arxiv.org/abs/2504.13617)|[r1-sgg](https://github.com/gpt4vision/r1-sgg)|\n", "2504.14906": "|[omniaudio: generating spatial audio from 360-degree video](https://arxiv.org/abs/2504.14906)|[omniaudio](https://github.com/liuhuadai/omniaudio)|\n", "2504.17522": "|[tablecenternet: a one-stage network for table structure recognition](https://arxiv.org/abs/2504.17522)|[tablecenternet](https://github.com/dreamy-xay/tablecenternet)|\n", "2504.21497": "|[magicportrait: temporally consistent face reenactment with 3d geometric guidance](https://arxiv.org/abs/2504.21497)|[magicportrait](https://github.com/weimengting/magicportrait)|\n", "2505.02350": "|[sparse ellipsoidal radial basis function network for point cloud surface representation](https://arxiv.org/abs/2505.02350)|[se-rbfnet](https://github.com/lianbobo/se-rbfnet)|\n", "2505.05007": "|[driving with context: online map matching for complex roads using lane markings and scenario recognition](https://arxiv.org/abs/2505.05007)|[lmsr-omm](https://github.com/trv-lab/lmsr-omm)|\n", "2505.05470": "|[flow-grpo: training flow matching models via online rl](https://arxiv.org/abs/2505.05470)|[flow_grpo](https://github.com/yifan123/flow_grpo)|\n", "2505.05573": "|[prompt to polyp: medical text-conditioned image synthesis with diffusion models](https://arxiv.org/abs/2505.05573)|[imageclefmed-medvqa-gi-2024-mmcp-team](https://github.com/thundercondor/imageclefmed-medvqa-gi-2024-mmcp-team)|\n", "2505.06393": "|[toward advancing license plate super-resolution in real-world scenarios: a dataset and benchmark](https://arxiv.org/abs/2505.06393)|[lpsrgan](https://github.com/valfride/lpsrgan)|\n", "2505.06428": "|[what do people want to know about artificial intelligence (ai)? the importance of answering end-user questions to explain autonomous vehicle (av) decisions](https://arxiv.org/abs/2505.06428)|[conversationalXAV](https://github.com/comp-hci-lab/conversationalXAV)|\n", "2505.06469": "|[kcluster: an llm-based clustering approach to knowledge component discovery](https://arxiv.org/abs/2505.06469)|[KCluster](https://github.com/weiyumou/KCluster)|\n", "2505.06507": "|[text-to-cadquery: a new paradigm for cad generation with scalable large model capabilities](https://arxiv.org/abs/2505.06507)|[text-to-cadquery](https://github.com/text-to-cadquery/text-to-cadquery)|\n", "2505.06517": "|[edge-enabled vio with long-tracked features for high-accuracy low-altitude iot navigation](https://arxiv.org/abs/2505.06517)|[FLOW-VIO](https://github.com/xiaohong-huang/FLOW-VIO)|\n", "2505.06527": "|[improving generalization of medical image registration foundation model](https://arxiv.org/abs/2505.06527)|[fm_sam](https://github.com/promise13/fm_sam)|\n", "2505.06536": "|[tacfn: transformer-based adaptive cross-modal fusion network for multimodal emotion recognition](https://arxiv.org/abs/2505.06536)|[tacfn](https://github.com/shuzihuaiyu/tacfn)|\n", "2505.06578": "|[compact and efficient neural networks for image recognition based on learned 2d separable transform](https://arxiv.org/abs/2505.06578)|[lst-2d](https://github.com/mak-sim/lst-2d)|\n", "2505.06592": "|[batch augmentation with unimodal fine-tuning for multimodal learning](https://arxiv.org/abs/2505.06592)|[multimodal](https://github.com/dipuk0506/multimodal)|\n", "2505.06646": "|[reproducing and improving chexnet: deep learning for chest x-ray disease classification](https://arxiv.org/abs/2505.06646)|[Deep-Learning-Project](https://github.com/dstrick17/Deep-Learning-Project)|\n", "2505.06663": "|[metor: a unified framework for mutual enhancement of objects and relationships in open-vocabulary video visual relationship detection](https://arxiv.org/abs/2505.06663)|[METOR](https://github.com/wangyongqi558/METOR)|\n", "2505.06684": "|[fnbench: benchmarking robust federated learning against noisy labels](https://arxiv.org/abs/2505.06684)|[fnbench](https://github.com/sprinter1999/fnbench)|\n", "2505.06702": "|[do language model agents align with humans in rating visualizations? an empirical study](https://arxiv.org/abs/2505.06702)|[Agents-Ratings-in-VIS-Experiments](https://github.com/ZekaiShao25/Agents-Ratings-in-VIS-Experiments)|\n", "2505.06796": "|[multimodal fake news detection: mfnd dataset and shallow-deep multitask learning](https://arxiv.org/abs/2505.06796)|[sdml](https://github.com/yunan-wang33/sdml)|\n", "2505.06934": "|[whitened clip as a likelihood surrogate of images and captions](https://arxiv.org/abs/2505.06934)|[W_CLIP](https://github.com/rbetser/W_CLIP)|\n", "2505.06937": "|[transformer-based dual-optical attention fusion crowd head point counting and localization network](https://arxiv.org/abs/2505.06937)|[tapnet](https://github.com/zz-zik/tapnet)|\n", "2505.06948": "|[unsupervised learning for class distribution mismatch](https://arxiv.org/abs/2505.06948)|[research](https://github.com/ruc-dwbi-ml/research)|\n", "2505.06975": "|[high-frequency prior-driven adaptive masking for accelerating image super-resolution](https://arxiv.org/abs/2505.06975)|[amsr](https://github.com/shangwei5/amsr)|\n", "2505.07001": "|[hallucination-aware multimodal benchmark for gastrointestinal image analysis with large vision-language models](https://arxiv.org/abs/2505.07001)|[hallucination-aware-vlm](https://github.com/bhattarailab/hallucination-aware-vlm)|\n", "2505.07007": "|[mellm: exploring llm-powered micro-expression understanding enhanced by subtle motion perception](https://arxiv.org/abs/2505.07007)|[mellm](https://github.com/zyzhangustc/mellm)|\n", "2505.07019": "|[a vision-language foundation model for leaf disease identification](https://arxiv.org/abs/2505.07019)|[scold](https://huggingface.co/enalis/scold)|\n", "2505.07071": "|[semantic-guided diffusion model for single-step image super-resolution](https://arxiv.org/abs/2505.07071)|[samsr](https://github.com/liu-zihang/samsr)|\n", "2505.07159": "|[skull stripping with purely synthetic data](https://arxiv.org/abs/2505.07159)|[PUMBA](https://github.com/pjsjongsung/PUMBA)|\n", "2505.07161": "|[towards actionable pedagogical feedback: a multi-perspective analysis of mathematics teaching and tutoring dialogue](https://arxiv.org/abs/2505.07161)|[speak-turn-emb-dialog-act-clf](https://github.com/zihaohe123/speak-turn-emb-dialog-act-clf)|\n", "2505.07164": "|[emovlm-kd: fusing distilled expertise with vision-language models for visual emotion analysis](https://arxiv.org/abs/2505.07164)|[emovlm-kd](https://github.com/sange1104/emovlm-kd)|\n", "2505.07175": "|[metrics that matter: evaluating image quality metrics for medical image generation](https://arxiv.org/abs/2505.07175)|[GenMed](https://github.com/YashDeo-York/GenMed)|\n", "2505.07219": "|[language-driven dual style mixing for single-domain generalized object detection](https://arxiv.org/abs/2505.07219)|[ldds](https://github.com/qinhongda8/ldds)|\n", "2505.07340": "|[thalamus: a user simulation toolkit for prototyping multimodal sensing studies](https://arxiv.org/abs/2505.07340)|[Thalamus](https://github.com/kayhan-latifzadeh/Thalamus)|\n", "2505.07375": "|[boosting global-local feature matching via anomaly synthesis for multi-class point cloud anomaly detection](https://arxiv.org/abs/2505.07375)|[GLFM-Multi-class-3DAD](https://github.com/hustCYQ/GLFM-Multi-class-3DAD)|\n", "2505.07387": "|[feature visualization in 3d convolutional neural networks](https://arxiv.org/abs/2505.07387)|[3dkernelvisualizer](https://github.com/yatanglilab/3dkernelvisualizer)|\n", "2505.07447": "|[unified continuous generative models](https://arxiv.org/abs/2505.07447)|[UCGM](https://github.com/LINs-Lab/UCGM)|\n", "2505.07477": "|[you only look one step: accelerating backpropagation in diffusion sampling with gradient shortcuts](https://arxiv.org/abs/2505.07477)|[sdo](https://github.com/deng-ai-lab/sdo)|\n", "2505.07496": "|[docvxqa: context-aware visual explanations for document question answering](https://arxiv.org/abs/2505.07496)|[docvxqa](https://github.com/dali92002/docvxqa)|\n", "2505.07689": "|[anatomical attention alignment representation for radiology report generation](https://arxiv.org/abs/2505.07689)|[a3net](https://github.com/vinh-ai/a3net)|\n", "2505.07812": "|[continuous visual autoregressive generation via score maximization](https://arxiv.org/abs/2505.07812)|[ear](https://github.com/shaochenze/ear)|\n"}, "2025-05-14": {"1907.01131": "|[learnable gated temporal shift module for deep video inpainting](https://arxiv.org/abs/1907.01131)|[Free-Form-Video-Inpainting](https://github.com/amjltc295/Free-Form-Video-Inpainting)|\n", "2307.05033": "|[towards anytime optical flow estimation with event cameras](https://arxiv.org/abs/2307.05033)|[eva-flow](https://github.com/yaozhuwa/eva-flow)|\n", "2308.13174": "|[deep learning-based interactive segmentation in remote sensing](https://arxiv.org/abs/2308.13174)|[segmap-qgis](https://github.com/titorx/segmap-qgis)|\n", "2310.00868": "|[rt-gan: recurrent temporal gan for adding lightweight temporal consistency to frame-based domain translation approaches](https://arxiv.org/abs/2310.00868)|[CEP](https://github.com/nadeemlab/CEP)|\n", "2312.06198": "|[optimized view and geometry distillation from multi-view diffuser](https://arxiv.org/abs/2312.06198)|[USD](https://github.com/YoujiaZhang/USD)|\n", "2401.12133": "|[vrmn-bd: a multi-modal natural behavior dataset of immersive human fear responses in vr stand-up interactive games](https://arxiv.org/abs/2401.12133)|[vrmn-bd](https://github.com/kindopstar/vrmn-bd)|\n", "2404.11824": "|[textcengen: attention-guided text-centric background adaptation for text-to-image generation](https://arxiv.org/abs/2404.11824)|[textcengen_background_adapt](https://github.com/tianyilt/textcengen_background_adapt)|\n", "2407.11802": "|[discriminative and consistent representation distillation](https://arxiv.org/abs/2407.11802)|[distillers](https://github.com/giakoumoglou/distillers)|\n", "2407.12073": "|[relational representation distillation](https://arxiv.org/abs/2407.12073)|[distillers](https://github.com/giakoumoglou/distillers)|\n", "2408.09030": "|[studying the effects of collaboration in interactive theme discovery systems](https://arxiv.org/abs/2408.09030)|[interactive-systems](https://github.com/blast-cu/interactive-systems)|\n", "2410.01723": "|[harmonica: harmonizing training and inference for better feature caching in diffusion transformer acceleration](https://arxiv.org/abs/2410.01723)|[harmonica](https://github.com/modeltc/harmonica)|\n", "2410.02240": "|[sca: improve semantic consistent in unrestricted adversarial attacks via ddpm inversion](https://arxiv.org/abs/2410.02240)|[sca](https://github.com/pan-zihao/sca)|\n", "2410.13757": "|[moba: multifaceted memory-enhanced adaptive planning for efficient mobile task automation](https://arxiv.org/abs/2410.13757)|[MobA](https://github.com/OpenDFM/MobA)|\n", "2411.18145": "|[choice: benchmarking the remote sensing capabilities of large vision-language models](https://arxiv.org/abs/2411.18145)|[choice](https://github.com/shawnan-whu/choice)|\n", "2412.06488": "|[enhancing scene coordinate regression with efficient keypoint detection and sequential information](https://arxiv.org/abs/2412.06488)|[SeqACE](https://github.com/sair-lab/SeqACE)|\n", "2412.10255": "|[anisora: exploring the frontiers of animation video generation in the sora era](https://arxiv.org/abs/2412.10255)|[index-anisora](https://github.com/bilibili/index-anisora)|\n", "2501.00958": "|[2.5 years in class: a multimodal textbook for vision-language pretraining](https://arxiv.org/abs/2501.00958)|[multimodal_textbook](https://github.com/damo-nlp-sg/multimodal_textbook)|\n", "2501.01645": "|[hlv-1k: a large-scale hour-long video benchmark for time-specific long video understanding](https://arxiv.org/abs/2501.01645)|[hlv-1k](https://github.com/vincent-zhq/hlv-1k)|\n", "2501.05014": "|[uav-vla: vision-language-action system for large scale aerial mission generation](https://arxiv.org/abs/2501.05014)|[uav-vla](https://github.com/sautenich/uav-vla)|\n", "2502.02283": "|[gp-gs: gaussian processes for enhanced gaussian splatting](https://arxiv.org/abs/2502.02283)|[GPGS](https://github.com/zhihaohaoran/GPGS)|\n", "2502.13818": "|[building age estimation: a new multi-modal benchmark dataset and community challenge](https://arxiv.org/abs/2502.13818)|[ai4eo_map_your_city](https://github.com/xmba15/ai4eo_map_your_city)|\n", "2503.01739": "|[videoufo: a million-scale user-focused dataset for text-to-video generation](https://arxiv.org/abs/2503.01739)|[benchufo](https://github.com/wangwenhao0716/benchufo)|\n", "2503.04325": "|[gbt-sam: adapting a foundational deep learning model for generalizable brain tumor segmentation via efficient integration of multi-parametric mri data](https://arxiv.org/abs/2503.04325)|[med-sam-brain](https://github.com/vpulab/med-sam-brain)|\n", "2503.09040": "|[motion blender gaussian splatting for dynamic scene reconstruction](https://arxiv.org/abs/2503.09040)|[motion-blender-gs](https://github.com/mlzxy/motion-blender-gs)|\n", "2503.10156": "|[automatic quality control in multi-centric fetal brain mri super-resolution reconstruction](https://arxiv.org/abs/2503.10156)|[fetmrqc_sr](https://github.com/medical-image-analysis-laboratory/fetmrqc_sr)|\n", "2504.02697": "|[learning phase distortion with selective state space models for video turbulence mitigation](https://arxiv.org/abs/2504.02697)|[mambatm](https://github.com/xg416/mambatm)|\n", "2504.17696": "|[hierarchical and multimodal data for daily activity understanding](https://arxiv.org/abs/2504.17696)|[DARai](https://github.com/olivesgatech/DARai)|\n", "2504.21435": "|[seriesbench: a benchmark for narrative-driven drama series understanding](https://arxiv.org/abs/2504.21435)|[seriesbench-cvpr2025](https://github.com/zackhxn/seriesbench-cvpr2025)|\n", "2504.21650": "|[holotime: taming video diffusion models for panoramic 4d scene generation](https://arxiv.org/abs/2504.21650)|[holotime](https://github.com/pku-yuangroup/holotime)|\n", "2505.05071": "|[fg-clip: fine-grained visual and textual alignment](https://arxiv.org/abs/2505.05071)|[fg-clip](https://github.com/360cvgroup/fg-clip)|\n", "2505.07530": "|[fluxsynid: a framework for identity-controlled synthetic face generation with document and live images](https://arxiv.org/abs/2505.07530)|[FLUXSynID](https://github.com/Raul2718/FLUXSynID)|\n", "2505.08031": "|[measuring and predicting variation in the difficulty of questions about data visualizations](https://arxiv.org/abs/2505.08031)|[viz_item_measures_cogsci2025](https://github.com/cogtoolslab/viz_item_measures_cogsci2025)|\n", "2505.08101": "|[topology-guided knowledge distillation for efficient point cloud processing](https://arxiv.org/abs/2505.08101)|[pointdistill](https://github.com/hysonlab/pointdistill)|\n", "2505.08117": "|[now you see it, now you don't: damage label agreement in drone & satellite post-disaster imagery](https://arxiv.org/abs/2505.08117)|[NowYouSeeItNowYouDont](https://github.com/TManzini/NowYouSeeItNowYouDont)|\n", "2505.08126": "|[asynchronous multi-object tracking with an event camera](https://arxiv.org/abs/2505.08126)|[AEMOT](https://github.com/angus-apps/AEMOT)|\n", "2505.08137": "|[large language models for computer-aided design: a survey](https://arxiv.org/abs/2505.08137)|[llms-cad-survey-taxonomy](https://github.com/lichengzhanguom/llms-cad-survey-taxonomy)|\n", "2505.08190": "|[unsupervised raindrop removal from a single image using conditional diffusion models](https://arxiv.org/abs/2505.08190)|[DropWiper](https://github.com/lhfazry/DropWiper)|\n", "2505.08196": "|[adc-gs: anchor-driven deformable and compressed gaussian splatting for dynamic scene reconstruction](https://arxiv.org/abs/2505.08196)|[adc-gs](https://github.com/h-huang774/adc-gs)|\n", "2505.08231": "|[hmpnet: a feature aggregation architecture for maritime object detection from a shipborne perspective](https://arxiv.org/abs/2505.08231)|[hmpnet](https://github.com/tustailab/hmpnet)|\n", "2505.08234": "|[removing watermarks with partial regeneration using semantic information](https://arxiv.org/abs/2505.08234)|[semanticregen](https://github.com/krtit/semanticregen)|\n", "2505.08245": "|[large language model psychometrics: a systematic review of evaluation, validation, and enhancement](https://arxiv.org/abs/2505.08245)|[awesome-llm-psychometrics](https://github.com/valuebyte-ai/awesome-llm-psychometrics)|\n", "2505.08246": "|[identifying memorization of diffusion models through p-laplace analysis](https://arxiv.org/abs/2505.08246)|[identifying-memorization-of-diffusion-models-through-p-laplace-analysis](https://github.com/jonathanbrok/identifying-memorization-of-diffusion-models-through-p-laplace-analysis)|\n", "2505.08247": "|[skeleton-guided diffusion model for accurate foot x-ray synthesis in hallux valgus diagnosis](https://arxiv.org/abs/2505.08247)|[sccdm](https://github.com/midisec/sccdm)|\n", "2505.08260": "|[few-shot novel category discovery](https://arxiv.org/abs/2505.08260)|[fsncd](https://github.com/ashengl/fsncd)|\n", "2505.08273": "|[irrmap: a large-scale comprehensive dataset for irrigation method mapping](https://arxiv.org/abs/2505.08273)|[irrmap](https://github.com/nibir088/irrmap)|\n", "2505.08316": "|[improving unsupervised task-driven models of ventral visual stream via relative position predictivity](https://arxiv.org/abs/2505.08316)|[unsup-vvs](https://github.com/rdz98/unsup-vvs)|\n", "2505.08437": "|[tt-df: a large-scale diffusion-based dataset and benchmark for human body forgery detection](https://arxiv.org/abs/2505.08437)|[tt-df](https://github.com/hashtag00002/tt-df)|\n", "2505.08455": "|[vcrbench: exploring long-form causal reasoning capabilities of large video language models](https://arxiv.org/abs/2505.08455)|[vcrbench](https://github.com/pritamqu/vcrbench)|\n", "2505.08468": "|[judging the judges: can large vision-language models fairly evaluate chart comprehension and reasoning?](https://arxiv.org/abs/2505.08468)|[chart_lvlm_judge](https://github.com/tahmedge/chart_lvlm_judge)|\n", "2505.08581": "|[resurgsam2: referring segment anything in surgical video via credible long-term tracking](https://arxiv.org/abs/2505.08581)|[resurgsam2](https://github.com/jinlab-imvr/resurgsam2)|\n", "2505.08601": "|[rejoining fragmented ancient bamboo slips with physics-driven deep learning](https://arxiv.org/abs/2505.08601)|[wisepanda](https://github.com/zhujinchi/wisepanda)|\n", "2505.08604": "|[unsupervised out-of-distribution detection in medical imaging using multi-exit class activation maps and feature masking](https://arxiv.org/abs/2505.08604)|[mecam-ood](https://github.com/windstormer/mecam-ood)|\n", "2505.08617": "|[openthinkimg: learning to think with images via visual tool reinforcement learning](https://arxiv.org/abs/2505.08617)|[openthinkimg](https://github.com/zhaochen0110/openthinkimg)|\n", "2505.08723": "|[timo: spatiotemporal foundation model for satellite image time series](https://arxiv.org/abs/2505.08723)|[timo](https://github.com/mililab/timo)|\n", "2505.08725": "|[extending large vision-language model for diverse interactive tasks in autonomous driving](https://arxiv.org/abs/2505.08725)|[drivemonkey](https://github.com/zc-zhao/drivemonkey)|\n"}, "2025-05-15": {"2207.14425": "|[3d cartoon face generation with controllable expressions from a single gan image](https://arxiv.org/abs/2207.14425)|[3D-Cartoon-Face-Generation](https://github.com/hwang1996/3D-Cartoon-Face-Generation)|\n", "2305.10947": "|[revisiting 16-bit neural network training: a practical approach for resource-limited learning](https://arxiv.org/abs/2305.10947)|[standalone_16bits_nn](https://github.com/yunblak/standalone_16bits_nn)|\n", "2306.14725": "|[error correcting 2d-3d cascaded network for myocardial infarct scar segmentation on late gadolinium enhancement cardiac magnetic resonance images](https://arxiv.org/abs/2306.14725)|[ecorc](https://github.com/matthi99/ecorc)|\n", "2312.15686": "|[pulaski: learning inter-rater variability using statistical distances to improve probabilistic segmentation](https://arxiv.org/abs/2312.15686)|[pulaski](https://github.com/soumickmj/pulaski)|\n", "2401.07378": "|[efficient approximation of earth mover's distance based on nearest neighbor search](https://arxiv.org/abs/2401.07378)|[nns-emd](https://github.com/gm3g11/nns-emd)|\n", "2402.00045": "|[detecting multimedia generated by large ai models: a survey](https://arxiv.org/abs/2402.00045)|[detect-laim-generated-multimedia-survey](https://github.com/purdue-m2/detect-laim-generated-multimedia-survey)|\n", "2407.19708": "|[alen: a dual-approach for uniform and non-uniform low-light image enhancement](https://arxiv.org/abs/2407.19708)|[alen](https://github.com/xingyumex/alen)|\n", "2408.08070": "|[mambamim: pre-training mamba with state space token interpolation and its application to medical image segmentation](https://arxiv.org/abs/2408.08070)|[mambamim](https://github.com/fenghetan9/mambamim)|\n", "2409.02562": "|[one homography is all you need: imm-based joint homography and multiple object state estimation](https://arxiv.org/abs/2409.02562)|[imm-jhse](https://github.com/Paulkie99/imm-jhse)|\n", "2409.15511": "|[bayesian computation with generative diffusion models by multilevel monte carlo](https://arxiv.org/abs/2409.15511)|[mlmcfordms](https://github.com/lshaw8317/mlmcfordms)|\n", "2409.18769": "|[state-of-the-art periorbital distance prediction and disease classification using periorbital features](https://arxiv.org/abs/2409.18769)|[periorbital_package](https://github.com/monkeygobah/periorbital_package)|\n", "2409.18872": "|[simulating dynamic tumor contrast enhancement in breast mri using conditional generative adversarial networks](https://arxiv.org/abs/2409.18872)|[SimulatingDCE](https://github.com/RichardObi/SimulatingDCE)|\n", "2410.07795": "|[optimal-state dynamics estimation for physics-based human motion capture from videos](https://arxiv.org/abs/2410.07795)|[osdcap](https://github.com/cuongle1206/osdcap)|\n", "2410.23854": "|[reflecting topology consistency and abnormality via learnable attentions for airway labeling](https://arxiv.org/abs/2410.23854)|[reflecting-topology-consistency-and-abnormality-via-learnable-attentions](https://github.com/endoluminalsurgicalvision-imr/reflecting-topology-consistency-and-abnormality-via-learnable-attentions)|\n", "2412.05888": "|[mcp-medsam: a powerful lightweight medical segment anything model trained with a single gpu in just one day](https://arxiv.org/abs/2412.05888)|[mcp-medsam](https://github.com/dong845/mcp-medsam)|\n", "2502.07409": "|[mgpath: vision-language model with multi-granular prompt learning for few-shot wsi classification](https://arxiv.org/abs/2502.07409)|[MGPATH](https://github.com/HauschildLab/MGPATH)|\n", "2503.18938": "|[adaworld: learning adaptable world models with latent actions](https://arxiv.org/abs/2503.18938)|[adaworld](https://github.com/little-podi/adaworld)|\n", "2503.21696": "|[embodied-reasoner: synergizing visual search, reasoning, and action for embodied interactive tasks](https://arxiv.org/abs/2503.21696)|[embodied_reasoner](https://github.com/zwq2018/embodied_reasoner)|\n", "2504.14988": "|[benchmarking large vision-language models on fine-grained image tasks: a comprehensive evaluation](https://arxiv.org/abs/2504.14988)|[fg-bmk](https://github.com/seu-vipgroup/fg-bmk)|\n", "2504.17938": "|[machine learning-based prediction of quality shifts on video streaming over 5g](https://arxiv.org/abs/2504.17938)|[5g-qoe-prediction](https://github.com/razaulmustafa852/5g-qoe-prediction)|\n", "2505.07634": "|[neural brain: a neuroscience-inspired framework for embodied agents](https://arxiv.org/abs/2505.07634)|[Neural-Brain-for-Embodied-Agents](https://github.com/CNJianLiu/Neural-Brain-for-Embodied-Agents)|\n", "2505.08527": "|[leveraging segment anything model for source-free domain adaptation via dual feature guided auto-prompting](https://arxiv.org/abs/2505.08527)|[dfg](https://github.com/xmed-lab/dfg)|\n", "2505.08568": "|[thermal detection of people with mobility restrictions for barrier reduction at traffic lights controlled intersections](https://arxiv.org/abs/2505.08568)|[yolo-thermal](https://github.com/leon2014dresden/yolo-thermal)|\n", "2505.08614": "|[waveguard: robust deepfake detection and source tracing via dual-tree complex wavelet and graph neural networks](https://arxiv.org/abs/2505.08614)|[waveguard](https://github.com/vpsg-research/waveguard)|\n", "2505.08817": "|[towards sfw sampling for diffusion models via external conditioning](https://arxiv.org/abs/2505.08817)|[sfws-stable-diffusion](https://github.com/camilocarvajalreyes/sfws-stable-diffusion)|\n", "2505.08854": "|[generative ai for autonomous driving: frontiers and opportunities](https://arxiv.org/abs/2505.08854)|[genai4ad](https://github.com/taco-group/genai4ad)|\n", "2505.08919": "|[template-guided reconstruction of pulmonary segments with neural implicit functions](https://arxiv.org/abs/2505.08919)|[impulse](https://github.com/m3dv/impulse)|\n", "2505.08932": "|[parameter-efficient fine-tuning of vision foundation model for forest floor segmentation from uav imagery](https://arxiv.org/abs/2505.08932)|[sam_peft](https://github.com/garrulus-project/sam_peft)|\n", "2505.08961": "|[differentiable channel selection in self-attention for person re-identification](https://arxiv.org/abs/2505.08961)|[dcs-attention](https://github.com/statistical-deep-learning/dcs-attention)|\n", "2505.08971": "|[prioritizing image-related tokens enhances vision-language pre-training](https://arxiv.org/abs/2505.08971)|[prior](https://github.com/yangyi-chen/prior)|\n", "2505.08999": "|[towards adaptive meta-gradient adversarial examples for visual tracking](https://arxiv.org/abs/2505.08999)|[amga](https://github.com/pgao-lab/amga)|\n", "2505.09092": "|[openlka: an open dataset of lane keeping assist from recent car models under real-world driving conditions](https://arxiv.org/abs/2505.09092)|[openlka](https://github.com/openlka/openlka)|\n", "2505.09140": "|[topodit-3d: topology-aware diffusion transformer with bottleneck structure for 3d point cloud generation](https://arxiv.org/abs/2505.09140)|[topodit-3d](https://github.com/zechao-guan/topodit-3d)|\n", "2505.09168": "|[drrnet: macro-micro feature fusion and dual reverse refinement for camouflaged object detection](https://arxiv.org/abs/2505.09168)|[drrnet](https://github.com/jerrysunning/drrnet)|\n", "2505.09252": "|[zero-shot multi-modal large language model v.s. supervised deep learning: a comparative study on ct-based intracranial hemorrhage subtyping](https://arxiv.org/abs/2505.09252)|[ich_mllms_validation](https://github.com/mileswyn/ich_mllms_validation)|\n", "2505.09262": "|[edbench: large-scale electron density data for molecular modeling](https://arxiv.org/abs/2505.09262)|[EDBench](https://github.com/HongxinXiang/EDBench)|\n", "2505.09263": "|[few-shot anomaly-driven generation for anomaly classification and segmentation](https://arxiv.org/abs/2505.09263)|[anogen](https://github.com/gaobb/anogen)|\n", "2505.09264": "|[learning to detect multi-class anomalies with just one normal image prompt](https://arxiv.org/abs/2505.09264)|[onenip](https://github.com/gaobb/onenip)|\n", "2505.09306": "|[predicting butterfly species presence from satellite imagery using soft contrastive regularisation](https://arxiv.org/abs/2505.09306)|[pecl](https://github.com/vdplasthijs/pecl)|\n", "2505.09323": "|[q-space guided collaborative attention translation network for flexible diffusion-weighted images synthesis](https://arxiv.org/abs/2505.09323)|[q-catn](https://github.com/idea89560041/q-catn)|\n", "2505.09350": "|[procedural low-poly terrain generation with terracing for computer games](https://arxiv.org/abs/2505.09350)|[Procedural-Low-Poly-Terrain-Generation](https://github.com/richardtivolt/Procedural-Low-Poly-Terrain-Generation)|\n", "2505.09356": "|[apr-transformer: initial pose estimation for localization in complex environments through absolute pose regression](https://arxiv.org/abs/2505.09356)|[apr-transformer](https://github.com/gt-arc/apr-transformer)|\n", "2505.09358": "|[marigold: affordable adaptation of diffusion-based image generators for image analysis](https://arxiv.org/abs/2505.09358)|[marigold](https://github.com/prs-eth/marigold)|\n", "2505.09372": "|[make: multi-aspect knowledge-enhanced vision-language pretraining for zero-shot dermatological assessment](https://arxiv.org/abs/2505.09372)|[make](https://github.com/siyuanyan1/make)|\n", "2505.09393": "|[umotion: uncertainty-driven human motion estimation from inertial and ultra-wideband units](https://arxiv.org/abs/2505.09393)|[umotion](https://github.com/kk9six/umotion)|\n", "2505.09413": "|[sparse point cloud patches rendering via splitting 2d gaussians](https://arxiv.org/abs/2505.09413)|[gaupcrender](https://github.com/murcherful/gaupcrender)|\n", "2505.09521": "|[spec2volcamu-net: a spectrogram-to-volume model for eeg-to-fmri reconstruction based on multi-directional time-frequency convolutional attention encoder and vision-mamba u-net](https://arxiv.org/abs/2505.09521)|[spec2volcamu-net](https://github.com/hdy6438/spec2volcamu-net)|\n", "2505.09528": "|[conformal bounds on full-reference image quality for imaging inverse problems](https://arxiv.org/abs/2505.09528)|[quality_uq](https://github.com/jwen307/quality_uq)|\n", "2505.09529": "|[contactless cardiac pulse monitoring using event cameras](https://arxiv.org/abs/2505.09529)|[contactless_cardiac_pulse_monitoring_using_event_cameras](https://github.com/c3imaging/contactless_cardiac_pulse_monitoring_using_event_cameras)|\n", "2505.09558": "|[wavreward: spoken dialogue models with generalist reward evaluators](https://arxiv.org/abs/2505.09558)|[wavreward](https://github.com/jishengpeng/wavreward)|\n", "2505.09568": "|[blip3-o: a family of fully open unified multimodal models-architecture, training and dataset](https://arxiv.org/abs/2505.09568)|[blip3o](https://github.com/jiuhaichen/blip3o)|\n"}, "2025-05-16": {"2303.09681": "|[highly efficient 3d human pose tracking from events with spiking spatiotemporal transformer](https://arxiv.org/abs/2303.09681)|[humanposetracking_snn](https://github.com/jimmyzou/humanposetracking_snn)|\n", "2306.07615": "|[uod: universal one-shot detection of anatomical landmarks](https://arxiv.org/abs/2306.07615)|[uod_universal_oneshot_detection](https://github.com/heqin-zhu/uod_universal_oneshot_detection)|\n", "2309.00287": "|[fast diffusion em: a diffusion model for blind inverse problems with application to deconvolution](https://arxiv.org/abs/2309.00287)|[fastdiffusionem](https://github.com/claroche-r/fastdiffusionem)|\n", "2311.08043": "|[contrastive learning for multi-object tracking with transformers](https://arxiv.org/abs/2311.08043)|[ContrasTR](https://github.com/pfdp0/ContrasTR)|\n", "2311.14435": "|[local concept embeddings for analysis of concept distributions in vision dnn feature spaces](https://arxiv.org/abs/2311.14435)|[local-concept-embeddings](https://github.com/continental/local-concept-embeddings)|\n", "2312.01797": "|[llm a*: human in the loop large language models enabled a* search for robotics](https://arxiv.org/abs/2312.01797)|[llm-a-](https://github.com/speedhawk/llm-a-)|\n", "2401.14066": "|[creativesynth: cross-art-attention for artistic image synthesis with multimodal diffusion](https://arxiv.org/abs/2401.14066)|[CreativeSynth](https://github.com/haha-lisa/CreativeSynth)|\n", "2403.07547": "|[smurf: continuous dynamics for motion-deblurring radiance fields](https://arxiv.org/abs/2403.07547)|[smurf](https://github.com/jho-yonsei/smurf)|\n", "2403.17525": "|[equipping sketch patches with context-aware positional encoding for graphic sketch representation](https://arxiv.org/abs/2403.17525)|[dc-gra2seq](https://github.com/sczang/dc-gra2seq)|\n", "2406.12632": "|[cyclic 2.5d perceptual loss for cross-modal 3d medical image synthesis: t1w mri to tau pet](https://arxiv.org/abs/2406.12632)|[Cyclic-2.5D-Perceptual-Loss](https://github.com/labhai-dev/Cyclic-2.5D-Perceptual-Loss)|\n", "2410.01262": "|[improving fine-grained control via aggregation of multiple diffusion models](https://arxiv.org/abs/2410.01262)|[amdm](https://github.com/hammour-steak/amdm)|\n", "2411.08665": "|[osmloc: single image-based visual localization in openstreetmap with fused geometric and semantic guidance](https://arxiv.org/abs/2411.08665)|[osmloc](https://github.com/whu-usi3dv/osmloc)|\n", "2411.13602": "|[translating electrocardiograms to cardiac magnetic resonance imaging useful for cardiac assessment and disease screening: a multi-center study ai for ecg to cmr translation study](https://arxiv.org/abs/2411.13602)|[ecg-cmr](https://github.com/yukui-1999/ecg-cmr)|\n", "2411.14347": "|[dino-x: a unified vision model for open-world object detection and understanding](https://arxiv.org/abs/2411.14347)|[dino-x-api](https://github.com/idea-research/dino-x-api)|\n", "2501.01482": "|[an unsupervised method for mri recovery: deep image prior with structured sparsity](https://arxiv.org/abs/2501.01482)|[discus](https://github.com/osu-mr/discus)|\n", "2501.03021": "|[a trust-guided approach to mr image reconstruction with side information](https://arxiv.org/abs/2501.03021)|[tgvn](https://github.com/sodicksonlab/tgvn)|\n", "2501.12331": "|[cinepro: robust training of foundation models for cancer detection in prostate ultrasound cineloops](https://arxiv.org/abs/2501.12331)|[cinepro](https://github.com/mharmanani/cinepro)|\n", "2502.19090": "|[endomamba: an efficient foundation model for endoscopic videos via hierarchical pre-training](https://arxiv.org/abs/2502.19090)|[endomamba](https://github.com/tiancuteqy/endomamba)|\n", "2502.19159": "|[a sliding layer merging method for efficient depth-wise pruning in llms](https://arxiv.org/abs/2502.19159)|[slm-a-sliding-layer-merging-method](https://github.com/920927/slm-a-sliding-layer-merging-method)|\n", "2503.20291": "|[cryosamu: enhancing 3d cryo-em density maps of protein structures at intermediate resolution with structure-aware multimodal u-nets](https://arxiv.org/abs/2503.20291)|[cryosamu](https://github.com/chenwei-zhang/cryosamu)|\n", "2503.21776": "|[video-r1: reinforcing video reasoning in mllms](https://arxiv.org/abs/2503.21776)|[video-r1](https://github.com/tulerfeng/video-r1)|\n", "2504.00496": "|[learned image compression with dictionary-based entropy model](https://arxiv.org/abs/2504.00496)|[dcae](https://github.com/labshuhanggu/dcae)|\n", "2504.02522": "|[charm: the missing piece in vit fine-tuning for image aesthetic assessment](https://arxiv.org/abs/2504.02522)|[charm](https://github.com/fbehrad/charm)|\n", "2504.13231": "|[wildfirecan-mmd: a multimodal dataset for classification of user-generated content during wildfires in canada](https://arxiv.org/abs/2504.13231)|[WildfireCanMMD-Multimedia-Classification-on-user-generated-content-During-Wildfires-in-Canada](https://github.com/Multimodal-Social-Media-Data-Analysis/WildfireCanMMD-Multimedia-Classification-on-user-generated-content-During-Wildfires-in-Canada)|\n", "2504.19458": "|[mitigating modality bias in multi-modal entity alignment from a causal perspective](https://arxiv.org/abs/2504.19458)|[CDMEA](https://github.com/sutaoyu/CDMEA)|\n", "2505.03186": "|[cogenav: versatile audio-visual representation learning via contrastive-generative synchronization](https://arxiv.org/abs/2505.03186)|[cogenav](https://github.com/humanmllm/cogenav)|\n", "2505.05901": "|[examining the source of defects from a mechanical perspective for 3d anomaly detection](https://arxiv.org/abs/2505.05901)|[mc4ad](https://github.com/hzzzzzhappy/mc4ad)|\n", "2505.06512": "|[hcma: hierarchical cross-model alignment for grounded text-to-image generation](https://arxiv.org/abs/2505.06512)|[hcma](https://github.com/hwang-cs-ime/hcma)|\n", "2505.08910": "|[behind maya: building a multilingual vision language model](https://arxiv.org/abs/2505.08910)|[maya](https://github.com/nahidalam/maya)|\n", "2505.09858": "|[mission balance: generating under-represented class samples using video diffusion models](https://arxiv.org/abs/2505.09858)|[surgvgen](https://gitlab.com/nct_tso_public/surgvgen)|\n", "2505.09901": "|[comparing exploration-exploitation strategies of llms and humans: insights from standard multi-armed bandit tasks](https://arxiv.org/abs/2505.09901)|[exploration](https://github.com/sjgershm/exploration)|\n", "2505.09927": "|[ddfp: data-dependent frequency prompt for source free domain adaptation of medical image segmentation](https://arxiv.org/abs/2505.09927)|[SFDA-DDFP](https://github.com/YYinn/SFDA-DDFP)|\n", "2505.09939": "|[non-registration change detection: a novel change detection task and benchmark dataset](https://arxiv.org/abs/2505.09939)|[nrcd](https://github.com/shanzard/nrcd)|\n", "2505.09943": "|[cspenet: contour-aware and saliency priors embedding network for infrared small target detection](https://arxiv.org/abs/2505.09943)|[cspenet](https://github.com/idip2025/cspenet)|\n", "2505.09971": "|[apcotta: continual test-time adaptation for semantic segmentation of airborne lidar point clouds](https://arxiv.org/abs/2505.09971)|[apcotta](https://github.com/gaoyuan2/apcotta)|\n", "2505.10046": "|[exploring the deep fusion of large language models and diffusion transformers for text-to-image synthesis](https://arxiv.org/abs/2505.10046)|[fuse-dit](https://github.com/tang-bd/fuse-dit)|\n", "2505.10049": "|[advances in radiance field for dynamic scene: from neural field to gaussian field](https://arxiv.org/abs/2505.10049)|[dynamic-radiation-field-paper-list](https://github.com/moonflo/dynamic-radiation-field-paper-list)|\n", "2505.10055": "|[psocr: benchmarking large multimodal models for optical character recognition in low-resource pashto language](https://arxiv.org/abs/2505.10055)|[pashtoocr](https://github.com/zirak-ai/pashtoocr)|\n", "2505.10088": "|[mmrl++: parameter-efficient and interaction-aware representation learning for vision-language models](https://arxiv.org/abs/2505.10088)|[MMRL](https://github.com/yunncheng/MMRL)|\n", "2505.10124": "|[imitate: image registration with context for unknown time frame recovery](https://arxiv.org/abs/2505.10124)|[imitate](https://github.com/kheil-z/imitate)|\n", "2505.10144": "|[vrsplat: fast and robust gaussian splatting for virtual reality](https://arxiv.org/abs/2505.10144)|[vrsplat](https://github.com/cekavis/vrsplat)|\n", "2505.10223": "|[data-agnostic augmentations for unknown variations: out-of-distribution generalisation in mri segmentation](https://arxiv.org/abs/2505.10223)|[augmentations-for-the-unknown](https://github.com/miagrouput/augmentations-for-the-unknown)|\n", "2505.10231": "|[on the interplay of human-ai alignment,fairness, and performance trade-offs in medical imaging](https://arxiv.org/abs/2505.10231)|[aligner](https://github.com/roypic/aligner)|\n", "2505.10250": "|[adhmr: aligning diffusion-based human mesh recovery via direct preference optimization](https://arxiv.org/abs/2505.10250)|[adhmr](https://github.com/shenwenhao01/adhmr)|\n", "2505.10281": "|[mfoghub: bridging multi-regional and multi-satellite data for global marine fog detection and forecasting](https://arxiv.org/abs/2505.10281)|[mfoghub](https://github.com/kaka0910/mfoghub)|\n", "2505.10289": "|[msci: addressing clip's inherent limitations for compositional zero-shot learning](https://arxiv.org/abs/2505.10289)|[msci](https://github.com/ltpwy/msci)|\n", "2505.10292": "|[storyreasoning dataset: using chain-of-thought for scene understanding and grounded story generation](https://arxiv.org/abs/2505.10292)|[storyreasoning](https://github.com/daniel3303/storyreasoning)|\n", "2505.10294": "|[miphei-vit: multiplex immunofluorescence prediction from h&e images using vit foundation models](https://arxiv.org/abs/2505.10294)|[miphei-vit](https://github.com/sanofi-public/miphei-vit)|\n", "2505.10348": "|[listennet: a lightweight spatio-temporal enhancement nested network for auditory attention detection](https://arxiv.org/abs/2505.10348)|[listennet](https://github.com/fchest/listennet)|\n", "2505.10351": "|[a unified and scalable membership inference method for visual self-supervised encoder via part-aware capability](https://arxiv.org/abs/2505.10351)|[partcrop](https://github.com/jiepku/partcrop)|\n", "2505.10420": "|[learned lightweight smartphone isp with unpaired data](https://arxiv.org/abs/2505.10420)|[learned-lightweight-smartphone-isp-with-unpaired-data](https://github.com/andreiiarhire/learned-lightweight-smartphone-isp-with-unpaired-data)|\n", "2505.10457": "|[seal: searching expandable architectures for incremental learning](https://arxiv.org/abs/2505.10457)|[seal](https://github.com/ai-tech-research-lab/seal)|\n", "2505.10473": "|[consistent quantity-quality control across scenes for deployment-aware gaussian splatting](https://arxiv.org/abs/2505.10473)|[ControlGS](https://github.com/zhang-fengdi/ControlGS)|\n", "2505.10496": "|[chexgenbench: a unified benchmark for fidelity, privacy and utility of synthetic chest radiographs](https://arxiv.org/abs/2505.10496)|[CheXGenBench](https://github.com/Raman1121/CheXGenBench)|\n", "2505.10518": "|[multi-token prediction needs registers](https://arxiv.org/abs/2505.10518)|[mutor](https://github.com/nasosger/mutor)|\n", "2505.10541": "|[exploring implicit visual misunderstandings in multimodal large language models through attention analysis](https://arxiv.org/abs/2505.10541)|[stme](https://github.com/welldonepf/stme)|\n", "2505.10551": "|[does feasibility matter? understanding the impact of feasibility on synthetic training data](https://arxiv.org/abs/2505.10551)|[syntheticdatafeasibility](https://github.com/yiveen/syntheticdatafeasibility)|\n", "2505.10557": "|[mathcoder-vl: bridging vision and code for enhanced multimodal mathematical reasoning](https://arxiv.org/abs/2505.10557)|[mathcoder](https://github.com/mathllm/mathcoder)|\n"}, "2025-05-17": {}, "2025-05-18": {}, "2025-05-19": {"2404.13274": "|[augmented object intelligence with xr-objects](https://arxiv.org/abs/2404.13274)|[xr-objects](https://github.com/google/xr-objects)|\n", "2406.11624": "|[words in motion: extracting interpretable control vectors for motion transformers](https://arxiv.org/abs/2406.11624)|[future-motion](https://github.com/kit-mrt/future-motion)|\n", "2407.03653": "|[reben: refined bigearthnet dataset for remote sensing image analysis](https://arxiv.org/abs/2407.03653)|[rico-hdl](https://github.com/rsim-tu-berlin/rico-hdl)|\n", "2409.04388": "|[question-answering dense video events](https://arxiv.org/abs/2409.04388)|[deve-qa](https://github.com/qhuni/deve-qa)|\n", "2409.18865": "|[positional encoder graph quantile neural networks for geographic data](https://arxiv.org/abs/2409.18865)|[pe-gnn](https://github.com/konstantinklemmer/pe-gnn)|\n", "2411.09101": "|[heuristical comparison of vision transformers against convolutional neural networks for semantic segmentation on remote sensing imagery](https://arxiv.org/abs/2411.09101)|[vit-vs-cnn-image-segmentation](https://github.com/ashimdahal/vit-vs-cnn-image-segmentation)|\n", "2411.09263": "|[rethinking weight-averaged model-merging](https://arxiv.org/abs/2411.09263)|[rethink-merge](https://github.com/billhhh/rethink-merge)|\n", "2411.12919": "|[robust multi-coil mri reconstruction via self-supervised denoising](https://arxiv.org/abs/2411.12919)|[gsure-diffusion-mri](https://github.com/utcsilab/gsure-diffusion-mri)|\n", "2411.17141": "|[learning robust anymodal segmentor with unimodal and cross-modal distillation](https://arxiv.org/abs/2411.17141)|[AnySeg](https://github.com/zhengxuJosh/AnySeg)|\n", "2411.18440": "|[understanding galaxy morphology evolution through cosmic time via redshift conditioned diffusion models](https://arxiv.org/abs/2411.18440)|[lizarraga_2024](https://github.com/astrodatalab/lizarraga_2024)|\n", "2412.09765": "|[l-wise: boosting human visual category learning through model-based image selection and enhancement](https://arxiv.org/abs/2412.09765)|[l-wise](https://github.com/morganbdt/l-wise)|\n", "2412.13303": "|[fastvlm: efficient vision encoding for vision language models](https://arxiv.org/abs/2412.13303)|[ml-fastvlm](https://github.com/apple/ml-fastvlm)|\n", "2501.11803": "|[automating high quality rt planning at scale](https://arxiv.org/abs/2501.11803)|[gdp-hmm_aapmchallenge](https://github.com/riqianggao/gdp-hmm_aapmchallenge)|\n", "2503.04114": "|[organize, then vote: exploring cognitive load in quadratic survey interfaces](https://arxiv.org/abs/2503.04114)|[Quadratic-Survey-Dataset-and-Analysis](https://github.com/CrowdDynamicsLab/Quadratic-Survey-Dataset-and-Analysis)|\n", "2503.17715": "|[normalized matching transformer](https://arxiv.org/abs/2503.17715)|[normmatchtrans](https://github.com/apollos1301/normmatchtrans)|\n", "2503.18931": "|[comp: continual multimodal pre-training for vision foundation models](https://arxiv.org/abs/2503.18931)|[CoMP-MM](https://github.com/SliMM-X/CoMP-MM)|\n", "2503.24121": "|[impact: a generic semantic loss for multimodal medical image registration](https://arxiv.org/abs/2503.24121)|[impactloss](https://github.com/vboussot/impactloss)|\n", "2504.04893": "|[scam: a real-world typographic robustness evaluation for multimodal foundation models](https://arxiv.org/abs/2504.04893)|[scam](https://github.com/bliss-e-v/scam)|\n", "2504.06148": "|[v-mage: a game evaluation framework for assessing vision-centric capabilities in multimodal large language models](https://arxiv.org/abs/2504.06148)|[v-mage](https://github.com/csu-jpg/v-mage)|\n", "2504.10400": "|[towards low-latency event-based obstacle avoidance on a fpga-drone](https://arxiv.org/abs/2504.10400)|[eva](https://github.com/pbonazzi/eva)|\n", "2504.13580": "|[leveraging automatic cad annotations for supervised learning in 3d scene understanding](https://arxiv.org/abs/2504.13580)|[SCANnotatepp](https://github.com/stefan-ainetter/SCANnotatepp)|\n", "2505.01481": "|[videohallu: evaluating and mitigating multi-modal hallucinations on synthetic video understanding](https://arxiv.org/abs/2505.01481)|[videohallu](https://github.com/zli12321/videohallu)|\n", "2505.04258": "|[rgb-event fusion with self-attention for collision prediction](https://arxiv.org/abs/2505.04258)|[eva](https://github.com/pbonazzi/eva)|\n", "2505.05848": "|[refref: a synthetic dataset and benchmark for reconstructing refractive and reflective objects](https://arxiv.org/abs/2505.05848)|[refref](https://github.com/yueyin27/refref)|\n", "2505.06003": "|[from pixels to perception: interpretable predictions via instance-wise grouped feature selection](https://arxiv.org/abs/2505.06003)|[p2p](https://github.com/mvandenhi/p2p)|\n", "2505.07449": "|[ophora: a large-scale data-driven text-guided ophthalmic surgical video generation model](https://arxiv.org/abs/2505.07449)|[ophora](https://github.com/mar-cry/ophora)|\n", "2505.10595": "|[arfc-wahnet: adaptive receptive field convolution and wavelet-attentive hierarchical network for infrared small target detection](https://arxiv.org/abs/2505.10595)|[arfc-wahnet](https://github.com/leaf2001/arfc-wahnet)|\n", "2505.10610": "|[mmlongbench: benchmarking long-context vision-language models effectively and thoroughly](https://arxiv.org/abs/2505.10610)|[mmlongbench](https://github.com/edinburghnlp/mmlongbench)|\n", "2505.10679": "|[are spatial-temporal graph convolution networks for human action recognition over-parameterized?](https://arxiv.org/abs/2505.10679)|[sparse-st-gcn](https://github.com/davelailai/sparse-st-gcn)|\n", "2505.10686": "|[neolightning: a modern reimagination of gesture-based sound design](https://arxiv.org/abs/2505.10686)|[reimaginingthebuchlalightning](https://github.com/yonghyunk1m/reimaginingthebuchlalightning)|\n", "2505.10687": "|[roisgan: a region guided generative adversarial framework for murine hippocampal subregion segmentation](https://arxiv.org/abs/2505.10687)|[roisgan](https://github.com/mehediazim/roisgan)|\n", "2505.10787": "|[ea-3dgs: efficient and adaptive 3d gaussians with highly enhanced quality for outdoor scenes](https://arxiv.org/abs/2505.10787)|[ea-3dgs](https://github.com/scut-bip-lab/ea-3dgs)|\n", "2505.10824": "|[textured mesh quality assessment using geometry and color field similarity](https://arxiv.org/abs/2505.10824)|[fmqm](https://github.com/yyyykf/fmqm)|\n", "2505.10836": "|[multimodal event detection: current approaches and defining the new playground through llms and vlms](https://arxiv.org/abs/2505.10836)|[multimodeleventdetection](https://github.com/salokr/multimodeleventdetection)|\n", "2505.10873": "|[hashing for structure-based anomaly detection](https://arxiv.org/abs/2505.10873)|[hashing-for-structure-based-anomaly-detection](https://github.com/ineveloppilif/hashing-for-structure-based-anomaly-detection)|\n", "2505.10874": "|[multilink: multi-class structure recovery via agglomerative clustering and model selection](https://arxiv.org/abs/2505.10874)|[multilink](https://github.com/magrilu/multilink)|\n", "2505.10888": "|[posebench3d: a cross-dataset analysis framework for 3d human pose estimation](https://arxiv.org/abs/2505.10888)|[poselab3d](https://github.com/bryanjvela/poselab3d)|\n", "2505.10931": "|[m4-sar: a multi-resolution, multi-polarization, multi-scene, multi-source dataset and benchmark for optical-sar fusion object detection](https://arxiv.org/abs/2505.10931)|[m4-sar](https://github.com/wchao0601/m4-sar)|\n", "2505.11003": "|[forensichub: a unified benchmark & codebase for all-domain fake image detection and localization](https://arxiv.org/abs/2505.11003)|[forensichub](https://github.com/scu-zjz/forensichub)|\n", "2505.11034": "|[cleanpatrick: a benchmark for image data cleaning](https://arxiv.org/abs/2505.11034)|[cleanpatrick](https://github.com/digital-dermatology/cleanpatrick)|\n", "2505.11060": "|[cubic: concept embeddings for unsupervised bias identification using vlms](https://arxiv.org/abs/2505.11060)|[cubic](https://github.com/david-mnd/cubic)|\n", "2505.11062": "|[hsrmamba: efficient wavelet stripe state space model for hyperspectral image super-resolution](https://arxiv.org/abs/2505.11062)|[hsrmamba](https://github.com/oldsweet/hsrmamba)|\n", "2505.11099": "|[hybrid-emba3d: geometry-aware and cross-path feature hybrid enhanced state space model for point cloud classification](https://arxiv.org/abs/2505.11099)|[hybrid-emba3d](https://github.com/l1277471578/hybrid-emba3d)|\n", "2505.11129": "|[phinet v2: a mask-free brain-inspired vision foundation model from video](https://arxiv.org/abs/2505.11129)|[phinetv2](https://github.com/oist/phinetv2)|\n", "2505.11131": "|[one image is worth a thousand words: a usability preservable text-image collaborative erasing framework](https://arxiv.org/abs/2505.11131)|[co-erasing](https://github.com/ferry-li/co-erasing)|\n", "2505.11146": "|[x2c: a dataset featuring nuanced facial expressions for realistic humanoid imitation](https://arxiv.org/abs/2505.11146)|[x2cnet](https://github.com/lipzh5/x2cnet)|\n", "2505.11196": "|[dico: revitalizing convnets for scalable and efficient diffusion modeling](https://arxiv.org/abs/2505.11196)|[dico](https://github.com/shallowdream204/dico)|\n", "2505.11237": "|[concept drift guided layernorm tuning for efficient multimodal metaphor identification](https://arxiv.org/abs/2505.11237)|[CDGLT](https://github.com/MSA-LMC/CDGLT)|\n", "2505.11245": "|[diffusion-npo: negative preference optimization for better preference aligned generation of diffusion models](https://arxiv.org/abs/2505.11245)|[diffusion-npo](https://github.com/g-u-n/diffusion-npo)|\n", "2505.11246": "|[entropy-driven genetic optimization for deep-feature-guided low-light image enhancement](https://arxiv.org/abs/2505.11246)|[entropy-driven-genetic-optimization-for-deep-feature-guided-low-light-image-enhancement](https://github.com/nirjhor-datta/entropy-driven-genetic-optimization-for-deep-feature-guided-low-light-image-enhancement)|\n", "2505.11293": "|[breaking the batch barrier (b3) of contrastive learning via smart batch mining](https://arxiv.org/abs/2505.11293)|[b3](https://github.com/raghavlite/b3)|\n", "2505.11326": "|[temporally-grounded language generation: a benchmark for real-time vision-language models](https://arxiv.org/abs/2505.11326)|[tglg](https://github.com/yukw777/tglg)|\n", "2505.11366": "|[learning multimodal ai algorithms for amplifying limited user input into high-dimensional control space](https://arxiv.org/abs/2505.11366)|[aras](https://github.com/abirilab/aras)|\n", "2505.11383": "|[dynam3d: dynamic layered 3d tokens empower vlm for vision-and-language navigation](https://arxiv.org/abs/2505.11383)|[dynam3d](https://github.com/mrzihan/dynam3d)|\n", "2505.11394": "|[from fibers to cells: fourier-based registration enables virtual cresyl violet staining from 3d polarized light imaging](https://arxiv.org/abs/2505.11394)|[pli2cells](https://github.com/fzj-inm1-bda/pli2cells)|\n", "2505.11405": "|[emotionhallucer: evaluating emotion hallucinations in multimodal large language models](https://arxiv.org/abs/2505.11405)|[emotionhallucer](https://github.com/xxtars/emotionhallucer)|\n", "2505.11409": "|[visual planning: let's think only with images](https://arxiv.org/abs/2505.11409)|[visualplanning](https://github.com/yix8/visualplanning)|\n", "2505.11417": "|[edgewisepersona: a dataset for on-device user profiling from natural language interactions](https://arxiv.org/abs/2505.11417)|[edgewisepersona](https://github.com/tclresearcheurope/edgewisepersona)|\n", "2505.11454": "|[humanibench: a human-centric framework for large multimodal models evaluation](https://arxiv.org/abs/2505.11454)|[humanibench](https://github.com/vectorinstitute/humanibench)|\n"}, "2025-05-20": {"2206.05751": "|[consistent attack: universal adversarial perturbation on embodied vision navigation](https://arxiv.org/abs/2206.05751)|[Consistent-Attack](https://github.com/yingchengyang/Consistent-Attack)|\n", "2207.06817": "|[pseudo-labeling based practical semi-supervised meta-training for few-shot learning](https://arxiv.org/abs/2207.06817)|[plml](https://github.com/ouyangtianran/plml)|\n", "2211.01095": "|[dpm-solver++: fast solver for guided sampling of diffusion probabilistic models](https://arxiv.org/abs/2211.01095)|[dpm-solver](https://github.com/luchengthu/dpm-solver)|\n", "2303.08730": "|[diffusionad: norm-guided one-step denoising diffusion for anomaly detection](https://arxiv.org/abs/2303.08730)|[diffusionad](https://github.com/huizhang0812/diffusionad)|\n", "2303.12267": "|[auto: adaptive outlier optimization for test-time ood detection](https://arxiv.org/abs/2303.12267)|[AUTO-for-OOD-detection](https://github.com/Puning97/AUTO-for-OOD-detection)|\n", "2305.15560": "|[differentially private synthetic data via foundation model apis 1: images](https://arxiv.org/abs/2305.15560)|[dpsda](https://github.com/microsoft/dpsda)|\n", "2306.05612": "|[spatial re-parameterization for n:m sparsity](https://arxiv.org/abs/2306.05612)|[spre](https://github.com/zyxxmu/spre)|\n", "2306.11766": "|[agreeing and disagreeing in collaborative knowledge graph construction: an analysis of wikidata](https://arxiv.org/abs/2306.11766)|[wikidata_disagreements](https://github.com/elisavetk/wikidata_disagreements)|\n", "2308.05257": "|[developing a hybrid convolutional neural network for automatic aphid counting in sugar beet fields](https://arxiv.org/abs/2308.05257)|[counting-aphids](https://github.com/junfenggaolab/counting-aphids)|\n", "2308.09307": "|[rethinking image forgery detection via soft contrastive learning and unsupervised clustering](https://arxiv.org/abs/2308.09307)|[focal](https://github.com/highwaywu/focal)|\n", "2310.10378": "|[cross-lingual consistency of factual knowledge in multilingual language models](https://arxiv.org/abs/2310.10378)|[Cross-Lingual-Consistency](https://github.com/Betswish/Cross-Lingual-Consistency)|\n", "2311.13706": "|[multi-view hybrid graph convolutional network for volume-to-mesh reconstruction in cardiovascular mri](https://arxiv.org/abs/2311.13706)|[hybridgnet_3d](https://github.com/ngaggion/hybridgnet_3d)|\n", "2312.03406": "|[does vector quantization fail in spatio-temporal forecasting? exploring a differentiable sparse soft-vector quantization approach](https://arxiv.org/abs/2312.03406)|[SVQ-Forecasting](https://github.com/Pachark/SVQ-Forecasting)|\n", "2312.04831": "|[towards enhanced image inpainting: mitigating unwanted object insertion and preserving color consistency](https://arxiv.org/abs/2312.04831)|[asuka-misato](https://github.com/yikai-wang/asuka-misato)|\n", "2402.15679": "|[scalable density-based clustering with random projections](https://arxiv.org/abs/2402.15679)|[sDbscan](https://github.com/NinhPham/sDbscan)|\n", "2403.08504": "|[offboard occupancy refinement with hybrid propagation for autonomous driving](https://arxiv.org/abs/2403.08504)|[occfiner](https://github.com/masterhow/occfiner)|\n", "2403.15576": "|[data-centric prediction explanation via kernelized stein discrepancy](https://arxiv.org/abs/2403.15576)|[hdexplain](https://github.com/mahtabsarvmaili/hdexplain)|\n", "2404.07495": "|[pillartrack:boosting pillar representation for transformer-based 3d single object tracking on point clouds](https://arxiv.org/abs/2404.07495)|[pillartrack](https://github.com/stiphyjay/pillartrack)|\n", "2405.02564": "|[probing human visual robustness with neurally-guided deep neural networks](https://arxiv.org/abs/2405.02564)|[NeuralGuidance](https://github.com/shaox192/NeuralGuidance)|\n", "2406.04207": "|[cdmamba: incorporating local clues into mamba for remote sensing image binary change detection](https://arxiv.org/abs/2406.04207)|[cdmamba](https://github.com/zmoka-zht/cdmamba)|\n", "2406.07089": "|[rs-agent: automating remote sensing tasks through intelligent agent](https://arxiv.org/abs/2406.07089)|[rs-agent](https://github.com/intellisensing/rs-agent)|\n", "2407.01976": "|[a bounding box is worth one token: interleaving layout and text in a large language model for document understanding](https://arxiv.org/abs/2407.01976)|[laytextllm](https://github.com/laytextllm/laytextllm)|\n", "2407.06159": "|[a semantic-aware and multi-guided network for infrared-visible image fusion](https://arxiv.org/abs/2407.06159)|[smfnet](https://github.com/abraham-einstein/smfnet)|\n", "2407.13195": "|[scalable exploration via ensemble++](https://arxiv.org/abs/2407.13195)|[ensemble_plus_plus](https://github.com/szrlee/ensemble_plus_plus)|\n", "2408.02803": "|[sico: an interactive size-controllable virtual try-on approach for informed decision-making](https://arxiv.org/abs/2408.02803)|[sico](https://github.com/sherryxtchen/sico)|\n", "2408.05159": "|[easyinv: toward fast and better ddim inversion](https://arxiv.org/abs/2408.05159)|[easyinv](https://github.com/potato-kitty/easyinv)|\n", "2409.14319": "|[scene-text grounding for text-based video question answering](https://arxiv.org/abs/2409.14319)|[vitxt-gqa](https://github.com/zhousheng97/vitxt-gqa)|\n", "2409.16902": "|[underwater camouflaged object tracking meets vision-language sam2](https://arxiv.org/abs/2409.16902)|[awesome-multimodal-object-tracking](https://github.com/983632847/awesome-multimodal-object-tracking)|\n", "2410.08151": "|[progressive autoregressive video diffusion models](https://arxiv.org/abs/2410.08151)|[pa_vdm](https://github.com/desaixie/pa_vdm)|\n", "2410.10733": "|[deep compression autoencoder for efficient high-resolution diffusion models](https://arxiv.org/abs/2410.10733)|[efficientvit](https://github.com/mit-han-lab/efficientvit)|\n", "2410.18388": "|[irregular tensor low-rank representation for hyperspectral image representation](https://arxiv.org/abs/2410.18388)|[itlrr](https://github.com/hb-studying/itlrr)|\n", "2410.21759": "|[intlora: integral low-rank adaptation of quantized diffusion models](https://arxiv.org/abs/2410.21759)|[intlora](https://github.com/csguoh/intlora)|\n", "2410.22076": "|[uspeech: ultrasound-enhanced speech with minimal human effort via cross-modal synthesis](https://arxiv.org/abs/2410.22076)|[USpeech](https://github.com/aiot-lab/USpeech)|\n", "2411.19551": "|[bootstraping clustering of gaussians for view-consistent 3d scene understanding](https://arxiv.org/abs/2411.19551)|[FreeGS](https://github.com/wb014/FreeGS)|\n", "2411.19722": "|[jetformer: an autoregressive generative model of raw images and text](https://arxiv.org/abs/2411.19722)|[big_vision](https://github.com/google-research/big_vision)|\n", "2411.19939": "|[vlsbench: unveiling visual leakage in multimodal safety](https://arxiv.org/abs/2411.19939)|[vlsbench](https://github.com/ai45lab/vlsbench)|\n", "2412.03210": "|[parametric perceptnet: a bio-inspired deep-net trained for image quality assessment](https://arxiv.org/abs/2412.03210)|[PerceptualTests](https://github.com/Jorgvt/PerceptualTests)|\n", "2412.09945": "|[going beyond feature similarity: effective dataset distillation based on class-aware conditional mutual information](https://arxiv.org/abs/2412.09945)|[cmidd](https://github.com/ndhg1213/cmidd)|\n", "2412.20056": "|[gsplatloc: ultra-precise camera localization via 3d gaussian splatting](https://arxiv.org/abs/2412.20056)|[gsplatloc](https://github.com/atticuszeller/gsplatloc)|\n", "2501.04697": "|[grokking at the edge of numerical stability](https://arxiv.org/abs/2501.04697)|[grokking-at-the-edge-of-numerical-stability](https://github.com/lucasprietoal/grokking-at-the-edge-of-numerical-stability)|\n", "2501.18116": "|[deepfrc: an end-to-end deep learning model for functional registration and classification](https://arxiv.org/abs/2501.18116)|[deepfrc](https://github.com/drivergo-93589/deepfrc)|\n", "2501.18427": "|[sana 1.5: efficient scaling of training-time and inference-time compute in linear diffusion transformer](https://arxiv.org/abs/2501.18427)|[Sana](https://github.com/NVlabs/Sana)|\n", "2501.19098": "|[$\\infty$-video: a training-free approach to long video understanding via continuous-time memory consolidation](https://arxiv.org/abs/2501.19098)|[infinite-video](https://github.com/deep-spin/infinite-video)|\n", "2502.00392": "|[refdrone: a challenging benchmark for referring expression comprehension in drone scenes](https://arxiv.org/abs/2502.00392)|[refdrone](https://github.com/sunzc-sunny/refdrone)|\n", "2502.03950": "|[lr0.fm: low-res benchmark and improving robustness for zero-shot classification in foundation models](https://arxiv.org/abs/2502.03950)|[LR0.FM](https://github.com/shyammarjit/LR0.FM)|\n", "2502.05415": "|[unicms: a unified consistency model for efficient multimodal generation and understanding](https://arxiv.org/abs/2502.05415)|[unicms](https://github.com/zhijie-group/unicms)|\n", "2502.09620": "|[exploring the potential of encoder-free architectures in 3d lmms](https://arxiv.org/abs/2502.09620)|[enel](https://github.com/ivan-tang-3d/enel)|\n", "2502.13407": "|[jl1-cd: a new benchmark for remote sensing change detection and a robust multi-teacher knowledge distillation framework](https://arxiv.org/abs/2502.13407)|[mtkd-cd](https://github.com/circlelzy/mtkd-cd)|\n", "2502.14471": "|[integrating extra modality helps segmentor find camouflaged objects well](https://arxiv.org/abs/2502.14471)|[multicos](https://github.com/cnyvfang/multicos)|\n", "2502.20034": "|[vision-encoders (already) know what they see: mitigating object hallucination via simple fine-grained clipscore](https://arxiv.org/abs/2502.20034)|[f-clip](https://github.com/abzb1/f-clip)|\n", "2502.20321": "|[unitok: a unified tokenizer for visual generation and understanding](https://arxiv.org/abs/2502.20321)|[unitok](https://github.com/foundationvision/unitok)|\n", "2503.05423": "|[semantic shift estimation via dual-projection and classifier reconstruction for exemplar-free class-incremental learning](https://arxiv.org/abs/2503.05423)|[icml25-dpcr](https://github.com/rhe502/icml25-dpcr)|\n", "2503.09641": "|[sana-sprint: one-step diffusion with continuous-time consistency distillation](https://arxiv.org/abs/2503.09641)|[Sana](https://github.com/NVlabs/Sana)|\n", "2503.14553": "|[redefining non-iid data in federated learning for computer vision tasks: migrating from labels to embeddings for task-specific data distributions](https://arxiv.org/abs/2503.14553)|[task-perspective-het](https://github.com/kasraborazjani/task-perspective-het)|\n", "2503.15558": "|[cosmos-reason1: from physical common sense to embodied reasoning](https://arxiv.org/abs/2503.15558)|[cosmos-reason1](https://github.com/nvidia-cosmos/cosmos-reason1)|\n", "2503.18225": "|[delora: decoupling angles and strength in low-rank adaptation](https://arxiv.org/abs/2503.18225)|[delora](https://github.com/explainableml/delora)|\n", "2503.18430": "|[cq-dino: mitigating gradient dilution via category queries for vast vocabulary object detection](https://arxiv.org/abs/2503.18430)|[cq-dino](https://github.com/redaigc/cq-dino)|\n", "2503.19325": "|[long-context autoregressive video modeling with next-frame prediction](https://arxiv.org/abs/2503.19325)|[FAR](https://github.com/showlab/FAR)|\n", "2503.21246": "|[dynamictrl: rethinking the basic structure and the role of text for high-quality human image animation](https://arxiv.org/abs/2503.21246)|[dynamictrl](https://github.com/gulucaptain/dynamictrl)|\n", "2504.02277": "|[beyond conventional transformers: the medical x-ray attention (mxa) block for improved multi-label diagnosis using knowledge distillation](https://arxiv.org/abs/2504.02277)|[beyond-conventional-transformers](https://github.com/hadi-m-ibrahim/beyond-conventional-transformers)|\n", "2504.07285": "|[a scalable approach to clustering embedding projections](https://arxiv.org/abs/2504.07285)|[embedding-atlas](https://github.com/apple/embedding-atlas)|\n", "2504.09897": "|[tamp: token-adaptive layerwise pruning in multimodal large language models](https://arxiv.org/abs/2504.09897)|[tamp](https://github.com/g-jwlee/tamp)|\n", "2504.10143": "|[on the value of cross-modal misalignment in multimodal representation learning](https://arxiv.org/abs/2504.10143)|[crossmodal_mislaignment](https://github.com/yichaocai1/crossmodal_mislaignment)|\n", "2504.11349": "|[explicit and implicit representations in ai-based 3d reconstruction for radiology: a systematic review](https://arxiv.org/abs/2504.11349)|[ai4radiology](https://github.com/bean-young/ai4radiology)|\n", "2504.16096": "|[brainprompt: multi-level brain prompt enhancement for neurological condition identification](https://arxiv.org/abs/2504.16096)|[brainprompt](https://github.com/angusmonroe/brainprompt)|\n", "2504.18165": "|[perfcam: digital twinning for production lines using 3d gaussian splatting and vision models](https://arxiv.org/abs/2504.18165)|[PerfCam](https://github.com/AstraZeneca/PerfCam)|\n", "2504.20518": "|[dynamic attention analysis for backdoor detection in text-to-image diffusion models](https://arxiv.org/abs/2504.20518)|[daa](https://github.com/robin-wzq/daa)|\n", "2504.20734": "|[universalrag: retrieval-augmented generation over corpora of diverse modalities and granularities](https://arxiv.org/abs/2504.20734)|[UniversalRAG](https://github.com/wgcyeo/UniversalRAG)|\n", "2505.01000": "|[togedule: scheduling meetings with large language models and adaptive representations of group availability](https://arxiv.org/abs/2505.01000)|[togedule](https://github.com/jyoonsong/togedule)|\n", "2505.01212": "|[high dynamic range novel view synthesis with single exposure](https://arxiv.org/abs/2505.01212)|[mono-hdr-3d](https://github.com/prinasi/mono-hdr-3d)|\n", "2505.02831": "|[no other representation component is needed: diffusion transformers can provide representation guidance by themselves](https://arxiv.org/abs/2505.02831)|[sra](https://github.com/vvvvvjdy/sra)|\n", "2505.03654": "|[regrap-llava: reasoning enabled graph-based personalized large language and vision assistant](https://arxiv.org/abs/2505.03654)|[regrap](https://github.com/xyfyyds/regrap)|\n", "2505.05022": "|[soap: style-omniscient animatable portraits](https://arxiv.org/abs/2505.05022)|[soap](https://github.com/tingtingliao/soap)|\n", "2505.05621": "|[a preliminary study for gpt-4o on image restoration](https://arxiv.org/abs/2505.05621)|[gpt_restoration](https://github.com/noxsine/gpt_restoration)|\n", "2505.05657": "|[arraydps: unsupervised blind speech separation with a diffusion prior](https://arxiv.org/abs/2505.05657)|[arraydps](https://github.com/arraydps/arraydps)|\n", "2505.05678": "|[instancegen: image generation with instance-level instructions](https://arxiv.org/abs/2505.05678)|[SLD](https://github.com/tsunghan-wu/SLD)|\n", "2505.05834": "|[dual-level fuzzy learning with patch guidance for image ordinal regression](https://arxiv.org/abs/2505.05834)|[dfpg-ord](https://github.com/zjumai/dfpg-ord)|\n", "2505.08586": "|[preprompt: predictive prompting for class incremental learning](https://arxiv.org/abs/2505.08586)|[PrePrompt](https://github.com/libo-huang/PrePrompt)|\n", "2505.09926": "|[adaptclip: adapting clip for universal visual anomaly detection](https://arxiv.org/abs/2505.09926)|[AdaptCLIP](https://github.com/gaobb/AdaptCLIP)|\n", "2505.11032": "|[dexgarmentlab: dexterous garment manipulation environment with generalizable policy](https://arxiv.org/abs/2505.11032)|[dexgarmentlab](https://github.com/wayrise/dexgarmentlab)|\n", "2505.11538": "|[brainnetmlp: an efficient and effective baseline for functional brain network classification](https://arxiv.org/abs/2505.11538)|[brainnetmlp](https://github.com/jayceonho/brainnetmlp)|\n", "2505.11581": "|[questioning representational optimism in deep learning: the fractured entangled representation hypothesis](https://arxiv.org/abs/2505.11581)|[fer](https://github.com/akarshkumar0101/fer)|\n", "2505.11594": "|[sageattention3: microscaling fp4 attention for inference and an exploration of 8-bit training](https://arxiv.org/abs/2505.11594)|[SageAttention](https://github.com/thu-ml/SageAttention)|\n", "2505.11612": "|[heart2mind: human-centered contestable psychiatric disorder diagnosis system using wearable ecg monitors](https://arxiv.org/abs/2505.11612)|[heart2mind](https://github.com/analytics-everywhere-lab/heart2mind)|\n", "2505.11703": "|[loft: lora-fused training dataset generation with few-shot guidance](https://arxiv.org/abs/2505.11703)|[loft](https://github.com/explainableml/loft)|\n", "2505.11720": "|[ugodit: unsupervised group deep image prior via transferable weights](https://arxiv.org/abs/2505.11720)|[ugodit](https://github.com/sjames40/ugodit)|\n", "2505.11797": "|[medvkan: efficient feature extraction with mamba and kan for medical image segmentation](https://arxiv.org/abs/2505.11797)|[medvkan](https://github.com/beginner-cjh/medvkan)|\n", "2505.11800": "|[self-learning hyperspectral and multispectral image fusion via adaptive residual guided subspace diffusion model](https://arxiv.org/abs/2505.11800)|[args-diff](https://github.com/zhu1116/args-diff)|\n", "2505.11838": "|[rvtbench: a benchmark for visual reasoning tasks](https://arxiv.org/abs/2505.11838)|[rvt](https://github.com/yiqings/rvt)|\n", "2505.11842": "|[video-safetybench: a benchmark for safety evaluation of video lvlms](https://arxiv.org/abs/2505.11842)|[video-safetybench](https://github.com/flageval-baai/video-safetybench)|\n", "2505.11882": "|[genzsl: generative zero-shot learning via inductive variational autoencoder](https://arxiv.org/abs/2505.11882)|[genzsl](https://github.com/shiming-chen/genzsl)|\n", "2505.11909": "|[bridging the inter-domain gap through low-level features for cross-modal medical image segmentation](https://arxiv.org/abs/2505.11909)|[lowbridge](https://github.com/joshualpf/lowbridge)|\n", "2505.11913": "|[joint manifold learning and optimal transport for dynamic imaging](https://arxiv.org/abs/2505.11913)|[joint-manifold-learning-and-ot](https://github.com/SCdummer/joint-manifold-learning-and-ot)|\n", "2505.12021": "|[cross-model transfer of task vectors via few-shot orthogonal alignment](https://arxiv.org/abs/2505.12021)|[crossmodeltransfer](https://github.com/kawakera-lab/crossmodeltransfer)|\n", "2505.12051": "|[enhanced multimodal hate video detection via channel-wise and modality-wise fusion](https://arxiv.org/abs/2505.12051)|[cmfusion](https://github.com/evelynz10/cmfusion)|\n", "2505.12066": "|[beluga whale detection from satellite imagery with point labels](https://arxiv.org/abs/2505.12066)|[beluga-seeker](https://github.com/voyagerxvoyagerx/beluga-seeker)|\n", "2505.12098": "|[love: benchmarking and evaluating text-to-video generation and video-to-text interpretation](https://arxiv.org/abs/2505.12098)|[love](https://github.com/intmegroup/love)|\n", "2505.12120": "|[histai: an open-source, large-scale whole slide image dataset for computational pathology](https://arxiv.org/abs/2505.12120)|[histai](https://github.com/histai/histai)|\n", "2505.12155": "|[softpq: robust instance segmentation evaluation via soft matching and tunable thresholds](https://arxiv.org/abs/2505.12155)|[SoftPQ](https://github.com/rkarmaka/SoftPQ)|\n", "2505.12191": "|[ditch the denoiser: emergence of noise robustness in self-supervised learning from data curriculum](https://arxiv.org/abs/2505.12191)|[noisy_dinov2](https://github.com/wenquanlu/noisy_dinov2)|\n", "2505.12199": "|[always clear depth: robust monocular depth estimation under adverse weather](https://arxiv.org/abs/2505.12199)|[acdepth](https://github.com/msscao/acdepth)|\n", "2505.12217": "|[hyperspectral image land cover captioning dataset for vision language models](https://arxiv.org/abs/2505.12217)|[hypercap](https://github.com/arya-domain/hypercap)|\n", "2505.12261": "|[openpros: a large-scale dataset for limited view prostate ultrasound computed tomography](https://arxiv.org/abs/2505.12261)|[openpros](https://github.com/hanchenwang/openpros)|\n", "2505.12266": "|[pmq-ve: progressive multi-frame quantization for video enhancement](https://arxiv.org/abs/2505.12266)|[pmq-ve](https://github.com/xiaobigfeng/pmq-ve)|\n", "2505.12267": "|[real-time spatial reasoning by mobile robots for reconstruction and navigation in dynamic lidar scenes](https://arxiv.org/abs/2505.12267)|[RTRecon](https://github.com/SZU-VCC/RTRecon)|\n", "2505.12280": "|[temporal-spectral-spatial unified remote sensing dense prediction](https://arxiv.org/abs/2505.12280)|[official_tssun](https://github.com/walking-shadow/official_tssun)|\n", "2505.12307": "|[logicocr: do your large multimodal models excel at logical reasoning on text-rich images?](https://arxiv.org/abs/2505.12307)|[logicocr](https://github.com/mililab/logicocr)|\n", "2505.12335": "|[is artificial intelligence generated image detection a solved problem?](https://arxiv.org/abs/2505.12335)|[aigibench](https://github.com/horizontel/aigibench)|\n", "2505.12363": "|[towards visuospatial cognition via hierarchical fusion of visual experts](https://arxiv.org/abs/2505.12363)|[vica](https://github.com/nkkbr/vica)|\n", "2505.12432": "|[observe-r1: unlocking reasoning abilities of mllms with dynamic progressive reinforcement learning](https://arxiv.org/abs/2505.12432)|[observe-r1](https://github.com/zrguo/observe-r1)|\n", "2505.12434": "|[videorft: incentivizing video reasoning capability in mllms via reinforced fine-tuning](https://arxiv.org/abs/2505.12434)|[videorft](https://github.com/qiwang98/videorft)|\n", "2505.12513": "|[globalgeotree: a multi-granular vision-language dataset for global tree species classification](https://arxiv.org/abs/2505.12513)|[globalgeotree](https://github.com/muyang99/globalgeotree)|\n", "2505.12532": "|[exploring sparsity for parameter efficient fine tuning using wavelets](https://arxiv.org/abs/2505.12532)|[sparse_peft](https://github.com/bilican/sparse_peft)|\n", "2505.12547": "|[promi: an efficient prototype-mixture baseline for few-shot segmentation with bounding-box annotations](https://arxiv.org/abs/2505.12547)|[promi](https://github.com/thalesgroup/promi)|\n", "2505.12630": "|[degradation-aware feature perturbation for all-in-one image restoration](https://arxiv.org/abs/2505.12630)|[dfpir](https://github.com/txphome/dfpir)|\n", "2505.12631": "|[multi-resolution haar network: enhancing human motion prediction via haar transform](https://arxiv.org/abs/2505.12631)|[haarmodic](https://github.com/xhaughearl/haarmodic)|\n", "2505.12650": "|[automat: enabling automated crystal structure reconstruction from microscopy via agentic tool use](https://arxiv.org/abs/2505.12650)|[automat](https://github.com/yyt-2378/automat)|\n", "2505.12669": "|[text2midi-inferalign: improving symbolic music generation with inference-time alignment](https://arxiv.org/abs/2505.12669)|[t2m-inferalign](https://github.com/amaai-lab/t2m-inferalign)|\n", "2505.12674": "|[few-step diffusion via score identity distillation](https://arxiv.org/abs/2505.12674)|[sid-lsg](https://github.com/mingyuanzhou/sid-lsg)|\n", "2505.12718": "|[automated bias assessment in ai-generated educational content using ceat framework](https://arxiv.org/abs/2505.12718)|[Automated-Word-Extraction](https://github.com/EricP66/Automated-Word-Extraction)|\n", "2505.12742": "|[mvar: visual autoregressive modeling with scale and spatial markovian conditioning](https://arxiv.org/abs/2505.12742)|[mvar](https://github.com/labshuhanggu/mvar)|\n", "2505.12766": "|[reasoning-ocr: can large multimodal models solve complex logical reasoning problems from ocr cues?](https://arxiv.org/abs/2505.12766)|[reasoningocr](https://github.com/hxyz-123/reasoningocr)|\n", "2505.12820": "|[rethinking features-fused-pyramid-neck for object detection](https://arxiv.org/abs/2505.12820)|[rethinking-fpn](https://github.com/alanli1997/rethinking-fpn)|\n", "2505.12834": "|[a study on the refining handwritten font by mixing font styles](https://arxiv.org/abs/2505.12834)|[FontFusionGAN](https://github.com/KumarAvinash44/FontFusionGAN)|\n", "2505.12835": "|[flightgpt: towards generalizable and interpretable uav vision-and-language navigation with vision-language models](https://arxiv.org/abs/2505.12835)|[flightgpt](https://github.com/pendulumclock/flightgpt)|\n", "2505.12849": "|[accelerate tarflow sampling with gs-jacobi iteration](https://arxiv.org/abs/2505.12849)|[gs-jacobi_for_tarflow](https://github.com/encoreus/gs-jacobi_for_tarflow)|\n", "2505.12861": "|[robust multimodal segmentation with representation regularization and hybrid prototype distillation](https://arxiv.org/abs/2505.12861)|[robustseg](https://github.com/robustseg/robustseg)|\n", "2505.12897": "|[epic: explanation of pretrained image classification networks via prototype](https://arxiv.org/abs/2505.12897)|[epic](https://github.com/piotr310100/epic)|\n", "2505.12903": "|[towards low-latency event stream-based visual object tracking: a slow-fast approach](https://arxiv.org/abs/2505.12903)|[slowfast_event_track](https://github.com/event-ahu/slowfast_event_track)|\n", "2505.12908": "|[dynamic graph induced contour-aware heat conduction network for event-based object detection](https://arxiv.org/abs/2505.12908)|[openevdet](https://github.com/event-ahu/openevdet)|\n", "2505.12911": "|[hiero: understanding the hierarchy of human behavior enhances reasoning on egocentric videos](https://arxiv.org/abs/2505.12911)|[hiero](https://github.com/sapeirone/hiero)|\n", "2505.12912": "|[uniformity first: uniformity-aware test-time adaptation of vision-language models against image corruption](https://arxiv.org/abs/2505.12912)|[uninfo](https://github.com/kzkadc/uninfo)|\n", "2505.12944": "|[calm-pde: continuous and adaptive convolutions for latent space modeling of time-dependent pdes](https://arxiv.org/abs/2505.12944)|[calm-pde](https://github.com/jhagnberger/calm-pde)|\n", "2505.12998": "|[a skull-adaptive framework for ai-based 3d transcranial focused ultrasound simulation](https://arxiv.org/abs/2505.12998)|[tfuscapes](https://github.com/camma-public/tfuscapes)|\n", "2505.12999": "|[a generalisable head mri defacing pipeline: evaluation on 2,566 meningioma scans](https://arxiv.org/abs/2505.12999)|[defacing_pipeline](https://github.com/cai4cai/defacing_pipeline)|\n", "2505.13010": "|[to bias or not to bias: detecting bias in news with bias-detector](https://arxiv.org/abs/2505.13010)|[newsbiasdetector](https://github.com/himel1996/newsbiasdetector)|\n", "2505.13032": "|[mmar: a challenging benchmark for deep reasoning in speech, audio, music, and their mix](https://arxiv.org/abs/2505.13032)|[mmar](https://github.com/ddlbojack/mmar)|\n", "2505.13088": "|[cross-modal feature fusion for robust point cloud registration with ambiguous geometry](https://arxiv.org/abs/2505.13088)|[coff](https://github.com/zhaoyiww/coff)|\n", "2505.13137": "|[learning to adapt to position bias in vision transformer classifiers](https://arxiv.org/abs/2505.13137)|[position-shap](https://github.com/rjbruin/position-shap)|\n", "2505.13152": "|[higher fidelity perceptual image and video compression with a latent conditioned residual denoising diffusion model](https://arxiv.org/abs/2505.13152)|[rescdc](https://github.com/jbrenig/rescdc)|\n", "2505.13201": "|[matpredict: a dataset and benchmark for learning material properties of diverse indoor objects](https://arxiv.org/abs/2505.13201)|[matpredict](https://github.com/arpan-kusari/matpredict)|\n", "2505.13211": "|[magi-1: autoregressive video generation at scale](https://arxiv.org/abs/2505.13211)|[magiattention](https://github.com/sandai-org/magiattention)|\n", "2505.13215": "|[hybrid 3d-4d gaussian splatting for fast dynamic scene representation](https://arxiv.org/abs/2505.13215)|[3D-4DGS](https://github.com/ohsngjun/3D-4DGS)|\n", "2505.13218": "|[human response to decision support in face matching: the influence of task difficulty and machine accuracy](https://arxiv.org/abs/2505.13218)|[humanresponse-dss-facematching](https://github.com/ealmenzar/humanresponse-dss-facematching)|\n", "2505.13233": "|[from local details to global context: advancing vision-language models with attention-based selection](https://arxiv.org/abs/2505.13233)|[abs](https://github.com/bit-da/abs)|\n", "2505.13235": "|[writevit: handwritten text generation with vision transformer](https://arxiv.org/abs/2505.13235)|[writevit](https://github.com/hnam-1765/writevit)|\n", "2505.13307": "|[rbf++: quantifying and optimizing reasoning boundaries across measurable and unmeasurable capabilities for chain-of-thought reasoning](https://arxiv.org/abs/2505.13307)|[reasoning-boundary](https://github.com/lightchen233/reasoning-boundary)|\n", "2505.13316": "|[denoising diffusion probabilistic model for point cloud compression at low bit-rates](https://arxiv.org/abs/2505.13316)|[ddpm-pcc](https://github.com/eidoslab/ddpm-pcc)|\n", "2505.13390": "|[mgpbd: a multigrid accelerated global xpbd solver](https://arxiv.org/abs/2505.13390)|[mgpbd](https://github.com/chunleili/mgpbd)|\n", "2505.13419": "|[feallm: advancing facial emotion analysis in multimodal large language models with emotional synergy and reasoning](https://arxiv.org/abs/2505.13419)|[feallm](https://github.com/953206211/feallm)|\n", "2505.13426": "|[g1: bootstrapping perception and reasoning abilities of vision-language model via reinforcement learning](https://arxiv.org/abs/2505.13426)|[g1](https://github.com/chenllliang/g1)|\n", "2505.13427": "|[mm-prm: enhancing multimodal mathematical reasoning with scalable step-level supervision](https://arxiv.org/abs/2505.13427)|[mm-prm](https://github.com/modalminds/mm-prm)|\n", "2505.13439": "|[vtbench: evaluating visual tokenizers for autoregressive image generation](https://arxiv.org/abs/2505.13439)|[VTBench](https://github.com/huawei-lin/VTBench)|\n", "2505.13440": "|[recollection from pensieve: novel view synthesis via learning from uncalibrated videos](https://arxiv.org/abs/2505.13440)|[pensieve](https://github.com/dwawayu/pensieve)|\n"}, "2025-05-21": {"2301.05191": "|[a unified framework for event-based frame interpolation with ad-hoc deblurring in the wild](https://arxiv.org/abs/2301.05191)|[refid](https://github.com/ahupujr/refid)|\n", "2305.04095": "|[gradient leakage defense with key-lock module for federated learning](https://arxiv.org/abs/2305.04095)|[fedkl](https://github.com/rand2ai/fedkl)|\n", "2311.00721": "|[empathy detection from text, audiovisual, audio or physiological signals: a systematic review of task formulations and machine learning methods](https://arxiv.org/abs/2311.00721)|[boolean-search-bib-abstract](https://github.com/hasan-rakibul/boolean-search-bib-abstract)|\n", "2311.16515": "|[automatic synthetic data and fine-grained adaptive feature alignment for composed person retrieval](https://arxiv.org/abs/2311.16515)|[Word4Per](https://github.com/Delong-liu-bupt/Word4Per)|\n", "2403.11083": "|[customizing visual-language foundation models for multi-modal anomaly detection and reasoning](https://arxiv.org/abs/2403.11083)|[customizable-vlm](https://github.com/xiaohao-xu/customizable-vlm)|\n", "2405.14979": "|[craftsman3d: high-fidelity mesh generation with 3d native generation and interactive geometry refiner](https://arxiv.org/abs/2405.14979)|[craftsman](https://github.com/wyysf-98/craftsman)|\n", "2407.10707": "|[interactive rendering of relightable and animatable gaussian avatars](https://arxiv.org/abs/2407.10707)|[interactraga](https://github.com/1231234zhan/interactraga)|\n", "2407.11850": "|[spacejam: a lightweight and regularization-free method for fast joint alignment of images](https://arxiv.org/abs/2407.11850)|[SpaceJAM](https://github.com/BGU-CS-VIL/SpaceJAM)|\n", "2407.19451": "|[perm: a parametric representation for multi-style 3d hair modeling](https://arxiv.org/abs/2407.19451)|[perm](https://github.com/c-he/perm)|\n", "2408.07337": "|[kind: knowledge integration and diversion for training decomposable models](https://arxiv.org/abs/2408.07337)|[kind](https://github.com/te4p0t/kind)|\n", "2409.09451": "|[on the generalizability of foundation models for crop type mapping](https://arxiv.org/abs/2409.09451)|[crop-type-transfer-learning](https://github.com/yichiac/crop-type-transfer-learning)|\n", "2409.11726": "|[revealing and mitigating the challenge of detecting character knowledge errors in llm role-playing](https://arxiv.org/abs/2409.11726)|[rp_kw_errors](https://github.com/wyripple/rp_kw_errors)|\n", "2411.15633": "|[orthogonal subspace decomposition for generalizable ai-generated image detection](https://arxiv.org/abs/2411.15633)|[effort-aigi-detection](https://github.com/yzy-stack/effort-aigi-detection)|\n", "2412.02508": "|[towards rich emotions in 3d avatars: a text-to-3d avatar generation benchmark](https://arxiv.org/abs/2412.02508)|[emoava](https://github.com/walkermitty/emoava)|\n", "2412.12974": "|[attentive eraser: unleashing diffusion model's object removal potential via self-attention redirection guidance](https://arxiv.org/abs/2412.12974)|[attentiveeraser](https://github.com/anonym0u3/attentiveeraser)|\n", "2501.02040": "|[a separable self-attention inspired by the state space model for computer vision](https://arxiv.org/abs/2501.02040)|[vminet](https://github.com/yws-wxs/vminet)|\n", "2501.03757": "|[neuroincept decoder for high-fidelity speech reconstruction from neural activity](https://arxiv.org/abs/2501.03757)|[NeuroInceptDecoder](https://github.com/owaismujtaba/NeuroInceptDecoder)|\n", "2501.12368": "|[internlm-xcomposer2.5-reward: a simple yet effective multi-modal reward model](https://arxiv.org/abs/2501.12368)|[internlm-xcomposer](https://github.com/internlm/internlm-xcomposer)|\n", "2502.01051": "|[diffusion model as a noise-aware latent reward model for step-level preference optimization](https://arxiv.org/abs/2502.01051)|[lpo](https://github.com/kwai-kolors/lpo)|\n", "2502.02171": "|[deepforest: sensing into self-occluding volumes of vegetation with aerial imaging](https://arxiv.org/abs/2502.02171)|[DeepForest-Sensing-Into-Self-Occluding-Volumes-of-Vegetation-With-Aerial-Imaging](https://github.com/mohamedhaiham94/DeepForest-Sensing-Into-Self-Occluding-Volumes-of-Vegetation-With-Aerial-Imaging)|\n", "2502.05505": "|[differentially private synthetic data via apis 3: using simulators instead of foundation model](https://arxiv.org/abs/2502.05505)|[dpsda](https://github.com/microsoft/dpsda)|\n", "2502.11163": "|[vlms as geoguessr masters: exceptional performance, hidden biases, and privacy risks](https://arxiv.org/abs/2502.11163)|[fairlocator](https://github.com/uscnlp-lime/fairlocator)|\n", "2502.13146": "|[re-align: aligning vision language models via retrieval-augmented direct preference optimization](https://arxiv.org/abs/2502.13146)|[re-align](https://github.com/taco-group/re-align)|\n", "2503.01776": "|[beyond matryoshka: revisiting sparse coding for adaptive representation](https://arxiv.org/abs/2503.01776)|[CSR_Adaptive_Rep](https://github.com/neilwen987/CSR_Adaptive_Rep)|\n", "2503.07035": "|[universal incremental learning: mitigating confusion from inter- and intra-task distribution randomness](https://arxiv.org/abs/2503.07035)|[uil](https://github.com/rolsheng/uil)|\n", "2503.07575": "|[visbias: measuring explicit and implicit social biases in vision language models](https://arxiv.org/abs/2503.07575)|[visbias](https://github.com/uscnlp-lime/visbias)|\n", "2503.11094": "|[open3dvqa: a benchmark for comprehensive spatial reasoning with multimodal large language model in open space](https://arxiv.org/abs/2503.11094)|[open3dvqa](https://github.com/weichenzh/open3dvqa)|\n", "2503.16282": "|[generalized few-shot 3d point cloud segmentation with vision-language model](https://arxiv.org/abs/2503.16282)|[gfs-vl](https://github.com/zhaochongan/gfs-vl)|\n", "2503.16505": "|[scalable evaluation of online facilitation strategies via synthetic simulation of discussions](https://arxiv.org/abs/2503.16505)|[synthetic_moderation_experiments](https://github.com/dimits-ts/synthetic_moderation_experiments)|\n", "2504.14440": "|[sg-reg: generalizable and efficient scene graph registration](https://arxiv.org/abs/2504.14440)|[sg-reg](https://github.com/hkust-aerial-robotics/sg-reg)|\n", "2504.14783": "|[how effective can dropout be in multiple instance learning ?](https://arxiv.org/abs/2504.14783)|[mildropout](https://github.com/chongqingnosubway/mildropout)|\n", "2504.17821": "|[videovista-culturallingo: 360$^\\circ$ horizons-bridging cultures, languages, and domains in video comprehension](https://arxiv.org/abs/2504.17821)|[videovista](https://github.com/hitsz-tmg/videovista)|\n", "2505.04058": "|[as3d: 2d-assisted cross-modal understanding with semantic-spatial scene graphs for 3d visual grounding](https://arxiv.org/abs/2505.04058)|[AS3D](https://github.com/onmyoji-xiao/AS3D)|\n", "2505.04612": "|[fastmap: revisiting dense and scalable structure from motion](https://arxiv.org/abs/2505.04612)|[fastmap](https://github.com/pals-ttic/fastmap)|\n", "2505.06699": "|[model steering: learning with a reference model improves generalization bounds and scaling laws](https://arxiv.org/abs/2505.06699)|[drrho-clip](https://github.com/optimization-ai/drrho-clip)|\n", "2505.07447": "|[unified continuous generative models](https://arxiv.org/abs/2505.07447)|[UCGM](https://github.com/LINs-Lab/UCGM)|\n", "2505.08175": "|[fast text-to-audio generation with adversarial post-training](https://arxiv.org/abs/2505.08175)|[stable-audio-tools](https://github.com/stability-ai/stable-audio-tools)|\n", "2505.10238": "|[mtvcrafter: 4d motion tokenization for open-world human image animation](https://arxiv.org/abs/2505.10238)|[mtvcrafter](https://github.com/dingyanb/mtvcrafter)|\n", "2505.10464": "|[hwa-unetr: hierarchical window aggregate unetr for 3d multimodal gastric lesion segmentation](https://arxiv.org/abs/2505.10464)|[hwa-unetr](https://github.com/jeming-creater/hwa-unetr)|\n", "2505.12427": "|[draglora: online optimization of lora adapters for drag-based image editing in diffusion model](https://arxiv.org/abs/2505.12427)|[draglora](https://github.com/sylvie-x/draglora)|\n", "2505.12482": "|[spectral-spatial self-supervised learning for few-shot hyperspectral image classification](https://arxiv.org/abs/2505.12482)|[s4l-fsc](https://github.com/wenchen-chen/s4l-fsc)|\n", "2505.12499": "|[contrastive alignment with semantic gap-aware corrections in text-video retrieval](https://arxiv.org/abs/2505.12499)|[gare-text-video-retrieval](https://github.com/musicman217/gare-text-video-retrieval)|\n", "2505.13232": "|[starft: robust fine-tuning of zero-shot models via spuriosity alignment](https://arxiv.org/abs/2505.13232)|[starft](https://github.com/alinlab/starft)|\n", "2505.13483": "|[emometa: a multimodal dataset for fine-grained emotion classification in chinese metaphors](https://arxiv.org/abs/2505.13483)|[emometa](https://github.com/dutir-ysq/emometa)|\n", "2505.13539": "|[eulearn: a 3d database for learning euler characteristics](https://arxiv.org/abs/2505.13539)|[eulearn_db](https://github.com/appliedgeometry/eulearn_db)|\n", "2505.13669": "|[geovlm: improving automated vehicle geolocalisation using vision-language matching](https://arxiv.org/abs/2505.13669)|[geovlm](https://github.com/cav-research-lab/geovlm)|\n", "2505.13773": "|[model cards for ai teammates: comparing human-ai team familiarization methods for high-stakes environments](https://arxiv.org/abs/2505.13773)|[maisr](https://github.com/gt-cec/maisr)|\n", "2505.13784": "|[transfer learning from visual speech recognition to mouthing recognition in german sign language](https://arxiv.org/abs/2505.13784)|[transfer-learning-vsr-mouthing-sign-language](https://github.com/nphamdinh/transfer-learning-vsr-mouthing-sign-language)|\n", "2505.13813": "|[flashkat: understanding and addressing performance bottlenecks in the kolmogorov-arnold transformer](https://arxiv.org/abs/2505.13813)|[flashkat](https://github.com/osu-starlab/flashkat)|\n", "2505.13839": "|[mgstream: motion-aware 3d gaussian for streamable dynamic scene reconstruction](https://arxiv.org/abs/2505.13839)|[mgstream](https://github.com/pcl3dv/mgstream)|\n", "2505.13906": "|[xdementnet: an explainable attention based deep convolutional network to detect alzheimer progression from mri data](https://arxiv.org/abs/2505.13906)|[XdementNET](https://github.com/SoyabulIslamLincoln/XdementNET)|\n", "2505.13928": "|[lovr: a benchmark for long video retrieval in multimodal contexts](https://arxiv.org/abs/2505.13928)|[lovr-benchmark](https://github.com/technomad-ds/lovr-benchmark)|\n", "2505.14008": "|[multi-label stereo matching for transparent scene depth estimation](https://arxiv.org/abs/2505.14008)|[TranScene](https://github.com/BFZD233/TranScene)|\n", "2505.14017": "|[end-to-end cortical surface reconstruction from clinical magnetic resonance images](https://arxiv.org/abs/2505.14017)|[brainnet](https://github.com/simnibs/brainnet)|\n", "2505.14042": "|[adversarially pretrained transformers may be universally robust in-context learners](https://arxiv.org/abs/2505.14042)|[universally-robust-in-context-learner](https://github.com/s-kumano/universally-robust-in-context-learner)|\n", "2505.14049": "|[learning concept-driven logical rules for interpretable and generalizable medical image classification](https://arxiv.org/abs/2505.14049)|[crl](https://github.com/obiyoag/crl)|\n", "2505.14059": "|[dolphin: document image parsing via heterogeneous anchor prompting](https://arxiv.org/abs/2505.14059)|[dolphin](https://github.com/bytedance/dolphin)|\n", "2505.14124": "|[intra-class patch swap for self-distillation](https://arxiv.org/abs/2505.14124)|[intra-class-patch-swap](https://github.com/hchoi71/intra-class-patch-swap)|\n", "2505.14246": "|[visual agentic reinforcement fine-tuning](https://arxiv.org/abs/2505.14246)|[visual-rft](https://github.com/liuziyu77/visual-rft)|\n", "2505.14254": "|[instructing text-to-image diffusion models via classifier-guided semantic optimization](https://arxiv.org/abs/2505.14254)|[caso](https://github.com/chang-yuanyuan/caso)|\n", "2505.14260": "|[speculative decoding reimagined for multimodal large language models](https://arxiv.org/abs/2505.14260)|[msd](https://github.com/lyn-lucy/msd)|\n", "2505.14318": "|[radar: enhancing radiology report generation with supplementary knowledge injection](https://arxiv.org/abs/2505.14318)|[Radar](https://github.com/wjhou/Radar)|\n", "2505.14329": "|[tf-mamba: text-enhanced fusion mamba with missing modalities for robust multimodal sentiment analysis](https://arxiv.org/abs/2505.14329)|[tf-mamba](https://github.com/codemous/tf-mamba)|\n", "2505.14333": "|[domain adaptation for multi-label image classification: a discriminator-free approach](https://arxiv.org/abs/2505.14333)|[dda-mlic](https://github.com/cvi2snt/dda-mlic)|\n", "2505.14346": "|[egocentric action-aware inertial localization in point clouds](https://arxiv.org/abs/2505.14346)|[ego-inertial-localization](https://github.com/mf-zhang/ego-inertial-localization)|\n", "2505.14362": "|[deepeyes: incentivizing \"thinking with images\" via reinforcement learning](https://arxiv.org/abs/2505.14362)|[deepeyes](https://github.com/visual-agent/deepeyes)|\n", "2505.14377": "|[when bias backfires: the modulatory role of counterfactual explanations on the adoption of algorithmic bias in xai-supported human decision-making](https://arxiv.org/abs/2505.14377)|[biasbackfiresxai2025](https://github.com/ukuhl/biasbackfiresxai2025)|\n", "2505.14414": "|[diving into the fusion of monocular priors for generalized stereo matching](https://arxiv.org/abs/2505.14414)|[Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching](https://github.com/YaoChengTang/Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching)|\n", "2505.14454": "|[video compression commander: plug-and-play inference acceleration for video large language models](https://arxiv.org/abs/2505.14454)|[vidcom2](https://github.com/xuyang-liu16/vidcom2)|\n", "2505.14460": "|[visualquality-r1: reasoning-induced image quality assessment via reinforcement learning to rank](https://arxiv.org/abs/2505.14460)|[visualquality-r1](https://github.com/tianhewu/visualquality-r1)|\n", "2505.14462": "|[ravenea: a benchmark for multimodal retrieval-augmented visual culture understanding](https://arxiv.org/abs/2505.14462)|[ravenea](https://github.com/yfyuan01/ravenea)|\n", "2505.14556": "|[dynadiff: single-stage decoding of images from continuously evolving fmri](https://arxiv.org/abs/2505.14556)|[dynadiff](https://github.com/facebookresearch/dynadiff)|\n", "2505.14629": "|[kerl: knowledge-enhanced personalized recipe recommendation using large language models](https://arxiv.org/abs/2505.14629)|[kerl](https://github.com/mohbattharani/kerl)|\n", "2505.14633": "|[will ai tell lies to save sick children? litmus-testing ai values prioritization with airiskdilemmas](https://arxiv.org/abs/2505.14633)|[litmusvalues](https://github.com/kellycyy/litmusvalues)|\n", "2505.14638": "|[dual precision quantization for efficient and accurate deep neural networks inference](https://arxiv.org/abs/2505.14638)|[neural-compressor](https://github.com/intel/neural-compressor)|\n", "2505.14646": "|[cad-coder: an open-source vision-language model for computer-aided design code generation](https://arxiv.org/abs/2505.14646)|[cad-coder](https://github.com/anniedoris/cad-coder)|\n", "2505.14664": "|[akrmap: adaptive kernel regression for trustworthy visualization of cross-modal embeddings](https://arxiv.org/abs/2505.14664)|[akrmap](https://github.com/yilinye/akrmap)|\n", "2505.14687": "|[grouping first, attending smartly: training-free acceleration for diffusion transformers](https://arxiv.org/abs/2505.14687)|[grat](https://github.com/oliverrensu/grat)|\n"}, "2025-05-22": {"2108.08532": "|[an information theory-inspired strategy for automatic network pruning](https://arxiv.org/abs/2108.08532)|[itpruner](https://github.com/mac-automl/itpruner)|\n", "2309.02244": "|[augmenting chest x-ray datasets with non-expert annotations](https://arxiv.org/abs/2309.02244)|[chestxr-label-reliability](https://github.com/purrlab/chestxr-label-reliability)|\n", "2310.06488": "|[spikeclip: a contrastive language-image pretrained spiking neural network](https://arxiv.org/abs/2310.06488)|[spikeclip](https://github.com/lvchangze/spikeclip)|\n", "2310.10224": "|[generalizing medical image representations via quaternion wavelet networks](https://arxiv.org/abs/2310.10224)|[QWT](https://github.com/ispamm/QWT)|\n", "2401.16991": "|[category-wise fine-tuning: resisting incorrect pseudo-labels in multi-label image classification with partial labels](https://arxiv.org/abs/2401.16991)|[category-wise-fine-tuning](https://github.com/maxium0526/category-wise-fine-tuning)|\n", "2404.14955": "|[a comprehensive survey for hyperspectral image classification: the evolution from conventional to transformers and mamba models](https://arxiv.org/abs/2404.14955)|[conventional-to-transformer-for-hyperspectral-image-classification-survey-2024](https://github.com/mahmad00/conventional-to-transformer-for-hyperspectral-image-classification-survey-2024)|\n", "2406.12030": "|[spa-vl: a comprehensive safety preference alignment dataset for vision language model](https://arxiv.org/abs/2406.12030)|[spa-vl-rlhf](https://github.com/echosechen/spa-vl-rlhf)|\n", "2406.18443": "|[boosting few-shot open-set object detection via prompt learning and robust decision boundary](https://arxiv.org/abs/2406.18443)|[ced-food](https://github.com/zjzwzw/ced-food)|\n", "2407.08800": "|[local clustering for lung cancer image classification via sparse solution technique](https://arxiv.org/abs/2407.08800)|[LocalClustering4LungCancer](https://github.com/zzzzms/LocalClustering4LungCancer)|\n", "2408.10007": "|[p3p: pseudo-3d pre-training for scaling 3d voxel-based masked autoencoders](https://arxiv.org/abs/2408.10007)|[p3p-mae](https://github.com/xuechaochen/p3p-mae)|\n", "2409.06000": "|[rayflex: an open-source rtl implementation of the hardware ray tracer datapath](https://arxiv.org/abs/2409.06000)|[rayflex](https://github.com/purdue-aalp/rayflex)|\n", "2409.07098": "|[diversity-driven view subset selection for indoor novel view synthesis](https://arxiv.org/abs/2409.07098)|[indoortraj](https://github.com/zehao-wang/indoortraj)|\n", "2409.07267": "|[minidrive: more efficient vision-language models with multi-level 2d features as text tokens for autonomous driving](https://arxiv.org/abs/2409.07267)|[minidrive](https://github.com/emzucas/minidrive)|\n", "2409.07571": "|[favor: features via voxel rendering for camera relocalization](https://arxiv.org/abs/2409.07571)|[FaVoR](https://github.com/utiasSTARS/FaVoR)|\n", "2409.12108": "|[sprmamba: surgical phase recognition for endoscopic submucosal dissection with mamba](https://arxiv.org/abs/2409.12108)|[sprmamba](https://github.com/zxnyyyyy/sprmamba)|\n", "2409.15477": "|[mediconfusion: can you trust your ai radiologist? probing the reliability of multimodal medical foundation models](https://arxiv.org/abs/2409.15477)|[MediConfusion](https://github.com/AIF4S/MediConfusion)|\n", "2411.08334": "|[mire: enhancing multimodal queries representation via fusion-free modality interaction for multimodal retrieval](https://arxiv.org/abs/2411.08334)|[mire](https://github.com/yeongjoonju/mire)|\n", "2411.10316": "|[m3tr: a generalist model for real-world hd map completion](https://arxiv.org/abs/2411.10316)|[m3tr](https://github.com/immel-f/m3tr)|\n", "2411.16375": "|[ca2-vdm: efficient autoregressive video diffusion model with causal generation and cache sharing](https://arxiv.org/abs/2411.16375)|[causalcache-vdm](https://github.com/dawn-lx/causalcache-vdm)|\n", "2412.03378": "|[volumetrically consistent 3d gaussian rasterization](https://arxiv.org/abs/2412.03378)|[Vol3DGS](https://github.com/chinmay0301ucsd/Vol3DGS)|\n", "2412.06141": "|[mmedpo: aligning medical vision-language models with clinical-aware multimodal preference optimization](https://arxiv.org/abs/2412.06141)|[mmedpo](https://github.com/aiming-lab/mmedpo)|\n", "2412.17806": "|[reconstructing people, places, and cameras](https://arxiv.org/abs/2412.17806)|[hsfm_release](https://github.com/hongsukchoi/hsfm_release)|\n", "2412.18884": "|[hv-bev: decoupling horizontal and vertical feature sampling for multi-view 3d object detection](https://arxiv.org/abs/2412.18884)|[hv-bev](https://github.com/uddd821/hv-bev)|\n", "2502.01081": "|[the jumping reasoning curve? tracking the evolution of reasoning performance in gpt-[n] and o-[n] models on multimodal puzzles](https://arxiv.org/abs/2502.01081)|[llm-puzzletest](https://github.com/declare-lab/llm-puzzletest)|\n", "2502.03654": "|[gompertz linear units: leveraging asymmetry for enhanced learning dynamics](https://arxiv.org/abs/2502.03654)|[GoLU](https://github.com/automl/GoLU)|\n", "2502.12110": "|[a-mem: agentic memory for llm agents](https://arxiv.org/abs/2502.12110)|[a-mem](https://github.com/agiresearch/a-mem)|\n", "2502.12562": "|[sea: low-resource safety alignment for multimodal large language models via synthetic embeddings](https://arxiv.org/abs/2502.12562)|[sea](https://github.com/zeronlp/sea)|\n", "2502.17429": "|[climb-3d: continual learning for imbalanced 3d instance segmentation](https://arxiv.org/abs/2502.17429)|[climb3d](https://github.com/vgthengane/climb3d)|\n", "2504.01805": "|[spacer: reinforcing mllms in video spatial reasoning](https://arxiv.org/abs/2504.01805)|[spacer](https://github.com/ouyangkun10/spacer)|\n", "2504.12739": "|[mask image watermarking](https://arxiv.org/abs/2504.12739)|[maskmark](https://github.com/hurunyi/maskmark)|\n", "2504.20930": "|[chestx-reasoner: advancing radiology foundation models with reasoning through step-by-step verification](https://arxiv.org/abs/2504.20930)|[ChestX-Reasoner](https://github.com/MAGIC-AI4Med/ChestX-Reasoner)|\n", "2505.01237": "|[cav-mae sync: improving contrastive audio-visual mask autoencoders via fine-grained alignment](https://arxiv.org/abs/2505.01237)|[cav-mae-sync](https://github.com/edsonroteia/cav-mae-sync)|\n", "2505.04046": "|[reliable disentanglement multi-view learning against view adversarial attacks](https://arxiv.org/abs/2505.04046)|[2025-IJCAI-RDML](https://github.com/Willy1005/2025-IJCAI-RDML)|\n", "2505.04788": "|[convex relaxation for robust vanishing point estimation in manhattan world](https://arxiv.org/abs/2505.04788)|[globustvp](https://github.com/wu-cvgl/globustvp)|\n", "2505.05049": "|[uncertainsam: fast and efficient uncertainty quantification of the segment anything model](https://arxiv.org/abs/2505.05049)|[UncertainSAM](https://github.com/GreenAutoML4FAS/UncertainSAM)|\n", "2505.05071": "|[fg-clip: fine-grained visual and textual alignment](https://arxiv.org/abs/2505.05071)|[fg-clip](https://github.com/360cvgroup/fg-clip)|\n", "2505.12620": "|[busterx: mllm-powered ai-generated video forgery detection and explanation](https://arxiv.org/abs/2505.12620)|[busterx](https://github.com/l8cv/busterx)|\n", "2505.13300": "|[dd-ranking: rethinking the evaluation of dataset distillation](https://arxiv.org/abs/2505.13300)|[dd-ranking](https://github.com/nus-hpc-ai-lab/dd-ranking)|\n", "2505.14074": "|[recreating neural activity during speech production with language and speech model embeddings](https://arxiv.org/abs/2505.14074)|[llm_brain_representations](https://github.com/owaismujtaba/llm_brain_representations)|\n", "2505.14100": "|[unlocking the power of sam 2 for few-shot segmentation](https://arxiv.org/abs/2505.14100)|[fssam](https://github.com/sam1224/fssam)|\n", "2505.14707": "|[crypticbio: a large multimodal dataset for visually confusing biodiversity](https://arxiv.org/abs/2505.14707)|[crypticbio](https://github.com/georgianagmanolache/crypticbio)|\n", "2505.14708": "|[draftattention: fast video diffusion via low-resolution attention guidance](https://arxiv.org/abs/2505.14708)|[draft-attention](https://github.com/shawnricecake/draft-attention)|\n", "2505.14709": "|[fastcar: cache attentive replay for fast auto-regressive video generation on the edge](https://arxiv.org/abs/2505.14709)|[fast-car](https://github.com/shawnricecake/fast-car)|\n", "2505.14714": "|[kgalign: joint semantic-structural knowledge encoding for multimodal fake news detection](https://arxiv.org/abs/2505.14714)|[kgalign](https://github.com/latuanvinh1998/kgalign)|\n", "2505.14717": "|[aneumo: a large-scale multimodal aneurysm dataset with computational fluid dynamics simulations and deep learning benchmarks](https://arxiv.org/abs/2505.14717)|[aneumo](https://github.com/xigui-li/aneumo)|\n", "2505.14747": "|[lod1 3d city model from lidar: the impact of segmentation accuracy on quality of urban 3d modeling and morphology extraction](https://arxiv.org/abs/2505.14747)|[LiDAR-3D-Building-Modeling](https://github.com/FatemehCh97/LiDAR-3D-Building-Modeling)|\n", "2505.14846": "|[open-set semi-supervised learning for long-tailed medical datasets](https://arxiv.org/abs/2505.14846)|[openltr](https://github.com/daniyanaj/openltr)|\n", "2505.14931": "|[colors matter: ai-driven exploration of human feature colors](https://arxiv.org/abs/2505.14931)|[Color-Matters-AI-Driven-Exploration-of-Human-Feature-Coloration](https://github.com/AiTaif7/Color-Matters-AI-Driven-Exploration-of-Human-Feature-Coloration)|\n", "2505.14948": "|[programmatic video prediction using large language models](https://arxiv.org/abs/2505.14948)|[ProgGen](https://github.com/metro-smiles/ProgGen)|\n", "2505.14951": "|[multimae meets earth observation: pre-training multi-modal multi-task masked autoencoders for earth observation tasks](https://arxiv.org/abs/2505.14951)|[multimae-meets-eo](https://github.com/josesosajs/multimae-meets-eo)|\n", "2505.14983": "|[toward informed av decision-making: computational model of well-being and trust in mobility](https://arxiv.org/abs/2505.14983)|[wellbeing-trust-model](https://github.com/honda-research-institute/wellbeing-trust-model)|\n", "2505.15031": "|[are the confidence scores of reviewers consistent with the review content? evidence from top conference proceedings in ai](https://arxiv.org/abs/2505.15031)|[confidence_score](https://github.com/njust-winchy/confidence_score)|\n", "2505.15075": "|[traveling across languages: benchmarking cross-lingual consistency in multimodal llms](https://arxiv.org/abs/2505.15075)|[traveling-across-languages](https://github.com/nlp-waseda/traveling-across-languages)|\n", "2505.15111": "|[ipad: iterative proposal-centric end-to-end autonomous driving](https://arxiv.org/abs/2505.15111)|[iPad](https://github.com/Kguo-cs/iPad)|\n", "2505.15120": "|[lung nodule-ssm: self-supervised lung nodule detection and classification in thoracic ct images](https://arxiv.org/abs/2505.15120)|[lung-nodule-ssm-self-supervised-lung-nodule-detection-and-classification](https://github.com/emeraldsnrpu/lung-nodule-ssm-self-supervised-lung-nodule-detection-and-classification)|\n", "2505.15133": "|[deepkd: a deeply decoupled and denoised knowledge distillation trainer](https://arxiv.org/abs/2505.15133)|[deepkd](https://github.com/haiduo/deepkd)|\n", "2505.15145": "|[cinetechbench: a benchmark for cinematographic technique understanding and generation](https://arxiv.org/abs/2505.15145)|[cinetechbench](https://github.com/pris-cv/cinetechbench)|\n", "2505.15184": "|[auxdet: auxiliary metadata matters for omni-domain infrared small target detection](https://arxiv.org/abs/2505.15184)|[auxdet](https://github.com/grokcv/auxdet)|\n", "2505.15185": "|[monosplat: generalizable 3d gaussian splatting from monocular depth foundation models](https://arxiv.org/abs/2505.15185)|[monosplat](https://github.com/cuhk-aim-group/monosplat)|\n", "2505.15217": "|[multimodal conditional information bottleneck for generalizable ai-generated image detection](https://arxiv.org/abs/2505.15217)|[infofd](https://github.com/ant0ny44/infofd)|\n", "2505.15232": "|[dc-scene: data-centric learning for 3d scene understanding](https://arxiv.org/abs/2505.15232)|[dc-scene](https://github.com/aigeeksgroup/dc-scene)|\n", "2505.15234": "|[sama-unet: enhancing medical image segmentation with self-adaptive mamba-like attention and causal-resonance learning](https://arxiv.org/abs/2505.15234)|[SAMA-UNet](https://github.com/sqbqamar/SAMA-UNet)|\n", "2505.15235": "|[x-grm: large gaussian reconstruction model for sparse-view x-rays to computed tomography](https://arxiv.org/abs/2505.15235)|[x-grm](https://github.com/cuhk-aim-group/x-grm)|\n", "2505.15270": "|[scaling diffusion transformers efficiently via $\\mu$p](https://arxiv.org/abs/2505.15270)|[Scaling-Diffusion-Transformers-muP](https://github.com/ML-GSAI/Scaling-Diffusion-Transformers-muP)|\n", "2505.15272": "|[diffprob: data pruning for face recognition](https://arxiv.org/abs/2505.15272)|[DiffProb](https://github.com/EduardaCaldeira/DiffProb)|\n", "2505.15282": "|[exploring in-image machine translation with real-world background](https://arxiv.org/abs/2505.15282)|[debackx](https://github.com/bithlp/debackx)|\n", "2505.15284": "|[kernel pca for out-of-distribution detection: non-linear kernel selections and approximations](https://arxiv.org/abs/2505.15284)|[ood-kpca-extension](https://github.com/fanghenshaometeor/ood-kpca-extension)|\n", "2505.15325": "|[softhgnn: soft hypergraph neural networks for general visual recognition](https://arxiv.org/abs/2505.15325)|[SoftHGNN](https://github.com/Mengqi-Lei/SoftHGNN)|\n", "2505.15364": "|[mhanet: multi-scale hybrid attention network for auditory attention detection](https://arxiv.org/abs/2505.15364)|[mhanet](https://github.com/fchest/mhanet)|\n", "2505.15379": "|[the p$^3$ dataset: pixels, points and polygons for multimodal building vectorization](https://arxiv.org/abs/2505.15379)|[pixelspointspolygons](https://github.com/raphaelsulzer/pixelspointspolygons)|\n", "2505.15435": "|[timecausality: evaluating the causal ability in time dimension for vision language models](https://arxiv.org/abs/2505.15435)|[timecausality](https://github.com/zeqing-wang/timecausality)|\n", "2505.15506": "|[prompt tuning vision language models with margin regularizer for few-shot learning under distribution shifts](https://arxiv.org/abs/2505.15506)|[promptmargin](https://github.com/debarshigit/promptmargin)|\n", "2505.15545": "|[seg_3d_by_pc2d: multi-view projection for domain generalization and adaptation in 3d semantic segmentation](https://arxiv.org/abs/2505.15545)|[ia4markings](https://github.com/andrewcaunes/ia4markings)|\n", "2505.15576": "|[visual perturbation and adaptive hard negative contrastive learning for compositional reasoning in vision-language models](https://arxiv.org/abs/2505.15576)|[ahnpl](https://github.com/nynu-bdai/ahnpl)|\n", "2505.15581": "|[uwsam: segment anything model guided underwater instance segmentation and a large-scale benchmark dataset](https://arxiv.org/abs/2505.15581)|[uiis10k](https://github.com/liamlian0727/uiis10k)|\n", "2505.15596": "|[exploring llm-generated feedback for economics essays: how teaching assistants evaluate and envision its use](https://arxiv.org/abs/2505.15596)|[aied2025-exploring-llm-generated-feedback-for-economics-essay](https://github.com/um-lifelong-learning-lab/aied2025-exploring-llm-generated-feedback-for-economics-essay)|\n", "2505.15628": "|[snap: a benchmark for testing the effects of capture conditions on fundamental vision tasks](https://arxiv.org/abs/2505.15628)|[snap](https://github.com/ykotseruba/snap)|\n", "2505.15637": "|[oral imaging for malocclusion issues assessments: omni dataset, deep learning baselines and benchmarking](https://arxiv.org/abs/2505.15637)|[omni](https://github.com/roundfacej/omni)|\n", "2505.15644": "|[fragfake: a dataset for fine-grained detection of edited images with vision language models](https://arxiv.org/abs/2505.15644)|[FragFake](https://github.com/Vincent-HKUSTGZ/FragFake)|\n", "2505.15649": "|[the devil is in fine-tuning and long-tailed problems:a new benchmark for scene text detection](https://arxiv.org/abs/2505.15649)|[ltb](https://github.com/pd162/ltb)|\n", "2505.15804": "|[star-r1: spatial transformation reasoning by reinforcing multimodal llms](https://arxiv.org/abs/2505.15804)|[star-r1](https://github.com/zongzhao23/star-r1)|\n", "2505.15809": "|[mmada: multimodal large diffusion language models](https://arxiv.org/abs/2505.15809)|[mmada](https://github.com/gen-verse/mmada)|\n", "2505.15812": "|[leveraging the powerful attention of a pre-trained diffusion model for exemplar-based image colorization](https://arxiv.org/abs/2505.15812)|[powerful-attention](https://github.com/satoshi-kosugi/powerful-attention)|\n", "2505.15816": "|[streamline without sacrifice -- squeeze out computation redundancy in lmm](https://arxiv.org/abs/2505.15816)|[proxyv](https://github.com/penghao-wu/proxyv)|\n", "2505.15818": "|[instructsam: a training-free framework for instruction-oriented remote sensing object recognition](https://arxiv.org/abs/2505.15818)|[InstructSAM](https://github.com/VoyagerXvoyagerx/InstructSAM)|\n"}, "2025-05-23": {"2308.10800": "|[fact-checking information from large language models can decrease headline discernment](https://arxiv.org/abs/2308.10800)|[ai_fact_checking](https://github.com/osome-iu/ai_fact_checking)|\n", "2311.02960": "|[understanding deep representation learning via layerwise feature compression and discrimination](https://arxiv.org/abs/2311.02960)|[pnc_dln](https://github.com/heimine/pnc_dln)|\n", "2408.15966": "|[more text, less point: towards 3d data-efficient point-language understanding](https://arxiv.org/abs/2408.15966)|[greenplm](https://github.com/tangyuan96/greenplm)|\n", "2409.01109": "|[sood-imagenet: a large-scale dataset for semantic out-of-distribution image classification and semantic segmentation](https://arxiv.org/abs/2409.01109)|[SOODImageNet](https://github.com/bach05/SOODImageNet)|\n", "2409.01175": "|[logit scaling for out-of-distribution detection](https://arxiv.org/abs/2409.01175)|[lts](https://github.com/andrijazz/lts)|\n", "2410.19552": "|[geollava: efficient fine-tuned vision-language models for temporal change detection in remote sensing](https://arxiv.org/abs/2410.19552)|[GeoLLaVA](https://github.com/HosamGen/GeoLLaVA)|\n", "2411.03948": "|[long-form text-to-music generation with adaptive prompts: a case study in tabletop role-playing games soundtracks](https://arxiv.org/abs/2411.03948)|[babel-bardo](https://github.com/felipemarra/babel-bardo)|\n", "2411.06790": "|[large-scale moral machine experiment on large language models](https://arxiv.org/abs/2411.06790)|[mmllm](https://github.com/kztakemoto/mmllm)|\n", "2411.08701": "|[trace: transformer-based risk assessment for clinical evaluation](https://arxiv.org/abs/2411.08701)|[TRACE](https://github.com/DionysisChristopoulos/TRACE)|\n", "2412.02573": "|[remote sensing spatio-temporal vision-language models: a comprehensive survey](https://arxiv.org/abs/2412.02573)|[awesome-rs-temporal-vlm](https://github.com/chen-yang-liu/awesome-rs-temporal-vlm)|\n", "2412.02575": "|[copy-move forgery detection and question answering for remote sensing image](https://arxiv.org/abs/2412.02575)|[rscmqa](https://github.com/shenyedepisa/rscmqa)|\n", "2412.04030": "|[mask of truth: model sensitivity to unexpected regions of medical images](https://arxiv.org/abs/2412.04030)|[mmc_masking_eyefundus](https://github.com/theosourget/mmc_masking_eyefundus)|\n", "2412.10255": "|[anisora: exploring the frontiers of animation video generation in the sora era](https://arxiv.org/abs/2412.10255)|[index-anisora](https://github.com/bilibili/index-anisora)|\n", "2412.19125": "|[advanced knowledge transfer: refined feature distillation for zero-shot quantization in edge computing](https://arxiv.org/abs/2412.19125)|[AKT-Advanced-knowledge-Transfer](https://github.com/Inpyo-Hong/AKT-Advanced-knowledge-Transfer)|\n", "2412.20157": "|[unirestorer: universal image restoration via adaptively estimating image degradation at proper granularity](https://arxiv.org/abs/2412.20157)|[unirestorer](https://github.com/mrluin/unirestorer)|\n", "2412.20798": "|[reconciling privacy and explainability in high-stakes: a systematic inquiry](https://arxiv.org/abs/2412.20798)|[DP](https://github.com/humblef-oo-l/DP)|\n", "2501.08575": "|[gotpr: general outdoor text-based place recognition using scene graph retrieval with openstreetmap](https://arxiv.org/abs/2501.08575)|[gotloc](https://github.com/donghwijung/gotloc)|\n", "2501.15415": "|[ocsu: optical chemical structure understanding for molecule-centric scientific discovery](https://arxiv.org/abs/2501.15415)|[OCSU](https://github.com/PharMolix/OCSU)|\n", "2501.17983": "|[efficient feature fusion for uav object detection](https://arxiv.org/abs/2501.17983)|[fmsa](https://github.com/gamepai0811/fmsa)|\n", "2502.01218": "|[provable ordering and continuity in vision-language pretraining for generalizable embodied agents](https://arxiv.org/abs/2502.01218)|[actol](https://github.com/daisy-zzz/actol)|\n", "2502.18225": "|[liver cirrhosis stage estimation from mri with deep learning](https://arxiv.org/abs/2502.18225)|[cirrhosisstage](https://github.com/junzengz/cirrhosisstage)|\n", "2503.01222": "|[retrieval-augmented perception: high-resolution image perception meets visual rag](https://arxiv.org/abs/2503.01222)|[rap](https://github.com/dreammr/rap)|\n", "2503.03637": "|[l2rdas: synthesizing 4d radar tensors for model generalization via dataset expansion](https://arxiv.org/abs/2503.03637)|[k-radar](https://github.com/kaist-avelab/k-radar)|\n", "2503.03644": "|[dongbamie: a multimodal information extraction dataset for evaluating semantic understanding of dongba pictograms](https://arxiv.org/abs/2503.03644)|[dongbamie](https://github.com/thinklis/dongbamie)|\n", "2503.09499": "|[mindgym: what matters in question synthesis for thinking-centric fine-tuning?](https://arxiv.org/abs/2503.09499)|[data-juicer](https://github.com/modelscope/data-juicer)|\n", "2503.11787": "|[eclare: efficient cross-planar learning for anisotropic resolution enhancement](https://arxiv.org/abs/2503.11787)|[eclare](https://github.com/sremedios/eclare)|\n", "2505.02567": "|[unified multimodal understanding and generation models: advances, challenges, and opportunities](https://arxiv.org/abs/2505.02567)|[awesome-unified-multimodal-models](https://github.com/aidc-ai/awesome-unified-multimodal-models)|\n", "2505.10049": "|[advances in radiance field for dynamic scene: from neural field to gaussian field](https://arxiv.org/abs/2505.10049)|[dynamic-radiation-field-paper-list](https://github.com/moonflo/dynamic-radiation-field-paper-list)|\n", "2505.10250": "|[adhmr: aligning diffusion-based human mesh recovery via direct preference optimization](https://arxiv.org/abs/2505.10250)|[adhmr](https://github.com/shenwenhao01/adhmr)|\n", "2505.10473": "|[consistent quantity-quality control across scenes for deployment-aware gaussian splatting](https://arxiv.org/abs/2505.10473)|[ControlGS](https://github.com/zhang-fengdi/ControlGS)|\n", "2505.12007": "|[multi-modal collaborative optimization and expansion network for event-assisted single-eye expression recognition](https://arxiv.org/abs/2505.12007)|[MCO-E-Net](https://github.com/hrdhrd/MCO-E-Net)|\n", "2505.12081": "|[visionreasoner: unified visual perception and reasoning via reinforcement learning](https://arxiv.org/abs/2505.12081)|[VisionReasoner](https://github.com/dvlab-research/VisionReasoner)|\n", "2505.14068": "|[place recognition: a comprehensive review, current challenges and future directions](https://arxiv.org/abs/2505.14068)|[sota-place-recognitioner](https://github.com/cv4ra/sota-place-recognitioner)|\n", "2505.15222": "|[continuous representation methods, theories, and applications: an overview and perspectives](https://arxiv.org/abs/2505.15222)|[continuous-representation-zoo](https://github.com/yisiluo/continuous-representation-zoo)|\n", "2505.15358": "|[objective bicycle occlusion level classification using a deformable parts-based model](https://arxiv.org/abs/2505.15358)|[Bicycle_Occlusion_Level](https://github.com/angelmangubat/Bicycle_Occlusion_Level)|\n", "2505.15441": "|[stronger vits with octic equivariance](https://arxiv.org/abs/2505.15441)|[octic-vits](https://github.com/davnords/octic-vits)|\n", "2505.15810": "|[gui-g1: understanding r1-zero-like training for visual grounding in gui agents](https://arxiv.org/abs/2505.15810)|[gui-g1](https://github.com/yuqi-zhou/gui-g1)|\n", "2505.15867": "|[scenir: visual semantic clarity through unsupervised scene graph retrieval](https://arxiv.org/abs/2505.15867)|[scenir-icml2025](https://github.com/nickhaidos/scenir-icml2025)|\n", "2505.15870": "|[satellites reveal mobility: a commuting origin-destination flow generator for global cities](https://arxiv.org/abs/2505.15870)|[generate-od-pubtools](https://github.com/tsinghua-fib-lab/generate-od-pubtools)|\n", "2505.15928": "|[viqagent: zero-shot video question answering via agent with open-vocabulary grounding validation](https://arxiv.org/abs/2505.15928)|[viqagent](https://github.com/t-montes/viqagent)|\n", "2505.16104": "|[hierarchical safety realignment: lightweight restoration of safety in pruned large vision-language models](https://arxiv.org/abs/2505.16104)|[hsr](https://github.com/theshineyue/hsr)|\n", "2505.16161": "|[deep learning-driven ultra-high-definition image restoration: a survey](https://arxiv.org/abs/2505.16161)|[uhd-image-restoration-survey](https://github.com/wlydlut/uhd-image-restoration-survey)|\n", "2505.16165": "|[re-trip : reflectivity instance augmented triangle descriptor for 3d place recognition](https://arxiv.org/abs/2505.16165)|[re-trip](https://github.com/pyc5714/re-trip)|\n", "2505.16175": "|[quickvideo: real-time long video understanding with system algorithm co-design](https://arxiv.org/abs/2505.16175)|[quickvideo](https://github.com/tiger-ai-lab/quickvideo)|\n", "2505.16264": "|[linea: fast and accurate line detection using scalable transformers](https://arxiv.org/abs/2505.16264)|[LINEA](https://github.com/SebastianJanampa/LINEA)|\n", "2505.16282": "|[arpo:end-to-end policy optimization for gui agents with experience replay](https://arxiv.org/abs/2505.16282)|[arpo](https://github.com/dvlab-research/arpo)|\n", "2505.16313": "|[accelerating targeted hard-label adversarial attacks in low-query black-box settings](https://arxiv.org/abs/2505.16313)|[tea](https://github.com/mdppml/tea)|\n", "2505.16321": "|[efficient motion prompt learning for robust visual tracking](https://arxiv.org/abs/2505.16321)|[motion-prompt-tracking](https://github.com/zj5559/motion-prompt-tracking)|\n", "2505.16335": "|[fpqvar: floating point quantization for visual autoregressive model with fpga hardware co-design](https://arxiv.org/abs/2505.16335)|[fpqvar](https://github.com/pku-sec-lab/fpqvar)|\n", "2505.16360": "|[style transfer with diffusion models for synthetic-to-real domain adaptation](https://arxiv.org/abs/2505.16360)|[cactif](https://github.com/echigot/cactif)|\n", "2505.16376": "|[decafnet: delegate and conquer for efficient temporal grounding in long videos](https://arxiv.org/abs/2505.16376)|[cvpr2025-decafnet](https://github.com/zijialewislu/cvpr2025-decafnet)|\n", "2505.16402": "|[advreal: adversarial patch generation framework with application to adversarial safety evaluation of object detection systems](https://arxiv.org/abs/2505.16402)|[advreal](https://github.com/huangyh98/advreal)|\n", "2505.16411": "|[mitigating hallucinations in vision-language models through image-guided head suppression](https://arxiv.org/abs/2505.16411)|[spin](https://github.com/yueche77/spin)|\n", "2505.16416": "|[circle-rope: cone-like decoupled rotary positional embedding for large vision-language models](https://arxiv.org/abs/2505.16416)|[circlerope](https://github.com/lose4578/circlerope)|\n", "2505.16441": "|[ranked entropy minimization for continual test-time adaptation](https://arxiv.org/abs/2505.16441)|[rem](https://github.com/pilshan/rem)|\n", "2505.16470": "|[benchmarking retrieval-augmented multimomal generation for document question answering](https://arxiv.org/abs/2505.16470)|[mmdocrag](https://github.com/mmdocrag/mmdocrag)|\n", "2505.16495": "|[alto: adaptive-length tokenizer for autoregressive mask generation](https://arxiv.org/abs/2505.16495)|[altollm](https://github.com/yayafengzi/altollm)|\n", "2505.16579": "|[bridging the dynamic perception gap: training-free draft chain-of-thought for dynamic multimodal spatial reasoning](https://arxiv.org/abs/2505.16579)|[d2r](https://github.com/cratileo/d2r)|\n", "2505.16625": "|[background matters: a cross-view bidirectional modeling framework for semi-supervised medical image segmentation](https://arxiv.org/abs/2505.16625)|[cvbm](https://github.com/caoluyang0830/cvbm)|\n", "2505.16650": "|[unsupervised network anomaly detection with autoencoders and traffic images](https://arxiv.org/abs/2505.16650)|[image-based-network-traffic-anomaly-detection](https://github.com/michaelneri/image-based-network-traffic-anomaly-detection)|\n", "2505.16658": "|[zero-shot hyperspectral pansharpening using hysteresis-based tuning for spectral quality control](https://arxiv.org/abs/2505.16658)|[rho-pnn](https://github.com/giu-guarino/rho-pnn)|\n", "2505.16663": "|[conav: collaborative cross-modal reasoning for embodied navigation](https://arxiv.org/abs/2505.16663)|[CoNav](https://github.com/oceanhao/CoNav)|\n", "2505.16673": "|[r1-sharevl: incentivizing reasoning capability of multimodal large language models via share-grpo](https://arxiv.org/abs/2505.16673)|[r1-sharevl](https://github.com/hjyao00/r1-sharevl)|\n", "2505.16685": "|[on the use of graphs for satellite image time series](https://arxiv.org/abs/2505.16685)|[graph4sits](https://github.com/corentin-dfg/graph4sits)|\n", "2505.16740": "|[robust vision-based runway detection through conformal prediction and conformal map](https://arxiv.org/abs/2505.16740)|[conformal_runway_detection](https://github.com/alyasltd/conformal_runway_detection)|\n", "2505.16778": "|[single domain generalization for few-shot counting via universal representation matching](https://arxiv.org/abs/2505.16778)|[urm](https://github.com/jbr97/urm)|\n", "2505.16792": "|[repa works until it doesn't: early-stopped, holistic alignment supercharges diffusion training](https://arxiv.org/abs/2505.16792)|[haste](https://github.com/nus-hpc-ai-lab/haste)|\n", "2505.16793": "|[reobench: benchmarking robustness of earth observation foundation models](https://arxiv.org/abs/2505.16793)|[reobench](https://github.com/lx709/reobench)|\n", "2505.16815": "|[perceptual quality assessment for embodied ai](https://arxiv.org/abs/2505.16815)|[embodiediqa](https://github.com/lcysyzxdxc/embodiediqa)|\n", "2505.16832": "|[from eduvisbench to eduvisagent: a benchmark and multi-agent framework for pedagogical visualization](https://arxiv.org/abs/2505.16832)|[eduvisbench](https://github.com/aiming-lab/eduvisbench)|\n", "2505.16864": "|[training-free efficient video generation via dynamic token carving](https://arxiv.org/abs/2505.16864)|[jenga](https://github.com/dvlab-research/jenga)|\n", "2505.16902": "|[realengine: simulating autonomous driving in realistic context](https://arxiv.org/abs/2505.16902)|[realengine](https://github.com/fudan-zvg/realengine)|\n", "2505.16916": "|[backdoor cleaning without external guidance in mllm fine-tuning](https://arxiv.org/abs/2505.16916)|[bye](https://github.com/xuankunrong/bye)|\n", "2505.16974": "|[openseg-r: improving open-vocabulary segmentation via step-by-step visual reasoning](https://arxiv.org/abs/2505.16974)|[openseg-r](https://github.com/hanzy1996/openseg-r)|\n", "2505.16977": "|[incorporating visual correspondence into diffusion model for virtual try-on](https://arxiv.org/abs/2505.16977)|[spm-diff](https://github.com/hidream-ai/spm-diff)|\n", "2505.16985": "|[extremely simple multimodal outlier synthesis for out-of-distribution detection and segmentation](https://arxiv.org/abs/2505.16985)|[featuremixing](https://github.com/mona4399/featuremixing)|\n", "2505.17002": "|[paeff: precise alignment and enhanced gated feature fusion for face-voice association](https://arxiv.org/abs/2505.17002)|[paeff](https://github.com/hannabdul/paeff)|\n", "2505.17008": "|[deep mineralogical segmentation of thin section images based on qemscan maps](https://arxiv.org/abs/2505.17008)|[deep-mineralogical-segmentation](https://github.com/ltracegeo/deep-mineralogical-segmentation)|\n", "2505.17012": "|[spatialscore: towards unified evaluation for multimodal spatial understanding](https://arxiv.org/abs/2505.17012)|[SpatialScore](https://github.com/haoningwu3639/SpatialScore)|\n", "2505.17017": "|[delving into rl for image generation with cot: a study on dpo vs. grpo](https://arxiv.org/abs/2505.17017)|[image-generation-cot](https://github.com/ziyuguo99/image-generation-cot)|\n", "2505.17018": "|[sophiavl-r1: reinforcing mllms reasoning with thinking reward](https://arxiv.org/abs/2505.17018)|[sophiavl-r1](https://github.com/kxfan2002/sophiavl-r1)|\n", "2505.17019": "|[let androids dream of electric sheep: a human-like image implication understanding and reasoning framework](https://arxiv.org/abs/2505.17019)|[let-androids-dream-of-electric-sheep](https://github.com/ming-zch/let-androids-dream-of-electric-sheep)|\n", "2505.17020": "|[crosslmm: decoupling long video sequences from lmms via dual cross-attention mechanisms](https://arxiv.org/abs/2505.17020)|[crosslmm](https://github.com/shilinyan99/crosslmm)|\n", "2505.17021": "|[arb: a comprehensive arabic multimodal reasoning benchmark](https://arxiv.org/abs/2505.17021)|[arb](https://github.com/mbzuai-oryx/arb)|\n", "2505.17022": "|[got-r1: unleashing reasoning capability of mllm for visual generation with reinforcement learning](https://arxiv.org/abs/2505.17022)|[got-r1](https://github.com/gogoduan/got-r1)|\n"}, "2025-05-24": {}, "2025-05-25": {}, "2025-05-26": {"2403.19924": "|[scenetracker: long-term scene flow estimation network](https://arxiv.org/abs/2403.19924)|[scenetracker](https://github.com/wwsource/scenetracker)|\n", "2410.15618": "|[erasing undesirable concepts in diffusion models with adversarial preservation](https://arxiv.org/abs/2410.15618)|[erasing-adversarial-preservation](https://github.com/tuananhbui89/erasing-adversarial-preservation)|\n", "2411.16598": "|[diffbreak: is diffusion-based purification robust?](https://arxiv.org/abs/2411.16598)|[DiffBreak](https://github.com/andrekassis/DiffBreak)|\n", "2411.19715": "|[forensics adapter: unleashing clip for generalizable face forgery detection](https://arxiv.org/abs/2411.19715)|[forensicsadapter](https://github.com/ouc-vas/forensicsadapter)|\n", "2412.12453": "|[multimodal classification and out-of-distribution detection for multimodal intent understanding](https://arxiv.org/abs/2412.12453)|[mintood](https://github.com/thuiar/mintood)|\n", "2501.18950": "|[fantastic targets for concept erasure in diffusion models and where to find them](https://arxiv.org/abs/2501.18950)|[adaptive-guided-erasure](https://github.com/tuananhbui89/adaptive-guided-erasure)|\n", "2502.11651": "|[mmxu: a multi-modal and multi-x-ray understanding dataset for disease progression](https://arxiv.org/abs/2502.11651)|[mmxu](https://github.com/linjiemu/mmxu)|\n", "2502.19260": "|[emt: a visual multi-task benchmark dataset for autonomous driving](https://arxiv.org/abs/2502.19260)|[emt-dataset](https://github.com/av-lab/emt-dataset)|\n", "2503.07435": "|[open-set gait recognition from sparse mmwave radar point clouds](https://arxiv.org/abs/2503.07435)|[OpenSetGaitRecognition_PCAA](https://github.com/rmazzier/OpenSetGaitRecognition_PCAA)|\n", "2503.22679": "|[q-insight: understanding image quality via visual reinforcement learning](https://arxiv.org/abs/2503.22679)|[q-insight](https://github.com/lwq20020127/q-insight)|\n", "2504.19838": "|[llm-powered gui agents in phone automation: surveying progress and prospects](https://arxiv.org/abs/2504.19838)|[awesome-llm-powered-phone-gui-agents](https://github.com/phonellm/awesome-llm-powered-phone-gui-agents)|\n", "2505.01476": "|[costfilter-ad: enhancing anomaly detection through matching cost filtering](https://arxiv.org/abs/2505.01476)|[costfilter-ad](https://github.com/zhe-sapi/costfilter-ad)|\n", "2505.05528": "|[x-transfer attacks: towards super transferable adversarial attacks on clip](https://arxiv.org/abs/2505.05528)|[XTransferBench](https://github.com/HanxunH/XTransferBench)|\n", "2505.10541": "|[exploring implicit visual misunderstandings in multimodal large language models through attention analysis](https://arxiv.org/abs/2505.10541)|[stme](https://github.com/welldonepf/stme)|\n", "2505.10595": "|[arfc-wahnet: adaptive receptive field convolution and wavelet-attentive hierarchical network for infrared small target detection](https://arxiv.org/abs/2505.10595)|[arfc-wahnet](https://github.com/leaf2001/arfc-wahnet)|\n", "2505.11454": "|[humanibench: a human-centric framework for large multimodal models evaluation](https://arxiv.org/abs/2505.11454)|[humanibench](https://github.com/vectorinstitute/humanibench)|\n", "2505.14151": "|[reactdiff: latent diffusion for facial reaction generation](https://arxiv.org/abs/2505.14151)|[reactdiff](https://github.com/hunan-tiger/reactdiff)|\n", "2505.16839": "|[lavida: a large diffusion language model for multimodal understanding](https://arxiv.org/abs/2505.16839)|[lavida](https://github.com/jacklishufan/lavida)|\n", "2505.16854": "|[think or not? selective reasoning via reinforcement learning for vision-language models](https://arxiv.org/abs/2505.16854)|[ton](https://github.com/kokolerk/ton)|\n", "2505.17475": "|[posebh: prototypical multi-dataset training beyond human pose estimation](https://arxiv.org/abs/2505.17475)|[PoseBH](https://github.com/uyoung-jeong/PoseBH)|\n", "2505.17883": "|[fastcav: efficient computation of concept activation vectors for explaining deep neural networks](https://arxiv.org/abs/2505.17883)|[fastcav](https://gitlab.com/dlr-dw/fastcav)|\n", "2505.18060": "|[semantic correspondence: unified benchmarking and a strong baseline](https://arxiv.org/abs/2505.18060)|[Semantic-Correspondence](https://github.com/Visual-AI/Semantic-Correspondence)|\n"}}