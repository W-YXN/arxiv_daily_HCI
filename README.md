# Daily ArXiv HCI

A curated collection of arXiv papers with open-source implementations, specifically focusing on Human-Computer Interaction (cs.HC) and related fields like Computer Graphics (cs.GR), Computer Vision (cs.CV), etc. This repository aims to serve researchers and practitioners in HCI by providing easy access to papers that come with their source code implementations.

## Overview
This project automatically tracks and analyzes papers from relevant HCI categories on arXiv daily using GitHub Actions. It specifically identifies and catalogs papers that have released their source code, making it easier for researchers in HCI and related areas to find implementable research work.

The main features include:
- Daily updates of papers with open-source implementations
- Focus on Human-Computer Interaction and related research
- Automatic tracking and organization

## Latest Updates 
|date|paper|code|
|---|---|---|
|2505.02567|[unified multimodal understanding and generation models: advances, challenges, and opportunities](https://arxiv.org/abs/2505.02567)|[awesome-unified-multimodal-models](https://github.com/aidc-ai/awesome-unified-multimodal-models)|
|2505.10049|[advances in radiance field for dynamic scene: from neural field to gaussian field](https://arxiv.org/abs/2505.10049)|[dynamic-radiation-field-paper-list](https://github.com/moonflo/dynamic-radiation-field-paper-list)|
|2505.10250|[adhmr: aligning diffusion-based human mesh recovery via direct preference optimization](https://arxiv.org/abs/2505.10250)|[adhmr](https://github.com/shenwenhao01/adhmr)|
|2505.10473|[consistent quantity-quality control across scenes for deployment-aware gaussian splatting](https://arxiv.org/abs/2505.10473)|[ControlGS](https://github.com/zhang-fengdi/ControlGS)|
|2505.12007|[multi-modal collaborative optimization and expansion network for event-assisted single-eye expression recognition](https://arxiv.org/abs/2505.12007)|[MCO-E-Net](https://github.com/hrdhrd/MCO-E-Net)|
|2505.12081|[visionreasoner: unified visual perception and reasoning via reinforcement learning](https://arxiv.org/abs/2505.12081)|[VisionReasoner](https://github.com/dvlab-research/VisionReasoner)|
|2505.14068|[place recognition: a comprehensive review, current challenges and future directions](https://arxiv.org/abs/2505.14068)|[sota-place-recognitioner](https://github.com/cv4ra/sota-place-recognitioner)|
|2505.15222|[continuous representation methods, theories, and applications: an overview and perspectives](https://arxiv.org/abs/2505.15222)|[continuous-representation-zoo](https://github.com/yisiluo/continuous-representation-zoo)|
|2505.15358|[objective bicycle occlusion level classification using a deformable parts-based model](https://arxiv.org/abs/2505.15358)|[Bicycle_Occlusion_Level](https://github.com/angelmangubat/Bicycle_Occlusion_Level)|
|2505.15441|[stronger vits with octic equivariance](https://arxiv.org/abs/2505.15441)|[octic-vits](https://github.com/davnords/octic-vits)|
|2505.15810|[gui-g1: understanding r1-zero-like training for visual grounding in gui agents](https://arxiv.org/abs/2505.15810)|[gui-g1](https://github.com/yuqi-zhou/gui-g1)|
|2505.15867|[scenir: visual semantic clarity through unsupervised scene graph retrieval](https://arxiv.org/abs/2505.15867)|[scenir-icml2025](https://github.com/nickhaidos/scenir-icml2025)|
|2505.15870|[satellites reveal mobility: a commuting origin-destination flow generator for global cities](https://arxiv.org/abs/2505.15870)|[generate-od-pubtools](https://github.com/tsinghua-fib-lab/generate-od-pubtools)|
|2505.15928|[viqagent: zero-shot video question answering via agent with open-vocabulary grounding validation](https://arxiv.org/abs/2505.15928)|[viqagent](https://github.com/t-montes/viqagent)|
|2505.16091|[oscar: one-step diffusion codec across multiple bit-rates](https://arxiv.org/abs/2505.16091)|[oscar](https://github.com/jp-guo/oscar)|
|2505.16104|[hierarchical safety realignment: lightweight restoration of safety in pruned large vision-language models](https://arxiv.org/abs/2505.16104)|[hsr](https://github.com/theshineyue/hsr)|
|2505.16161|[deep learning-driven ultra-high-definition image restoration: a survey](https://arxiv.org/abs/2505.16161)|[uhd-image-restoration-survey](https://github.com/wlydlut/uhd-image-restoration-survey)|
|2505.16165|[re-trip : reflectivity instance augmented triangle descriptor for 3d place recognition](https://arxiv.org/abs/2505.16165)|[re-trip](https://github.com/pyc5714/re-trip)|
|2505.16175|[quickvideo: real-time long video understanding with system algorithm co-design](https://arxiv.org/abs/2505.16175)|[quickvideo](https://github.com/tiger-ai-lab/quickvideo)|
|2505.16264|[linea: fast and accurate line detection using scalable transformers](https://arxiv.org/abs/2505.16264)|[LINEA](https://github.com/SebastianJanampa/LINEA)|
|2505.16282|[arpo:end-to-end policy optimization for gui agents with experience replay](https://arxiv.org/abs/2505.16282)|[arpo](https://github.com/dvlab-research/arpo)|
|2505.16313|[accelerating targeted hard-label adversarial attacks in low-query black-box settings](https://arxiv.org/abs/2505.16313)|[tea](https://github.com/mdppml/tea)|
|2505.16321|[efficient motion prompt learning for robust visual tracking](https://arxiv.org/abs/2505.16321)|[motion-prompt-tracking](https://github.com/zj5559/motion-prompt-tracking)|
|2505.16335|[fpqvar: floating point quantization for visual autoregressive model with fpga hardware co-design](https://arxiv.org/abs/2505.16335)|[fpqvar](https://github.com/pku-sec-lab/fpqvar)|
|2505.16360|[style transfer with diffusion models for synthetic-to-real domain adaptation](https://arxiv.org/abs/2505.16360)|[cactif](https://github.com/echigot/cactif)|
|2505.16376|[decafnet: delegate and conquer for efficient temporal grounding in long videos](https://arxiv.org/abs/2505.16376)|[cvpr2025-decafnet](https://github.com/zijialewislu/cvpr2025-decafnet)|
|2505.16402|[advreal: adversarial patch generation framework with application to adversarial safety evaluation of object detection systems](https://arxiv.org/abs/2505.16402)|[advreal](https://github.com/huangyh98/advreal)|
|2505.16411|[mitigating hallucinations in vision-language models through image-guided head suppression](https://arxiv.org/abs/2505.16411)|[spin](https://github.com/yueche77/spin)|
|2505.16416|[circle-rope: cone-like decoupled rotary positional embedding for large vision-language models](https://arxiv.org/abs/2505.16416)|[circlerope](https://github.com/lose4578/circlerope)|
|2505.16441|[ranked entropy minimization for continual test-time adaptation](https://arxiv.org/abs/2505.16441)|[rem](https://github.com/pilshan/rem)|
|2505.16470|[benchmarking retrieval-augmented multimomal generation for document question answering](https://arxiv.org/abs/2505.16470)|[mmdocrag](https://github.com/mmdocrag/mmdocrag)|
|2505.16495|[alto: adaptive-length tokenizer for autoregressive mask generation](https://arxiv.org/abs/2505.16495)|[altollm](https://github.com/yayafengzi/altollm)|
|2505.16579|[bridging the dynamic perception gap: training-free draft chain-of-thought for dynamic multimodal spatial reasoning](https://arxiv.org/abs/2505.16579)|[d2r](https://github.com/cratileo/d2r)|
|2505.16625|[background matters: a cross-view bidirectional modeling framework for semi-supervised medical image segmentation](https://arxiv.org/abs/2505.16625)|[cvbm](https://github.com/caoluyang0830/cvbm)|
|2505.16650|[unsupervised network anomaly detection with autoencoders and traffic images](https://arxiv.org/abs/2505.16650)|[image-based-network-traffic-anomaly-detection](https://github.com/michaelneri/image-based-network-traffic-anomaly-detection)|
|2505.16658|[zero-shot hyperspectral pansharpening using hysteresis-based tuning for spectral quality control](https://arxiv.org/abs/2505.16658)|[rho-pnn](https://github.com/giu-guarino/rho-pnn)|
|2505.16663|[conav: collaborative cross-modal reasoning for embodied navigation](https://arxiv.org/abs/2505.16663)|[CoNav](https://github.com/oceanhao/CoNav)|
|2505.16673|[r1-sharevl: incentivizing reasoning capability of multimodal large language models via share-grpo](https://arxiv.org/abs/2505.16673)|[r1-sharevl](https://github.com/hjyao00/r1-sharevl)|
|2505.16685|[on the use of graphs for satellite image time series](https://arxiv.org/abs/2505.16685)|[graph4sits](https://github.com/corentin-dfg/graph4sits)|
|2505.16740|[robust vision-based runway detection through conformal prediction and conformal map](https://arxiv.org/abs/2505.16740)|[conformal_runway_detection](https://github.com/alyasltd/conformal_runway_detection)|
|2505.16778|[single domain generalization for few-shot counting via universal representation matching](https://arxiv.org/abs/2505.16778)|[urm](https://github.com/jbr97/urm)|
|2505.16792|[repa works until it doesn't: early-stopped, holistic alignment supercharges diffusion training](https://arxiv.org/abs/2505.16792)|[haste](https://github.com/nus-hpc-ai-lab/haste)|
|2505.16793|[reobench: benchmarking robustness of earth observation foundation models](https://arxiv.org/abs/2505.16793)|[reobench](https://github.com/lx709/reobench)|
|2505.16815|[perceptual quality assessment for embodied ai](https://arxiv.org/abs/2505.16815)|[embodiediqa](https://github.com/lcysyzxdxc/embodiediqa)|
|2505.16832|[from eduvisbench to eduvisagent: a benchmark and multi-agent framework for pedagogical visualization](https://arxiv.org/abs/2505.16832)|[eduvisbench](https://github.com/aiming-lab/eduvisbench)|
|2505.16864|[training-free efficient video generation via dynamic token carving](https://arxiv.org/abs/2505.16864)|[jenga](https://github.com/dvlab-research/jenga)|
|2505.16902|[realengine: simulating autonomous driving in realistic context](https://arxiv.org/abs/2505.16902)|[realengine](https://github.com/fudan-zvg/realengine)|
|2505.16916|[backdoor cleaning without external guidance in mllm fine-tuning](https://arxiv.org/abs/2505.16916)|[bye](https://github.com/xuankunrong/bye)|
|2505.16974|[openseg-r: improving open-vocabulary segmentation via step-by-step visual reasoning](https://arxiv.org/abs/2505.16974)|[openseg-r](https://github.com/hanzy1996/openseg-r)|
|2505.16977|[incorporating visual correspondence into diffusion model for virtual try-on](https://arxiv.org/abs/2505.16977)|[spm-diff](https://github.com/hidream-ai/spm-diff)|
|2505.16985|[extremely simple multimodal outlier synthesis for out-of-distribution detection and segmentation](https://arxiv.org/abs/2505.16985)|[featuremixing](https://github.com/mona4399/featuremixing)|
|2505.16990|[dimple: discrete diffusion multimodal large language model with parallel decoding](https://arxiv.org/abs/2505.16990)|[dimple](https://github.com/yu-rp/dimple)|
|2505.17002|[paeff: precise alignment and enhanced gated feature fusion for face-voice association](https://arxiv.org/abs/2505.17002)|[paeff](https://github.com/hannabdul/paeff)|
|2505.17008|[deep mineralogical segmentation of thin section images based on qemscan maps](https://arxiv.org/abs/2505.17008)|[deep-mineralogical-segmentation](https://github.com/ltracegeo/deep-mineralogical-segmentation)|
|2505.17012|[spatialscore: towards unified evaluation for multimodal spatial understanding](https://arxiv.org/abs/2505.17012)|[SpatialScore](https://github.com/haoningwu3639/SpatialScore)|
|2505.17017|[delving into rl for image generation with cot: a study on dpo vs. grpo](https://arxiv.org/abs/2505.17017)|[image-generation-cot](https://github.com/ziyuguo99/image-generation-cot)|
|2505.17018|[sophiavl-r1: reinforcing mllms reasoning with thinking reward](https://arxiv.org/abs/2505.17018)|[sophiavl-r1](https://github.com/kxfan2002/sophiavl-r1)|
|2505.17019|[let androids dream of electric sheep: a human-like image implication understanding and reasoning framework](https://arxiv.org/abs/2505.17019)|[let-androids-dream-of-electric-sheep](https://github.com/ming-zch/let-androids-dream-of-electric-sheep)|
|2505.17020|[crosslmm: decoupling long video sequences from lmms via dual cross-attention mechanisms](https://arxiv.org/abs/2505.17020)|[crosslmm](https://github.com/shilinyan99/crosslmm)|
|2505.17021|[arb: a comprehensive arabic multimodal reasoning benchmark](https://arxiv.org/abs/2505.17021)|[arb](https://github.com/mbzuai-oryx/arb)|
|2505.17022|[got-r1: unleashing reasoning capability of mllm for visual generation with reinforcement learning](https://arxiv.org/abs/2505.17022)|[got-r1](https://github.com/gogoduan/got-r1)|
|2505.01237|[cav-mae sync: improving contrastive audio-visual mask autoencoders via fine-grained alignment](https://arxiv.org/abs/2505.01237)|[cav-mae-sync](https://github.com/edsonroteia/cav-mae-sync)|
|2505.04046|[reliable disentanglement multi-view learning against view adversarial attacks](https://arxiv.org/abs/2505.04046)|[2025-IJCAI-RDML](https://github.com/Willy1005/2025-IJCAI-RDML)|
|2505.04788|[convex relaxation for robust vanishing point estimation in manhattan world](https://arxiv.org/abs/2505.04788)|[globustvp](https://github.com/wu-cvgl/globustvp)|
|2505.05049|[uncertainsam: fast and efficient uncertainty quantification of the segment anything model](https://arxiv.org/abs/2505.05049)|[UncertainSAM](https://github.com/GreenAutoML4FAS/UncertainSAM)|
|2505.05071|[fg-clip: fine-grained visual and textual alignment](https://arxiv.org/abs/2505.05071)|[fg-clip](https://github.com/360cvgroup/fg-clip)|
|2505.12620|[busterx: mllm-powered ai-generated video forgery detection and explanation](https://arxiv.org/abs/2505.12620)|[busterx](https://github.com/l8cv/busterx)|
|2505.13300|[dd-ranking: rethinking the evaluation of dataset distillation](https://arxiv.org/abs/2505.13300)|[dd-ranking](https://github.com/nus-hpc-ai-lab/dd-ranking)|
|2505.14074|[recreating neural activity during speech production with language and speech model embeddings](https://arxiv.org/abs/2505.14074)|[llm_brain_representations](https://github.com/owaismujtaba/llm_brain_representations)|
|2505.14100|[unlocking the power of sam 2 for few-shot segmentation](https://arxiv.org/abs/2505.14100)|[fssam](https://github.com/sam1224/fssam)|
|2505.14707|[crypticbio: a large multimodal dataset for visually confusing biodiversity](https://arxiv.org/abs/2505.14707)|[crypticbio](https://github.com/georgianagmanolache/crypticbio)|
|2505.14708|[draftattention: fast video diffusion via low-resolution attention guidance](https://arxiv.org/abs/2505.14708)|[draft-attention](https://github.com/shawnricecake/draft-attention)|
|2505.14709|[fastcar: cache attentive replay for fast auto-regressive video generation on the edge](https://arxiv.org/abs/2505.14709)|[fast-car](https://github.com/shawnricecake/fast-car)|
|2505.14714|[kgalign: joint semantic-structural knowledge encoding for multimodal fake news detection](https://arxiv.org/abs/2505.14714)|[kgalign](https://github.com/latuanvinh1998/kgalign)|
|2505.14717|[aneumo: a large-scale multimodal aneurysm dataset with computational fluid dynamics simulations and deep learning benchmarks](https://arxiv.org/abs/2505.14717)|[aneumo](https://github.com/xigui-li/aneumo)|
|2505.14747|[lod1 3d city model from lidar: the impact of segmentation accuracy on quality of urban 3d modeling and morphology extraction](https://arxiv.org/abs/2505.14747)|[LiDAR-3D-Building-Modeling](https://github.com/FatemehCh97/LiDAR-3D-Building-Modeling)|
|2505.14846|[open-set semi-supervised learning for long-tailed medical datasets](https://arxiv.org/abs/2505.14846)|[openltr](https://github.com/daniyanaj/openltr)|
|2505.14931|[colors matter: ai-driven exploration of human feature colors](https://arxiv.org/abs/2505.14931)|[Color-Matters-AI-Driven-Exploration-of-Human-Feature-Coloration](https://github.com/AiTaif7/Color-Matters-AI-Driven-Exploration-of-Human-Feature-Coloration)|
|2505.14948|[programmatic video prediction using large language models](https://arxiv.org/abs/2505.14948)|[ProgGen](https://github.com/metro-smiles/ProgGen)|
|2505.14951|[multimae meets earth observation: pre-training multi-modal multi-task masked autoencoders for earth observation tasks](https://arxiv.org/abs/2505.14951)|[multimae-meets-eo](https://github.com/josesosajs/multimae-meets-eo)|
|2505.14983|[toward informed av decision-making: computational model of well-being and trust in mobility](https://arxiv.org/abs/2505.14983)|[wellbeing-trust-model](https://github.com/honda-research-institute/wellbeing-trust-model)|
|2505.15031|[are the confidence scores of reviewers consistent with the review content? evidence from top conference proceedings in ai](https://arxiv.org/abs/2505.15031)|[confidence_score](https://github.com/njust-winchy/confidence_score)|
|2505.15075|[traveling across languages: benchmarking cross-lingual consistency in multimodal llms](https://arxiv.org/abs/2505.15075)|[traveling-across-languages](https://github.com/nlp-waseda/traveling-across-languages)|
|2505.15111|[ipad: iterative proposal-centric end-to-end autonomous driving](https://arxiv.org/abs/2505.15111)|[iPad](https://github.com/Kguo-cs/iPad)|
|2505.15120|[lung nodule-ssm: self-supervised lung nodule detection and classification in thoracic ct images](https://arxiv.org/abs/2505.15120)|[lung-nodule-ssm-self-supervised-lung-nodule-detection-and-classification](https://github.com/emeraldsnrpu/lung-nodule-ssm-self-supervised-lung-nodule-detection-and-classification)|
|2505.15133|[deepkd: a deeply decoupled and denoised knowledge distillation trainer](https://arxiv.org/abs/2505.15133)|[deepkd](https://github.com/haiduo/deepkd)|
|2505.15145|[cinetechbench: a benchmark for cinematographic technique understanding and generation](https://arxiv.org/abs/2505.15145)|[cinetechbench](https://github.com/pris-cv/cinetechbench)|
|2505.15184|[auxdet: auxiliary metadata matters for omni-domain infrared small target detection](https://arxiv.org/abs/2505.15184)|[auxdet](https://github.com/grokcv/auxdet)|
|2505.15185|[monosplat: generalizable 3d gaussian splatting from monocular depth foundation models](https://arxiv.org/abs/2505.15185)|[monosplat](https://github.com/cuhk-aim-group/monosplat)|
|2505.15217|[multimodal conditional information bottleneck for generalizable ai-generated image detection](https://arxiv.org/abs/2505.15217)|[infofd](https://github.com/ant0ny44/infofd)|
|2505.15232|[dc-scene: data-centric learning for 3d scene understanding](https://arxiv.org/abs/2505.15232)|[dc-scene](https://github.com/aigeeksgroup/dc-scene)|
|2505.15234|[sama-unet: enhancing medical image segmentation with self-adaptive mamba-like attention and causal-resonance learning](https://arxiv.org/abs/2505.15234)|[SAMA-UNet](https://github.com/sqbqamar/SAMA-UNet)|
|2505.15235|[x-grm: large gaussian reconstruction model for sparse-view x-rays to computed tomography](https://arxiv.org/abs/2505.15235)|[x-grm](https://github.com/cuhk-aim-group/x-grm)|
|2505.15270|[scaling diffusion transformers efficiently via $\mu$p](https://arxiv.org/abs/2505.15270)|[Scaling-Diffusion-Transformers-muP](https://github.com/ML-GSAI/Scaling-Diffusion-Transformers-muP)|
|2505.15272|[diffprob: data pruning for face recognition](https://arxiv.org/abs/2505.15272)|[DiffProb](https://github.com/EduardaCaldeira/DiffProb)|
|2505.15282|[exploring in-image machine translation with real-world background](https://arxiv.org/abs/2505.15282)|[debackx](https://github.com/bithlp/debackx)|
|2505.15284|[kernel pca for out-of-distribution detection: non-linear kernel selections and approximations](https://arxiv.org/abs/2505.15284)|[ood-kpca-extension](https://github.com/fanghenshaometeor/ood-kpca-extension)|
|2505.15325|[softhgnn: soft hypergraph neural networks for general visual recognition](https://arxiv.org/abs/2505.15325)|[SoftHGNN](https://github.com/Mengqi-Lei/SoftHGNN)|
|2505.15364|[mhanet: multi-scale hybrid attention network for auditory attention detection](https://arxiv.org/abs/2505.15364)|[mhanet](https://github.com/fchest/mhanet)|
|2505.15379|[the p$^3$ dataset: pixels, points and polygons for multimodal building vectorization](https://arxiv.org/abs/2505.15379)|[pixelspointspolygons](https://github.com/raphaelsulzer/pixelspointspolygons)|
|2505.15435|[timecausality: evaluating the causal ability in time dimension for vision language models](https://arxiv.org/abs/2505.15435)|[timecausality](https://github.com/zeqing-wang/timecausality)|
|2505.15506|[prompt tuning vision language models with margin regularizer for few-shot learning under distribution shifts](https://arxiv.org/abs/2505.15506)|[promptmargin](https://github.com/debarshigit/promptmargin)|
|2505.15545|[seg_3d_by_pc2d: multi-view projection for domain generalization and adaptation in 3d semantic segmentation](https://arxiv.org/abs/2505.15545)|[ia4markings](https://github.com/andrewcaunes/ia4markings)|
|2505.15576|[visual perturbation and adaptive hard negative contrastive learning for compositional reasoning in vision-language models](https://arxiv.org/abs/2505.15576)|[ahnpl](https://github.com/nynu-bdai/ahnpl)|
|2505.15581|[uwsam: segment anything model guided underwater instance segmentation and a large-scale benchmark dataset](https://arxiv.org/abs/2505.15581)|[uiis10k](https://github.com/liamlian0727/uiis10k)|
|2505.15596|[exploring llm-generated feedback for economics essays: how teaching assistants evaluate and envision its use](https://arxiv.org/abs/2505.15596)|[aied2025-exploring-llm-generated-feedback-for-economics-essay](https://github.com/um-lifelong-learning-lab/aied2025-exploring-llm-generated-feedback-for-economics-essay)|
|2505.15628|[snap: a benchmark for testing the effects of capture conditions on fundamental vision tasks](https://arxiv.org/abs/2505.15628)|[snap](https://github.com/ykotseruba/snap)|
|2505.15637|[oral imaging for malocclusion issues assessments: omni dataset, deep learning baselines and benchmarking](https://arxiv.org/abs/2505.15637)|[omni](https://github.com/roundfacej/omni)|
|2505.15644|[fragfake: a dataset for fine-grained detection of edited images with vision language models](https://arxiv.org/abs/2505.15644)|[FragFake](https://github.com/Vincent-HKUSTGZ/FragFake)|
|2505.15649|[the devil is in fine-tuning and long-tailed problems:a new benchmark for scene text detection](https://arxiv.org/abs/2505.15649)|[ltb](https://github.com/pd162/ltb)|
|2505.15804|[star-r1: spacial transformation reasoning by reinforcing multimodal llms](https://arxiv.org/abs/2505.15804)|[star-r1](https://github.com/zongzhao23/star-r1)|
|2505.15809|[mmada: multimodal large diffusion language models](https://arxiv.org/abs/2505.15809)|[mmada](https://github.com/gen-verse/mmada)|
|2505.15812|[leveraging the powerful attention of a pre-trained diffusion model for exemplar-based image colorization](https://arxiv.org/abs/2505.15812)|[powerful-attention](https://github.com/satoshi-kosugi/powerful-attention)|
|2505.15816|[streamline without sacrifice -- squeeze out computation redundancy in lmm](https://arxiv.org/abs/2505.15816)|[proxyv](https://github.com/penghao-wu/proxyv)|
|2505.15818|[instructsam: a training-free framework for instruction-oriented remote sensing object recognition](https://arxiv.org/abs/2505.15818)|[InstructSAM](https://github.com/VoyagerXvoyagerx/InstructSAM)|
|2505.04058|[as3d: 2d-assisted cross-modal understanding with semantic-spatial scene graphs for 3d visual grounding](https://arxiv.org/abs/2505.04058)|[AS3D](https://github.com/onmyoji-xiao/AS3D)|
|2505.04612|[fastmap: revisiting dense and scalable structure from motion](https://arxiv.org/abs/2505.04612)|[fastmap](https://github.com/pals-ttic/fastmap)|
|2505.06699|[model steering: learning with a reference model improves generalization bounds and scaling laws](https://arxiv.org/abs/2505.06699)|[drrho-clip](https://github.com/optimization-ai/drrho-clip)|
|2505.07447|[unified continuous generative models](https://arxiv.org/abs/2505.07447)|[UCGM](https://github.com/LINs-Lab/UCGM)|
|2505.08175|[fast text-to-audio generation with adversarial post-training](https://arxiv.org/abs/2505.08175)|[stable-audio-tools](https://github.com/stability-ai/stable-audio-tools)|
|2505.10238|[mtvcrafter: 4d motion tokenization for open-world human image animation](https://arxiv.org/abs/2505.10238)|[mtvcrafter](https://github.com/dingyanb/mtvcrafter)|
|2505.10464|[hwa-unetr: hierarchical window aggregate unetr for 3d multimodal gastric lesion segmentation](https://arxiv.org/abs/2505.10464)|[hwa-unetr](https://github.com/jeming-creater/hwa-unetr)|
|2505.12427|[draglora: online optimization of lora adapters for drag-based image editing in diffusion model](https://arxiv.org/abs/2505.12427)|[draglora](https://github.com/sylvie-x/draglora)|
|2505.12482|[spectral-spatial self-supervised learning for few-shot hyperspectral image classification](https://arxiv.org/abs/2505.12482)|[s4l-fsc](https://github.com/wenchen-chen/s4l-fsc)|
|2505.12499|[contrastive alignment with semantic gap-aware corrections in text-video retrieval](https://arxiv.org/abs/2505.12499)|[gare-text-video-retrieval](https://github.com/musicman217/gare-text-video-retrieval)|
|2505.13061|[3d visual illusion depth estimation](https://arxiv.org/abs/2505.13061)|[3d-visual-illusion-depth-estimation](https://github.com/yaochengtang/3d-visual-illusion-depth-estimation)|
|2505.13232|[starft: robust fine-tuning of zero-shot models via spuriosity alignment](https://arxiv.org/abs/2505.13232)|[starft](https://github.com/alinlab/starft)|
|2505.13483|[emometa: a multimodal dataset for fine-grained emotion classification in chinese metaphors](https://arxiv.org/abs/2505.13483)|[emometa](https://github.com/dutir-ysq/emometa)|
|2505.13539|[eulearn: a 3d database for learning euler characteristics](https://arxiv.org/abs/2505.13539)|[eulearn_db](https://github.com/appliedgeometry/eulearn_db)|
|2505.13669|[geovlm: improving automated vehicle geolocalisation using vision-language matching](https://arxiv.org/abs/2505.13669)|[geovlm](https://github.com/cav-research-lab/geovlm)|
|2505.13740|[improving compositional generation with diffusion models using lift scores](https://arxiv.org/abs/2505.13740)|[complift](https://github.com/rainorangelemon/complift)|
|2505.13773|[model cards for ai teammates: comparing human-ai team familiarization methods for high-stakes environments](https://arxiv.org/abs/2505.13773)|[maisr](https://github.com/gt-cec/maisr)|
|2505.13784|[transfer learning from visual speech recognition to mouthing recognition in german sign language](https://arxiv.org/abs/2505.13784)|[transfer-learning-vsr-mouthing-sign-language](https://github.com/nphamdinh/transfer-learning-vsr-mouthing-sign-language)|
|2505.13813|[flashkat: understanding and addressing performance bottlenecks in the kolmogorov-arnold transformer](https://arxiv.org/abs/2505.13813)|[flashkat](https://github.com/osu-starlab/flashkat)|
|2505.13839|[mgstream: motion-aware 3d gaussian for streamable dynamic scene reconstruction](https://arxiv.org/abs/2505.13839)|[mgstream](https://github.com/pcl3dv/mgstream)|
|2505.13906|[xdementnet: an explainable attention based deep convolutional network to detect alzheimer progression from mri data](https://arxiv.org/abs/2505.13906)|[XdementNET](https://github.com/SoyabulIslamLincoln/XdementNET)|
|2505.13928|[lovr: a benchmark for long video retrieval in multimodal contexts](https://arxiv.org/abs/2505.13928)|[lovr-benchmark](https://github.com/technomad-ds/lovr-benchmark)|
|2505.14008|[multi-label stereo matching for transparent scene depth estimation](https://arxiv.org/abs/2505.14008)|[TranScene](https://github.com/BFZD233/TranScene)|
|2505.14017|[end-to-end cortical surface reconstruction from clinical magnetic resonance images](https://arxiv.org/abs/2505.14017)|[brainnet](https://github.com/simnibs/brainnet)|
|2505.14042|[adversarially pretrained transformers may be universally robust in-context learners](https://arxiv.org/abs/2505.14042)|[universally-robust-in-context-learner](https://github.com/s-kumano/universally-robust-in-context-learner)|
|2505.14049|[learning concept-driven logical rules for interpretable and generalizable medical image classification](https://arxiv.org/abs/2505.14049)|[crl](https://github.com/obiyoag/crl)|
|2505.14059|[dolphin: document image parsing via heterogeneous anchor prompting](https://arxiv.org/abs/2505.14059)|[dolphin](https://github.com/bytedance/dolphin)|
|2505.14124|[intra-class patch swap for self-distillation](https://arxiv.org/abs/2505.14124)|[intra-class-patch-swap](https://github.com/hchoi71/intra-class-patch-swap)|
|2505.14246|[visual agentic reinforcement fine-tuning](https://arxiv.org/abs/2505.14246)|[visual-rft](https://github.com/liuziyu77/visual-rft)|
|2505.14254|[instructing text-to-image diffusion models via classifier-guided semantic optimization](https://arxiv.org/abs/2505.14254)|[caso](https://github.com/chang-yuanyuan/caso)|
|2505.14260|[speculative decoding reimagined for multimodal large language models](https://arxiv.org/abs/2505.14260)|[msd](https://github.com/lyn-lucy/msd)|
|2505.14318|[radar: enhancing radiology report generation with supplementary knowledge injection](https://arxiv.org/abs/2505.14318)|[Radar](https://github.com/wjhou/Radar)|
|2505.14329|[tf-mamba: text-enhanced fusion mamba with missing modalities for robust multimodal sentiment analysis](https://arxiv.org/abs/2505.14329)|[tf-mamba](https://github.com/codemous/tf-mamba)|
|2505.14333|[domain adaptation for multi-label image classification: a discriminator-free approach](https://arxiv.org/abs/2505.14333)|[dda-mlic](https://github.com/cvi2snt/dda-mlic)|
|2505.14346|[egocentric action-aware inertial localization in point clouds](https://arxiv.org/abs/2505.14346)|[ego-inertial-localization](https://github.com/mf-zhang/ego-inertial-localization)|
|2505.14362|[deepeyes: incentivizing "thinking with images" via reinforcement learning](https://arxiv.org/abs/2505.14362)|[deepeyes](https://github.com/visual-agent/deepeyes)|
|2505.14377|[when bias backfires: the modulatory role of counterfactual explanations on the adoption of algorithmic bias in xai-supported human decision-making](https://arxiv.org/abs/2505.14377)|[biasbackfiresxai2025](https://github.com/ukuhl/biasbackfiresxai2025)|
|2505.14414|[diving into the fusion of monocular priors for generalized stereo matching](https://arxiv.org/abs/2505.14414)|[Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching](https://github.com/YaoChengTang/Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching)|
|2505.14454|[video compression commander: plug-and-play inference acceleration for video large language models](https://arxiv.org/abs/2505.14454)|[vidcom2](https://github.com/xuyang-liu16/vidcom2)|
|2505.14460|[visualquality-r1: reasoning-induced image quality assessment via reinforcement learning to rank](https://arxiv.org/abs/2505.14460)|[visualquality-r1](https://github.com/tianhewu/visualquality-r1)|
|2505.14462|[ravenea: a benchmark for multimodal retrieval-augmented visual culture understanding](https://arxiv.org/abs/2505.14462)|[ravenea](https://github.com/yfyuan01/ravenea)|
|2505.14556|[dynadiff: single-stage decoding of images from continuously evolving fmri](https://arxiv.org/abs/2505.14556)|[dynadiff](https://github.com/facebookresearch/dynadiff)|
|2505.14629|[kerl: knowledge-enhanced personalized recipe recommendation using large language models](https://arxiv.org/abs/2505.14629)|[kerl](https://github.com/mohbattharani/kerl)|
|2505.14633|[will ai tell lies to save sick children? litmus-testing ai values prioritization with airiskdilemmas](https://arxiv.org/abs/2505.14633)|[litmusvalues](https://github.com/kellycyy/litmusvalues)|
|2505.14638|[dual precision quantization for efficient and accurate deep neural networks inference](https://arxiv.org/abs/2505.14638)|[neural-compressor](https://github.com/intel/neural-compressor)|
|2505.14646|[cad-coder: an open-source vision-language model for computer-aided design code generation](https://arxiv.org/abs/2505.14646)|[cad-coder](https://github.com/anniedoris/cad-coder)|
|2505.14664|[akrmap: adaptive kernel regression for trustworthy visualization of cross-modal embeddings](https://arxiv.org/abs/2505.14664)|[akrmap](https://github.com/yilinye/akrmap)|
|2505.14687|[grouping first, attending smartly: training-free acceleration for diffusion transformers](https://arxiv.org/abs/2505.14687)|[grat](https://github.com/oliverrensu/grat)|
|2505.01000|[togedule: scheduling meetings with large language models and adaptive representations of group availability](https://arxiv.org/abs/2505.01000)|[togedule](https://github.com/jyoonsong/togedule)|
|2505.01212|[high dynamic range novel view synthesis with single exposure](https://arxiv.org/abs/2505.01212)|[mono-hdr-3d](https://github.com/prinasi/mono-hdr-3d)|
|2505.02831|[no other representation component is needed: diffusion transformers can provide representation guidance by themselves](https://arxiv.org/abs/2505.02831)|[sra](https://github.com/vvvvvjdy/sra)|
|2505.03654|[regrap-llava: reasoning enabled graph-based personalized large language and vision assistant](https://arxiv.org/abs/2505.03654)|[regrap](https://github.com/xyfyyds/regrap)|
|2505.05022|[soap: style-omniscient animatable portraits](https://arxiv.org/abs/2505.05022)|[soap](https://github.com/tingtingliao/soap)|
|2505.05621|[a preliminary study for gpt-4o on image restoration](https://arxiv.org/abs/2505.05621)|[gpt_restoration](https://github.com/noxsine/gpt_restoration)|
|2505.05657|[arraydps: unsupervised blind speech separation with a diffusion prior](https://arxiv.org/abs/2505.05657)|[arraydps](https://github.com/arraydps/arraydps)|
|2505.05678|[instancegen: image generation with instance-level instructions](https://arxiv.org/abs/2505.05678)|[SLD](https://github.com/tsunghan-wu/SLD)|
|2505.05834|[dual-level fuzzy learning with patch guidance for image ordinal regression](https://arxiv.org/abs/2505.05834)|[dfpg-ord](https://github.com/zjumai/dfpg-ord)|
|2505.08586|[preprompt: predictive prompting for class incremental learning](https://arxiv.org/abs/2505.08586)|[PrePrompt](https://github.com/libo-huang/PrePrompt)|
|2505.09926|[adaptclip: adapting clip for universal visual anomaly detection](https://arxiv.org/abs/2505.09926)|[AdaptCLIP](https://github.com/gaobb/AdaptCLIP)|
|2505.11032|[dexgarmentlab: dexterous garment manipulation environment with generalizable policy](https://arxiv.org/abs/2505.11032)|[dexgarmentlab](https://github.com/wayrise/dexgarmentlab)|
|2505.11538|[brainnetmlp: an efficient and effective baseline for functional brain network classification](https://arxiv.org/abs/2505.11538)|[brainnetmlp](https://github.com/jayceonho/brainnetmlp)|
|2505.11581|[questioning representational optimism in deep learning: the fractured entangled representation hypothesis](https://arxiv.org/abs/2505.11581)|[fer](https://github.com/akarshkumar0101/fer)|
|2505.11594|[sageattention3: microscaling fp4 attention for inference and an exploration of 8-bit training](https://arxiv.org/abs/2505.11594)|[SageAttention](https://github.com/thu-ml/SageAttention)|
|2505.11612|[heart2mind: human-centered contestable psychiatric disorder diagnosis system using wearable ecg monitors](https://arxiv.org/abs/2505.11612)|[heart2mind](https://github.com/analytics-everywhere-lab/heart2mind)|
|2505.11703|[loft: lora-fused training dataset generation with few-shot guidance](https://arxiv.org/abs/2505.11703)|[loft](https://github.com/explainableml/loft)|
|2505.11720|[ugodit: unsupervised group deep image prior via transferable weights](https://arxiv.org/abs/2505.11720)|[ugodit](https://github.com/sjames40/ugodit)|
|2505.11797|[medvkan: efficient feature extraction with mamba and kan for medical image segmentation](https://arxiv.org/abs/2505.11797)|[medvkan](https://github.com/beginner-cjh/medvkan)|
|2505.11800|[self-learning hyperspectral and multispectral image fusion via adaptive residual guided subspace diffusion model](https://arxiv.org/abs/2505.11800)|[args-diff](https://github.com/zhu1116/args-diff)|
|2505.11838|[rvtbench: a benchmark for visual reasoning tasks](https://arxiv.org/abs/2505.11838)|[rvt](https://github.com/yiqings/rvt)|
|2505.11842|[video-safetybench: a benchmark for safety evaluation of video lvlms](https://arxiv.org/abs/2505.11842)|[video-safetybench](https://github.com/flageval-baai/video-safetybench)|
|2505.11882|[genzsl: generative zero-shot learning via inductive variational autoencoder](https://arxiv.org/abs/2505.11882)|[genzsl](https://github.com/shiming-chen/genzsl)|
|2505.11909|[bridging the inter-domain gap through low-level features for cross-modal medical image segmentation](https://arxiv.org/abs/2505.11909)|[lowbridge](https://github.com/joshualpf/lowbridge)|
|2505.11913|[joint manifold learning and optimal transport for dynamic imaging](https://arxiv.org/abs/2505.11913)|[joint-manifold-learning-and-ot](https://github.com/SCdummer/joint-manifold-learning-and-ot)|
|2505.12021|[cross-model transfer of task vectors via few-shot orthogonal alignment](https://arxiv.org/abs/2505.12021)|[crossmodeltransfer](https://github.com/kawakera-lab/crossmodeltransfer)|
|2505.12051|[enhanced multimodal hate video detection via channel-wise and modality-wise fusion](https://arxiv.org/abs/2505.12051)|[cmfusion](https://github.com/evelynz10/cmfusion)|
|2505.12066|[beluga whale detection from satellite imagery with point labels](https://arxiv.org/abs/2505.12066)|[beluga-seeker](https://github.com/voyagerxvoyagerx/beluga-seeker)|
|2505.12098|[love: benchmarking and evaluating text-to-video generation and video-to-text interpretation](https://arxiv.org/abs/2505.12098)|[love](https://github.com/intmegroup/love)|
|2505.12120|[histai: an open-source, large-scale whole slide image dataset for computational pathology](https://arxiv.org/abs/2505.12120)|[histai](https://github.com/histai/histai)|
|2505.12155|[softpq: robust instance segmentation evaluation via soft matching and tunable thresholds](https://arxiv.org/abs/2505.12155)|[SoftPQ](https://github.com/rkarmaka/SoftPQ)|
|2505.12191|[ditch the denoiser: emergence of noise robustness in self-supervised learning from data curriculum](https://arxiv.org/abs/2505.12191)|[noisy_dinov2](https://github.com/wenquanlu/noisy_dinov2)|
|2505.12199|[always clear depth: robust monocular depth estimation under adverse weather](https://arxiv.org/abs/2505.12199)|[acdepth](https://github.com/msscao/acdepth)|
|2505.12217|[hyperspectral image land cover captioning dataset for vision language models](https://arxiv.org/abs/2505.12217)|[hypercap](https://github.com/arya-domain/hypercap)|
|2505.12261|[openpros: a large-scale dataset for limited view prostate ultrasound computed tomography](https://arxiv.org/abs/2505.12261)|[openpros](https://github.com/hanchenwang/openpros)|
|2505.12266|[pmq-ve: progressive multi-frame quantization for video enhancement](https://arxiv.org/abs/2505.12266)|[pmq-ve](https://github.com/xiaobigfeng/pmq-ve)|
|2505.12267|[real-time spatial reasoning by mobile robots for reconstruction and navigation in dynamic lidar scenes](https://arxiv.org/abs/2505.12267)|[RTRecon](https://github.com/SZU-VCC/RTRecon)|
|2505.12280|[temporal-spectral-spatial unified remote sensing dense prediction](https://arxiv.org/abs/2505.12280)|[official_tssun](https://github.com/walking-shadow/official_tssun)|
|2505.12307|[logicocr: do your large multimodal models excel at logical reasoning on text-rich images?](https://arxiv.org/abs/2505.12307)|[logicocr](https://github.com/mililab/logicocr)|
|2505.12335|[is artificial intelligence generated image detection a solved problem?](https://arxiv.org/abs/2505.12335)|[aigibench](https://github.com/horizontel/aigibench)|
|2505.12363|[towards visuospatial cognition via hierarchical fusion of visual experts](https://arxiv.org/abs/2505.12363)|[vica](https://github.com/nkkbr/vica)|
|2505.12432|[observe-r1: unlocking reasoning abilities of mllms with dynamic progressive reinforcement learning](https://arxiv.org/abs/2505.12432)|[observe-r1](https://github.com/zrguo/observe-r1)|
|2505.12434|[videorft: incentivizing video reasoning capability in mllms via reinforced fine-tuning](https://arxiv.org/abs/2505.12434)|[videorft](https://github.com/qiwang98/videorft)|
|2505.12513|[globalgeotree: a multi-granular vision-language dataset for global tree species classification](https://arxiv.org/abs/2505.12513)|[globalgeotree](https://github.com/muyang99/globalgeotree)|
|2505.12532|[exploring sparsity for parameter efficient fine tuning using wavelets](https://arxiv.org/abs/2505.12532)|[sparse_peft](https://github.com/bilican/sparse_peft)|
|2505.12547|[promi: an efficient prototype-mixture baseline for few-shot segmentation with bounding-box annotations](https://arxiv.org/abs/2505.12547)|[promi](https://github.com/thalesgroup/promi)|
|2505.12630|[degradation-aware feature perturbation for all-in-one image restoration](https://arxiv.org/abs/2505.12630)|[dfpir](https://github.com/txphome/dfpir)|
|2505.12631|[multi-resolution haar network: enhancing human motion prediction via haar transform](https://arxiv.org/abs/2505.12631)|[haarmodic](https://github.com/xhaughearl/haarmodic)|
|2505.12650|[automat: enabling automated crystal structure reconstruction from microscopy via agentic tool use](https://arxiv.org/abs/2505.12650)|[automat](https://github.com/yyt-2378/automat)|
|2505.12669|[text2midi-inferalign: improving symbolic music generation with inference-time alignment](https://arxiv.org/abs/2505.12669)|[t2m-inferalign](https://github.com/amaai-lab/t2m-inferalign)|
|2505.12674|[few-step diffusion via score identity distillation](https://arxiv.org/abs/2505.12674)|[sid-lsg](https://github.com/mingyuanzhou/sid-lsg)|
|2505.12718|[automated bias assessment in ai-generated educational content using ceat framework](https://arxiv.org/abs/2505.12718)|[Automated-Word-Extraction](https://github.com/EricP66/Automated-Word-Extraction)|
|2505.12742|[mvar: visual autoregressive modeling with scale and spatial markovian conditioning](https://arxiv.org/abs/2505.12742)|[mvar](https://github.com/labshuhanggu/mvar)|
|2505.12766|[reasoning-ocr: can large multimodal models solve complex logical reasoning problems from ocr cues?](https://arxiv.org/abs/2505.12766)|[reasoningocr](https://github.com/hxyz-123/reasoningocr)|
|2505.12820|[rethinking features-fused-pyramid-neck for object detection](https://arxiv.org/abs/2505.12820)|[rethinking-fpn](https://github.com/alanli1997/rethinking-fpn)|
|2505.12834|[a study on the refining handwritten font by mixing font styles](https://arxiv.org/abs/2505.12834)|[FontFusionGAN](https://github.com/KumarAvinash44/FontFusionGAN)|
|2505.12835|[flightgpt: towards generalizable and interpretable uav vision-and-language navigation with vision-language models](https://arxiv.org/abs/2505.12835)|[flightgpt](https://github.com/pendulumclock/flightgpt)|
|2505.12849|[accelerate tarflow sampling with gs-jacobi iteration](https://arxiv.org/abs/2505.12849)|[gs-jacobi_for_tarflow](https://github.com/encoreus/gs-jacobi_for_tarflow)|
|2505.12861|[robust multimodal segmentation with representation regularization and hybrid prototype distillation](https://arxiv.org/abs/2505.12861)|[robustseg](https://github.com/robustseg/robustseg)|
|2505.12897|[epic: explanation of pretrained image classification networks via prototype](https://arxiv.org/abs/2505.12897)|[epic](https://github.com/piotr310100/epic)|
|2505.12903|[towards low-latency event stream-based visual object tracking: a slow-fast approach](https://arxiv.org/abs/2505.12903)|[slowfast_event_track](https://github.com/event-ahu/slowfast_event_track)|
|2505.12908|[dynamic graph induced contour-aware heat conduction network for event-based object detection](https://arxiv.org/abs/2505.12908)|[openevdet](https://github.com/event-ahu/openevdet)|
|2505.12911|[hiero: understanding the hierarchy of human behavior enhances reasoning on egocentric videos](https://arxiv.org/abs/2505.12911)|[hiero](https://github.com/sapeirone/hiero)|
|2505.12912|[uniformity first: uniformity-aware test-time adaptation of vision-language models against image corruption](https://arxiv.org/abs/2505.12912)|[uninfo](https://github.com/kzkadc/uninfo)|
|2505.12944|[calm-pde: continuous and adaptive convolutions for latent space modeling of time-dependent pdes](https://arxiv.org/abs/2505.12944)|[calm-pde](https://github.com/jhagnberger/calm-pde)|
|2505.12998|[a skull-adaptive framework for ai-based 3d transcranial focused ultrasound simulation](https://arxiv.org/abs/2505.12998)|[tfuscapes](https://github.com/camma-public/tfuscapes)|
|2505.12999|[a generalisable head mri defacing pipeline: evaluation on 2,566 meningioma scans](https://arxiv.org/abs/2505.12999)|[defacing_pipeline](https://github.com/cai4cai/defacing_pipeline)|
|2505.13010|[to bias or not to bias: detecting bias in news with bias-detector](https://arxiv.org/abs/2505.13010)|[newsbiasdetector](https://github.com/himel1996/newsbiasdetector)|
|2505.13032|[mmar: a challenging benchmark for deep reasoning in speech, audio, music, and their mix](https://arxiv.org/abs/2505.13032)|[mmar](https://github.com/ddlbojack/mmar)|
|2505.13088|[cross-modal feature fusion for robust point cloud registration with ambiguous geometry](https://arxiv.org/abs/2505.13088)|[coff](https://github.com/zhaoyiww/coff)|
|2505.13137|[learning to adapt to position bias in vision transformer classifiers](https://arxiv.org/abs/2505.13137)|[position-shap](https://github.com/rjbruin/position-shap)|
|2505.13152|[higher fidelity perceptual image and video compression with a latent conditioned residual denoising diffusion model](https://arxiv.org/abs/2505.13152)|[rescdc](https://github.com/jbrenig/rescdc)|
|2505.13201|[matpredict: a dataset and benchmark for learning material properties of diverse indoor objects](https://arxiv.org/abs/2505.13201)|[matpredict](https://github.com/arpan-kusari/matpredict)|
|2505.13211|[magi-1: autoregressive video generation at scale](https://arxiv.org/abs/2505.13211)|[magiattention](https://github.com/sandai-org/magiattention)|
|2505.13215|[hybrid 3d-4d gaussian splatting for fast dynamic scene representation](https://arxiv.org/abs/2505.13215)|[3D-4DGS](https://github.com/ohsngjun/3D-4DGS)|
|2505.13218|[human response to decision support in face matching: the influence of task difficulty and machine accuracy](https://arxiv.org/abs/2505.13218)|[humanresponse-dss-facematching](https://github.com/ealmenzar/humanresponse-dss-facematching)|
|2505.13233|[from local details to global context: advancing vision-language models with attention-based selection](https://arxiv.org/abs/2505.13233)|[abs](https://github.com/bit-da/abs)|
|2505.13235|[writevit: handwritten text generation with vision transformer](https://arxiv.org/abs/2505.13235)|[writevit](https://github.com/hnam-1765/writevit)|
|2505.13307|[rbf++: quantifying and optimizing reasoning boundaries across measurable and unmeasurable capabilities for chain-of-thought reasoning](https://arxiv.org/abs/2505.13307)|[reasoning-boundary](https://github.com/lightchen233/reasoning-boundary)|
|2505.13316|[denoising diffusion probabilistic model for point cloud compression at low bit-rates](https://arxiv.org/abs/2505.13316)|[ddpm-pcc](https://github.com/eidoslab/ddpm-pcc)|
|2505.13390|[mgpbd: a multigrid accelerated global xpbd solver](https://arxiv.org/abs/2505.13390)|[mgpbd](https://github.com/chunleili/mgpbd)|
|2505.13419|[feallm: advancing facial emotion analysis in multimodal large language models with emotional synergy and reasoning](https://arxiv.org/abs/2505.13419)|[feallm](https://github.com/953206211/feallm)|
|2505.13426|[g1: bootstrapping perception and reasoning abilities of vision-language model via reinforcement learning](https://arxiv.org/abs/2505.13426)|[g1](https://github.com/chenllliang/g1)|
|2505.13427|[mm-prm: enhancing multimodal mathematical reasoning with scalable step-level supervision](https://arxiv.org/abs/2505.13427)|[mm-prm](https://github.com/modalminds/mm-prm)|
|2505.13439|[vtbench: evaluating visual tokenizers for autoregressive image generation](https://arxiv.org/abs/2505.13439)|[VTBench](https://github.com/huawei-lin/VTBench)|
|2505.13440|[recollection from pensieve: novel view synthesis via learning from uncalibrated videos](https://arxiv.org/abs/2505.13440)|[pensieve](https://github.com/dwawayu/pensieve)|


## Archives
- [May 2025](archives/2025/05.md)
- [April 2025](archives/2025/04.md)
