# Daily ArXiv HCI

A curated collection of arXiv papers with open-source implementations, specifically focusing on Human-Computer Interaction (cs.HC) and related fields like Computer Graphics (cs.GR), Computer Vision (cs.CV), etc. This repository aims to serve researchers and practitioners in HCI by providing easy access to papers that come with their source code implementations.

## Overview
This project automatically tracks and analyzes papers from relevant HCI categories on arXiv daily using GitHub Actions. It specifically identifies and catalogs papers that have released their source code, making it easier for researchers in HCI and related areas to find implementable research work.

The main features include:
- Daily updates of papers with open-source implementations
- Focus on Human-Computer Interaction and related research
- Automatic tracking and organization

## Latest Updates 
|date|paper|code|
|---|---|---|
|2506.01923|[taxadiffusion: progressively trained diffusion model for fine-grained species generation](https://arxiv.org/abs/2506.01923)|[TaxaDiffusion](https://github.com/aminK8/TaxaDiffusion)|
|2506.07977|[oneig-bench: omni-dimensional nuanced evaluation for image generation](https://arxiv.org/abs/2506.07977)|[oneig-benchmark](https://github.com/oneig-bench/oneig-benchmark)|
|2506.16398|[hyperpath: knowledge-guided hyperbolic semantic hierarchy modeling for wsi analysis](https://arxiv.org/abs/2506.16398)|[hyperpath](https://github.com/lambert-hpx/hyperpath)|
|2506.18575|[2d triangle splatting for direct differentiable mesh training](https://arxiv.org/abs/2506.18575)|[triangle-splatting](https://github.com/GaodeRender/triangle-splatting)|
|2506.20152|[loss-aware automatic selection of structured pruning criteria for deep neural network acceleration](https://arxiv.org/abs/2506.20152)|[laasp](https://github.com/ghimiredhikura/laasp)|
|2506.20355|[practical insights on the effect of different encodings, ans√§tze and measurements in quantum and hybrid convolutional neural networks](https://arxiv.org/abs/2506.20355)|[QML-Satellite-Image-Classification](https://github.com/uriballo/QML-Satellite-Image-Classification)|
|2506.05199|[grounding beyond detection: enhancing contextual understanding in embodied 3d grounding](https://arxiv.org/abs/2506.05199)|[deground](https://github.com/zyn213/deground)|
|2506.09399|[improving out-of-distribution detection via dynamic covariance calibration](https://arxiv.org/abs/2506.09399)|[ooddcc](https://github.com/workerbcd/ooddcc)|
|2506.12006|[crossmoda challenge: evolution of cross-modality domain adaptation techniques for vestibular schwannoma and cochlea segmentation from 2021 to 2023](https://arxiv.org/abs/2506.12006)|[cmda2022.superpolymerization](https://github.com/fiy2w/cmda2022.superpolymerization)|
|2506.15201|[privacy-shielded image compression: defending against exploitation from vision-language pretrained models](https://arxiv.org/abs/2506.15201)|[psic](https://github.com/jiayinxu5499/psic)|
|2506.17885|[cloud-aware sar fusion for enhanced optical sensing in space missions](https://arxiv.org/abs/2506.17885)|[Cloud-Removal](https://github.com/thoailt/Cloud-Removal)|
|2506.18335|[rethinking decoder design: improving biomarker segmentation using depth-to-space restoration and residual linear attention](https://arxiv.org/abs/2506.18335)|[mcads-decoder](https://github.com/saadwazir/mcads-decoder)|
|2506.18810|[concisehint: boosting efficient reasoning via continuous concise hints during generation](https://arxiv.org/abs/2506.18810)|[ConciseHint](https://github.com/tsa18/ConciseHint)|
|2506.11142|[farcluss: fuzzy adaptive rebalancing and contrastive uncertainty learning for semi-supervised semantic segmentation](https://arxiv.org/abs/2506.11142)|[FARCLUSS](https://github.com/psychofict/FARCLUSS)|
|2506.12524|[inference-time gaze refinement for micro-expression recognition: enhancing event-based eye tracking with motion-aware post-processing](https://arxiv.org/abs/2506.12524)|[eyelorin](https://github.com/eye-tracking-for-physiological-sensing/eyelorin)|
|2506.13642|[stream-omni: simultaneous multimodal interactions with large language-vision-speech model](https://arxiv.org/abs/2506.13642)|[stream-omni](https://github.com/ictnlp/stream-omni)|
|2506.15698|[global context-aware representation learning for spatially resolved transcriptomics](https://arxiv.org/abs/2506.15698)|[spotscape](https://github.com/yunhak0/spotscape)|
|2506.16262|[r3evision: a survey on robust rendering, restoration, and enhancement for 3d low-level vision](https://arxiv.org/abs/2506.16262)|[awesome-3d-low-level-vision](https://github.com/cmlab-korea/awesome-3d-low-level-vision)|
|2506.16318|[segment anything for satellite imagery: a strong baseline and a regional dataset for automatic field delineation](https://arxiv.org/abs/2506.16318)|[eras-dataset](https://github.com/cscribano/eras-dataset)|
|2506.16784|[textbrats: text-guided volumetric brain tumor segmentation with innovative dataset development and fusion module exploration](https://arxiv.org/abs/2506.16784)|[textbrats](https://github.com/jupitern52/textbrats)|
|2506.16796|[realsr-r1: reinforcement learning for real-world image super-resolution with vision-language chain-of-thought](https://arxiv.org/abs/2506.16796)|[realsr-r1](https://github.com/junboooo/realsr-r1)|
|2506.17101|[multi-label scene classification for autonomous vehicles: acquiring and accumulating knowledge from diverse datasets](https://arxiv.org/abs/2506.17101)|[kaa-cal](https://github.com/kelisbu/kaa-cal)|
|2506.17220|[emergent temporal correspondences from video diffusion transformers](https://arxiv.org/abs/2506.17220)|[DiffTrack](https://github.com/cvlab-kaist/DiffTrack)|
|2506.01444|[variance-based defense against blended backdoor attacks](https://arxiv.org/abs/2506.01444)|[BackdoorBench](https://github.com/Orange-OpenSource/BackdoorBench)|
|2506.06561|[lamp-cap: personalized figure caption generation with multimodal figure profiles](https://arxiv.org/abs/2506.06561)|[lamp-cap](https://github.com/crowd-ai-lab/lamp-cap)|
|2506.09965|[reinforcing spatial reasoning in vision-language models with interwoven thinking and visual drawing](https://arxiv.org/abs/2506.09965)|[vilasr](https://github.com/antresearchnlp/vilasr)|
|2506.10730|[iqe-clip: instance-aware query embedding for zero-/few-shot anomaly detection in medical domain](https://arxiv.org/abs/2506.10730)|[iqe-clip](https://github.com/hongh0/iqe-clip)|
|2506.11140|[autonomous computer vision development with agentic ai](https://arxiv.org/abs/2506.11140)|[OpenManus-SimpleMind](https://github.com/jink-ucla/OpenManus-SimpleMind)|
|2506.11302|[tardis stride: a spatio-temporal road image dataset and world model for autonomy](https://arxiv.org/abs/2506.11302)|[tardis](https://github.com/tera-ai/tardis)|
|2506.12400|[perceptual-gs: scene-adaptive perceptual densification for gaussian splatting](https://arxiv.org/abs/2506.12400)|[perceptual-gs](https://github.com/eezkni/perceptual-gs)|
|2506.13045|[a comprehensive survey on continual learning in generative models](https://arxiv.org/abs/2506.13045)|[awesome-continual-learning-in-generative-models](https://github.com/ghy0501/awesome-continual-learning-in-generative-models)|
|2506.14243|[cross-modal geometric hierarchy fusion: an implicit-submap driven framework for resilient 3d place recognition](https://arxiv.org/abs/2506.14243)|[CMGHF](https://github.com/HBLT-hub/CMGHF)|
|2506.14777|[webxaii: an open-source web framework to study human-xai interaction](https://arxiv.org/abs/2506.14777)|[webxaii](https://github.com/pajean/webxaii)|
|2506.15258|[privacy-preserving chest x-ray classification in latent space with homomorphically encrypted neural inference](https://arxiv.org/abs/2506.15258)|[latent-he](https://github.com/jongdory/latent-he)|
|2506.15564|[show-o2: improved native unified multimodal models](https://arxiv.org/abs/2506.15564)|[show-o](https://github.com/showlab/show-o)|
|2506.15591|[one-step diffusion for detail-rich and temporally consistent video super-resolution](https://arxiv.org/abs/2506.15591)|[dloral](https://github.com/yjsunnn/dloral)|
|2506.15711|[shadow defense against gradient inversion attack in federated learning](https://arxiv.org/abs/2506.15711)|[ShadowDef](https://github.com/tekap404/ShadowDef)|
|2506.15860|[user-guided force-directed graph layout](https://arxiv.org/abs/2506.15860)|[uggly](https://github.com/sciluna/uggly)|
|2506.15940|[polyline path masked attention for vision transformer](https://arxiv.org/abs/2506.15940)|[ppma](https://github.com/zhongchenzhao/ppma)|
|2506.15980|[advanced sign language video generation with compressed and quantized multi-condition tokenization](https://arxiv.org/abs/2506.15980)|[signvip](https://github.com/umnooob/signvip)|
|2506.15988|[adversarial attacks and detection in visual place recognition for safer robot navigation](https://arxiv.org/abs/2506.15988)|[aarapsiproject](https://github.com/QVPR/aarapsiproject)|
|2506.16017|[endomust: monocular depth estimation for robotic endoscopy via end-to-end multi-step self-supervised training](https://arxiv.org/abs/2506.16017)|[endomust](https://github.com/baymaxshao/endomust)|
|2506.16073|[td3net: a temporal densely connected multi-dilated convolutional network for lipreading](https://arxiv.org/abs/2506.16073)|[td3net-a-temporal-densely-connected-multi-dilated-convolutional-network-for-lipreading](https://github.com/leebh-kor/td3net-a-temporal-densely-connected-multi-dilated-convolutional-network-for-lipreading)|
|2506.16141|[grpo-care: consistency-aware reinforcement learning for multimodal reasoning](https://arxiv.org/abs/2506.16141)|[grpo-care](https://github.com/tencentarc/grpo-care)|
|2506.16209|[videogan-based trajectory proposal for automated vehicles](https://arxiv.org/abs/2506.16209)|[video-gan-trajectories](https://github.com/ajmariani/video-gan-trajectories)|
|2506.16265|[dense 3d displacement estimation for landslide monitoring via fusion of tls point clouds and embedded rgb images](https://arxiv.org/abs/2506.16265)|[fusion4landslide](https://github.com/zhaoyiww/fusion4landslide)|
|2506.16349|[watermarking autoregressive image generation](https://arxiv.org/abs/2506.16349)|[wmar](https://github.com/facebookresearch/wmar)|
|2506.16353|[mambahash: visual state space deep hashing model for large-scale image retrieval](https://arxiv.org/abs/2506.16353)|[mambahash](https://github.com/shuaichaochao/mambahash)|
|2506.16371|[agc-drive: a large-scale dataset for real-world aerial-ground collaboration in driving scenarios](https://arxiv.org/abs/2506.16371)|[agc-drive](https://github.com/percepx/agc-drive)|
|2506.16401|[trajscenellm: a multimodal perspective on semantic gps trajectory analysis](https://arxiv.org/abs/2506.16401)|[trajscenellm](https://github.com/februarysea/trajscenellm)|
|2506.16504|[hunyuan3d 2.5: towards high-fidelity 3d assets generation with ultimate details](https://arxiv.org/abs/2506.16504)|[hunyuan3d-2](https://github.com/tencent/hunyuan3d-2)|
|2506.16572|[diffo: single-step diffusion for image compression at ultra-low bitrates](https://arxiv.org/abs/2506.16572)|[diffo](https://github.com/freemasti/diffo)|
|2506.16643|[see what i mean? expressiveness and clarity in robot display design](https://arxiv.org/abs/2506.16643)|[huamn_cozmo_interaction](https://github.com/mattufts/huamn_cozmo_interaction)|
|2506.16728|[few-shot generalized category discovery with retrieval-guided decision boundary enhancement](https://arxiv.org/abs/2506.16728)|[fsgcd](https://github.com/ryh1218/fsgcd)|
|2506.16743|[noise-informed diffusion-generated image detection with anomaly attention](https://arxiv.org/abs/2506.16743)|[nasa-swin](https://github.com/weinanguan/nasa-swin)|
|2506.16819|[loupe: a generalizable and adaptive framework for image forgery detection](https://arxiv.org/abs/2506.16819)|[loupe](https://github.com/kamichanw/loupe)|
|2506.16842|[camera calibration via circular patterns: a comprehensive framework with measurement uncertainty and unbiased projection model](https://arxiv.org/abs/2506.16842)|[discocal](https://github.com/chaehyeonsong/discocal)|
|2506.16856|[parkformer: a transformer-based parking policy with goal embedding and pedestrian-aware control](https://arxiv.org/abs/2506.16856)|[parkformer](https://github.com/little-snail-f/parkformer)|
|2506.16940|[lunarloc: segment-based global localization on the moon](https://arxiv.org/abs/2506.16940)|[lunarloc-data](https://github.com/mit-acl/lunarloc-data)|
|2506.16960|[visual-instructed degradation diffusion for all-in-one image restoration](https://arxiv.org/abs/2506.16960)|[defusion](https://github.com/luowyang/defusion)|
|2506.16962|[enhancing step-by-step and verifiable medical reasoning in mllms](https://arxiv.org/abs/2506.16962)|[chiron-o1](https://github.com/manglu097/chiron-o1)|
|2506.17113|[mexa: towards general multimodal reasoning with dynamic multi-expert aggregation](https://arxiv.org/abs/2506.17113)|[mexa](https://github.com/yui010206/mexa)|
|2506.17119|[rgbtrack: fast, robust depth-free 6d pose estimation and tracking](https://arxiv.org/abs/2506.17119)|[rgbtrack](https://github.com/greatenanoymous/rgbtrack)|
|2506.17159|[co-seg++: mutual prompt-guided collaborative learning for versatile medical segmentation](https://arxiv.org/abs/2506.17159)|[co-seg-plus](https://github.com/xq141839/co-seg-plus)|
|2506.17186|[yasmot: yet another stereo image multi-object tracker](https://arxiv.org/abs/2506.17186)|[yasmot](https://github.com/ketil-malde/yasmot)|
|2506.17196|[detecting llm-generated short answers and effects on learner performance](https://arxiv.org/abs/2506.17196)|[ai-detection](https://github.com/shambhavib20/ai-detection)|
|2506.17202|[unifork: exploring modality alignment for unified multimodal understanding and generation](https://arxiv.org/abs/2506.17202)|[unifork](https://github.com/tliby/unifork)|
|2506.17213|[long-term traffic simulation with interleaved autoregressive motion and scenario generation](https://arxiv.org/abs/2506.17213)|[infgen](https://github.com/orangesodahub/infgen)|
|2506.17218|[machine mental imagery: empower multimodal reasoning with latent visual tokens](https://arxiv.org/abs/2506.17218)|[mirage](https://github.com/umass-embodied-agi/mirage)|


## Archives
- [June 2025](archives/2025/06.md)
- [May 2025](archives/2025/05.md)
- [April 2025](archives/2025/04.md)
