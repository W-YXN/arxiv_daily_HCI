# Daily ArXiv HCI

A curated collection of arXiv papers with open-source implementations, specifically focusing on Human-Computer Interaction (cs.HC) and related fields like Computer Graphics (cs.GR), Computer Vision (cs.CV), etc. This repository aims to serve researchers and practitioners in HCI by providing easy access to papers that come with their source code implementations.

## Overview
This project automatically tracks and analyzes papers from relevant HCI categories on arXiv daily using GitHub Actions. It specifically identifies and catalogs papers that have released their source code, making it easier for researchers in HCI and related areas to find implementable research work.

The main features include:
- Daily updates of papers with open-source implementations
- Focus on Human-Computer Interaction and related research
- Automatic tracking and organization

## Latest Updates 
|date|paper|code|
|---|---|---|
|2506.00073|[the automated but risky game: modeling agent-to-agent negotiations and transactions in consumer markets](https://arxiv.org/abs/2506.00073)|[A2A-NT](https://github.com/ShenzheZhu/A2A-NT)|
|2506.08011|[play to generalize: learning to reason through game play](https://arxiv.org/abs/2506.08011)|[vigal](https://github.com/yunfeixie233/vigal)|
|2506.08735|[inceptionmamba: an efficient hybrid network with large band convolution and bottleneck mamba](https://arxiv.org/abs/2506.08735)|[inceptionmamba](https://github.com/wake1021/inceptionmamba)|
|2506.09042|[cosmos-drive-dreams: scalable synthetic driving data generation with world foundation models](https://arxiv.org/abs/2506.09042)|[cosmos-drive-dreams](https://github.com/nv-tlabs/cosmos-drive-dreams)|
|2506.09476|[urban1960satseg: unsupervised semantic segmentation of mid-20$^{th}$ century urban landscapes with satellite imageries](https://arxiv.org/abs/2506.09476)|[urban1960satseg](https://github.com/tianxiang-hao/urban1960satseg)|
|2506.10009|[the iris file extension](https://arxiv.org/abs/2506.10009)|[iris-codec](https://github.com/irisdigitalpathology/iris-codec)|
|2506.10150|[when large language models are reliable for judging empathic communication](https://arxiv.org/abs/2506.10150)|[replication-data-and-code-when-LLMs-reliable-empathic-communication](https://github.com/aakriti1kumar/replication-data-and-code-when-LLMs-reliable-empathic-communication)|
|2506.10452|[towards robust multimodal emotion recognition under missing modalities and distribution shifts](https://arxiv.org/abs/2506.10452)|[cider](https://github.com/gw-zhong/cider)|
|2506.03662|[zero-shot temporal interaction localization for egocentric videos](https://arxiv.org/abs/2506.03662)|[egoloc](https://github.com/irmvlab/egoloc)|
|2506.07986|[rethinking cross-modal interaction in multimodal diffusion transformers](https://arxiv.org/abs/2506.07986)|[taca](https://github.com/vchitect/taca)|
|2506.08010|[vision transformers don't need trained registers](https://arxiv.org/abs/2506.08010)|[test-time-registers](https://github.com/nickjiang2378/test-time-registers)|
|2506.08849|[adapting vision-language foundation model for next generation medical ultrasound image analysis](https://arxiv.org/abs/2506.08849)|[nextgen-uia](https://github.com/jinggqu/nextgen-uia)|
|2506.08900|[mirage: multimodal foundation model and benchmark for comprehensive retinal oct image analysis](https://arxiv.org/abs/2506.08900)|[mirage](https://github.com/j-morano/mirage)|
|2506.08908|[skipvar: accelerating visual autoregressive modeling via adaptive frequency-aware skipping](https://arxiv.org/abs/2506.08908)|[skipvar](https://github.com/fakerone-li/skipvar)|
|2506.09022|[do multiple instance learning models transfer?](https://arxiv.org/abs/2506.09022)|[mil-lab](https://github.com/mahmoodlab/mil-lab)|
|2506.09217|[perception characteristics distance: measuring stability and robustness of perception system in dynamic conditions under a certain decision rule](https://arxiv.org/abs/2506.09217)|[pcd_python](https://github.com/datadrivenwheels/pcd_python)|
|2506.09237|[patchguard: adversarially robust anomaly detection and localization through vision transformers and pseudo anomalies](https://arxiv.org/abs/2506.09237)|[patchgaurd](https://github.com/rohban-lab/patchgaurd)|
|2506.09344|[ming-omni: a unified multimodal model for perception and generation](https://arxiv.org/abs/2506.09344)|[ming](https://github.com/inclusionai/ming)|
|2506.09353|[davsp: safety alignment for large vision-language models via deep aligned visual safety prompt](https://arxiv.org/abs/2506.09353)|[davsp](https://github.com/zhangyitonggg/davsp)|
|2506.09369|[scalelsd: scalable deep line segment detection streamlined](https://arxiv.org/abs/2506.09369)|[scalelsd](https://github.com/ant-research/scalelsd)|
|2506.09403|[srpl-sfda: sam-guided reliable pseudo-labels for source-free domain adaptation in medical image segmentation](https://arxiv.org/abs/2506.09403)|[srpl-sfda](https://github.com/hilab-git/srpl-sfda)|
|2506.09416|[noise conditional variational score distillation](https://arxiv.org/abs/2506.09416)|[ncvsd](https://github.com/xypeng9903/ncvsd)|
|2506.09420|[a call for collaborative intelligence: why human-agent systems should precede ai autonomy](https://arxiv.org/abs/2506.09420)|[awesome-llm-based-human-agent-systems](https://github.com/henrypengzou/awesome-llm-based-human-agent-systems)|
|2506.09522|[revisit what you see: disclose language prior in vision tokens for efficient guided decoding of lvlms](https://arxiv.org/abs/2506.09522)|[ReVisiT](https://github.com/bscho333/ReVisiT)|
|2506.09626|[ecam: a contrastive learning approach to avoid environmental collision in trajectory forecasting](https://arxiv.org/abs/2506.09626)|[ecam](https://github.com/cvml-cfu/ecam)|
|2506.09650|[hopadiff: holistic-partial aware fourier conditioned diffusion for referring human action segmentation in multi-person scenarios](https://arxiv.org/abs/2506.09650)|[hopadiff](https://github.com/kpeng9510/hopadiff)|
|2506.09668|[cinema: conditional implicit neural multi-modal atlas for a spatio-temporal representation of the perinatal brain](https://arxiv.org/abs/2506.09668)|[cinema](https://github.com/m-dannecker/cinema)|
|2506.09691|[adding simple structure at inference improves vision-language compositionality](https://arxiv.org/abs/2506.09691)|[structure-inference-compositionality](https://github.com/imirandam/structure-inference-compositionality)|
|2506.09695|[towards practical alzheimer's disease diagnosis: a lightweight and interpretable spiking neural model](https://arxiv.org/abs/2506.09695)|[fastersnn](https://github.com/wuchangw/fastersnn)|
|2506.09709|[training-free voice conversion with factorized optimal transport](https://arxiv.org/abs/2506.09709)|[mkl-vc](https://github.com/alobashev/mkl-vc)|
|2506.09718|[non-contact health monitoring during daily personal care routines](https://arxiv.org/abs/2506.09718)|[fusionvitals](https://github.com/mcjacktang/fusionvitals)|
|2506.09724|[the four color theorem for cell instance segmentation](https://arxiv.org/abs/2506.09724)|[fcis](https://github.com/zhangye-zoe/fcis)|
|2506.09733|[atmosmj: revisiting gating mechanism for ai weather forecasting beyond the year scale](https://arxiv.org/abs/2506.09733)|[README.md](https://github.com/jmj2316/AtmosMJ/blob/main/README.md)|
|2506.09777|[inverting black-box face recognition systems via zero-order optimization in eigenface space](https://arxiv.org/abs/2506.09777)|[adversarialfaces](https://github.com/fusionbrainlab/adversarialfaces)|
|2506.09790|[comfyui-r1: exploring reasoning models for workflow generation](https://arxiv.org/abs/2506.09790)|[comfyui-copilot](https://github.com/aidc-ai/comfyui-copilot)|
|2506.09849|[intphys 2: benchmarking intuitive physics understanding in complex synthetic environments](https://arxiv.org/abs/2506.09849)|[intphys2](https://github.com/facebookresearch/intphys2)|
|2506.09881|[leveraging depth and language for open-vocabulary domain-generalized semantic segmentation](https://arxiv.org/abs/2506.09881)|[vireo](https://github.com/anonymouse-9c53tp182bvz/vireo)|
|2506.09883|[3d-aware vision-language models fine-tuning with geometric distillation](https://arxiv.org/abs/2506.09883)|[3d-vlm-gd](https://github.com/kaist-cvml/3d-vlm-gd)|
|2506.09895|[equicaps: predictor-free pose-aware pre-trained capsule networks](https://arxiv.org/abs/2506.09895)|[equicaps](https://github.com/aberdeenml/equicaps)|
|2506.09920|[structural-spectral graph convolution with evidential edge learning for hyperspectral image clustering](https://arxiv.org/abs/2506.09920)|[ssgco-egael](https://github.com/jhqi/ssgco-egael)|
|2506.09943|[causalvqa: a physically grounded causal reasoning benchmark for video models](https://arxiv.org/abs/2506.09943)|[causalvqa](https://github.com/facebookresearch/causalvqa)|
|2506.09949|[sampling theory for super-resolution with implicit neural representations](https://arxiv.org/abs/2506.09949)|[super_inrs](https://github.com/gregongie/super_inrs)|
|2506.09953|[outside knowledge conversational video (okcv) dataset -- dialoguing over videos](https://arxiv.org/abs/2506.09953)|[okcv](https://github.com/c-patsch/okcv)|
|2506.09965|[reinforcing spatial reasoning in vision-language models with interwoven thinking and visual drawing](https://arxiv.org/abs/2506.09965)|[vilasr](https://github.com/antresearchnlp/vilasr)|
|2506.09980|[efficient part-level 3d object generation via dual volume packing](https://arxiv.org/abs/2506.09980)|[partpacker](https://github.com/nvlabs/partpacker)|
|2506.09985|[v-jepa 2: self-supervised video models enable understanding, prediction and planning](https://arxiv.org/abs/2506.09985)|[vjepa2](https://github.com/facebookresearch/vjepa2)|
|2506.09989|[hearing hands: generating sounds from physical interactions in 3d scenes](https://arxiv.org/abs/2506.09989)|[hearing_hands](https://github.com/dou-yiming/hearing_hands)|
|2506.05633|[noninvasive precision modulation of high-level neural population activity via natural vision perturbations](https://arxiv.org/abs/2506.05633)|[directionalneuralmodulation](https://github.com/ggaziv/directionalneuralmodulation)|
|2506.07327|[case: contrastive activation for saliency estimation](https://arxiv.org/abs/2506.07327)|[case-saliency](https://github.com/dwil2444/case-saliency)|
|2506.07977|[oneig-bench: omni-dimensional nuanced evaluation for image generation](https://arxiv.org/abs/2506.07977)|[oneig-benchmark](https://github.com/oneig-bench/oneig-benchmark)|
|2506.08071|[cure: cultural gaps in the long tail of text-to-image systems](https://arxiv.org/abs/2506.08071)|[cure-bench](https://github.com/aniketrege/cure-bench)|
|2506.08189|[open world scene graph generation using vision language models](https://arxiv.org/abs/2506.08189)|[pix2grp_cvpr2024](https://github.com/shtuplus/pix2grp_cvpr2024)|
|2506.08280|[snap-and-tune: combining deep learning and test-time optimization for high-fidelity cardiovascular volumetric meshing](https://arxiv.org/abs/2506.08280)|[deep-cardiac-volumetric-mesh](https://github.com/danpak94/deep-cardiac-volumetric-mesh)|
|2506.08299|[openrr-1k: a scalable dataset for real-world reflection removal](https://arxiv.org/abs/2506.08299)|[openrr-1k](https://github.com/caijie0620/openrr-1k)|
|2506.08361|[image demoir\'eing using dual camera fusion on mobile phones](https://arxiv.org/abs/2506.08361)|[dcid](https://github.com/mrduckk/dcid)|
|2506.08391|[second: mitigating perceptual hallucination in vision-language models via selective and contrastive decoding](https://arxiv.org/abs/2506.08391)|[second](https://github.com/aidaslab/second)|
|2506.08520|[plug-and-play linear attention for pre-trained image and video restoration models](https://arxiv.org/abs/2506.08520)|[pnp_nystra](https://github.com/srinivas-512/pnp_nystra)|
|2506.08591|[diversity-guided mlp reduction for efficient large vision transformers](https://arxiv.org/abs/2506.08591)|[DGMR](https://github.com/visresearch/DGMR)|
|2506.08611|[towards class-wise fair adversarial training via anti-bias soft label distillation](https://arxiv.org/abs/2506.08611)|[absld](https://github.com/zhaoshiji123/absld)|
|2506.08613|[samselect: a spectral index search for marine debris visualization using segment anything](https://arxiv.org/abs/2506.08613)|[samselect](https://github.com/geojoost/samselect)|
|2506.08691|[vrest: enhancing reasoning in large vision-language models through tree search and self-reward mechanism](https://arxiv.org/abs/2506.08691)|[vrest](https://github.com/garyjiajia/vrest)|
|2506.08694|[mosic: optimal-transport motion trajectory for dense self-supervised learning](https://arxiv.org/abs/2506.08694)|[mosic](https://github.com/smsd75/mosic)|
|2506.08761|[normalized radon cumulative distribution transforms for invariance and robustness in optimal transport based image classification](https://arxiv.org/abs/2506.08761)|[nr-cdt](https://github.com/drbeckmann/nr-cdt)|
|2506.08887|[discovla: discrepancy reduction in vision, language, and alignment for parameter-efficient video-text retrieval](https://arxiv.org/abs/2506.08887)|[dsicovla](https://github.com/lunarshen/dsicovla)|
|2506.08949|[sss: semi-supervised sam-2 with efficient prompting for medical imaging segmentation](https://arxiv.org/abs/2506.08949)|[sss](https://github.com/aigeeksgroup/sss)|
|2506.08997|[sdtagnet: leveraging text-annotated navigation maps for online hd map construction](https://arxiv.org/abs/2506.08997)|[sdtagnet](https://github.com/immel-f/sdtagnet)|
|2506.09045|[magcache: fast video generation with magnitude-aware cache](https://arxiv.org/abs/2506.09045)|[magcache](https://github.com/zehong-ma/magcache)|
|2506.00978|[capaa: classifier-agnostic projector-based adversarial attack](https://arxiv.org/abs/2506.00978)|[capaa](https://github.com/zhanliqxq/capaa)|
|2506.03988|[raid: a dataset for testing the adversarial robustness of ai-generated image detectors](https://arxiv.org/abs/2506.03988)|[raid](https://github.com/pralab/raid)|
|2506.05660|[tissunet: improved extracranial tissue and cranium segmentation for children through adulthood](https://arxiv.org/abs/2506.05660)|[TissUNet](https://github.com/AIM-KannLab/TissUNet)|
|2506.06474|[edge-enabled collaborative object detection for real-time multi-vehicle perception](https://arxiv.org/abs/2506.06474)|[Edge-CAV](https://github.com/EverettRichards/Edge-CAV)|
|2506.06667|[flood-damagesense: multimodal mamba with multitask learning for building flood damage assessment using sar remote sensing imagery](https://arxiv.org/abs/2506.06667)|[flood-damagesense](https://github.com/violayhho/flood-damagesense)|
|2506.06771|[loopdb: a loop closure dataset for large scale simultaneous localization and mapping](https://arxiv.org/abs/2506.06771)|[loopdb](https://github.com/rovislab/loopdb)|
|2506.06906|[knn-defense: defense against 3d adversarial point clouds using nearest-neighbor search](https://arxiv.org/abs/2506.06906)|[3d-knn-defense](https://github.com/nimajam41/3d-knn-defense)|
|2506.06933|[rewriting the budget: a general framework for black-box attacks under cost asymmetry](https://arxiv.org/abs/2506.06933)|[asymmetric-attacks](https://github.com/mahdisalmani/asymmetric-attacks)|
|2506.07138|[learning compact vision tokens for efficient large multimodal models](https://arxiv.org/abs/2506.07138)|[LLaVA-STF](https://github.com/visresearch/LLaVA-STF)|
|2506.07364|[multiple object stitching for unsupervised representation learning](https://arxiv.org/abs/2506.07364)|[MultipleObjectStitching](https://github.com/visresearch/MultipleObjectStitching)|
|2506.07530|[bitvla: 1-bit vision-language-action models for robotics manipulation](https://arxiv.org/abs/2506.07530)|[bitvla](https://github.com/ustcwhy/bitvla)|
|2506.07539|[domain randomization for object detection in manufacturing applications using synthetic data: a comprehensive study](https://arxiv.org/abs/2506.07539)|[synmfg_code](https://github.com/jacobhenningsson95/synmfg_code)|
|2506.07773|[trend-aware fashion recommendation with visual segmentation and semantic similarity](https://arxiv.org/abs/2506.07773)|[fashionrecommender](https://github.com/meddjilani/fashionrecommender)|
|2506.07811|[looking beyond visible cues: implicit video question answering via dual-clue reasoning](https://arxiv.org/abs/2506.07811)|[implicit-videoqa](https://github.com/tychen-sjtu/implicit-videoqa)|
|2506.07857|[logosp: local-global grouping of superpoints for unsupervised semantic segmentation of 3d point clouds](https://arxiv.org/abs/2506.07857)|[logosp](https://github.com/vlar-group/logosp)|
|2506.07860|[egocentric event-based vision for ping pong ball trajectory prediction](https://arxiv.org/abs/2506.07860)|[event_based_ping_pong_ball_trajectory_prediction](https://github.com/uzh-rpg/event_based_ping_pong_ball_trajectory_prediction)|
|2506.07865|[freegave: 3d physics learning from dynamic videos by gaussian velocity](https://arxiv.org/abs/2506.07865)|[freegave](https://github.com/vlar-group/freegave)|
|2506.07878|[spatio-temporal state space model for efficient event-based optical flow](https://arxiv.org/abs/2506.07878)|[e-stmflow](https://github.com/ahmedhumais/e-stmflow)|
|2506.07883|[diffusion counterfactual generation with semantic abduction](https://arxiv.org/abs/2506.07883)|[diffusion-counterfactuals](https://github.com/rajatrasal/diffusion-counterfactuals)|
|2506.07903|[diffuse everything: multimodal diffusion models on arbitrary state spaces](https://arxiv.org/abs/2506.07903)|[diffuse-everything](https://github.com/kevinrojas1499/diffuse-everything)|
|2506.07905|[wethink: toward general-purpose vision-language reasoning via reinforcement learning](https://arxiv.org/abs/2506.07905)|[wethink](https://github.com/yangjie-cv/wethink)|
|2506.07964|[slidecoder: layout-aware rag-enhanced hierarchical slide generation from design](https://arxiv.org/abs/2506.07964)|[slidecoder](https://github.com/vinsontang1/slidecoder)|
|2506.07966|[space-10: a comprehensive benchmark for multimodal large language models in compositional spatial intelligence](https://arxiv.org/abs/2506.07966)|[space-10](https://github.com/cuzyoung/space-10)|
|2506.07971|[cyberv: cybernetics for test-time scaling in video understanding](https://arxiv.org/abs/2506.07971)|[cyberv](https://github.com/marinero4972/cyberv)|
|2506.07985|[rethinking crowd-sourced evaluation of neuron explanations](https://arxiv.org/abs/2506.07985)|[efficient_neuron_eval](https://github.com/trustworthy-ml-lab/efficient_neuron_eval)|
|2506.07992|[pairedit: learning semantic variations for exemplar-based image editing](https://arxiv.org/abs/2506.07992)|[pairedit](https://github.com/xudonmao/pairedit)|
|2506.07998|[generative modeling of weights: generalization or memorization?](https://arxiv.org/abs/2506.07998)|[weight_memorization](https://github.com/boyazeng/weight_memorization)|
|2506.08013|[stablemtl: repurposing latent diffusion models for multi-task learning from partially annotated synthetic datasets](https://arxiv.org/abs/2506.08013)|[stablemtl](https://github.com/astra-vision/stablemtl)|
|2506.02761|[rethinking machine unlearning in image generation models](https://arxiv.org/abs/2506.02761)|[igmu](https://github.com/ryliu68/igmu)|
|2506.03582|[semioccam: a robust semi-supervised image recognition network using sparse labels](https://arxiv.org/abs/2506.03582)|[SemiOccam](https://github.com/Shu1L0n9/SemiOccam)|
|2506.03664|[assessing intersectional bias in representations of pre-trained image recognition models](https://arxiv.org/abs/2506.03664)|[inntrospect](https://github.com/valeriekrug/inntrospect)|
|2506.04525|[user altruism in recommendation systems](https://arxiv.org/abs/2506.04525)|[recsys](https://github.com/mckitch24/recsys)|
|2506.05280|[unifying appearance codes and bilateral grids for driving scene gaussian splatting](https://arxiv.org/abs/2506.05280)|[bilateral-driving](https://github.com/bigcileng/bilateral-driving)|
|2506.05358|[can chatgpt perform image splicing detection? a preliminary study](https://arxiv.org/abs/2506.05358)|[LLM-Image-Splicing-Detection](https://github.com/confusedDip/LLM-Image-Splicing-Detection)|
|2506.05398|[igsm: improved geometric and sensitivity matching for finetuning pruned diffusion models](https://arxiv.org/abs/2506.05398)|[igsm-official](https://github.com/fate4869/igsm-official)|
|2506.05890|[unleashing the potential of consistency learning for detecting and grounding multi-modal media manipulation](https://arxiv.org/abs/2506.05890)|[cscl](https://github.com/liyih/cscl)|
|2506.06006|[bootstrapping world models from dynamics models in multimodal foundation models](https://arxiv.org/abs/2506.06006)|[vlm-world-model](https://github.com/yfqiu-nlp/vlm-world-model)|
|2506.06199|[3dflowaction: learning cross-embodiment manipulation from 3d flow world model](https://arxiv.org/abs/2506.06199)|[3dflowaction](https://github.com/hoyyyaard/3dflowaction)|


## Archives
- [June 2025](archives/2025/06.md)
- [May 2025](archives/2025/05.md)
- [April 2025](archives/2025/04.md)
