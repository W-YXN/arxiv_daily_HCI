# Daily ArXiv HCI

A curated collection of arXiv papers with open-source implementations, specifically focusing on Human-Computer Interaction (cs.HC) and related fields like Computer Graphics (cs.GR), Computer Vision (cs.CV), etc. This repository aims to serve researchers and practitioners in HCI by providing easy access to papers that come with their source code implementations.

## Overview
This project automatically tracks and analyzes papers from relevant HCI categories on arXiv daily using GitHub Actions. It specifically identifies and catalogs papers that have released their source code, making it easier for researchers in HCI and related areas to find implementable research work.

The main features include:
- Daily updates of papers with open-source implementations
- Focus on Human-Computer Interaction and related research
- Automatic tracking and organization

## Latest Updates 
|date|paper|code|
|---|---|---|
|2506.03988|[raid: a dataset for testing the adversarial robustness of ai-generated image detectors](https://arxiv.org/abs/2506.03988)|[raid](https://github.com/pralab/raid)|
|2506.05660|[tissunet: improved extracranial tissue and cranium segmentation for children through adulthood](https://arxiv.org/abs/2506.05660)|[TissUNet](https://github.com/AIM-KannLab/TissUNet)|
|2506.06474|[edge-enabled collaborative object detection for real-time multi-vehicle perception](https://arxiv.org/abs/2506.06474)|[Edge-CAV](https://github.com/EverettRichards/Edge-CAV)|
|2506.07138|[learning compact vision tokens for efficient large multimodal models](https://arxiv.org/abs/2506.07138)|[LLaVA-STF](https://github.com/visresearch/LLaVA-STF)|
|2506.07364|[multiple object stitching for unsupervised representation learning](https://arxiv.org/abs/2506.07364)|[MultipleObjectStitching](https://github.com/visresearch/MultipleObjectStitching)|
|2506.02761|[rethinking machine unlearning in image generation models](https://arxiv.org/abs/2506.02761)|[igmu](https://github.com/ryliu68/igmu)|
|2506.03582|[semioccam: a robust semi-supervised image recognition network using sparse labels](https://arxiv.org/abs/2506.03582)|[SemiOccam](https://github.com/Shu1L0n9/SemiOccam)|
|2506.05280|[unifying appearance codes and bilateral grids for driving scene gaussian splatting](https://arxiv.org/abs/2506.05280)|[bilateral-driving](https://github.com/bigcileng/bilateral-driving)|
|2506.05358|[can chatgpt perform image splicing detection? a preliminary study](https://arxiv.org/abs/2506.05358)|[LLM-Image-Splicing-Detection](https://github.com/confusedDip/LLM-Image-Splicing-Detection)|
|2506.01950|[dualmap: online open-vocabulary semantic mapping for natural language navigation in dynamic changing scenes](https://arxiv.org/abs/2506.01950)|[dualmap](https://github.com/eku127/dualmap)|
|2506.02896|[flysearch: exploring how vision-language models explore](https://arxiv.org/abs/2506.02896)|[flysearch](https://github.com/gmum/flysearch)|
|2506.03310|[the reader is the metric: how textual features and reader profiles explain conflicting evaluations of ai creative writing](https://arxiv.org/abs/2506.03310)|[the-reader-is-the-metric](https://github.com/grmarco/the-reader-is-the-metric)|
|2506.03385|[from reality to recognition: evaluating visualization analogies for novice chart comprehension](https://arxiv.org/abs/2506.03385)|[analogyvis](https://github.com/hivelabuoft/analogyvis)|
|2506.03478|[facial appearance capture at home with patch-level reflectance prior](https://arxiv.org/abs/2506.03478)|[dora](https://github.com/yxuhan/dora)|
|2506.03530|[how far are we from predicting missing modalities with foundation models?](https://arxiv.org/abs/2506.03530)|[afm2](https://github.com/guanzhou-ke/afm2)|
|2506.03594|[splart: articulation estimation and part-level reconstruction with 3d gaussian splatting](https://arxiv.org/abs/2506.03594)|[splart](https://github.com/ripl/splart)|
|2506.03662|[zero-shot temporal interaction localization for egocentric videos](https://arxiv.org/abs/2506.03662)|[egoloc](https://github.com/irmvlab/egoloc)|
|2506.03735|[generating pedagogically meaningful visuals for math word problems: a new benchmark and analysis of text-to-image models](https://arxiv.org/abs/2506.03735)|[math2visual](https://github.com/eth-lre/math2visual)|
|2506.03831|[conformer-based ultrasound-to-speech conversion](https://arxiv.org/abs/2506.03831)|[conformer_UTS](https://github.com/ibrahimkhaliloglu/conformer_UTS)|
|2506.04016|[dreaming up scale invariance via inverse renormalization group](https://arxiv.org/abs/2506.04016)|[upscaling_ising](https://github.com/adam-rancon/upscaling_ising)|
|2506.04043|[think like a person before responding: a multi-faceted evaluation of persona-guided llms for countering hate](https://arxiv.org/abs/2506.04043)|[woah-2025](https://github.com/mikelkn/woah-2025)|
|2506.04211|[diffusion domain teacher: diffusion guided domain adaptive object detector](https://arxiv.org/abs/2506.04211)|[Diffusion-Domain-Teacher](https://github.com/heboyong/Diffusion-Domain-Teacher)|
|2506.04218|[pseudo-simulation for autonomous driving](https://arxiv.org/abs/2506.04218)|[navsim](https://github.com/autonomousvision/navsim)|


## Archives
- [June 2025](archives/2025/06.md)
- [May 2025](archives/2025/05.md)
- [April 2025](archives/2025/04.md)
