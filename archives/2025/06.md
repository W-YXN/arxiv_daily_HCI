# June 2025 Archive

[Back to README](../../README.md)

|date|paper|code|
|---|---|---|
|2506.03662|[zero-shot temporal interaction localization for egocentric videos](https://arxiv.org/abs/2506.03662)|[egoloc](https://github.com/irmvlab/egoloc)|
|2506.08849|[adapting vision-language foundation model for next generation medical ultrasound image analysis](https://arxiv.org/abs/2506.08849)|[nextgen-uia](https://github.com/jinggqu/nextgen-uia)|
|2506.09420|[a call for collaborative intelligence: why human-agent systems should precede ai autonomy](https://arxiv.org/abs/2506.09420)|[awesome-llm-based-human-agent-systems](https://github.com/henrypengzou/awesome-llm-based-human-agent-systems)|
|2506.09522|[revisit what you see: disclose language prior in vision tokens for efficient guided decoding of lvlms](https://arxiv.org/abs/2506.09522)|[ReVisiT](https://github.com/bscho333/ReVisiT)|
|2506.09733|[atmosmj: revisiting gating mechanism for ai weather forecasting beyond the year scale](https://arxiv.org/abs/2506.09733)|[README.md](https://github.com/jmj2316/AtmosMJ/blob/main/README.md)|
|2506.09883|[3d-aware vision-language models fine-tuning with geometric distillation](https://arxiv.org/abs/2506.09883)|[3d-vlm-gd](https://github.com/kaist-cvml/3d-vlm-gd)|
|2506.07327|[case: contrastive activation for saliency estimation](https://arxiv.org/abs/2506.07327)|[case-saliency](https://github.com/dwil2444/case-saliency)|
|2506.08189|[open world scene graph generation using vision language models](https://arxiv.org/abs/2506.08189)|[pix2grp_cvpr2024](https://github.com/shtuplus/pix2grp_cvpr2024)|
|2506.08591|[diversity-guided mlp reduction for efficient large vision transformers](https://arxiv.org/abs/2506.08591)|[DGMR](https://github.com/visresearch/DGMR)|
|2506.08887|[discovla: discrepancy reduction in vision, language, and alignment for parameter-efficient video-text retrieval](https://arxiv.org/abs/2506.08887)|[dsicovla](https://github.com/lunarshen/dsicovla)|
|2506.09045|[magcache: fast video generation with magnitude-aware cache](https://arxiv.org/abs/2506.09045)|[magcache](https://github.com/zehong-ma/magcache)|
|2506.00978|[capaa: classifier-agnostic projector-based adversarial attack](https://arxiv.org/abs/2506.00978)|[capaa](https://github.com/zhanliqxq/capaa)|
|2506.03988|[raid: a dataset for testing the adversarial robustness of ai-generated image detectors](https://arxiv.org/abs/2506.03988)|[raid](https://github.com/pralab/raid)|
|2506.05660|[tissunet: improved extracranial tissue and cranium segmentation for children through adulthood](https://arxiv.org/abs/2506.05660)|[TissUNet](https://github.com/AIM-KannLab/TissUNet)|
|2506.06474|[edge-enabled collaborative object detection for real-time multi-vehicle perception](https://arxiv.org/abs/2506.06474)|[Edge-CAV](https://github.com/EverettRichards/Edge-CAV)|
|2506.06667|[flood-damagesense: multimodal mamba with multitask learning for building flood damage assessment using sar remote sensing imagery](https://arxiv.org/abs/2506.06667)|[flood-damagesense](https://github.com/violayhho/flood-damagesense)|
|2506.07138|[learning compact vision tokens for efficient large multimodal models](https://arxiv.org/abs/2506.07138)|[LLaVA-STF](https://github.com/visresearch/LLaVA-STF)|
|2506.07364|[multiple object stitching for unsupervised representation learning](https://arxiv.org/abs/2506.07364)|[MultipleObjectStitching](https://github.com/visresearch/MultipleObjectStitching)|
|2506.07865|[freegave: 3d physics learning from dynamic videos by gaussian velocity](https://arxiv.org/abs/2506.07865)|[freegave](https://github.com/vlar-group/freegave)|
|2506.02761|[rethinking machine unlearning in image generation models](https://arxiv.org/abs/2506.02761)|[igmu](https://github.com/ryliu68/igmu)|
|2506.03582|[semioccam: a robust semi-supervised image recognition network using sparse labels](https://arxiv.org/abs/2506.03582)|[SemiOccam](https://github.com/Shu1L0n9/SemiOccam)|
|2506.03664|[assessing intersectional bias in representations of pre-trained image recognition models](https://arxiv.org/abs/2506.03664)|[inntrospect](https://github.com/valeriekrug/inntrospect)|
|2506.04525|[user altruism in recommendation systems](https://arxiv.org/abs/2506.04525)|[recsys](https://github.com/mckitch24/recsys)|
|2506.05280|[unifying appearance codes and bilateral grids for driving scene gaussian splatting](https://arxiv.org/abs/2506.05280)|[bilateral-driving](https://github.com/bigcileng/bilateral-driving)|
|2506.05358|[can chatgpt perform image splicing detection? a preliminary study](https://arxiv.org/abs/2506.05358)|[LLM-Image-Splicing-Detection](https://github.com/confusedDip/LLM-Image-Splicing-Detection)|
|2506.05890|[unleashing the potential of consistency learning for detecting and grounding multi-modal media manipulation](https://arxiv.org/abs/2506.05890)|[cscl](https://github.com/liyih/cscl)|
|2506.02444|[svimo: synchronized diffusion for video and motion generation in hand-object interaction scenarios](https://arxiv.org/abs/2506.02444)|[SViMo_code](https://github.com/Droliven/SViMo_code)|
|2506.03614|[vlms can aggregate scattered training patches](https://arxiv.org/abs/2506.03614)|[visual-stitching](https://github.com/zhziszz/visual-stitching)|
|2506.03951|[rethinking the stability-plasticity trade-off in continual learning from an architectural perspective](https://arxiv.org/abs/2506.03951)|[Dual-Arch](https://github.com/byyx666/Dual-Arch)|
|2506.03956|[adapt before continual learning](https://arxiv.org/abs/2506.03956)|[ACL_code](https://github.com/byyx666/ACL_code)|
|2506.04283|[ssimbad: sigma scaling with ssim-guided balanced diffusion for animeface colorization](https://arxiv.org/abs/2506.04283)|[ssimbad-sigma-scaling-with-ssim-guided-balanced-diffusion-for-animeface-colorization](https://github.com/giventicket/ssimbad-sigma-scaling-with-ssim-guided-balanced-diffusion-for-animeface-colorization)|
|2506.04444|[photoreal scene reconstruction from an egocentric device](https://arxiv.org/abs/2506.04444)|[egocentric_splats](https://github.com/facebookresearch/egocentric_splats)|
|2506.04453|[gradient inversion attacks on parameter-efficient fine-tuning](https://arxiv.org/abs/2506.04453)|[peftleak](https://github.com/info-ucr/peftleak)|
|2506.04755|[truth in the few: high-value data selection for efficient multi-modal reasoning](https://arxiv.org/abs/2506.04755)|[rap](https://github.com/leo-ssl/rap)|
|2506.04842|[mineinsight: a multi-sensor dataset for humanitarian demining robotics in off-road environments](https://arxiv.org/abs/2506.04842)|[mineinsight](https://github.com/mariomlz99/mineinsight)|
|2506.04867|[llms for sensory-motor control: combining in-context and iterative learning](https://arxiv.org/abs/2506.04867)|[llm-robotics-article](https://github.com/jtyska/llm-robotics-article)|
|2506.05204|[oggsplat: open gaussian growing for generalizable reconstruction with expanded field-of-view](https://arxiv.org/abs/2506.05204)|[OGGSplat](https://github.com/Yanbo-23/OGGSplat)|
|2506.05274|[from play to replay: composed video retrieval for temporally fine-grained videos](https://arxiv.org/abs/2506.05274)|[tf-covr](https://github.com/ucf-crcv/tf-covr)|
|2506.01950|[dualmap: online open-vocabulary semantic mapping for natural language navigation in dynamic changing scenes](https://arxiv.org/abs/2506.01950)|[dualmap](https://github.com/eku127/dualmap)|
|2506.02896|[flysearch: exploring how vision-language models explore](https://arxiv.org/abs/2506.02896)|[flysearch](https://github.com/gmum/flysearch)|
|2506.03310|[the reader is the metric: how textual features and reader profiles explain conflicting evaluations of ai creative writing](https://arxiv.org/abs/2506.03310)|[the-reader-is-the-metric](https://github.com/grmarco/the-reader-is-the-metric)|
|2506.03385|[from reality to recognition: evaluating visualization analogies for novice chart comprehension](https://arxiv.org/abs/2506.03385)|[analogyvis](https://github.com/hivelabuoft/analogyvis)|
|2506.03478|[facial appearance capture at home with patch-level reflectance prior](https://arxiv.org/abs/2506.03478)|[dora](https://github.com/yxuhan/dora)|
|2506.03530|[how far are we from predicting missing modalities with foundation models?](https://arxiv.org/abs/2506.03530)|[afm2](https://github.com/guanzhou-ke/afm2)|
|2506.03594|[splart: articulation estimation and part-level reconstruction with 3d gaussian splatting](https://arxiv.org/abs/2506.03594)|[splart](https://github.com/ripl/splart)|
|2506.03662|[zero-shot temporal interaction localization for egocentric videos](https://arxiv.org/abs/2506.03662)|[egoloc](https://github.com/irmvlab/egoloc)|
|2506.03735|[generating pedagogically meaningful visuals for math word problems: a new benchmark and analysis of text-to-image models](https://arxiv.org/abs/2506.03735)|[math2visual](https://github.com/eth-lre/math2visual)|
|2506.03831|[conformer-based ultrasound-to-speech conversion](https://arxiv.org/abs/2506.03831)|[conformer_UTS](https://github.com/ibrahimkhaliloglu/conformer_UTS)|
|2506.04016|[dreaming up scale invariance via inverse renormalization group](https://arxiv.org/abs/2506.04016)|[upscaling_ising](https://github.com/adam-rancon/upscaling_ising)|
|2506.04043|[think like a person before responding: a multi-faceted evaluation of persona-guided llms for countering hate](https://arxiv.org/abs/2506.04043)|[woah-2025](https://github.com/mikelkn/woah-2025)|
|2506.04211|[diffusion domain teacher: diffusion guided domain adaptive object detector](https://arxiv.org/abs/2506.04211)|[Diffusion-Domain-Teacher](https://github.com/heboyong/Diffusion-Domain-Teacher)|
|2506.04218|[pseudo-simulation for autonomous driving](https://arxiv.org/abs/2506.04218)|[navsim](https://github.com/autonomousvision/navsim)|
|2506.02214|[is pmbok guide the right fit for ai? re-evaluating project management in the face of artificial intelligence projects](https://arxiv.org/abs/2506.02214)|[geti](https://github.com/open-edge-platform/geti)|
|2506.02312|[dual encoding feature filtering generalized attention unet for retinal vessel segmentation](https://arxiv.org/abs/2506.02312)|[DEFFA-Unet](https://github.com/TauhidScu/DEFFA-Unet)|
|2506.02380|[eyenavgs: a 6-dof navigation dataset and record-n-replay software for real-world 3dgs scenes in vr](https://arxiv.org/abs/2506.02380)|[EyeNavGS_Software](https://github.com/symmru/EyeNavGS_Software)|
|2506.02514|[to embody or not: the effect of embodiment on user perception of llm-based conversational agents](https://arxiv.org/abs/2506.02514)|[to-embody-or-not](https://github.com/amaai-lab/to-embody-or-not)|
|2506.02736|[genea-slam2: dynamic slam with autoencoder-preprocessed genetic keypoints resampling and depth variance-guided dynamic region removal](https://arxiv.org/abs/2506.02736)|[GeneA-SLAM2](https://github.com/qingshufan/GeneA-SLAM2)|
|2506.02794|[physgaia: a physics-aware dataset of multi-body interactions for dynamic novel view synthesis](https://arxiv.org/abs/2506.02794)|[physgaia](https://github.com/mjmjeong/physgaia)|
|2506.02893|[dense match summarization for faster two-view estimation](https://arxiv.org/abs/2506.02893)|[DMS](https://github.com/jastermark/DMS)|
|2506.02895|[voltex: food volume estimation using text-guided segmentation and neural surface reconstruction](https://arxiv.org/abs/2506.02895)|[voltex](https://github.com/gcvcg/voltex)|
|2506.02911|[cell-o1: training llms to solve single-cell reasoning puzzles with reinforcement learning](https://arxiv.org/abs/2506.02911)|[cell-o1](https://github.com/ncbi-nlp/cell-o1)|
|2506.03097|[egovlm: policy optimization for egocentric video understanding](https://arxiv.org/abs/2506.03097)|[videgovlm](https://github.com/adityavavre/videgovlm)|
|2506.00325|[towards effective and efficient adversarial defense with diffusion models for robust visual tracking](https://arxiv.org/abs/2506.00325)|[DiffDf](https://github.com/pgao-lab/DiffDf)|
|2506.01091|[promptvfx: text-driven fields for open-world 3d gaussian animation](https://arxiv.org/abs/2506.01091)|[promptvfx](https://github.com/3Dwe-ai/promptvfx)|
|2506.01391|[agentcpm-gui: building mobile-use agents with reinforcement fine-tuning](https://arxiv.org/abs/2506.01391)|[AgentCPM-GUI](https://github.com/OpenBMB/AgentCPM-GUI)|
|2506.01482|[automatic stage lighting control: is it a rule-driven process or generative task?](https://arxiv.org/abs/2506.01482)|[Skip-BART](https://github.com/RS2002/Skip-BART)|
|2506.01806|[ridgeformer: mutli-stage contrastive training for fine-grained cross-domain fingerprint recognition](https://arxiv.org/abs/2506.01806)|[Ridgeformer](https://github.com/KNITPhoenix/Ridgeformer)|
|2506.01923|[taxadiffusion: progressively trained diffusion model for fine-grained species generation](https://arxiv.org/abs/2506.01923)|[TaxaDiffusion](https://github.com/aminK8/TaxaDiffusion)|

