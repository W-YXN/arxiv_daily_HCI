# June 2025 Archive

[Back to README](../../README.md)

|date|paper|code|
|---|---|---|
|2506.01413|[incentivizing reasoning for advanced instruction-following of large language models](https://arxiv.org/abs/2506.01413)|[raif](https://github.com/yuleiqin/raif)|
|2506.08011|[play to generalize: learning to reason through game play](https://arxiv.org/abs/2506.08011)|[vigal](https://github.com/yunfeixie233/vigal)|
|2506.08735|[inceptionmamba: an efficient hybrid network with large band convolution and bottleneck mamba](https://arxiv.org/abs/2506.08735)|[inceptionmamba](https://github.com/wake1021/inceptionmamba)|
|2506.09042|[cosmos-drive-dreams: scalable synthetic driving data generation with world foundation models](https://arxiv.org/abs/2506.09042)|[cosmos-drive-dreams](https://github.com/nv-tlabs/cosmos-drive-dreams)|
|2506.09476|[urban1960satseg: unsupervised semantic segmentation of mid-20$^{th}$ century urban landscapes with satellite imageries](https://arxiv.org/abs/2506.09476)|[urban1960satseg](https://github.com/tianxiang-hao/urban1960satseg)|
|2506.09612|[consistent story generation with asymmetry zigzag sampling](https://arxiv.org/abs/2506.09612)|[asymmetry-zigzag-storydiffusion](https://github.com/mingxiao-li/asymmetry-zigzag-storydiffusion)|
|2506.09834|[mmme: a spontaneous multi-modal micro-expression dataset enabling visual-physiological fusion](https://arxiv.org/abs/2506.09834)|[mmme](https://github.com/mac0504/mmme)|
|2506.10036|[token perturbation guidance for diffusion models](https://arxiv.org/abs/2506.10036)|[token-perturbation-guidance](https://github.com/taatiteam/token-perturbation-guidance)|
|2506.10128|[vicrit: a verifiable reinforcement learning proxy task for visual perception in vlms](https://arxiv.org/abs/2506.10128)|[vicrit](https://github.com/si0wang/vicrit)|
|2506.10142|[rethinking brain tumor segmentation from the frequency domain perspective](https://arxiv.org/abs/2506.10142)|[hff](https://github.com/vinyehshaw/hff)|
|2506.10150|[when large language models are reliable for judging empathic communication](https://arxiv.org/abs/2506.10150)|[replication-data-and-code-when-LLMs-reliable-empathic-communication](https://github.com/aakriti1kumar/replication-data-and-code-when-LLMs-reliable-empathic-communication)|
|2506.10174|[retrieval of surface solar radiation through implicit albedo recovery from temporal context](https://arxiv.org/abs/2506.10174)|[hemu-dev](https://github.com/frischwood/hemu-dev)|
|2506.10178|[attention, please! revisiting attentive probing for masked image modeling](https://arxiv.org/abs/2506.10178)|[efficient-probing](https://github.com/billpsomas/efficient-probing)|
|2506.10182|[improving personalized search with regularized low-rank parameter updates](https://arxiv.org/abs/2506.10182)|[polar-vl](https://github.com/adobe-research/polar-vl)|
|2506.10228|[california crop yield benchmark: combining satellite image, climate, evapotranspiration, and soil data layers for county-level yield forecasting of over 70 crops](https://arxiv.org/abs/2506.10228)|[california-crop-yield-benchmark](https://github.com/plant-ai-biophysics-lab/california-crop-yield-benchmark)|
|2506.10325|[swdl: stratum-wise difference learning with deep laplacian pyramid for semi-supervised 3d intracranial hemorrhage segmentation](https://arxiv.org/abs/2506.10325)|[swdl](https://github.com/siat-ct-lab/swdl)|
|2506.10366|[fsatfusion: frequency-spatial attention transformer for infrared and visible image fusion](https://arxiv.org/abs/2506.10366)|[fsatfusion](https://github.com/lmmh058/fsatfusion)|
|2506.10386|[leveraging 6dof pose foundation models for mapping marine sediment burial](https://arxiv.org/abs/2506.10386)|[barrels](https://github.com/jerukan/barrels)|
|2506.10390|[dart: differentiable dynamic adaptive region tokenizer for vision transformer and mamba](https://arxiv.org/abs/2506.10390)|[dart](https://github.com/hcplab-sysu/dart)|
|2506.10391|[reconmost: multi-layer sea temperature reconstruction with observations-guided diffusion](https://arxiv.org/abs/2506.10391)|[reconmost](https://github.com/norsheep/reconmost)|
|2506.10425|[it's not the target, it's the background: rethinking infrared small target detection via deep patch-free low-rank representations](https://arxiv.org/abs/2506.10425)|[lrrnet](https://github.com/halongbao/lrrnet)|
|2506.10452|[towards robust multimodal emotion recognition under missing modalities and distribution shifts](https://arxiv.org/abs/2506.10452)|[cider](https://github.com/gw-zhong/cider)|
|2506.10468|[low-barrier dataset collection with real human body for interactive per-garment virtual try-on](https://arxiv.org/abs/2506.10468)|[RTV](https://github.com/ZaiqiangWu/RTV)|
|2506.10550|[contextrefine-clip for epic-kitchens-100 multi-instance retrieval challenge 2025](https://arxiv.org/abs/2506.10550)|[contextrefine-clip](https://github.com/delcayr/contextrefine-clip)|
|2506.10580|[transformer imu calibrator: dynamic on-body imu calibration for inertial motion capture](https://arxiv.org/abs/2506.10580)|[tic](https://github.com/zuocx1996/tic)|
|2506.10601|[semantic-decoupled spatial partition guided point-supervised oriented object detection](https://arxiv.org/abs/2506.10601)|[ssp](https://github.com/antxinyuan/ssp)|
|2506.10609|[mstar: box-free multi-query scene text retrieval with attention recycling](https://arxiv.org/abs/2506.10609)|[mstar](https://github.com/yingift/mstar)|
|2506.10612|[textailor: customized text-aligned texturing via effective resampling](https://arxiv.org/abs/2506.10612)|[textailor](https://github.com/adios42/textailor)|
|2506.10632|[hessian geometry of latent space in generative models](https://arxiv.org/abs/2506.10632)|[hessian-geometry-of-diffusion-models](https://github.com/alobashev/hessian-geometry-of-diffusion-models)|
|2506.10821|[videodeepresearch: long video understanding with agentic tool using](https://arxiv.org/abs/2506.10821)|[videodeepresearch](https://github.com/yhy-2000/videodeepresearch)|
|2506.10890|[creatiposter: towards editable and controllable multi-layer graphic design generation](https://arxiv.org/abs/2506.10890)|[creatiposter](https://github.com/graphic-design-ai/creatiposter)|
|2506.10895|[air: zero-shot generative model adaptation with iterative refinement](https://arxiv.org/abs/2506.10895)|[air](https://github.com/guimeng-leo-liu/air)|
|2506.10967|[beyond attention or similarity: maximizing conditional diversity for token pruning in mllms](https://arxiv.org/abs/2506.10967)|[cdpruner](https://github.com/theia-4869/cdpruner)|
|2506.10977|[quadricformer: scene as superquadrics for 3d semantic occupancy prediction](https://arxiv.org/abs/2506.10977)|[quadricformer](https://github.com/zuosc19/quadricformer)|
|2506.03662|[zero-shot temporal interaction localization for egocentric videos](https://arxiv.org/abs/2506.03662)|[egoloc](https://github.com/irmvlab/egoloc)|
|2506.05982|[mca-bench: a multimodal benchmark for evaluating captcha robustness against vlm-based attacks](https://arxiv.org/abs/2506.05982)|[mca-bench](https://github.com/noheadwuzonglin/mca-bench)|
|2506.07400|[medchat: a multi-agent framework for multimodal diagnosis with large language models](https://arxiv.org/abs/2506.07400)|[medchat](https://github.com/purdue-m2/medchat)|
|2506.07986|[rethinking cross-modal interaction in multimodal diffusion transformers](https://arxiv.org/abs/2506.07986)|[taca](https://github.com/vchitect/taca)|
|2506.08010|[vision transformers don't need trained registers](https://arxiv.org/abs/2506.08010)|[test-time-registers](https://github.com/nickjiang2378/test-time-registers)|
|2506.08772|[rs-mtdf: multi-teacher distillation and fusion for remote sensing semi-supervised semantic segmentation](https://arxiv.org/abs/2506.08772)|[semi-supervised-semantic-segmentation-with-distillation](https://github.com/earth-insights/semi-supervised-semantic-segmentation-with-distillation)|
|2506.08849|[adapting vision-language foundation model for next generation medical ultrasound image analysis](https://arxiv.org/abs/2506.08849)|[nextgen-uia](https://github.com/jinggqu/nextgen-uia)|
|2506.08900|[mirage: multimodal foundation model and benchmark for comprehensive retinal oct image analysis](https://arxiv.org/abs/2506.08900)|[mirage](https://github.com/j-morano/mirage)|
|2506.08908|[skipvar: accelerating visual autoregressive modeling via adaptive frequency-aware skipping](https://arxiv.org/abs/2506.08908)|[skipvar](https://github.com/fakerone-li/skipvar)|
|2506.09022|[do multiple instance learning models transfer?](https://arxiv.org/abs/2506.09022)|[mil-lab](https://github.com/mahmoodlab/mil-lab)|
|2506.09217|[perception characteristics distance: measuring stability and robustness of perception system in dynamic conditions under a certain decision rule](https://arxiv.org/abs/2506.09217)|[pcd_python](https://github.com/datadrivenwheels/pcd_python)|
|2506.09237|[patchguard: adversarially robust anomaly detection and localization through vision transformers and pseudo anomalies](https://arxiv.org/abs/2506.09237)|[patchgaurd](https://github.com/rohban-lab/patchgaurd)|
|2506.09344|[ming-omni: a unified multimodal model for perception and generation](https://arxiv.org/abs/2506.09344)|[ming](https://github.com/inclusionai/ming)|
|2506.09353|[davsp: safety alignment for large vision-language models via deep aligned visual safety prompt](https://arxiv.org/abs/2506.09353)|[davsp](https://github.com/zhangyitonggg/davsp)|
|2506.09363|[sage: exploring the boundaries of unsafe concept domain with semantic-augment erasing](https://arxiv.org/abs/2506.09363)|[sage](https://github.com/kevinlight831/sage)|
|2506.09369|[scalelsd: scalable deep line segment detection streamlined](https://arxiv.org/abs/2506.09369)|[scalelsd](https://github.com/ant-research/scalelsd)|
|2506.09385|[reid5o: achieving omni multi-modal person re-identification in a single model](https://arxiv.org/abs/2506.09385)|[reid5o_orbench](https://github.com/zplusdragon/reid5o_orbench)|
|2506.09403|[srpl-sfda: sam-guided reliable pseudo-labels for source-free domain adaptation in medical image segmentation](https://arxiv.org/abs/2506.09403)|[srpl-sfda](https://github.com/hilab-git/srpl-sfda)|
|2506.09416|[noise conditional variational score distillation](https://arxiv.org/abs/2506.09416)|[ncvsd](https://github.com/xypeng9903/ncvsd)|
|2506.09420|[a call for collaborative intelligence: why human-agent systems should precede ai autonomy](https://arxiv.org/abs/2506.09420)|[awesome-llm-based-human-agent-systems](https://github.com/henrypengzou/awesome-llm-based-human-agent-systems)|
|2506.09522|[revisit what you see: disclose language prior in vision tokens for efficient guided decoding of lvlms](https://arxiv.org/abs/2506.09522)|[ReVisiT](https://github.com/bscho333/ReVisiT)|
|2506.09626|[ecam: a contrastive learning approach to avoid environmental collision in trajectory forecasting](https://arxiv.org/abs/2506.09626)|[ecam](https://github.com/cvml-cfu/ecam)|
|2506.09650|[hopadiff: holistic-partial aware fourier conditioned diffusion for referring human action segmentation in multi-person scenarios](https://arxiv.org/abs/2506.09650)|[hopadiff](https://github.com/kpeng9510/hopadiff)|
|2506.09668|[cinema: conditional implicit neural multi-modal atlas for a spatio-temporal representation of the perinatal brain](https://arxiv.org/abs/2506.09668)|[cinema](https://github.com/m-dannecker/cinema)|
|2506.09691|[adding simple structure at inference improves vision-language compositionality](https://arxiv.org/abs/2506.09691)|[structure-inference-compositionality](https://github.com/imirandam/structure-inference-compositionality)|
|2506.09695|[towards practical alzheimer's disease diagnosis: a lightweight and interpretable spiking neural model](https://arxiv.org/abs/2506.09695)|[fastersnn](https://github.com/wuchangw/fastersnn)|
|2506.09709|[training-free voice conversion with factorized optimal transport](https://arxiv.org/abs/2506.09709)|[mkl-vc](https://github.com/alobashev/mkl-vc)|
|2506.09718|[non-contact health monitoring during daily personal care routines](https://arxiv.org/abs/2506.09718)|[fusionvitals](https://github.com/mcjacktang/fusionvitals)|
|2506.09724|[the four color theorem for cell instance segmentation](https://arxiv.org/abs/2506.09724)|[fcis](https://github.com/zhangye-zoe/fcis)|
|2506.09733|[atmosmj: revisiting gating mechanism for ai weather forecasting beyond the year scale](https://arxiv.org/abs/2506.09733)|[README.md](https://github.com/jmj2316/AtmosMJ/blob/main/README.md)|
|2506.09736|[vision matters: simple visual perturbations can boost multimodal math reasoning](https://arxiv.org/abs/2506.09736)|[easyr1](https://github.com/hiyouga/easyr1)|
|2506.09777|[inverting black-box face recognition systems via zero-order optimization in eigenface space](https://arxiv.org/abs/2506.09777)|[adversarialfaces](https://github.com/fusionbrainlab/adversarialfaces)|
|2506.09790|[comfyui-r1: exploring reasoning models for workflow generation](https://arxiv.org/abs/2506.09790)|[comfyui-copilot](https://github.com/aidc-ai/comfyui-copilot)|
|2506.09849|[intphys 2: benchmarking intuitive physics understanding in complex synthetic environments](https://arxiv.org/abs/2506.09849)|[intphys2](https://github.com/facebookresearch/intphys2)|
|2506.09881|[leveraging depth and language for open-vocabulary domain-generalized semantic segmentation](https://arxiv.org/abs/2506.09881)|[vireo](https://github.com/anonymouse-9c53tp182bvz/vireo)|
|2506.09883|[3d-aware vision-language models fine-tuning with geometric distillation](https://arxiv.org/abs/2506.09883)|[3d-vlm-gd](https://github.com/kaist-cvml/3d-vlm-gd)|
|2506.09895|[equicaps: predictor-free pose-aware pre-trained capsule networks](https://arxiv.org/abs/2506.09895)|[equicaps](https://github.com/aberdeenml/equicaps)|
|2506.09920|[structural-spectral graph convolution with evidential edge learning for hyperspectral image clustering](https://arxiv.org/abs/2506.09920)|[ssgco-egael](https://github.com/jhqi/ssgco-egael)|
|2506.09943|[causalvqa: a physically grounded causal reasoning benchmark for video models](https://arxiv.org/abs/2506.09943)|[causalvqa](https://github.com/facebookresearch/causalvqa)|
|2506.09949|[sampling theory for super-resolution with implicit neural representations](https://arxiv.org/abs/2506.09949)|[super_inrs](https://github.com/gregongie/super_inrs)|
|2506.09952|[unipre3d: unified pre-training of 3d point cloud models with cross-modal gaussian splatting](https://arxiv.org/abs/2506.09952)|[unipre3d](https://github.com/wangzy22/unipre3d)|
|2506.09953|[outside knowledge conversational video (okcv) dataset -- dialoguing over videos](https://arxiv.org/abs/2506.09953)|[okcv](https://github.com/c-patsch/okcv)|
|2506.09965|[reinforcing spatial reasoning in vision-language models with interwoven thinking and visual drawing](https://arxiv.org/abs/2506.09965)|[vilasr](https://github.com/antresearchnlp/vilasr)|
|2506.09980|[efficient part-level 3d object generation via dual volume packing](https://arxiv.org/abs/2506.09980)|[partpacker](https://github.com/nvlabs/partpacker)|
|2506.09985|[v-jepa 2: self-supervised video models enable understanding, prediction and planning](https://arxiv.org/abs/2506.09985)|[vjepa2](https://github.com/facebookresearch/vjepa2)|
|2506.09989|[hearing hands: generating sounds from physical interactions in 3d scenes](https://arxiv.org/abs/2506.09989)|[hearing_hands](https://github.com/dou-yiming/hearing_hands)|
|2506.05633|[noninvasive precision modulation of high-level neural population activity via natural vision perturbations](https://arxiv.org/abs/2506.05633)|[directionalneuralmodulation](https://github.com/ggaziv/directionalneuralmodulation)|
|2506.07327|[case: contrastive activation for saliency estimation](https://arxiv.org/abs/2506.07327)|[case-saliency](https://github.com/dwil2444/case-saliency)|
|2506.07977|[oneig-bench: omni-dimensional nuanced evaluation for image generation](https://arxiv.org/abs/2506.07977)|[oneig-benchmark](https://github.com/oneig-bench/oneig-benchmark)|
|2506.08071|[cure: cultural gaps in the long tail of text-to-image systems](https://arxiv.org/abs/2506.08071)|[cure-bench](https://github.com/aniketrege/cure-bench)|
|2506.08185|[surgeon style fingerprinting and privacy risk quantification via discrete diffusion models in a vision-language-action framework](https://arxiv.org/abs/2506.08185)|[surgeon_style_fingerprinting](https://github.com/huixin-zhan-ai/surgeon_style_fingerprinting)|
|2506.08189|[open world scene graph generation using vision language models](https://arxiv.org/abs/2506.08189)|[pix2grp_cvpr2024](https://github.com/shtuplus/pix2grp_cvpr2024)|
|2506.08277|[instruction-tuned video-audio models elucidate functional specialization in the brain](https://arxiv.org/abs/2506.08277)|[mllm_videos](https://github.com/subbareddy248/mllm_videos)|
|2506.08280|[snap-and-tune: combining deep learning and test-time optimization for high-fidelity cardiovascular volumetric meshing](https://arxiv.org/abs/2506.08280)|[deep-cardiac-volumetric-mesh](https://github.com/danpak94/deep-cardiac-volumetric-mesh)|
|2506.08299|[openrr-1k: a scalable dataset for real-world reflection removal](https://arxiv.org/abs/2506.08299)|[openrr-1k](https://github.com/caijie0620/openrr-1k)|
|2506.08353|[an adaptive method stabilizing activations for enhanced generalization](https://arxiv.org/abs/2506.08353)|[adaact](https://github.com/hseung88/adaact)|
|2506.08361|[image demoir\'eing using dual camera fusion on mobile phones](https://arxiv.org/abs/2506.08361)|[dcid](https://github.com/mrduckk/dcid)|
|2506.08391|[second: mitigating perceptual hallucination in vision-language models via selective and contrastive decoding](https://arxiv.org/abs/2506.08391)|[second](https://github.com/aidaslab/second)|
|2506.08520|[plug-and-play linear attention for pre-trained image and video restoration models](https://arxiv.org/abs/2506.08520)|[pnp_nystra](https://github.com/srinivas-512/pnp_nystra)|
|2506.08591|[diversity-guided mlp reduction for efficient large vision transformers](https://arxiv.org/abs/2506.08591)|[DGMR](https://github.com/visresearch/DGMR)|
|2506.08611|[towards class-wise fair adversarial training via anti-bias soft label distillation](https://arxiv.org/abs/2506.08611)|[absld](https://github.com/zhaoshiji123/absld)|
|2506.08613|[samselect: a spectral index search for marine debris visualization using segment anything](https://arxiv.org/abs/2506.08613)|[samselect](https://github.com/geojoost/samselect)|
|2506.08618|[hsg-12m: a large-scale spatial multigraph dataset](https://arxiv.org/abs/2506.08618)|[hsg-12m](https://github.com/sarinstein-yan/hsg-12m)|
|2506.08691|[vrest: enhancing reasoning in large vision-language models through tree search and self-reward mechanism](https://arxiv.org/abs/2506.08691)|[vrest](https://github.com/garyjiajia/vrest)|
|2506.08694|[mosic: optimal-transport motion trajectory for dense self-supervised learning](https://arxiv.org/abs/2506.08694)|[mosic](https://github.com/smsd75/mosic)|
|2506.08761|[normalized radon cumulative distribution transforms for invariance and robustness in optimal transport based image classification](https://arxiv.org/abs/2506.08761)|[nr-cdt](https://github.com/drbeckmann/nr-cdt)|
|2506.08862|[streamsplat: towards online dynamic 3d reconstruction from uncalibrated video streams](https://arxiv.org/abs/2506.08862)|[streamsplat](https://github.com/nickwzk/streamsplat)|
|2506.08887|[discovla: discrepancy reduction in vision, language, and alignment for parameter-efficient video-text retrieval](https://arxiv.org/abs/2506.08887)|[dsicovla](https://github.com/lunarshen/dsicovla)|
|2506.08915|[inherently faithful attention maps for vision transformers](https://arxiv.org/abs/2506.08915)|[ifam](https://github.com/ananthu-aniraj/ifam)|
|2506.08949|[sss: semi-supervised sam-2 with efficient prompting for medical imaging segmentation](https://arxiv.org/abs/2506.08949)|[sss](https://github.com/aigeeksgroup/sss)|
|2506.08990|[efficient medical vision-language alignment through adapting masked vision models](https://arxiv.org/abs/2506.08990)|[alta](https://github.com/dopaminelcy/alta)|
|2506.08997|[sdtagnet: leveraging text-annotated navigation maps for online hd map construction](https://arxiv.org/abs/2506.08997)|[sdtagnet](https://github.com/immel-f/sdtagnet)|
|2506.09040|[autoregressive semantic visual reconstruction helps vlms understand better](https://arxiv.org/abs/2506.09040)|[asvr](https://github.com/alenjandrowang/asvr)|
|2506.09045|[magcache: fast video generation with magnitude-aware cache](https://arxiv.org/abs/2506.09045)|[magcache](https://github.com/zehong-ma/magcache)|
|2506.00978|[capaa: classifier-agnostic projector-based adversarial attack](https://arxiv.org/abs/2506.00978)|[capaa](https://github.com/zhanliqxq/capaa)|
|2506.03988|[raid: a dataset for testing the adversarial robustness of ai-generated image detectors](https://arxiv.org/abs/2506.03988)|[raid](https://github.com/pralab/raid)|
|2506.05660|[tissunet: improved extracranial tissue and cranium segmentation for children through adulthood](https://arxiv.org/abs/2506.05660)|[TissUNet](https://github.com/AIM-KannLab/TissUNet)|
|2506.06315|[an open-source python framework and synthetic ecg image datasets for digitization, lead and lead name detection, and overlapping signal segmentation](https://arxiv.org/abs/2506.06315)|[ecg-image-and-signal-dataset](https://github.com/rezakarbasi/ecg-image-and-signal-dataset)|
|2506.06474|[edge-enabled collaborative object detection for real-time multi-vehicle perception](https://arxiv.org/abs/2506.06474)|[Edge-CAV](https://github.com/EverettRichards/Edge-CAV)|
|2506.06664|[generalized trajectory scoring for end-to-end multimodal planning](https://arxiv.org/abs/2506.06664)|[gtrs](https://github.com/nvlabs/gtrs)|
|2506.06667|[flood-damagesense: multimodal mamba with multitask learning for building flood damage assessment using sar remote sensing imagery](https://arxiv.org/abs/2506.06667)|[flood-damagesense](https://github.com/violayhho/flood-damagesense)|
|2506.06710|[a systematic investigation on deep learning-based omnidirectional image and video super-resolution](https://arxiv.org/abs/2506.06710)|[survey-on-odisr-and-odvsr](https://github.com/nqian1/survey-on-odisr-and-odvsr)|
|2506.06771|[loopdb: a loop closure dataset for large scale simultaneous localization and mapping](https://arxiv.org/abs/2506.06771)|[loopdb](https://github.com/rovislab/loopdb)|
|2506.06906|[knn-defense: defense against 3d adversarial point clouds using nearest-neighbor search](https://arxiv.org/abs/2506.06906)|[3d-knn-defense](https://github.com/nimajam41/3d-knn-defense)|
|2506.06933|[rewriting the budget: a general framework for black-box attacks under cost asymmetry](https://arxiv.org/abs/2506.06933)|[asymmetric-attacks](https://github.com/mahdisalmani/asymmetric-attacks)|
|2506.07138|[learning compact vision tokens for efficient large multimodal models](https://arxiv.org/abs/2506.07138)|[LLaVA-STF](https://github.com/visresearch/LLaVA-STF)|
|2506.07364|[multiple object stitching for unsupervised representation learning](https://arxiv.org/abs/2506.07364)|[MultipleObjectStitching](https://github.com/visresearch/MultipleObjectStitching)|
|2506.07530|[bitvla: 1-bit vision-language-action models for robotics manipulation](https://arxiv.org/abs/2506.07530)|[bitvla](https://github.com/ustcwhy/bitvla)|
|2506.07539|[domain randomization for object detection in manufacturing applications using synthetic data: a comprehensive study](https://arxiv.org/abs/2506.07539)|[synmfg_code](https://github.com/jacobhenningsson95/synmfg_code)|
|2506.07558|[immersive visualization of flat surfaces using ray marching](https://arxiv.org/abs/2506.07558)|[raymarchingflatsurfaces](https://github.com/fabianlander/raymarchingflatsurfaces)|
|2506.07773|[trend-aware fashion recommendation with visual segmentation and semantic similarity](https://arxiv.org/abs/2506.07773)|[fashionrecommender](https://github.com/meddjilani/fashionrecommender)|
|2506.07811|[looking beyond visible cues: implicit video question answering via dual-clue reasoning](https://arxiv.org/abs/2506.07811)|[implicit-videoqa](https://github.com/tychen-sjtu/implicit-videoqa)|
|2506.07841|[diffusion models under low-noise regime](https://arxiv.org/abs/2506.07841)|[diffusion_low_noise_regime](https://github.com/lizardp1/diffusion_low_noise_regime)|
|2506.07857|[logosp: local-global grouping of superpoints for unsupervised semantic segmentation of 3d point clouds](https://arxiv.org/abs/2506.07857)|[logosp](https://github.com/vlar-group/logosp)|
|2506.07860|[egocentric event-based vision for ping pong ball trajectory prediction](https://arxiv.org/abs/2506.07860)|[event_based_ping_pong_ball_trajectory_prediction](https://github.com/uzh-rpg/event_based_ping_pong_ball_trajectory_prediction)|
|2506.07865|[freegave: 3d physics learning from dynamic videos by gaussian velocity](https://arxiv.org/abs/2506.07865)|[freegave](https://github.com/vlar-group/freegave)|
|2506.07878|[spatio-temporal state space model for efficient event-based optical flow](https://arxiv.org/abs/2506.07878)|[e-stmflow](https://github.com/ahmedhumais/e-stmflow)|
|2506.07883|[diffusion counterfactual generation with semantic abduction](https://arxiv.org/abs/2506.07883)|[diffusion-counterfactuals](https://github.com/rajatrasal/diffusion-counterfactuals)|
|2506.07905|[wethink: toward general-purpose vision-language reasoning via reinforcement learning](https://arxiv.org/abs/2506.07905)|[wethink](https://github.com/yangjie-cv/wethink)|
|2506.07917|[speedy deformable 3d gaussian splatting: fast rendering and compression of dynamic scenes](https://arxiv.org/abs/2506.07917)|[speede3dgs](https://github.com/tuallen/speede3dgs)|
|2506.07964|[slidecoder: layout-aware rag-enhanced hierarchical slide generation from design](https://arxiv.org/abs/2506.07964)|[slidecoder](https://github.com/vinsontang1/slidecoder)|
|2506.07966|[space-10: a comprehensive benchmark for multimodal large language models in compositional spatial intelligence](https://arxiv.org/abs/2506.07966)|[space-10](https://github.com/cuzyoung/space-10)|
|2506.07971|[cyberv: cybernetics for test-time scaling in video understanding](https://arxiv.org/abs/2506.07971)|[cyberv](https://github.com/marinero4972/cyberv)|
|2506.07985|[rethinking crowd-sourced evaluation of neuron explanations](https://arxiv.org/abs/2506.07985)|[efficient_neuron_eval](https://github.com/trustworthy-ml-lab/efficient_neuron_eval)|
|2506.07992|[pairedit: learning semantic variations for exemplar-based image editing](https://arxiv.org/abs/2506.07992)|[pairedit](https://github.com/xudonmao/pairedit)|
|2506.07998|[generative modeling of weights: generalization or memorization?](https://arxiv.org/abs/2506.07998)|[weight_memorization](https://github.com/boyazeng/weight_memorization)|
|2506.08013|[stablemtl: repurposing latent diffusion models for multi-task learning from partially annotated synthetic datasets](https://arxiv.org/abs/2506.08013)|[stablemtl](https://github.com/astra-vision/stablemtl)|
|2506.02761|[rethinking machine unlearning in image generation models](https://arxiv.org/abs/2506.02761)|[igmu](https://github.com/ryliu68/igmu)|
|2506.03582|[semioccam: a robust semi-supervised image recognition network using sparse labels](https://arxiv.org/abs/2506.03582)|[SemiOccam](https://github.com/Shu1L0n9/SemiOccam)|
|2506.03664|[assessing intersectional bias in representations of pre-trained image recognition models](https://arxiv.org/abs/2506.03664)|[inntrospect](https://github.com/valeriekrug/inntrospect)|
|2506.04525|[user altruism in recommendation systems](https://arxiv.org/abs/2506.04525)|[recsys](https://github.com/mckitch24/recsys)|
|2506.05280|[unifying appearance codes and bilateral grids for driving scene gaussian splatting](https://arxiv.org/abs/2506.05280)|[bilateral-driving](https://github.com/bigcileng/bilateral-driving)|
|2506.05358|[can chatgpt perform image splicing detection? a preliminary study](https://arxiv.org/abs/2506.05358)|[LLM-Image-Splicing-Detection](https://github.com/confusedDip/LLM-Image-Splicing-Detection)|
|2506.05398|[igsm: improved geometric and sensitivity matching for finetuning pruned diffusion models](https://arxiv.org/abs/2506.05398)|[igsm-official](https://github.com/fate4869/igsm-official)|
|2506.05890|[unleashing the potential of consistency learning for detecting and grounding multi-modal media manipulation](https://arxiv.org/abs/2506.05890)|[cscl](https://github.com/liyih/cscl)|
|2506.06006|[bootstrapping world models from dynamics models in multimodal foundation models](https://arxiv.org/abs/2506.06006)|[vlm-world-model](https://github.com/yfqiu-nlp/vlm-world-model)|
|2506.06199|[3dflowaction: learning cross-embodiment manipulation from 3d flow world model](https://arxiv.org/abs/2506.06199)|[3dflowaction](https://github.com/hoyyyaard/3dflowaction)|
|2506.02444|[svimo: synchronized diffusion for video and motion generation in hand-object interaction scenarios](https://arxiv.org/abs/2506.02444)|[SViMo_code](https://github.com/Droliven/SViMo_code)|
|2506.03614|[vlms can aggregate scattered training patches](https://arxiv.org/abs/2506.03614)|[visual-stitching](https://github.com/zhziszz/visual-stitching)|
|2506.03951|[rethinking the stability-plasticity trade-off in continual learning from an architectural perspective](https://arxiv.org/abs/2506.03951)|[Dual-Arch](https://github.com/byyx666/Dual-Arch)|
|2506.03956|[adapt before continual learning](https://arxiv.org/abs/2506.03956)|[ACL_code](https://github.com/byyx666/ACL_code)|
|2506.04283|[ssimbad: sigma scaling with ssim-guided balanced diffusion for animeface colorization](https://arxiv.org/abs/2506.04283)|[ssimbad-sigma-scaling-with-ssim-guided-balanced-diffusion-for-animeface-colorization](https://github.com/giventicket/ssimbad-sigma-scaling-with-ssim-guided-balanced-diffusion-for-animeface-colorization)|
|2506.04444|[photoreal scene reconstruction from an egocentric device](https://arxiv.org/abs/2506.04444)|[egocentric_splats](https://github.com/facebookresearch/egocentric_splats)|
|2506.04453|[gradient inversion attacks on parameter-efficient fine-tuning](https://arxiv.org/abs/2506.04453)|[peftleak](https://github.com/info-ucr/peftleak)|
|2506.04755|[truth in the few: high-value data selection for efficient multi-modal reasoning](https://arxiv.org/abs/2506.04755)|[rap](https://github.com/leo-ssl/rap)|
|2506.04842|[mineinsight: a multi-sensor dataset for humanitarian demining robotics in off-road environments](https://arxiv.org/abs/2506.04842)|[mineinsight](https://github.com/mariomlz99/mineinsight)|
|2506.04867|[llms for sensory-motor control: combining in-context and iterative learning](https://arxiv.org/abs/2506.04867)|[llm-robotics-article](https://github.com/jtyska/llm-robotics-article)|
|2506.05204|[oggsplat: open gaussian growing for generalizable reconstruction with expanded field-of-view](https://arxiv.org/abs/2506.05204)|[OGGSplat](https://github.com/Yanbo-23/OGGSplat)|
|2506.05274|[from play to replay: composed video retrieval for temporally fine-grained videos](https://arxiv.org/abs/2506.05274)|[tf-covr](https://github.com/ucf-crcv/tf-covr)|
|2506.01950|[dualmap: online open-vocabulary semantic mapping for natural language navigation in dynamic changing scenes](https://arxiv.org/abs/2506.01950)|[dualmap](https://github.com/eku127/dualmap)|
|2506.02896|[flysearch: exploring how vision-language models explore](https://arxiv.org/abs/2506.02896)|[flysearch](https://github.com/gmum/flysearch)|
|2506.03310|[the reader is the metric: how textual features and reader profiles explain conflicting evaluations of ai creative writing](https://arxiv.org/abs/2506.03310)|[the-reader-is-the-metric](https://github.com/grmarco/the-reader-is-the-metric)|
|2506.03385|[from reality to recognition: evaluating visualization analogies for novice chart comprehension](https://arxiv.org/abs/2506.03385)|[analogyvis](https://github.com/hivelabuoft/analogyvis)|
|2506.03478|[facial appearance capture at home with patch-level reflectance prior](https://arxiv.org/abs/2506.03478)|[dora](https://github.com/yxuhan/dora)|
|2506.03530|[how far are we from predicting missing modalities with foundation models?](https://arxiv.org/abs/2506.03530)|[afm2](https://github.com/guanzhou-ke/afm2)|
|2506.03594|[splart: articulation estimation and part-level reconstruction with 3d gaussian splatting](https://arxiv.org/abs/2506.03594)|[splart](https://github.com/ripl/splart)|
|2506.03662|[zero-shot temporal interaction localization for egocentric videos](https://arxiv.org/abs/2506.03662)|[egoloc](https://github.com/irmvlab/egoloc)|
|2506.03735|[generating pedagogically meaningful visuals for math word problems: a new benchmark and analysis of text-to-image models](https://arxiv.org/abs/2506.03735)|[math2visual](https://github.com/eth-lre/math2visual)|
|2506.03831|[conformer-based ultrasound-to-speech conversion](https://arxiv.org/abs/2506.03831)|[conformer_UTS](https://github.com/ibrahimkhaliloglu/conformer_UTS)|
|2506.04016|[dreaming up scale invariance via inverse renormalization group](https://arxiv.org/abs/2506.04016)|[upscaling_ising](https://github.com/adam-rancon/upscaling_ising)|
|2506.04043|[think like a person before responding: a multi-faceted evaluation of persona-guided llms for countering hate](https://arxiv.org/abs/2506.04043)|[woah-2025](https://github.com/mikelkn/woah-2025)|
|2506.04211|[diffusion domain teacher: diffusion guided domain adaptive object detector](https://arxiv.org/abs/2506.04211)|[Diffusion-Domain-Teacher](https://github.com/heboyong/Diffusion-Domain-Teacher)|
|2506.04218|[pseudo-simulation for autonomous driving](https://arxiv.org/abs/2506.04218)|[navsim](https://github.com/autonomousvision/navsim)|
|2506.02214|[is pmbok guide the right fit for ai? re-evaluating project management in the face of artificial intelligence projects](https://arxiv.org/abs/2506.02214)|[geti](https://github.com/open-edge-platform/geti)|
|2506.02312|[dual encoding feature filtering generalized attention unet for retinal vessel segmentation](https://arxiv.org/abs/2506.02312)|[DEFFA-Unet](https://github.com/TauhidScu/DEFFA-Unet)|
|2506.02380|[eyenavgs: a 6-dof navigation dataset and record-n-replay software for real-world 3dgs scenes in vr](https://arxiv.org/abs/2506.02380)|[EyeNavGS_Software](https://github.com/symmru/EyeNavGS_Software)|
|2506.02514|[to embody or not: the effect of embodiment on user perception of llm-based conversational agents](https://arxiv.org/abs/2506.02514)|[to-embody-or-not](https://github.com/amaai-lab/to-embody-or-not)|
|2506.02736|[genea-slam2: dynamic slam with autoencoder-preprocessed genetic keypoints resampling and depth variance-guided dynamic region removal](https://arxiv.org/abs/2506.02736)|[GeneA-SLAM2](https://github.com/qingshufan/GeneA-SLAM2)|
|2506.02794|[physgaia: a physics-aware dataset of multi-body interactions for dynamic novel view synthesis](https://arxiv.org/abs/2506.02794)|[physgaia](https://github.com/mjmjeong/physgaia)|
|2506.02893|[dense match summarization for faster two-view estimation](https://arxiv.org/abs/2506.02893)|[DMS](https://github.com/jastermark/DMS)|
|2506.02895|[voltex: food volume estimation using text-guided segmentation and neural surface reconstruction](https://arxiv.org/abs/2506.02895)|[voltex](https://github.com/gcvcg/voltex)|
|2506.02911|[cell-o1: training llms to solve single-cell reasoning puzzles with reinforcement learning](https://arxiv.org/abs/2506.02911)|[cell-o1](https://github.com/ncbi-nlp/cell-o1)|
|2506.03097|[egovlm: policy optimization for egocentric video understanding](https://arxiv.org/abs/2506.03097)|[videgovlm](https://github.com/adityavavre/videgovlm)|
|2506.00325|[towards effective and efficient adversarial defense with diffusion models for robust visual tracking](https://arxiv.org/abs/2506.00325)|[DiffDf](https://github.com/pgao-lab/DiffDf)|
|2506.01091|[promptvfx: text-driven fields for open-world 3d gaussian animation](https://arxiv.org/abs/2506.01091)|[promptvfx](https://github.com/3Dwe-ai/promptvfx)|
|2506.01391|[agentcpm-gui: building mobile-use agents with reinforcement fine-tuning](https://arxiv.org/abs/2506.01391)|[AgentCPM-GUI](https://github.com/OpenBMB/AgentCPM-GUI)|
|2506.01482|[automatic stage lighting control: is it a rule-driven process or generative task?](https://arxiv.org/abs/2506.01482)|[Skip-BART](https://github.com/RS2002/Skip-BART)|
|2506.01806|[ridgeformer: mutli-stage contrastive training for fine-grained cross-domain fingerprint recognition](https://arxiv.org/abs/2506.01806)|[Ridgeformer](https://github.com/KNITPhoenix/Ridgeformer)|
|2506.01923|[taxadiffusion: progressively trained diffusion model for fine-grained species generation](https://arxiv.org/abs/2506.01923)|[TaxaDiffusion](https://github.com/aminK8/TaxaDiffusion)|

