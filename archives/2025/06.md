# June 2025 Archive

[Back to README](../../README.md)

|date|paper|code|
|---|---|---|
|2506.08010|[vision transformers don't need trained registers](https://arxiv.org/abs/2506.08010)|[test-time-registers](https://github.com/nickjiang2378/test-time-registers)|
|2506.09042|[cosmos-drive-dreams: scalable synthetic driving data generation with world foundation models](https://arxiv.org/abs/2506.09042)|[cosmos-drive-dreams](https://github.com/nv-tlabs/cosmos-drive-dreams)|
|2506.09881|[leveraging depth and language for open-vocabulary domain-generalized semantic segmentation](https://arxiv.org/abs/2506.09881)|[vireo](https://github.com/anonymouse-9c53tp182bvz/vireo)|
|2506.13045|[a comprehensive survey on continual learning in generative models](https://arxiv.org/abs/2506.13045)|[awesome-continual-learning-in-generative-models](https://github.com/ghy0501/awesome-continual-learning-in-generative-models)|
|2506.13776|[recommendations and reporting checklist for rigorous & transparent human baselines in model evaluations](https://arxiv.org/abs/2506.13776)|[human-baselines](https://github.com/kevinlwei/human-baselines)|
|2506.14777|[webxaii: an open-source web framework to study human-xai interaction](https://arxiv.org/abs/2506.14777)|[webxaii](https://github.com/pajean/webxaii)|
|2506.14823|[villa: a neuro-symbolic approach for animal monitoring](https://arxiv.org/abs/2506.14823)|[ViLLa](https://github.com/HarshaKoduri123/ViLLa)|
|2506.14842|[pictsure: pretraining embeddings matters for in-context learning image classifiers](https://arxiv.org/abs/2506.14842)|[pictsure-library](https://github.com/pictsure/pictsure-library)|
|2506.14907|[perl: permutation-enhanced reinforcement learning for interleaved vision-language reasoning](https://arxiv.org/abs/2506.14907)|[perl](https://github.com/alchemistyzz/perl)|
|2506.15078|[enhancing vector quantization with distributional matching: a theoretical and empirical study](https://arxiv.org/abs/2506.15078)|[wasserstein-vq](https://github.com/vq-research/wasserstein-vq)|
|2506.15084|[an empirical study of bugs in data visualization libraries](https://arxiv.org/abs/2506.15084)|[dataviz-lib-bugs](https://github.com/williamlus/dataviz-lib-bugs)|
|2506.15154|[sonicverse: multi-task learning for music feature-informed captioning](https://arxiv.org/abs/2506.15154)|[sonicverse](https://github.com/amaai-lab/sonicverse)|
|2506.15160|[enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation](https://arxiv.org/abs/2506.15160)|[pointdistribution](https://github.com/agent9717/pointdistribution)|
|2506.15182|[classification of multi-parametric body mri series using deep learning](https://arxiv.org/abs/2506.15182)|[mri_classifier](https://github.com/boahk/mri_classifier)|
|2506.15200|[conquering the retina: bringing visual in-context learning to oct](https://arxiv.org/abs/2506.15200)|[thesis-visual-in-context-learning](https://github.com/negralessio/thesis-visual-in-context-learning)|
|2506.15201|[privacy-shielded image compression: defending against exploitation from vision-language pretrained models](https://arxiv.org/abs/2506.15201)|[psic](https://github.com/jiayinxu5499/psic)|
|2506.15218|[dm-fnet: unified multimodal medical image fusion via diffusion process-trained encoder-decoder](https://arxiv.org/abs/2506.15218)|[dm-fnet](https://github.com/hedan-11/dm-fnet)|
|2506.15228|[abc: adaptive bayesnet structure learning for computational scalable multi-task image compression](https://arxiv.org/abs/2506.15228)|[cbench_basic](https://github.com/worldlife123/cbench_basic)|
|2506.15258|[privacy-preserving chest x-ray classification in latent space with homomorphically encrypted neural inference](https://arxiv.org/abs/2506.15258)|[latent-he](https://github.com/jongdory/latent-he)|
|2506.15312|[one-shot face sketch synthesis in the wild via generative diffusion prior and instruction tuning](https://arxiv.org/abs/2506.15312)|[os-sketch](https://github.com/hanwu3125/os-sketch)|
|2506.15313|[mapfm: foundation model-driven hd mapping with multi-task contextual learning](https://arxiv.org/abs/2506.15313)|[mapfm](https://github.com/livanoff/mapfm)|
|2506.15365|[fedwsidd: federated whole slide image classification via dataset distillation](https://arxiv.org/abs/2506.15365)|[fedwsidd](https://github.com/f1onae/fedwsidd)|
|2506.15368|[open-world object counting in videos](https://arxiv.org/abs/2506.15368)|[countvid](https://github.com/niki-amini-naieni/countvid)|
|2506.15442|[hunyuan3d 2.1: from images to high-fidelity 3d assets with production-ready pbr material](https://arxiv.org/abs/2506.15442)|[hunyuan3d-2.1](https://github.com/tencent-hunyuan/hunyuan3d-2.1)|
|2506.15499|[pixel-level certified explanations via randomized smoothing](https://arxiv.org/abs/2506.15499)|[certified-attributions](https://github.com/alaaanani/certified-attributions)|
|2506.15564|[show-o2: improved native unified multimodal models](https://arxiv.org/abs/2506.15564)|[show-o](https://github.com/showlab/show-o)|
|2506.15591|[one-step diffusion for detail-rich and temporally consistent video super-resolution](https://arxiv.org/abs/2506.15591)|[dloral](https://github.com/yjsunnn/dloral)|
|2506.15682|[evolutionary caching to accelerate your off-the-shelf diffusion model](https://arxiv.org/abs/2506.15682)|[ecad](https://github.com/aniaggarwal/ecad)|
|2506.01391|[agentcpm-gui: building mobile-use agents with reinforcement fine-tuning](https://arxiv.org/abs/2506.01391)|[AgentCPM-GUI](https://github.com/OpenBMB/AgentCPM-GUI)|
|2506.01413|[incentivizing reasoning for advanced instruction-following of large language models](https://arxiv.org/abs/2506.01413)|[raif](https://github.com/yuleiqin/raif)|
|2506.07917|[speedy deformable 3d gaussian splatting: fast rendering and compression of dynamic scenes](https://arxiv.org/abs/2506.07917)|[speede3dgs](https://github.com/tuallen/speede3dgs)|
|2506.08915|[inherently faithful attention maps for vision transformers](https://arxiv.org/abs/2506.08915)|[ifam](https://github.com/ananthu-aniraj/ifam)|
|2506.11154|[slrnet: a real-time lstm-based sign language recognition system](https://arxiv.org/abs/2506.11154)|[SLRNet](https://github.com/Khushi-739/SLRNet)|
|2506.13657|[lecture video visual objects (lvvo) dataset: a benchmark for visual object detection in educational videos](https://arxiv.org/abs/2506.13657)|[lvvo_dataset](https://github.com/dipayan1109033/lvvo_dataset)|
|2506.13807|[brats orchestrator : democratizing and disseminating state-of-the-art brain tumor image analysis](https://arxiv.org/abs/2506.13807)|[brats](https://github.com/brainlesion/brats)|
|2506.14107|[déjà vu: efficient video-language query engine with learning-based inter-frame computation reuse](https://arxiv.org/abs/2506.14107)|[dejavu](https://github.com/casys-kaist/dejavu)|
|2506.14130|[kdmos:knowledge distillation for motion segmentation](https://arxiv.org/abs/2506.14130)|[kdmos](https://github.com/scnu-rislab/kdmos)|
|2506.14243|[cross-modal geometric hierarchy fusion: an implicit-submap driven framework for resilient 3d place recognition](https://arxiv.org/abs/2506.14243)|[CMGHF](https://github.com/HBLT-hub/CMGHF)|
|2506.14582|[busting the paper ballot: voting meets adversarial machine learning](https://arxiv.org/abs/2506.14582)|[busting-the-ballot](https://github.com/votercenter/busting-the-ballot)|
|2506.14605|[unsupervised imaging inverse problems with diffusion distribution matching](https://arxiv.org/abs/2506.14605)|[ddm4ip](https://github.com/inria-thoth/ddm4ip)|
|2506.00868|[multiverse through deepfakes: the multifakeverse dataset of person-centric visual and conceptual manipulations](https://arxiv.org/abs/2506.00868)|[multifakeverse](https://github.com/parul-gupta/multifakeverse)|
|2506.03662|[zero-shot temporal interaction localization for egocentric videos](https://arxiv.org/abs/2506.03662)|[egoloc](https://github.com/irmvlab/egoloc)|
|2506.05633|[noninvasive precision modulation of high-level neural population activity via natural vision perturbations](https://arxiv.org/abs/2506.05633)|[directionalneuralmodulation](https://github.com/ggaziv/directionalneuralmodulation)|
|2506.06962|[ar-rag: autoregressive retrieval augmentation for image generation](https://arxiv.org/abs/2506.06962)|[AR-RAG](https://github.com/PLUM-Lab/AR-RAG)|
|2506.07327|[case: contrastive activation for saliency estimation](https://arxiv.org/abs/2506.07327)|[case-saliency](https://github.com/dwil2444/case-saliency)|
|2506.08185|[agentic surgical ai: surgeon style fingerprinting and privacy risk quantification via discrete diffusion in a vision-language-action framework](https://arxiv.org/abs/2506.08185)|[surgeon_style_fingerprinting](https://github.com/huixin-zhan-ai/surgeon_style_fingerprinting)|
|2506.09482|[marrying autoregressive transformer and diffusion with multi-reference autoregression](https://arxiv.org/abs/2506.09482)|[transdiff](https://github.com/transdiff/transdiff)|
|2506.10425|[it's not the target, it's the background: rethinking infrared small target detection via deep patch-free low-rank representations](https://arxiv.org/abs/2506.10425)|[lrrnet](https://github.com/halongbao/lrrnet)|
|2506.10821|[videodeepresearch: long video understanding with agentic tool using](https://arxiv.org/abs/2506.10821)|[videodeepresearch](https://github.com/yhy-2000/videodeepresearch)|
|2506.11140|[autonomous computer vision development with agentic ai](https://arxiv.org/abs/2506.11140)|[OpenManus-SimpleMind](https://github.com/jink-ucla/OpenManus-SimpleMind)|
|2506.12214|[clip the landscape: automated tagging of crowdsourced landscape images](https://arxiv.org/abs/2506.12214)|[ClipTheLandscape](https://github.com/SpaceTimeLab/ClipTheLandscape)|
|2506.12258|[egoprivacy: what your first-person camera says about you?](https://arxiv.org/abs/2506.12258)|[ego-privacy](https://github.com/williamium3000/ego-privacy)|
|2506.12269|[icme 2025 grand challenge on video super-resolution for video conferencing](https://arxiv.org/abs/2506.12269)|[vsr-challenge](https://github.com/microsoft/vsr-challenge)|
|2506.12295|[matchplant: an open-source pipeline for uav-based single-plant detection and data extraction](https://arxiv.org/abs/2506.12295)|[MatchPlant](https://github.com/JacobWashburn-USDA/MatchPlant)|
|2506.12339|[sheetmind: an end-to-end llm-powered multi-agent framework for spreadsheet automation](https://arxiv.org/abs/2506.12339)|[excel-agent](https://github.com/colonel-aureliano/excel-agent)|
|2506.12348|[real-time per-garment virtual try-on with temporal consistency for loose-fitting garments](https://arxiv.org/abs/2506.12348)|[RTV](https://github.com/ZaiqiangWu/RTV)|
|2506.12356|[splashnet: split-and-share encoders for accurate and efficient typing with surface electromyography](https://arxiv.org/abs/2506.12356)|[splashnet](https://github.com/nhadidi/splashnet)|
|2506.12413|[domain generalization for person re-identification: a survey towards domain-agnostic person matching](https://arxiv.org/abs/2506.12413)|[awesome-domain-generalizable-person-re-id](https://github.com/perceptualai-lab/awesome-domain-generalizable-person-re-id)|
|2506.12430|[pushing the limits of safety: a technical report on the atlas challenge 2025](https://arxiv.org/abs/2506.12430)|[atlas_challenge_2025](https://github.com/ny1024/atlas_challenge_2025)|
|2506.12524|[inference-time gaze refinement for micro-expression recognition: enhancing event-based eye tracking with motion-aware post-processing](https://arxiv.org/abs/2506.12524)|[eyelorin](https://github.com/eye-tracking-for-physiological-sensing/eyelorin)|
|2506.12541|[bsa: ball sparse attention for large-scale geometries](https://arxiv.org/abs/2506.12541)|[bsa](https://github.com/britacatalin/bsa)|
|2506.12610|[oscnet v1.5: energy efficient hopfield network on cmos oscillators for image classification](https://arxiv.org/abs/2506.12610)|[oscnet](https://github.com/russrobin/oscnet)|
|2506.12683|[evaluating cell type inference in vision language models under varying visual context](https://arxiv.org/abs/2506.12683)|[vlmcce](https://github.com/a12dongithub/vlmcce)|
|2506.12693|[zero-shot denoising via neural compression: theoretical and algorithmic framework](https://arxiv.org/abs/2506.12693)|[zs-ncdenoiser](https://github.com/computational-imaging-ru/zs-ncdenoiser)|
|2506.12935|[soundmind: rl-incentivized logic reasoning for audio-language models](https://arxiv.org/abs/2506.12935)|[soundmind](https://github.com/xid32/soundmind)|
|2506.12992|[smarthome-bench: a comprehensive benchmark for video anomaly detection in smart homes using multi-modal large language models](https://arxiv.org/abs/2506.12992)|[smarthome-bench-llm](https://github.com/xinyi-0724/smarthome-bench-llm)|
|2506.13001|[personalizable long-context symbolic music infilling with midi-rwkv](https://arxiv.org/abs/2506.13001)|[midi-rwkv](https://github.com/christianazinn/midi-rwkv)|
|2506.13027|[detrpose: real-time end-to-end transformer model for multi-person pose estimation](https://arxiv.org/abs/2506.13027)|[DETRPose](https://github.com/SebastianJanampa/DETRPose)|
|2506.13051|[stress-testing multimodal foundation models for crystallographic reasoning](https://arxiv.org/abs/2506.13051)|[stresstestingmmfmincr](https://github.com/kurbanintelligencelab/stresstestingmmfmincr)|
|2506.13089|[superpoint-slam3: augmenting orb-slam3 with deep features, adaptive nms, and learning-based loop closure](https://arxiv.org/abs/2506.13089)|[superpointslam3](https://github.com/shahram95/superpointslam3)|
|2506.13160|[certdw: towards certified dataset ownership verification via conformal prediction](https://arxiv.org/abs/2506.13160)|[certdw](https://github.com/ncepuqiaoting/certdw)|
|2506.13260|[come: adding scene-centric forecasting control to occupancy world model](https://arxiv.org/abs/2506.13260)|[come](https://github.com/synsin0/come)|
|2506.13275|[the transition matrix -- a classification of navigational patterns between lms course sections](https://arxiv.org/abs/2506.13275)|[Transition-Matrix](https://github.com/TobiasHildebrandt/Transition-Matrix)|
|2506.13326|[vis-shepherd: constructing critic for llm-based data visualization generation](https://arxiv.org/abs/2506.13326)|[vis-shepherd](https://github.com/bopan3/vis-shepherd)|
|2506.13348|[texturesplat: per-primitive texture mapping for reflective gaussian splatting](https://arxiv.org/abs/2506.13348)|[texturesplat](https://github.com/maeyounes/texturesplat)|
|2506.13387|[tr2m: transferring monocular relative depth to metric depth with language descriptions and scale-oriented contrast](https://arxiv.org/abs/2506.13387)|[tr2m](https://github.com/beileicui/tr2m)|
|2506.13415|[simple is what you need for efficient and accurate medical image segmentation](https://arxiv.org/abs/2506.13415)|[simpleunet](https://github.com/frankyu5666666/simpleunet)|
|2506.13465|[sa-lut: spatial adaptive 4d look-up table for photorealistic style transfer](https://arxiv.org/abs/2506.13465)|[sa-lut](https://github.com/ry3ng/sa-lut)|
|2506.13516|[micro-macro gaussian splatting with enhanced scalability for unconstrained scene reconstruction](https://arxiv.org/abs/2506.13516)|[smw-gs](https://github.com/kidleyh/smw-gs)|
|2506.13642|[stream-omni: simultaneous multimodal interactions with large language-vision-speech model](https://arxiv.org/abs/2506.13642)|[stream-omni](https://github.com/ictnlp/stream-omni)|
|2506.13685|[an llm's apology: outsourcing awkwardness in the age of ai](https://arxiv.org/abs/2506.13685)|[flake-bench](https://github.com/cloakless/flake-bench)|
|2506.13750|[test3r: learning to reconstruct 3d at test time](https://arxiv.org/abs/2506.13750)|[test3r](https://github.com/nopqaq/test3r)|
|2506.13757|[autovla: a vision-language-action model for end-to-end autonomous driving with adaptive reasoning and reinforcement fine-tuning](https://arxiv.org/abs/2506.13757)|[AutoVLA](https://github.com/ucla-mobility/AutoVLA)|
|2506.00073|[the automated but risky game: modeling agent-to-agent negotiations and transactions in consumer markets](https://arxiv.org/abs/2506.00073)|[A2A-NT](https://github.com/ShenzheZhu/A2A-NT)|
|2506.07903|[diffuse everything: multimodal diffusion models on arbitrary state spaces](https://arxiv.org/abs/2506.07903)|[diffuse-everything](https://github.com/kevinrojas1499/diffuse-everything)|
|2506.10009|[the iris file extension](https://arxiv.org/abs/2506.10009)|[iris-codec](https://github.com/irisdigitalpathology/iris-codec)|
|2506.10669|[pipvit: patch-based visual interpretable prototypes for retinal image analysis](https://arxiv.org/abs/2506.10669)|[pipvit](https://github.com/marziehoghbaie/pipvit)|
|2506.10730|[iqe-clip: instance-aware query embedding for zero-/few-shot anomaly detection in medical domain](https://arxiv.org/abs/2506.10730)|[iqe-clip](https://github.com/hongh0/iqe-clip)|
|2506.11131|[segment this thing: foveated tokenization for efficient point-prompted segmentation](https://arxiv.org/abs/2506.11131)|[segment_this_thing](https://github.com/facebookresearch/segment_this_thing)|
|2506.11133|[monocular 3d hand pose estimation with implicit camera alignment](https://arxiv.org/abs/2506.11133)|[handrepo](https://github.com/cpantazop/handrepo)|
|2506.11136|[jafar: jack up any feature at any resolution](https://arxiv.org/abs/2506.11136)|[jafar](https://github.com/paulcouairon/jafar)|
|2506.11139|[grids often outperform implicit neural representations](https://arxiv.org/abs/2506.11139)|[inr-benchmark](https://github.com/voilalab/inr-benchmark)|
|2506.11142|[farcluss: fuzzy adaptive rebalancing and contrastive uncertainty learning for semi-supervised semantic segmentation](https://arxiv.org/abs/2506.11142)|[FARCLUSS](https://github.com/psychofict/FARCLUSS)|
|2506.11252|[anti-aliased 2d gaussian splatting](https://arxiv.org/abs/2506.11252)|[aa-2dgs](https://github.com/maeyounes/aa-2dgs)|
|2506.11477|[fame: a lightweight spatio-temporal network for model attribution of face-swap deepfakes](https://arxiv.org/abs/2506.11477)|[FAME](https://github.com/wasim004/FAME)|
|2506.11543|[fima-q: post-training quantization for vision transformers by fisher information matrix approximation](https://arxiv.org/abs/2506.11543)|[fima-q](https://github.com/shihewang/fima-q)|
|2506.11661|[prohibited items segmentation via occlusion-aware bilayer modeling](https://arxiv.org/abs/2506.11661)|[occ](https://github.com/ryh1218/occ)|
|2506.11777|[self-supervised learning of echocardiographic video representations via online cluster distillation](https://arxiv.org/abs/2506.11777)|[discovr](https://github.com/mdivyanshu97/discovr)|
|2506.11823|[structural similarity-inspired unfolding for lightweight image super-resolution](https://arxiv.org/abs/2506.11823)|[ssiu](https://github.com/eezkni/ssiu)|
|2506.11827|[auditory-tactile congruence for synthesis of adaptive pain expressions in robopatients](https://arxiv.org/abs/2506.11827)|[submission_codes](https://github.com/nsaitarun-git/submission_codes)|
|2506.11989|[simple radiology vllm test-time scaling with thought graph traversal](https://arxiv.org/abs/2506.11989)|[Thought-Graph-Traversal](https://github.com/glerium/Thought-Graph-Traversal)|
|2506.12007|[simshift: a benchmark for adapting neural surrogates to distribution shifts](https://arxiv.org/abs/2506.12007)|[simshift](https://github.com/psetinek/simshift)|
|2506.08011|[play to generalize: learning to reason through game play](https://arxiv.org/abs/2506.08011)|[vigal](https://github.com/yunfeixie233/vigal)|
|2506.08735|[inceptionmamba: an efficient hybrid network with large band convolution and bottleneck mamba](https://arxiv.org/abs/2506.08735)|[inceptionmamba](https://github.com/wake1021/inceptionmamba)|
|2506.09042|[cosmos-drive-dreams: scalable synthetic driving data generation with world foundation models](https://arxiv.org/abs/2506.09042)|[cosmos-drive-dreams](https://github.com/nv-tlabs/cosmos-drive-dreams)|
|2506.09476|[urban1960satseg: unsupervised semantic segmentation of mid-20$^{th}$ century urban landscapes with satellite imageries](https://arxiv.org/abs/2506.09476)|[urban1960satseg](https://github.com/tianxiang-hao/urban1960satseg)|
|2506.09612|[consistent story generation with asymmetry zigzag sampling](https://arxiv.org/abs/2506.09612)|[asymmetry-zigzag-storydiffusion](https://github.com/mingxiao-li/asymmetry-zigzag-storydiffusion)|
|2506.09834|[mmme: a spontaneous multi-modal micro-expression dataset enabling visual-physiological fusion](https://arxiv.org/abs/2506.09834)|[mmme](https://github.com/mac0504/mmme)|
|2506.10036|[token perturbation guidance for diffusion models](https://arxiv.org/abs/2506.10036)|[token-perturbation-guidance](https://github.com/taatiteam/token-perturbation-guidance)|
|2506.10128|[vicrit: a verifiable reinforcement learning proxy task for visual perception in vlms](https://arxiv.org/abs/2506.10128)|[vicrit](https://github.com/si0wang/vicrit)|
|2506.10142|[rethinking brain tumor segmentation from the frequency domain perspective](https://arxiv.org/abs/2506.10142)|[hff](https://github.com/vinyehshaw/hff)|
|2506.10150|[when large language models are reliable for judging empathic communication](https://arxiv.org/abs/2506.10150)|[replication-data-and-code-when-LLMs-reliable-empathic-communication](https://github.com/aakriti1kumar/replication-data-and-code-when-LLMs-reliable-empathic-communication)|
|2506.10174|[retrieval of surface solar radiation through implicit albedo recovery from temporal context](https://arxiv.org/abs/2506.10174)|[hemu-dev](https://github.com/frischwood/hemu-dev)|
|2506.10178|[attention, please! revisiting attentive probing for masked image modeling](https://arxiv.org/abs/2506.10178)|[efficient-probing](https://github.com/billpsomas/efficient-probing)|
|2506.10182|[improving personalized search with regularized low-rank parameter updates](https://arxiv.org/abs/2506.10182)|[polar-vl](https://github.com/adobe-research/polar-vl)|
|2506.10228|[california crop yield benchmark: combining satellite image, climate, evapotranspiration, and soil data layers for county-level yield forecasting of over 70 crops](https://arxiv.org/abs/2506.10228)|[california-crop-yield-benchmark](https://github.com/plant-ai-biophysics-lab/california-crop-yield-benchmark)|
|2506.10325|[swdl: stratum-wise difference learning with deep laplacian pyramid for semi-supervised 3d intracranial hemorrhage segmentation](https://arxiv.org/abs/2506.10325)|[swdl](https://github.com/siat-ct-lab/swdl)|
|2506.10366|[fsatfusion: frequency-spatial attention transformer for infrared and visible image fusion](https://arxiv.org/abs/2506.10366)|[fsatfusion](https://github.com/lmmh058/fsatfusion)|
|2506.10386|[leveraging 6dof pose foundation models for mapping marine sediment burial](https://arxiv.org/abs/2506.10386)|[barrels](https://github.com/jerukan/barrels)|
|2506.10390|[dart: differentiable dynamic adaptive region tokenizer for vision transformer and mamba](https://arxiv.org/abs/2506.10390)|[dart](https://github.com/hcplab-sysu/dart)|
|2506.10391|[reconmost: multi-layer sea temperature reconstruction with observations-guided diffusion](https://arxiv.org/abs/2506.10391)|[reconmost](https://github.com/norsheep/reconmost)|
|2506.10452|[towards robust multimodal emotion recognition under missing modalities and distribution shifts](https://arxiv.org/abs/2506.10452)|[cider](https://github.com/gw-zhong/cider)|
|2506.10468|[low-barrier dataset collection with real human body for interactive per-garment virtual try-on](https://arxiv.org/abs/2506.10468)|[RTV](https://github.com/ZaiqiangWu/RTV)|
|2506.10550|[contextrefine-clip for epic-kitchens-100 multi-instance retrieval challenge 2025](https://arxiv.org/abs/2506.10550)|[contextrefine-clip](https://github.com/delcayr/contextrefine-clip)|
|2506.10580|[transformer imu calibrator: dynamic on-body imu calibration for inertial motion capture](https://arxiv.org/abs/2506.10580)|[tic](https://github.com/zuocx1996/tic)|
|2506.10601|[semantic-decoupled spatial partition guided point-supervised oriented object detection](https://arxiv.org/abs/2506.10601)|[ssp](https://github.com/antxinyuan/ssp)|
|2506.10609|[mstar: box-free multi-query scene text retrieval with attention recycling](https://arxiv.org/abs/2506.10609)|[mstar](https://github.com/yingift/mstar)|
|2506.10612|[textailor: customized text-aligned texturing via effective resampling](https://arxiv.org/abs/2506.10612)|[textailor](https://github.com/adios42/textailor)|
|2506.10632|[hessian geometry of latent space in generative models](https://arxiv.org/abs/2506.10632)|[hessian-geometry-of-diffusion-models](https://github.com/alobashev/hessian-geometry-of-diffusion-models)|
|2506.10890|[creatiposter: towards editable and controllable multi-layer graphic design generation](https://arxiv.org/abs/2506.10890)|[creatiposter](https://github.com/graphic-design-ai/creatiposter)|
|2506.10895|[air: zero-shot generative model adaptation with iterative refinement](https://arxiv.org/abs/2506.10895)|[air](https://github.com/guimeng-leo-liu/air)|
|2506.10967|[beyond attention or similarity: maximizing conditional diversity for token pruning in mllms](https://arxiv.org/abs/2506.10967)|[cdpruner](https://github.com/theia-4869/cdpruner)|
|2506.10977|[quadricformer: scene as superquadrics for 3d semantic occupancy prediction](https://arxiv.org/abs/2506.10977)|[quadricformer](https://github.com/zuosc19/quadricformer)|
|2506.05982|[mca-bench: a multimodal benchmark for evaluating captcha robustness against vlm-based attacks](https://arxiv.org/abs/2506.05982)|[mca-bench](https://github.com/noheadwuzonglin/mca-bench)|
|2506.07400|[medchat: a multi-agent framework for multimodal diagnosis with large language models](https://arxiv.org/abs/2506.07400)|[medchat](https://github.com/purdue-m2/medchat)|
|2506.07986|[rethinking cross-modal interaction in multimodal diffusion transformers](https://arxiv.org/abs/2506.07986)|[taca](https://github.com/vchitect/taca)|
|2506.08010|[vision transformers don't need trained registers](https://arxiv.org/abs/2506.08010)|[test-time-registers](https://github.com/nickjiang2378/test-time-registers)|
|2506.08772|[rs-mtdf: multi-teacher distillation and fusion for remote sensing semi-supervised semantic segmentation](https://arxiv.org/abs/2506.08772)|[semi-supervised-semantic-segmentation-with-distillation](https://github.com/earth-insights/semi-supervised-semantic-segmentation-with-distillation)|
|2506.08849|[adapting vision-language foundation model for next generation medical ultrasound image analysis](https://arxiv.org/abs/2506.08849)|[nextgen-uia](https://github.com/jinggqu/nextgen-uia)|
|2506.08900|[mirage: multimodal foundation model and benchmark for comprehensive retinal oct image analysis](https://arxiv.org/abs/2506.08900)|[mirage](https://github.com/j-morano/mirage)|
|2506.08908|[skipvar: accelerating visual autoregressive modeling via adaptive frequency-aware skipping](https://arxiv.org/abs/2506.08908)|[skipvar](https://github.com/fakerone-li/skipvar)|
|2506.09022|[do multiple instance learning models transfer?](https://arxiv.org/abs/2506.09022)|[mil-lab](https://github.com/mahmoodlab/mil-lab)|
|2506.09217|[perception characteristics distance: measuring stability and robustness of perception system in dynamic conditions under a certain decision rule](https://arxiv.org/abs/2506.09217)|[pcd_python](https://github.com/datadrivenwheels/pcd_python)|
|2506.09237|[patchguard: adversarially robust anomaly detection and localization through vision transformers and pseudo anomalies](https://arxiv.org/abs/2506.09237)|[patchgaurd](https://github.com/rohban-lab/patchgaurd)|
|2506.09344|[ming-omni: a unified multimodal model for perception and generation](https://arxiv.org/abs/2506.09344)|[ming](https://github.com/inclusionai/ming)|
|2506.09353|[davsp: safety alignment for large vision-language models via deep aligned visual safety prompt](https://arxiv.org/abs/2506.09353)|[davsp](https://github.com/zhangyitonggg/davsp)|
|2506.09363|[sage: exploring the boundaries of unsafe concept domain with semantic-augment erasing](https://arxiv.org/abs/2506.09363)|[sage](https://github.com/kevinlight831/sage)|
|2506.09369|[scalelsd: scalable deep line segment detection streamlined](https://arxiv.org/abs/2506.09369)|[scalelsd](https://github.com/ant-research/scalelsd)|
|2506.09385|[reid5o: achieving omni multi-modal person re-identification in a single model](https://arxiv.org/abs/2506.09385)|[reid5o_orbench](https://github.com/zplusdragon/reid5o_orbench)|
|2506.09403|[srpl-sfda: sam-guided reliable pseudo-labels for source-free domain adaptation in medical image segmentation](https://arxiv.org/abs/2506.09403)|[srpl-sfda](https://github.com/hilab-git/srpl-sfda)|
|2506.09416|[noise conditional variational score distillation](https://arxiv.org/abs/2506.09416)|[ncvsd](https://github.com/xypeng9903/ncvsd)|
|2506.09420|[a call for collaborative intelligence: why human-agent systems should precede ai autonomy](https://arxiv.org/abs/2506.09420)|[awesome-llm-based-human-agent-systems](https://github.com/henrypengzou/awesome-llm-based-human-agent-systems)|
|2506.09522|[revisit what you see: disclose language prior in vision tokens for efficient guided decoding of lvlms](https://arxiv.org/abs/2506.09522)|[ReVisiT](https://github.com/bscho333/ReVisiT)|
|2506.09626|[ecam: a contrastive learning approach to avoid environmental collision in trajectory forecasting](https://arxiv.org/abs/2506.09626)|[ecam](https://github.com/cvml-cfu/ecam)|
|2506.09650|[hopadiff: holistic-partial aware fourier conditioned diffusion for referring human action segmentation in multi-person scenarios](https://arxiv.org/abs/2506.09650)|[hopadiff](https://github.com/kpeng9510/hopadiff)|
|2506.09668|[cinema: conditional implicit neural multi-modal atlas for a spatio-temporal representation of the perinatal brain](https://arxiv.org/abs/2506.09668)|[cinema](https://github.com/m-dannecker/cinema)|
|2506.09691|[adding simple structure at inference improves vision-language compositionality](https://arxiv.org/abs/2506.09691)|[structure-inference-compositionality](https://github.com/imirandam/structure-inference-compositionality)|
|2506.09695|[towards practical alzheimer's disease diagnosis: a lightweight and interpretable spiking neural model](https://arxiv.org/abs/2506.09695)|[fastersnn](https://github.com/wuchangw/fastersnn)|
|2506.09709|[training-free voice conversion with factorized optimal transport](https://arxiv.org/abs/2506.09709)|[mkl-vc](https://github.com/alobashev/mkl-vc)|
|2506.09718|[non-contact health monitoring during daily personal care routines](https://arxiv.org/abs/2506.09718)|[fusionvitals](https://github.com/mcjacktang/fusionvitals)|
|2506.09724|[the four color theorem for cell instance segmentation](https://arxiv.org/abs/2506.09724)|[fcis](https://github.com/zhangye-zoe/fcis)|
|2506.09733|[atmosmj: revisiting gating mechanism for ai weather forecasting beyond the year scale](https://arxiv.org/abs/2506.09733)|[README.md](https://github.com/jmj2316/AtmosMJ/blob/main/README.md)|
|2506.09736|[vision matters: simple visual perturbations can boost multimodal math reasoning](https://arxiv.org/abs/2506.09736)|[easyr1](https://github.com/hiyouga/easyr1)|
|2506.09777|[inverting black-box face recognition systems via zero-order optimization in eigenface space](https://arxiv.org/abs/2506.09777)|[adversarialfaces](https://github.com/fusionbrainlab/adversarialfaces)|
|2506.09790|[comfyui-r1: exploring reasoning models for workflow generation](https://arxiv.org/abs/2506.09790)|[comfyui-copilot](https://github.com/aidc-ai/comfyui-copilot)|
|2506.09849|[intphys 2: benchmarking intuitive physics understanding in complex synthetic environments](https://arxiv.org/abs/2506.09849)|[intphys2](https://github.com/facebookresearch/intphys2)|
|2506.09881|[leveraging depth and language for open-vocabulary domain-generalized semantic segmentation](https://arxiv.org/abs/2506.09881)|[vireo](https://github.com/anonymouse-9c53tp182bvz/vireo)|
|2506.09883|[3d-aware vision-language models fine-tuning with geometric distillation](https://arxiv.org/abs/2506.09883)|[3d-vlm-gd](https://github.com/kaist-cvml/3d-vlm-gd)|
|2506.09895|[equicaps: predictor-free pose-aware pre-trained capsule networks](https://arxiv.org/abs/2506.09895)|[equicaps](https://github.com/aberdeenml/equicaps)|
|2506.09920|[structural-spectral graph convolution with evidential edge learning for hyperspectral image clustering](https://arxiv.org/abs/2506.09920)|[ssgco-egael](https://github.com/jhqi/ssgco-egael)|
|2506.09943|[causalvqa: a physically grounded causal reasoning benchmark for video models](https://arxiv.org/abs/2506.09943)|[causalvqa](https://github.com/facebookresearch/causalvqa)|
|2506.09949|[sampling theory for super-resolution with implicit neural representations](https://arxiv.org/abs/2506.09949)|[super_inrs](https://github.com/gregongie/super_inrs)|
|2506.09952|[unipre3d: unified pre-training of 3d point cloud models with cross-modal gaussian splatting](https://arxiv.org/abs/2506.09952)|[unipre3d](https://github.com/wangzy22/unipre3d)|
|2506.09953|[outside knowledge conversational video (okcv) dataset -- dialoguing over videos](https://arxiv.org/abs/2506.09953)|[okcv](https://github.com/c-patsch/okcv)|
|2506.09965|[reinforcing spatial reasoning in vision-language models with interwoven thinking and visual drawing](https://arxiv.org/abs/2506.09965)|[vilasr](https://github.com/antresearchnlp/vilasr)|
|2506.09980|[efficient part-level 3d object generation via dual volume packing](https://arxiv.org/abs/2506.09980)|[partpacker](https://github.com/nvlabs/partpacker)|
|2506.09985|[v-jepa 2: self-supervised video models enable understanding, prediction and planning](https://arxiv.org/abs/2506.09985)|[vjepa2](https://github.com/facebookresearch/vjepa2)|
|2506.09989|[hearing hands: generating sounds from physical interactions in 3d scenes](https://arxiv.org/abs/2506.09989)|[hearing_hands](https://github.com/dou-yiming/hearing_hands)|
|2506.07977|[oneig-bench: omni-dimensional nuanced evaluation for image generation](https://arxiv.org/abs/2506.07977)|[oneig-benchmark](https://github.com/oneig-bench/oneig-benchmark)|
|2506.08071|[cure: cultural gaps in the long tail of text-to-image systems](https://arxiv.org/abs/2506.08071)|[cure-bench](https://github.com/aniketrege/cure-bench)|
|2506.08189|[open world scene graph generation using vision language models](https://arxiv.org/abs/2506.08189)|[pix2grp_cvpr2024](https://github.com/shtuplus/pix2grp_cvpr2024)|
|2506.08277|[instruction-tuned video-audio models elucidate functional specialization in the brain](https://arxiv.org/abs/2506.08277)|[mllm_videos](https://github.com/subbareddy248/mllm_videos)|
|2506.08280|[snap-and-tune: combining deep learning and test-time optimization for high-fidelity cardiovascular volumetric meshing](https://arxiv.org/abs/2506.08280)|[deep-cardiac-volumetric-mesh](https://github.com/danpak94/deep-cardiac-volumetric-mesh)|
|2506.08299|[openrr-1k: a scalable dataset for real-world reflection removal](https://arxiv.org/abs/2506.08299)|[openrr-1k](https://github.com/caijie0620/openrr-1k)|
|2506.08353|[an adaptive method stabilizing activations for enhanced generalization](https://arxiv.org/abs/2506.08353)|[adaact](https://github.com/hseung88/adaact)|
|2506.08361|[image demoir\'eing using dual camera fusion on mobile phones](https://arxiv.org/abs/2506.08361)|[dcid](https://github.com/mrduckk/dcid)|
|2506.08391|[second: mitigating perceptual hallucination in vision-language models via selective and contrastive decoding](https://arxiv.org/abs/2506.08391)|[second](https://github.com/aidaslab/second)|
|2506.08520|[plug-and-play linear attention for pre-trained image and video restoration models](https://arxiv.org/abs/2506.08520)|[pnp_nystra](https://github.com/srinivas-512/pnp_nystra)|
|2506.08591|[diversity-guided mlp reduction for efficient large vision transformers](https://arxiv.org/abs/2506.08591)|[DGMR](https://github.com/visresearch/DGMR)|
|2506.08611|[towards class-wise fair adversarial training via anti-bias soft label distillation](https://arxiv.org/abs/2506.08611)|[absld](https://github.com/zhaoshiji123/absld)|
|2506.08613|[samselect: a spectral index search for marine debris visualization using segment anything](https://arxiv.org/abs/2506.08613)|[samselect](https://github.com/geojoost/samselect)|
|2506.08618|[hsg-12m: a large-scale spatial multigraph dataset](https://arxiv.org/abs/2506.08618)|[hsg-12m](https://github.com/sarinstein-yan/hsg-12m)|
|2506.08691|[vrest: enhancing reasoning in large vision-language models through tree search and self-reward mechanism](https://arxiv.org/abs/2506.08691)|[vrest](https://github.com/garyjiajia/vrest)|
|2506.08694|[mosic: optimal-transport motion trajectory for dense self-supervised learning](https://arxiv.org/abs/2506.08694)|[mosic](https://github.com/smsd75/mosic)|
|2506.08761|[normalized radon cumulative distribution transforms for invariance and robustness in optimal transport based image classification](https://arxiv.org/abs/2506.08761)|[nr-cdt](https://github.com/drbeckmann/nr-cdt)|
|2506.08862|[streamsplat: towards online dynamic 3d reconstruction from uncalibrated video streams](https://arxiv.org/abs/2506.08862)|[streamsplat](https://github.com/nickwzk/streamsplat)|
|2506.08887|[discovla: discrepancy reduction in vision, language, and alignment for parameter-efficient video-text retrieval](https://arxiv.org/abs/2506.08887)|[dsicovla](https://github.com/lunarshen/dsicovla)|
|2506.08949|[sss: semi-supervised sam-2 with efficient prompting for medical imaging segmentation](https://arxiv.org/abs/2506.08949)|[sss](https://github.com/aigeeksgroup/sss)|
|2506.08990|[efficient medical vision-language alignment through adapting masked vision models](https://arxiv.org/abs/2506.08990)|[alta](https://github.com/dopaminelcy/alta)|
|2506.08997|[sdtagnet: leveraging text-annotated navigation maps for online hd map construction](https://arxiv.org/abs/2506.08997)|[sdtagnet](https://github.com/immel-f/sdtagnet)|
|2506.09040|[autoregressive semantic visual reconstruction helps vlms understand better](https://arxiv.org/abs/2506.09040)|[asvr](https://github.com/alenjandrowang/asvr)|
|2506.09045|[magcache: fast video generation with magnitude-aware cache](https://arxiv.org/abs/2506.09045)|[magcache](https://github.com/zehong-ma/magcache)|
|2506.00978|[capaa: classifier-agnostic projector-based adversarial attack](https://arxiv.org/abs/2506.00978)|[capaa](https://github.com/zhanliqxq/capaa)|
|2506.03988|[raid: a dataset for testing the adversarial robustness of ai-generated image detectors](https://arxiv.org/abs/2506.03988)|[raid](https://github.com/pralab/raid)|
|2506.05660|[tissunet: improved extracranial tissue and cranium segmentation for children through adulthood](https://arxiv.org/abs/2506.05660)|[TissUNet](https://github.com/AIM-KannLab/TissUNet)|
|2506.06315|[an open-source python framework and synthetic ecg image datasets for digitization, lead and lead name detection, and overlapping signal segmentation](https://arxiv.org/abs/2506.06315)|[ecg-image-and-signal-dataset](https://github.com/rezakarbasi/ecg-image-and-signal-dataset)|
|2506.06474|[edge-enabled collaborative object detection for real-time multi-vehicle perception](https://arxiv.org/abs/2506.06474)|[Edge-CAV](https://github.com/EverettRichards/Edge-CAV)|
|2506.06664|[generalized trajectory scoring for end-to-end multimodal planning](https://arxiv.org/abs/2506.06664)|[gtrs](https://github.com/nvlabs/gtrs)|
|2506.06667|[flood-damagesense: multimodal mamba with multitask learning for building flood damage assessment using sar remote sensing imagery](https://arxiv.org/abs/2506.06667)|[flood-damagesense](https://github.com/violayhho/flood-damagesense)|
|2506.06710|[a systematic investigation on deep learning-based omnidirectional image and video super-resolution](https://arxiv.org/abs/2506.06710)|[survey-on-odisr-and-odvsr](https://github.com/nqian1/survey-on-odisr-and-odvsr)|
|2506.06771|[loopdb: a loop closure dataset for large scale simultaneous localization and mapping](https://arxiv.org/abs/2506.06771)|[loopdb](https://github.com/rovislab/loopdb)|
|2506.06906|[knn-defense: defense against 3d adversarial point clouds using nearest-neighbor search](https://arxiv.org/abs/2506.06906)|[3d-knn-defense](https://github.com/nimajam41/3d-knn-defense)|
|2506.06933|[rewriting the budget: a general framework for black-box attacks under cost asymmetry](https://arxiv.org/abs/2506.06933)|[asymmetric-attacks](https://github.com/mahdisalmani/asymmetric-attacks)|
|2506.07138|[learning compact vision tokens for efficient large multimodal models](https://arxiv.org/abs/2506.07138)|[LLaVA-STF](https://github.com/visresearch/LLaVA-STF)|
|2506.07364|[multiple object stitching for unsupervised representation learning](https://arxiv.org/abs/2506.07364)|[MultipleObjectStitching](https://github.com/visresearch/MultipleObjectStitching)|
|2506.07530|[bitvla: 1-bit vision-language-action models for robotics manipulation](https://arxiv.org/abs/2506.07530)|[bitvla](https://github.com/ustcwhy/bitvla)|
|2506.07539|[domain randomization for object detection in manufacturing applications using synthetic data: a comprehensive study](https://arxiv.org/abs/2506.07539)|[synmfg_code](https://github.com/jacobhenningsson95/synmfg_code)|
|2506.07558|[immersive visualization of flat surfaces using ray marching](https://arxiv.org/abs/2506.07558)|[raymarchingflatsurfaces](https://github.com/fabianlander/raymarchingflatsurfaces)|
|2506.07773|[trend-aware fashion recommendation with visual segmentation and semantic similarity](https://arxiv.org/abs/2506.07773)|[fashionrecommender](https://github.com/meddjilani/fashionrecommender)|
|2506.07811|[looking beyond visible cues: implicit video question answering via dual-clue reasoning](https://arxiv.org/abs/2506.07811)|[implicit-videoqa](https://github.com/tychen-sjtu/implicit-videoqa)|
|2506.07841|[diffusion models under low-noise regime](https://arxiv.org/abs/2506.07841)|[diffusion_low_noise_regime](https://github.com/lizardp1/diffusion_low_noise_regime)|
|2506.07857|[logosp: local-global grouping of superpoints for unsupervised semantic segmentation of 3d point clouds](https://arxiv.org/abs/2506.07857)|[logosp](https://github.com/vlar-group/logosp)|
|2506.07860|[egocentric event-based vision for ping pong ball trajectory prediction](https://arxiv.org/abs/2506.07860)|[event_based_ping_pong_ball_trajectory_prediction](https://github.com/uzh-rpg/event_based_ping_pong_ball_trajectory_prediction)|
|2506.07865|[freegave: 3d physics learning from dynamic videos by gaussian velocity](https://arxiv.org/abs/2506.07865)|[freegave](https://github.com/vlar-group/freegave)|
|2506.07878|[spatio-temporal state space model for efficient event-based optical flow](https://arxiv.org/abs/2506.07878)|[e-stmflow](https://github.com/ahmedhumais/e-stmflow)|
|2506.07883|[diffusion counterfactual generation with semantic abduction](https://arxiv.org/abs/2506.07883)|[diffusion-counterfactuals](https://github.com/rajatrasal/diffusion-counterfactuals)|
|2506.07905|[wethink: toward general-purpose vision-language reasoning via reinforcement learning](https://arxiv.org/abs/2506.07905)|[wethink](https://github.com/yangjie-cv/wethink)|
|2506.07917|[speedy deformable 3d gaussian splatting: fast rendering and compression of dynamic scenes](https://arxiv.org/abs/2506.07917)|[speede3dgs](https://github.com/tuallen/speede3dgs)|
|2506.07964|[slidecoder: layout-aware rag-enhanced hierarchical slide generation from design](https://arxiv.org/abs/2506.07964)|[slidecoder](https://github.com/vinsontang1/slidecoder)|
|2506.07966|[space-10: a comprehensive benchmark for multimodal large language models in compositional spatial intelligence](https://arxiv.org/abs/2506.07966)|[space-10](https://github.com/cuzyoung/space-10)|
|2506.07971|[cyberv: cybernetics for test-time scaling in video understanding](https://arxiv.org/abs/2506.07971)|[cyberv](https://github.com/marinero4972/cyberv)|
|2506.07985|[rethinking crowd-sourced evaluation of neuron explanations](https://arxiv.org/abs/2506.07985)|[efficient_neuron_eval](https://github.com/trustworthy-ml-lab/efficient_neuron_eval)|
|2506.07992|[pairedit: learning semantic variations for exemplar-based image editing](https://arxiv.org/abs/2506.07992)|[pairedit](https://github.com/xudonmao/pairedit)|
|2506.07998|[generative modeling of weights: generalization or memorization?](https://arxiv.org/abs/2506.07998)|[weight_memorization](https://github.com/boyazeng/weight_memorization)|
|2506.08013|[stablemtl: repurposing latent diffusion models for multi-task learning from partially annotated synthetic datasets](https://arxiv.org/abs/2506.08013)|[stablemtl](https://github.com/astra-vision/stablemtl)|
|2506.02761|[rethinking machine unlearning in image generation models](https://arxiv.org/abs/2506.02761)|[igmu](https://github.com/ryliu68/igmu)|
|2506.03582|[semioccam: a robust semi-supervised image recognition network using sparse labels](https://arxiv.org/abs/2506.03582)|[SemiOccam](https://github.com/Shu1L0n9/SemiOccam)|
|2506.03664|[assessing intersectional bias in representations of pre-trained image recognition models](https://arxiv.org/abs/2506.03664)|[inntrospect](https://github.com/valeriekrug/inntrospect)|
|2506.04525|[user altruism in recommendation systems](https://arxiv.org/abs/2506.04525)|[recsys](https://github.com/mckitch24/recsys)|
|2506.05280|[unifying appearance codes and bilateral grids for driving scene gaussian splatting](https://arxiv.org/abs/2506.05280)|[bilateral-driving](https://github.com/bigcileng/bilateral-driving)|
|2506.05358|[can chatgpt perform image splicing detection? a preliminary study](https://arxiv.org/abs/2506.05358)|[LLM-Image-Splicing-Detection](https://github.com/confusedDip/LLM-Image-Splicing-Detection)|
|2506.05398|[igsm: improved geometric and sensitivity matching for finetuning pruned diffusion models](https://arxiv.org/abs/2506.05398)|[igsm-official](https://github.com/fate4869/igsm-official)|
|2506.05890|[unleashing the potential of consistency learning for detecting and grounding multi-modal media manipulation](https://arxiv.org/abs/2506.05890)|[cscl](https://github.com/liyih/cscl)|
|2506.06006|[bootstrapping world models from dynamics models in multimodal foundation models](https://arxiv.org/abs/2506.06006)|[vlm-world-model](https://github.com/yfqiu-nlp/vlm-world-model)|
|2506.06199|[3dflowaction: learning cross-embodiment manipulation from 3d flow world model](https://arxiv.org/abs/2506.06199)|[3dflowaction](https://github.com/hoyyyaard/3dflowaction)|
|2506.02444|[svimo: synchronized diffusion for video and motion generation in hand-object interaction scenarios](https://arxiv.org/abs/2506.02444)|[SViMo_code](https://github.com/Droliven/SViMo_code)|
|2506.03614|[vlms can aggregate scattered training patches](https://arxiv.org/abs/2506.03614)|[visual-stitching](https://github.com/zhziszz/visual-stitching)|
|2506.03951|[rethinking the stability-plasticity trade-off in continual learning from an architectural perspective](https://arxiv.org/abs/2506.03951)|[Dual-Arch](https://github.com/byyx666/Dual-Arch)|
|2506.03956|[adapt before continual learning](https://arxiv.org/abs/2506.03956)|[ACL_code](https://github.com/byyx666/ACL_code)|
|2506.04283|[ssimbad: sigma scaling with ssim-guided balanced diffusion for animeface colorization](https://arxiv.org/abs/2506.04283)|[ssimbad-sigma-scaling-with-ssim-guided-balanced-diffusion-for-animeface-colorization](https://github.com/giventicket/ssimbad-sigma-scaling-with-ssim-guided-balanced-diffusion-for-animeface-colorization)|
|2506.04444|[photoreal scene reconstruction from an egocentric device](https://arxiv.org/abs/2506.04444)|[egocentric_splats](https://github.com/facebookresearch/egocentric_splats)|
|2506.04453|[gradient inversion attacks on parameter-efficient fine-tuning](https://arxiv.org/abs/2506.04453)|[peftleak](https://github.com/info-ucr/peftleak)|
|2506.04755|[truth in the few: high-value data selection for efficient multi-modal reasoning](https://arxiv.org/abs/2506.04755)|[rap](https://github.com/leo-ssl/rap)|
|2506.04842|[mineinsight: a multi-sensor dataset for humanitarian demining robotics in off-road environments](https://arxiv.org/abs/2506.04842)|[mineinsight](https://github.com/mariomlz99/mineinsight)|
|2506.04867|[llms for sensory-motor control: combining in-context and iterative learning](https://arxiv.org/abs/2506.04867)|[llm-robotics-article](https://github.com/jtyska/llm-robotics-article)|
|2506.05204|[oggsplat: open gaussian growing for generalizable reconstruction with expanded field-of-view](https://arxiv.org/abs/2506.05204)|[OGGSplat](https://github.com/Yanbo-23/OGGSplat)|
|2506.05274|[from play to replay: composed video retrieval for temporally fine-grained videos](https://arxiv.org/abs/2506.05274)|[tf-covr](https://github.com/ucf-crcv/tf-covr)|
|2506.01950|[dualmap: online open-vocabulary semantic mapping for natural language navigation in dynamic changing scenes](https://arxiv.org/abs/2506.01950)|[dualmap](https://github.com/eku127/dualmap)|
|2506.02896|[flysearch: exploring how vision-language models explore](https://arxiv.org/abs/2506.02896)|[flysearch](https://github.com/gmum/flysearch)|
|2506.03310|[the reader is the metric: how textual features and reader profiles explain conflicting evaluations of ai creative writing](https://arxiv.org/abs/2506.03310)|[the-reader-is-the-metric](https://github.com/grmarco/the-reader-is-the-metric)|
|2506.03385|[from reality to recognition: evaluating visualization analogies for novice chart comprehension](https://arxiv.org/abs/2506.03385)|[analogyvis](https://github.com/hivelabuoft/analogyvis)|
|2506.03478|[facial appearance capture at home with patch-level reflectance prior](https://arxiv.org/abs/2506.03478)|[dora](https://github.com/yxuhan/dora)|
|2506.03530|[how far are we from predicting missing modalities with foundation models?](https://arxiv.org/abs/2506.03530)|[afm2](https://github.com/guanzhou-ke/afm2)|
|2506.03594|[splart: articulation estimation and part-level reconstruction with 3d gaussian splatting](https://arxiv.org/abs/2506.03594)|[splart](https://github.com/ripl/splart)|
|2506.03662|[zero-shot temporal interaction localization for egocentric videos](https://arxiv.org/abs/2506.03662)|[egoloc](https://github.com/irmvlab/egoloc)|
|2506.03735|[generating pedagogically meaningful visuals for math word problems: a new benchmark and analysis of text-to-image models](https://arxiv.org/abs/2506.03735)|[math2visual](https://github.com/eth-lre/math2visual)|
|2506.03831|[conformer-based ultrasound-to-speech conversion](https://arxiv.org/abs/2506.03831)|[conformer_UTS](https://github.com/ibrahimkhaliloglu/conformer_UTS)|
|2506.04016|[dreaming up scale invariance via inverse renormalization group](https://arxiv.org/abs/2506.04016)|[upscaling_ising](https://github.com/adam-rancon/upscaling_ising)|
|2506.04043|[think like a person before responding: a multi-faceted evaluation of persona-guided llms for countering hate](https://arxiv.org/abs/2506.04043)|[woah-2025](https://github.com/mikelkn/woah-2025)|
|2506.04211|[diffusion domain teacher: diffusion guided domain adaptive object detector](https://arxiv.org/abs/2506.04211)|[Diffusion-Domain-Teacher](https://github.com/heboyong/Diffusion-Domain-Teacher)|
|2506.04218|[pseudo-simulation for autonomous driving](https://arxiv.org/abs/2506.04218)|[navsim](https://github.com/autonomousvision/navsim)|
|2506.02214|[is pmbok guide the right fit for ai? re-evaluating project management in the face of artificial intelligence projects](https://arxiv.org/abs/2506.02214)|[geti](https://github.com/open-edge-platform/geti)|
|2506.02312|[dual encoding feature filtering generalized attention unet for retinal vessel segmentation](https://arxiv.org/abs/2506.02312)|[DEFFA-Unet](https://github.com/TauhidScu/DEFFA-Unet)|
|2506.02380|[eyenavgs: a 6-dof navigation dataset and record-n-replay software for real-world 3dgs scenes in vr](https://arxiv.org/abs/2506.02380)|[EyeNavGS_Software](https://github.com/symmru/EyeNavGS_Software)|
|2506.02514|[to embody or not: the effect of embodiment on user perception of llm-based conversational agents](https://arxiv.org/abs/2506.02514)|[to-embody-or-not](https://github.com/amaai-lab/to-embody-or-not)|
|2506.02736|[genea-slam2: dynamic slam with autoencoder-preprocessed genetic keypoints resampling and depth variance-guided dynamic region removal](https://arxiv.org/abs/2506.02736)|[GeneA-SLAM2](https://github.com/qingshufan/GeneA-SLAM2)|
|2506.02794|[physgaia: a physics-aware dataset of multi-body interactions for dynamic novel view synthesis](https://arxiv.org/abs/2506.02794)|[physgaia](https://github.com/mjmjeong/physgaia)|
|2506.02893|[dense match summarization for faster two-view estimation](https://arxiv.org/abs/2506.02893)|[DMS](https://github.com/jastermark/DMS)|
|2506.02895|[voltex: food volume estimation using text-guided segmentation and neural surface reconstruction](https://arxiv.org/abs/2506.02895)|[voltex](https://github.com/gcvcg/voltex)|
|2506.02911|[cell-o1: training llms to solve single-cell reasoning puzzles with reinforcement learning](https://arxiv.org/abs/2506.02911)|[cell-o1](https://github.com/ncbi-nlp/cell-o1)|
|2506.03097|[egovlm: policy optimization for egocentric video understanding](https://arxiv.org/abs/2506.03097)|[videgovlm](https://github.com/adityavavre/videgovlm)|
|2506.00325|[towards effective and efficient adversarial defense with diffusion models for robust visual tracking](https://arxiv.org/abs/2506.00325)|[DiffDf](https://github.com/pgao-lab/DiffDf)|
|2506.01091|[promptvfx: text-driven fields for open-world 3d gaussian animation](https://arxiv.org/abs/2506.01091)|[promptvfx](https://github.com/3Dwe-ai/promptvfx)|
|2506.01391|[agentcpm-gui: building mobile-use agents with reinforcement fine-tuning](https://arxiv.org/abs/2506.01391)|[AgentCPM-GUI](https://github.com/OpenBMB/AgentCPM-GUI)|
|2506.01482|[automatic stage lighting control: is it a rule-driven process or generative task?](https://arxiv.org/abs/2506.01482)|[Skip-BART](https://github.com/RS2002/Skip-BART)|
|2506.01806|[ridgeformer: mutli-stage contrastive training for fine-grained cross-domain fingerprint recognition](https://arxiv.org/abs/2506.01806)|[Ridgeformer](https://github.com/KNITPhoenix/Ridgeformer)|
|2506.01923|[taxadiffusion: progressively trained diffusion model for fine-grained species generation](https://arxiv.org/abs/2506.01923)|[TaxaDiffusion](https://github.com/aminK8/TaxaDiffusion)|

