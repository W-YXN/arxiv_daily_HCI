# May 2025 Archive

[Back to README](../../README.md)

|date|paper|code|
|---|---|---|
|2505.04229|[a weak supervision learning approach towards an equitable mobility estimation](https://arxiv.org/abs/2505.04229)|[equitable_mobility_estimation](https://github.com/societal-computing/equitable_mobility_estimation)|
|2505.12363|[towards visuospatial cognition via hierarchical fusion of visual experts](https://arxiv.org/abs/2505.12363)|[vica](https://github.com/nkkbr/vica)|
|2505.14664|[akrmap: adaptive kernel regression for trustworthy visualization of cross-modal embeddings](https://arxiv.org/abs/2505.14664)|[akrmap](https://github.com/yilinye/akrmap)|
|2505.16832|[from eduvisbench to eduvisagent: a benchmark and multi-agent framework for reasoning-driven pedagogical visualization](https://arxiv.org/abs/2505.16832)|[eduvisbench](https://github.com/aiming-lab/eduvisbench)|
|2505.17002|[paeff: precise alignment and enhanced gated feature fusion for face-voice association](https://arxiv.org/abs/2505.17002)|[paeff](https://github.com/hannabdul/paeff)|
|2505.17937|[survival games: human-llm strategic showdowns under severe resource scarcity](https://arxiv.org/abs/2505.17937)|[survival-games](https://github.com/hong123123/survival-games)|
|2505.20292|[opens2v-nexus: a detailed benchmark and million-scale dataset for subject-to-video generation](https://arxiv.org/abs/2505.20292)|[ConsisID](https://github.com/PKU-YuanGroup/ConsisID)|
|2505.21136|[sageattention2++: a more efficient implementation of sageattention2](https://arxiv.org/abs/2505.21136)|[SageAttention](https://github.com/thu-ml/SageAttention)|
|2505.21544|[vision meets language: a rag-augmented yolov8 framework for coffee disease diagnosis and farmer assistance](https://arxiv.org/abs/2505.21544)|[A-RAG-Augmented-YOLOv8-Framework](https://github.com/semanto-mondal/A-RAG-Augmented-YOLOv8-Framework)|
|2505.21925|[renderformer: transformer-based neural rendering of triangle meshes with global illumination](https://arxiv.org/abs/2505.21925)|[renderformer](https://github.com/microsoft/renderformer)|
|2505.21954|[unitalk: towards universal active speaker detection in real world scenarios](https://arxiv.org/abs/2505.21954)|[UniTalk-ASD-code](https://github.com/plnguyen2908/UniTalk-ASD-code)|
|2505.22228|[gomatching++: parameter- and data-efficient arbitrary-shaped video text spotting and benchmarking](https://arxiv.org/abs/2505.22228)|[gomatching](https://github.com/hxyz-123/gomatching)|
|2505.22664|[zero-shot vision encoder grafting via llm surrogates](https://arxiv.org/abs/2505.22664)|[zero](https://github.com/facebookresearch/zero)|
|2505.10464|[hwa-unetr: hierarchical window aggregate unetr for 3d multimodal gastric lesion segmentation](https://arxiv.org/abs/2505.10464)|[hwa-unetr](https://github.com/jeming-creater/hwa-unetr)|
|2505.10610|[mmlongbench: benchmarking long-context vision-language models effectively and thoroughly](https://arxiv.org/abs/2505.10610)|[mmlongbench](https://github.com/edinburghnlp/mmlongbench)|
|2505.12155|[softpq: robust instance segmentation evaluation via soft matching and tunable thresholds](https://arxiv.org/abs/2505.12155)|[SoftPQ](https://github.com/rkarmaka/SoftPQ)|
|2505.12499|[rebalancing contrastive alignment with learnable semantic gaps in text-video retrieval](https://arxiv.org/abs/2505.12499)|[gare-text-video-retrieval](https://github.com/musicman217/gare-text-video-retrieval)|
|2505.13539|[eulearn: a 3d database for learning euler characteristics](https://arxiv.org/abs/2505.13539)|[eulearn_db](https://github.com/appliedgeometry/eulearn_db)|
|2505.15812|[leveraging the powerful attention of a pre-trained diffusion model for exemplar-based image colorization](https://arxiv.org/abs/2505.15812)|[powerful-attention](https://github.com/satoshi-kosugi/powerful-attention)|
|2505.17013|[when are concepts erased from diffusion models?](https://arxiv.org/abs/2505.17013)|[diffusionconcepterasure](https://github.com/kevinlu4588/diffusionconcepterasure)|
|2505.17629|[transbench: breaking barriers for transferable graphical user interface agents in dynamic digital environments](https://arxiv.org/abs/2505.17629)|[transbench](https://github.com/buaa-irip-llm/transbench)|
|2505.18022|[remotesam: towards segment anything for earth observation](https://arxiv.org/abs/2505.18022)|[RemoteSAM](https://github.com/1e12Leon/RemoteSAM)|
|2505.18060|[semantic correspondence: unified benchmarking and a strong baseline](https://arxiv.org/abs/2505.18060)|[Semantic-Correspondence](https://github.com/Visual-AI/Semantic-Correspondence)|
|2505.18958|[cdpdnet: integrating text guidance with hybrid vision encoders for medical image segmentation](https://arxiv.org/abs/2505.18958)|[cdpdnet](https://github.com/wujiong-hub/cdpdnet)|
|2505.20414|[retromotion: retrocausal motion forecasting models are instructable](https://arxiv.org/abs/2505.20414)|[future-motion](https://github.com/kit-mrt/future-motion)|
|2505.20426|[mmperspective: do mllms understand perspective? a comprehensive benchmark for perspective perception, reasoning, and robustness](https://arxiv.org/abs/2505.20426)|[MMPerspective](https://github.com/yunlong10/MMPerspective)|
|2505.20753|[understand, think, and answer: advancing visual reasoning with large multimodal models](https://arxiv.org/abs/2505.20753)|[griffon](https://github.com/jefferyzhan/griffon)|
|2505.21032|[featinv: spatially resolved mapping from feature space to input space using conditional diffusion models](https://arxiv.org/abs/2505.21032)|[FeatInv](https://github.com/AI4HealthUOL/FeatInv)|
|2505.21152|[robis: robust binary segmentation for high-resolution industrial images](https://arxiv.org/abs/2505.21152)|[robis](https://github.com/xrli-u/robis)|
|2505.21375|[geollava-8k: scaling remote-sensing multimodal large language models to 8k resolution](https://arxiv.org/abs/2505.21375)|[GeoLLaVA-8K](https://github.com/MiliLab/GeoLLaVA-8K)|
|2505.04119|[gaprompt: geometry-aware point cloud prompt for 3d vision model](https://arxiv.org/abs/2505.04119)|[icml2025-vgp](https://github.com/zhoujiahuan1991/icml2025-vgp)|
|2505.04121|[vision graph prompting via semantic low-rank decomposition](https://arxiv.org/abs/2505.04121)|[icml2025-vgp](https://github.com/zhoujiahuan1991/icml2025-vgp)|
|2505.08614|[waveguard: robust deepfake detection and source tracing via dual-tree complex wavelet and graph neural networks](https://arxiv.org/abs/2505.08614)|[waveguard](https://github.com/vpsg-research/waveguard)|
|2505.11131|[one image is worth a thousand words: a usability preservable text-image collaborative erasing framework](https://arxiv.org/abs/2505.11131)|[co-erasing](https://github.com/ferry-li/co-erasing)|
|2505.12266|[pmq-ve: progressive multi-frame quantization for video enhancement](https://arxiv.org/abs/2505.12266)|[pmq-ve](https://github.com/xiaobigfeng/pmq-ve)|
|2505.12513|[globalgeotree: a multi-granular vision-language dataset for global tree species classification](https://arxiv.org/abs/2505.12513)|[globalgeotree](https://github.com/muyang99/globalgeotree)|
|2505.12728|[flash: latent-aware semi-autoregressive speculative decoding for multimodal tasks](https://arxiv.org/abs/2505.12728)|[flashsd](https://github.com/zihuaevan/flashsd)|
|2505.13061|[3d visual illusion depth estimation](https://arxiv.org/abs/2505.13061)|[3d-visual-illusion-depth-estimation](https://github.com/yaochengtang/3d-visual-illusion-depth-estimation)|
|2505.13740|[improving compositional generation with diffusion models using lift scores](https://arxiv.org/abs/2505.13740)|[complift](https://github.com/rainorangelemon/complift)|
|2505.14362|[deepeyes: incentivizing "thinking with images" via reinforcement learning](https://arxiv.org/abs/2505.14362)|[deepeyes](https://github.com/visual-agent/deepeyes)|
|2505.15235|[x-grm: large gaussian reconstruction model for sparse-view x-rays to computed tomography](https://arxiv.org/abs/2505.15235)|[x-grm](https://github.com/cuhk-aim-group/x-grm)|
|2505.15660|[exploring the limits of vision-language-action manipulations in cross-task generalization](https://arxiv.org/abs/2505.15660)|[X-ICM](https://github.com/jiaming-zhou/X-ICM)|
|2505.16882|[tracking the flight: exploring a computational framework for analyzing escape responses in plains zebra (equus quagga)](https://arxiv.org/abs/2505.16882)|[zebras-stitching](https://github.com/neuroinformatics-unit/zebras-stitching)|
|2505.16990|[dimple: discrete diffusion multimodal large language model with parallel decoding](https://arxiv.org/abs/2505.16990)|[dimple](https://github.com/yu-rp/dimple)|
|2505.18156|[injectlab: a tactical framework for adversarial threat modeling against large language models](https://arxiv.org/abs/2505.18156)|[injectlab](https://github.com/ahow2004/injectlab)|
|2505.18175|[evaluation in eeg emotion recognition: state-of-the-art review and unified framework](https://arxiv.org/abs/2505.18175)|[eegain](https://github.com/emotionlab/eegain)|
|2505.18197|[a novel benchmark and dataset for efficient 3d gaussian splatting with gaussian point cloud compression](https://arxiv.org/abs/2505.18197)|[GausPcc](https://github.com/Wangkkklll/GausPcc)|
|2505.18412|[rehabilitation exercise quality assessment and feedback generation using large language models with prompt engineering](https://arxiv.org/abs/2505.18412)|[exercisellm](https://github.com/jessicaxtang/exercisellm)|
|2505.18487|[grounding bodily awareness in visual representations for efficient policy learning](https://arxiv.org/abs/2505.18487)|[icon](https://github.com/henrywjl/icon)|
|2505.18536|[reinforcement fine-tuning powers reasoning capability of multimodal large language models](https://arxiv.org/abs/2505.18536)|[awesome-rl-based-reasoning-mllms](https://github.com/sun-haoyuan23/awesome-rl-based-reasoning-mllms)|
|2505.18546|[reflectgan: modeling vegetation effects for soil carbon estimation from satellite imagery](https://arxiv.org/abs/2505.18546)|[reflectgan](https://github.com/dristidatta/reflectgan)|
|2505.18547|[diffusion blend: inference-time multi-preference alignment for diffusion models](https://arxiv.org/abs/2505.18547)|[db-2025](https://github.com/bluewoods127/db-2025)|
|2505.18582|[on denoising walking videos for gait recognition](https://arxiv.org/abs/2505.18582)|[opengait](https://github.com/shiqiyu/opengait)|
|2505.18614|[mavl: a multilingual audio-video lyrics dataset for animated song translation](https://arxiv.org/abs/2505.18614)|[MAVL](https://github.com/k1064190/MAVL)|
|2505.18730|[align beyond prompts: evaluating world knowledge alignment in text-to-image generation](https://arxiv.org/abs/2505.18730)|[abp](https://github.com/smile365317/abp)|
|2505.18787|[think twice before adaptation: improving adaptability of deepfake detection via online test-time adaptation](https://arxiv.org/abs/2505.18787)|[t2a-think-twice-before-adaptation](https://github.com/honghanh2104/t2a-think-twice-before-adaptation)|
|2505.18829|[litecua: computer as mcp server for computer-use agent on aios](https://arxiv.org/abs/2505.18829)|[aios](https://github.com/agiresearch/aios)|
|2505.18956|[how do images align and complement lidar? towards a harmonized multi-modal 3d panoptic segmentation](https://arxiv.org/abs/2505.18956)|[ial](https://github.com/impl-lab/ial)|
|2505.18983|[amorlip: efficient language-image pretraining via amortization](https://arxiv.org/abs/2505.18983)|[amorlip](https://github.com/haotiansun14/amorlip)|
|2505.18985|[strict: stress test of rendering images containing text](https://arxiv.org/abs/2505.18985)|[strict-bench](https://github.com/tianyu-z/strict-bench)|
|2505.18989|[spars: self-play adversarial reinforcement learning for segmentation of liver tumours](https://arxiv.org/abs/2505.18989)|[spars](https://github.com/catalinatan/spars)|
|2505.19000|[veripo: cultivating long reasoning in video-llms via verifier-gudied iterative policy optimization](https://arxiv.org/abs/2505.19000)|[veripo](https://github.com/hitsz-tmg/veripo)|
|2505.19015|[can multimodal large language models understand spatial relations?](https://arxiv.org/abs/2505.19015)|[spatialmqa](https://github.com/ziyan-xiaoyu/spatialmqa)|
|2505.19028|[infochartqa: a benchmark for multimodal question answering on infographic charts](https://arxiv.org/abs/2505.19028)|[infochartqa](https://github.com/cooldawnant/infochartqa)|
|2505.19031|[medical large vision language models with multi-image visual ability](https://arxiv.org/abs/2505.19031)|[med-mim](https://github.com/xikai97/med-mim)|
|2505.19065|[mmp-2k: a benchmark multi-labeled macro photography image quality assessment database](https://arxiv.org/abs/2505.19065)|[mmp-2k](https://github.com/future-iqa/mmp-2k)|
|2505.19084|[jodi: unification of visual generation and understanding via joint modeling](https://arxiv.org/abs/2505.19084)|[jodi](https://github.com/vipl-genun/jodi)|
|2505.19094|[satori-r1: incentivizing multimodal reasoning with spatial grounding and verifiable rewards](https://arxiv.org/abs/2505.19094)|[satori-r1](https://github.com/justairr/satori-r1)|
|2505.19120|[freqformer: image-demoir\'eing transformer via efficient frequency decomposition](https://arxiv.org/abs/2505.19120)|[freqformer](https://github.com/xyliu339/freqformer)|
|2505.19147|[shifting ai efficiency from model-centric to data-centric compression](https://arxiv.org/abs/2505.19147)|[awesome-token-level-model-compression](https://github.com/xuyang-liu16/awesome-token-level-model-compression)|
|2505.19148|[dista-net: dynamic closely-spaced infrared small target unmixing](https://arxiv.org/abs/2505.19148)|[grokcso](https://github.com/grokcv/grokcso)|
|2505.19159|[a joint learning framework with feature reconstruction and prediction for incomplete satellite image time series in agricultural semantic segmentation](https://arxiv.org/abs/2505.19159)|[joint_frp](https://github.com/wangyuze-csu/joint_frp)|
|2505.19161|[benchmarking laparoscopic surgical image restoration and beyond](https://arxiv.org/abs/2505.19161)|[surgical-image-restoration](https://github.com/pjlallen/surgical-image-restoration)|
|2505.19190|[i2moe: interpretable multimodal interaction-aware mixture-of-experts](https://arxiv.org/abs/2505.19190)|[i2moe](https://github.com/raina-xin/i2moe)|
|2505.19196|[step-level reward for free in rl-based t2i diffusion model fine-tuning](https://arxiv.org/abs/2505.19196)|[coca](https://github.com/lil-shake/coca)|
|2505.19208|[domain and task-focused example selection for data-efficient contrastive medical image segmentation](https://arxiv.org/abs/2505.19208)|[polycl](https://github.com/tbwa233/polycl)|
|2505.19218|[advancing video self-supervised learning via image foundation models](https://arxiv.org/abs/2505.19218)|[advise-video-ssl](https://github.com/jingwwu/advise-video-ssl)|
|2505.19225|[meditok: a unified tokenizer for medical image synthesis and interpretation](https://arxiv.org/abs/2505.19225)|[meditok](https://github.com/masaaki-75/meditok)|
|2505.19235|[corematching: a co-adaptive sparse inference framework with token and neuron pruning for comprehensive acceleration of vision-language models](https://arxiv.org/abs/2505.19235)|[2025-icml-corematching](https://github.com/wangqinsi1/2025-icml-corematching)|
|2505.19249|[rgc-bent: a novel dataset for bent radio galaxy classification](https://arxiv.org/abs/2505.19249)|[rgc-bent](https://github.com/mirsazzathossain/rgc-bent)|
|2505.19264|[improving novel view synthesis of 360$^\circ$ scenes in extremely sparse views by jointly training hemisphere sampled synthetic images](https://arxiv.org/abs/2505.19264)|[hemisparsegs](https://github.com/angchen-dev/hemisparsegs)|
|2505.19319|[holistic white-light polyp classification via alignment-free dense distillation of auxiliary optical chromoendoscopy](https://arxiv.org/abs/2505.19319)|[add](https://github.com/huster-hq/add)|
|2505.19434|[cstrack: enhancing rgb-x tracking via compact spatiotemporal features](https://arxiv.org/abs/2505.19434)|[cstrack](https://github.com/xiaokunfeng/cstrack)|
|2505.19455|[mm-prompt: cross-modal prompt tuning for continual visual question answering](https://arxiv.org/abs/2505.19455)|[cvqa](https://github.com/xli04/cvqa)|
|2505.19503|[locality-aware zero-shot human-object interaction detection](https://arxiv.org/abs/2505.19503)|[lain](https://github.com/oreochocolate/lain)|
|2505.19536|[flowcut: rethinking redundancy via information flow for efficient vision-language models](https://arxiv.org/abs/2505.19536)|[flowcut](https://github.com/tungchintao/flowcut)|
|2505.19546|[smart-pc: skeletal model adaptation for robust test-time training in point clouds](https://arxiv.org/abs/2505.19546)|[smart-pc](https://github.com/alibahri94/smart-pc)|
|2505.19564|[k-buffers: a plug-in method for enhancing neural fields with multiple buffers](https://arxiv.org/abs/2505.19564)|[k-buffers](https://github.com/renhaofan/k-buffers)|
|2505.19571|[vtbench: comprehensive benchmark suite towards real-world virtual try-on models](https://arxiv.org/abs/2505.19571)|[vtbench](https://github.com/huuxiaobin/vtbench)|
|2505.19611|[align and surpass human camouflaged perception: visual refocus reinforcement fine-tuning](https://arxiv.org/abs/2505.19611)|[vrrf](https://github.com/huuxiaobin/vrrf)|
|2505.19618|[rotation-equivariant self-supervised method in image denoising](https://arxiv.org/abs/2505.19618)|[adarenet](https://github.com/liuhanze623/adarenet)|
|2505.19638|[hf-vton: high-fidelity virtual try-on via consistent geometric and semantic alignment](https://arxiv.org/abs/2505.19638)|[hf-vton](https://github.com/mmlph/hf-vton)|
|2505.19652|[sacm: seeg-audio contrastive matching for chinese speech decoding](https://arxiv.org/abs/2505.19652)|[SACM](https://github.com/WangHongbinary/SACM)|
|2505.19659|[langdaug: langevin data augmentation for multi-source domain generalization in medical image segmentation](https://arxiv.org/abs/2505.19659)|[langdaug](https://github.com/backpropagator/langdaug)|
|2505.19692|[drivecamsim: generalizable camera simulation via explicit camera modeling for autonomous driving](https://arxiv.org/abs/2505.19692)|[drivecamsim](https://github.com/swc-17/drivecamsim)|
|2505.19742|[haodiff: human-aware one-step diffusion via dual-prompt guidance](https://arxiv.org/abs/2505.19742)|[haodiff](https://github.com/gobunu/haodiff)|
|2505.19779|[advancements in medical image classification through fine-tuning natural domain foundation models](https://arxiv.org/abs/2505.19779)|[medical-transfer-learning](https://github.com/sajjad-sh33/medical-transfer-learning)|
|2505.19793|[depth-guided bundle sampling for efficient generalizable neural radiance field reconstruction](https://arxiv.org/abs/2505.19793)|[gdb-nerf](https://github.com/klmav-cuc/gdb-nerf)|
|2505.19799|[a regularization-guided equivariant approach for image restoration](https://arxiv.org/abs/2505.19799)|[eq-reg](https://github.com/yulu919/eq-reg)|
|2505.19805|[translation-equivariance of normalization layers and aliasing in convolutional neural networks](https://arxiv.org/abs/2505.19805)|[normalization-layers](https://github.com/jscanvic/normalization-layers)|
|2505.19812|[efficient multi-modal long context learning for training-free adaptation](https://arxiv.org/abs/2505.19812)|[emloc](https://github.com/zehong-ma/emloc)|
|2505.19813|[golf-nrt: integrating global context and local geometry for few-shot view synthesis](https://arxiv.org/abs/2505.19813)|[golf-nrt](https://github.com/klmav-cuc/golf-nrt)|
|2505.19863|[fruitnerf++: a generalized multi-fruit counting method utilizing contrastive learning and neural radiance fields](https://arxiv.org/abs/2505.19863)|[fruitnerfpp](https://github.com/meyerls/fruitnerfpp)|
|2505.19877|[vad-r1: towards video anomaly reasoning via perception-to-cognition chain-of-thought](https://arxiv.org/abs/2505.19877)|[vad-r1](https://github.com/wbfwonderful/vad-r1)|
|2505.19889|[omnifall: a unified staged-to-wild benchmark for human fall detection](https://arxiv.org/abs/2505.19889)|[omnifall-experiments](https://github.com/simplexsigil/omnifall-experiments)|
|2505.19972|[phi: bridging domain shift in long-term action quality assessment via progressive hierarchical instruction](https://arxiv.org/abs/2505.19972)|[phi_aqa](https://github.com/zhoukanglei/phi_aqa)|
|2505.20024|[reasonplan: unified scene prediction and decision reasoning for closed-loop autonomous driving](https://arxiv.org/abs/2505.20024)|[reasonplan](https://github.com/liuxueyi/reasonplan)|
|2505.20038|[towards video to piano music generation with chain-of-perform support benchmarks](https://arxiv.org/abs/2505.20038)|[video-to-audio-and-piano](https://github.com/acappemin/video-to-audio-and-piano)|
|2505.20049|[data-free class-incremental gesture recognition with prototype-guided pseudo feature replay](https://arxiv.org/abs/2505.20049)|[pgpfr-3](https://github.com/sunao-101/pgpfr-3)|
|2505.20053|[multimodal llm-guided semantic correction in text-to-image diffusion](https://arxiv.org/abs/2505.20053)|[ppad](https://github.com/hellozicky/ppad)|
|2505.20107|[refining few-step text-to-multiview diffusion via reinforcement learning](https://arxiv.org/abs/2505.20107)|[mvc-zigal](https://github.com/ziyizhang27/mvc-zigal)|
|2505.20124|[tuna: comprehensive fine-grained temporal understanding evaluation on dense dynamic videos](https://arxiv.org/abs/2505.20124)|[TUNA](https://github.com/friedrichor/TUNA)|
|2505.20126|[ob3d: a new dataset for benchmarking omnidirectional 3d reconstruction using blender](https://arxiv.org/abs/2505.20126)|[omnidirectional_blender_3d_dataset](https://github.com/gsisaoki/omnidirectional_blender_3d_dataset)|
|2505.20152|[hard negative contrastive learning for fine-grained geometric understanding in large multimodal models](https://arxiv.org/abs/2505.20152)|[mmgeolm](https://github.com/thu-keg/mmgeolm)|
|2505.20156|[hunyuanvideo-avatar: high-fidelity audio-driven human animation for multiple characters](https://arxiv.org/abs/2505.20156)|[hunyuanvideo-avatar](https://github.com/tencent-hunyuan/hunyuanvideo-avatar)|
|2505.20255|[anicrafter: customizing realistic human-centric animation via avatar-background conditioning in video diffusion models](https://arxiv.org/abs/2505.20255)|[anicrafter](https://github.com/myniuuu/anicrafter)|
|2505.20256|[omni-r1: reinforcement learning for omnimodal reasoning via two-system collaboration](https://arxiv.org/abs/2505.20256)|[omni-r1](https://github.com/aim-uofa/omni-r1)|
|2505.20275|[imgedit: a unified image editing dataset and benchmark](https://arxiv.org/abs/2505.20275)|[imgedit](https://github.com/pku-yuangroup/imgedit)|
|2505.20277|[omnicharacter: towards immersive role-playing agents with seamless speech-language personality interaction](https://arxiv.org/abs/2505.20277)|[damo-convai](https://github.com/alibabaresearch/damo-convai)|
|2505.20288|[hierarchical masked autoregressive models with low-resolution token pivots](https://arxiv.org/abs/2505.20288)|[himar](https://github.com/hidream-ai/himar)|
|2505.20291|[visualized text-to-image retrieval](https://arxiv.org/abs/2505.20291)|[visualize-then-retrieve](https://github.com/xiaowu0162/visualize-then-retrieve)|
|2505.20297|[disa: diffusion step annealing in autoregressive image generation](https://arxiv.org/abs/2505.20297)|[disa](https://github.com/qinyu-allen-zhao/disa)|
|2505.20298|[mangavqa and mangalmm: a benchmark and specialized model for multimodal manga understanding](https://arxiv.org/abs/2505.20298)|[mangalmm](https://github.com/manga109/mangalmm)|
|2505.01476|[costfilter-ad: enhancing anomaly detection through matching cost filtering](https://arxiv.org/abs/2505.01476)|[costfilter-ad](https://github.com/zhe-sapi/costfilter-ad)|
|2505.05528|[x-transfer attacks: towards super transferable adversarial attacks on clip](https://arxiv.org/abs/2505.05528)|[XTransferBench](https://github.com/HanxunH/XTransferBench)|
|2505.10541|[exploring implicit visual misunderstandings in multimodal large language models through attention analysis](https://arxiv.org/abs/2505.10541)|[stme](https://github.com/welldonepf/stme)|
|2505.10595|[arfc-wahnet: adaptive receptive field convolution and wavelet-attentive hierarchical network for infrared small target detection](https://arxiv.org/abs/2505.10595)|[arfc-wahnet](https://github.com/leaf2001/arfc-wahnet)|
|2505.11454|[humanibench: a human-centric framework for large multimodal models evaluation](https://arxiv.org/abs/2505.11454)|[humanibench](https://github.com/vectorinstitute/humanibench)|
|2505.14151|[reactdiff: latent diffusion for facial reaction generation](https://arxiv.org/abs/2505.14151)|[reactdiff](https://github.com/hunan-tiger/reactdiff)|
|2505.15425|[on the robustness of medical vision-language models: are they truly generalizable?](https://arxiv.org/abs/2505.15425)|[robustmedclip](https://github.com/biomedia-mbzuai/robustmedclip)|
|2505.16809|[hypergraph tversky-aware domain incremental learning for brain tumor segmentation with missing modalities](https://arxiv.org/abs/2505.16809)|[rehydil](https://github.com/reeive/rehydil)|
|2505.16839|[lavida: a large diffusion language model for multimodal understanding](https://arxiv.org/abs/2505.16839)|[lavida](https://github.com/jacklishufan/lavida)|
|2505.16854|[think or not? selective reasoning via reinforcement learning for vision-language models](https://arxiv.org/abs/2505.16854)|[ton](https://github.com/kokolerk/ton)|
|2505.17114|[raven: query-guided representation alignment for question answering over audio, video, embedded sensors, and natural language](https://arxiv.org/abs/2505.17114)|[raven](https://github.com/bashlab/raven)|
|2505.17241|[generative ai and creativity: a systematic literature review and meta-analysis](https://arxiv.org/abs/2505.17241)|[meta-analysis-llms-creativity](https://github.com/sm2982/meta-analysis-llms-creativity)|
|2505.17440|[veattack: downstream-agnostic vision encoder attack against large vision language models](https://arxiv.org/abs/2505.17440)|[veattack-lvlm](https://github.com/hfmei/veattack-lvlm)|
|2505.17475|[posebh: prototypical multi-dataset training beyond human pose estimation](https://arxiv.org/abs/2505.17475)|[PoseBH](https://github.com/uyoung-jeong/PoseBH)|
|2505.17534|[co-reinforcement learning for unified multimodal understanding and generation](https://arxiv.org/abs/2505.17534)|[ULM-R1](https://github.com/mm-vl/ULM-R1)|
|2505.17551|[center-aware residual anomaly synthesis for multi-class industrial anomaly detection](https://arxiv.org/abs/2505.17551)|[CRAS](https://github.com/cqylunlun/CRAS)|
|2505.17556|[wildfire spread forecasting with deep learning](https://arxiv.org/abs/2505.17556)|[wildfirespread](https://github.com/orion-ai-lab/wildfirespread)|
|2505.17581|[modem: a morton-order degradation estimation mechanism for adverse weather image recovery](https://arxiv.org/abs/2505.17581)|[modem](https://github.com/hainuo-wang/modem)|
|2505.17591|[minkunext-si: improving point cloud-based place recognition including spherical coordinates and lidar intensity](https://arxiv.org/abs/2505.17591)|[minkunext-si](https://github.com/judithv/minkunext-si)|
|2505.17739|[feasible action space reduction for quantifying causal responsibility in continuous spatial interactions](https://arxiv.org/abs/2505.17739)|[continuousfear](https://github.com/dai-lab-herald/continuousfear)|
|2505.17771|[topopoint: enhance topology reasoning via endpoint detection in autonomous driving](https://arxiv.org/abs/2505.17771)|[topopoint](https://github.com/franpin/topopoint)|
|2505.17807|[temporal consistency constrained transferable adversarial attacks with background mixup for action recognition](https://arxiv.org/abs/2505.17807)|[bmtc_transferattackvid](https://github.com/mlvccn/bmtc_transferattackvid)|
|2505.17883|[fastcav: efficient computation of concept activation vectors for explaining deep neural networks](https://arxiv.org/abs/2505.17883)|[fastcav](https://gitlab.com/dlr-dw/fastcav)|
|2505.17884|[track anything annotate: video annotation and dataset generation of computer vision models](https://arxiv.org/abs/2505.17884)|[track-anything-annotate](https://github.com/lnikioffic/track-anything-annotate)|
|2505.17908|[comfymind: toward general-purpose generation via tree-based planning and reactive feedback](https://arxiv.org/abs/2505.17908)|[ComfyMind](https://github.com/EnVision-Research/ComfyMind)|
|2505.17911|[object-level cross-view geo-localization with location enhancement and multi-head cross attention](https://arxiv.org/abs/2505.17911)|[ocgnet](https://github.com/zheyangh/ocgnet)|
|2505.18015|[semsegbench & detecbench: benchmarking reliability and generalization beyond classification](https://arxiv.org/abs/2505.18015)|[benchmarking_reliability_generalization](https://github.com/shashankskagnihotri/benchmarking_reliability_generalization)|
|2505.18025|[3d face reconstruction error decomposed: a modular benchmark for fair and fast method evaluation](https://arxiv.org/abs/2505.18025)|[M3DFB](https://github.com/sariyanidi/M3DFB)|
|2505.18028|[knot so simple: a minimalistic environment for spatial reasoning](https://arxiv.org/abs/2505.18028)|[knotgym](https://github.com/lil-lab/knotgym)|
|2505.18035|[camme: adaptive deepfake image detection with multi-modal cross-attention](https://arxiv.org/abs/2505.18035)|[camme](https://github.com/magnet300/camme)|
|2505.18153|[ren: fast and efficient region encodings from patch-based image encoders](https://arxiv.org/abs/2505.18153)|[ren](https://github.com/savya08/ren)|
|2505.02567|[unified multimodal understanding and generation models: advances, challenges, and opportunities](https://arxiv.org/abs/2505.02567)|[awesome-unified-multimodal-models](https://github.com/aidc-ai/awesome-unified-multimodal-models)|
|2505.10049|[advances in radiance field for dynamic scene: from neural field to gaussian field](https://arxiv.org/abs/2505.10049)|[dynamic-radiation-field-paper-list](https://github.com/moonflo/dynamic-radiation-field-paper-list)|
|2505.10250|[adhmr: aligning diffusion-based human mesh recovery via direct preference optimization](https://arxiv.org/abs/2505.10250)|[adhmr](https://github.com/shenwenhao01/adhmr)|
|2505.10473|[consistent quantity-quality control across scenes for deployment-aware gaussian splatting](https://arxiv.org/abs/2505.10473)|[ControlGS](https://github.com/zhang-fengdi/ControlGS)|
|2505.12007|[multi-modal collaborative optimization and expansion network for event-assisted single-eye expression recognition](https://arxiv.org/abs/2505.12007)|[MCO-E-Net](https://github.com/hrdhrd/MCO-E-Net)|
|2505.12081|[visionreasoner: unified visual perception and reasoning via reinforcement learning](https://arxiv.org/abs/2505.12081)|[easyr1](https://github.com/hiyouga/easyr1)|
|2505.14068|[place recognition: a comprehensive review, current challenges and future directions](https://arxiv.org/abs/2505.14068)|[sota-place-recognitioner](https://github.com/cv4ra/sota-place-recognitioner)|
|2505.15222|[continuous representation methods, theories, and applications: an overview and perspectives](https://arxiv.org/abs/2505.15222)|[continuous-representation-zoo](https://github.com/yisiluo/continuous-representation-zoo)|
|2505.15358|[objective bicycle occlusion level classification using a deformable parts-based model](https://arxiv.org/abs/2505.15358)|[Bicycle_Occlusion_Level](https://github.com/angelmangubat/Bicycle_Occlusion_Level)|
|2505.15441|[stronger vits with octic equivariance](https://arxiv.org/abs/2505.15441)|[octic-vits](https://github.com/davnords/octic-vits)|
|2505.15810|[gui-g1: understanding r1-zero-like training for visual grounding in gui agents](https://arxiv.org/abs/2505.15810)|[gui-g1](https://github.com/yuqi-zhou/gui-g1)|
|2505.15867|[scenir: visual semantic clarity through unsupervised scene graph retrieval](https://arxiv.org/abs/2505.15867)|[scenir-icml2025](https://github.com/nickhaidos/scenir-icml2025)|
|2505.15870|[satellites reveal mobility: a commuting origin-destination flow generator for global cities](https://arxiv.org/abs/2505.15870)|[generate-od-pubtools](https://github.com/tsinghua-fib-lab/generate-od-pubtools)|
|2505.15928|[viqagent: zero-shot video question answering via agent with open-vocabulary grounding validation](https://arxiv.org/abs/2505.15928)|[viqagent](https://github.com/t-montes/viqagent)|
|2505.16029|[learning better representations for crowded pedestrians in offboard lidar-camera 3d tracking-by-detection](https://arxiv.org/abs/2505.16029)|[pcp-mv](https://github.com/nicholasli1995/pcp-mv)|
|2505.16104|[hierarchical safety realignment: lightweight restoration of safety in pruned large vision-language models](https://arxiv.org/abs/2505.16104)|[hsr](https://github.com/theshineyue/hsr)|
|2505.16161|[deep learning-driven ultra-high-definition image restoration: a survey](https://arxiv.org/abs/2505.16161)|[uhd-image-restoration-survey](https://github.com/wlydlut/uhd-image-restoration-survey)|
|2505.16165|[re-trip : reflectivity instance augmented triangle descriptor for 3d place recognition](https://arxiv.org/abs/2505.16165)|[re-trip](https://github.com/pyc5714/re-trip)|
|2505.16175|[quickvideo: real-time long video understanding with system algorithm co-design](https://arxiv.org/abs/2505.16175)|[quickvideo](https://github.com/tiger-ai-lab/quickvideo)|
|2505.16264|[linea: fast and accurate line detection using scalable transformers](https://arxiv.org/abs/2505.16264)|[LINEA](https://github.com/SebastianJanampa/LINEA)|
|2505.16282|[arpo:end-to-end policy optimization for gui agents with experience replay](https://arxiv.org/abs/2505.16282)|[arpo](https://github.com/dvlab-research/arpo)|
|2505.16313|[accelerating targeted hard-label adversarial attacks in low-query black-box settings](https://arxiv.org/abs/2505.16313)|[tea](https://github.com/mdppml/tea)|
|2505.16321|[efficient motion prompt learning for robust visual tracking](https://arxiv.org/abs/2505.16321)|[motion-prompt-tracking](https://github.com/zj5559/motion-prompt-tracking)|
|2505.16335|[fpqvar: floating point quantization for visual autoregressive model with fpga hardware co-design](https://arxiv.org/abs/2505.16335)|[fpqvar](https://github.com/pku-sec-lab/fpqvar)|
|2505.16360|[style transfer with diffusion models for synthetic-to-real domain adaptation](https://arxiv.org/abs/2505.16360)|[cactif](https://github.com/echigot/cactif)|
|2505.16376|[decafnet: delegate and conquer for efficient temporal grounding in long videos](https://arxiv.org/abs/2505.16376)|[cvpr2025-decafnet](https://github.com/zijialewislu/cvpr2025-decafnet)|
|2505.16402|[advreal: adversarial patch generation framework with application to adversarial safety evaluation of object detection systems](https://arxiv.org/abs/2505.16402)|[advreal](https://github.com/huangyh98/advreal)|
|2505.16411|[mitigating hallucinations in vision-language models through image-guided head suppression](https://arxiv.org/abs/2505.16411)|[spin](https://github.com/yueche77/spin)|
|2505.16416|[circle-rope: cone-like decoupled rotary positional embedding for large vision-language models](https://arxiv.org/abs/2505.16416)|[circlerope](https://github.com/lose4578/circlerope)|
|2505.16441|[ranked entropy minimization for continual test-time adaptation](https://arxiv.org/abs/2505.16441)|[rem](https://github.com/pilshan/rem)|
|2505.16470|[benchmarking retrieval-augmented multimomal generation for document question answering](https://arxiv.org/abs/2505.16470)|[mmdocrag](https://github.com/mmdocrag/mmdocrag)|
|2505.16495|[alto: adaptive-length tokenizer for autoregressive mask generation](https://arxiv.org/abs/2505.16495)|[altollm](https://github.com/yayafengzi/altollm)|
|2505.16579|[bridging the dynamic perception gap: training-free draft chain-of-thought for dynamic multimodal spatial reasoning](https://arxiv.org/abs/2505.16579)|[d2r](https://github.com/cratileo/d2r)|
|2505.16625|[background matters: a cross-view bidirectional modeling framework for semi-supervised medical image segmentation](https://arxiv.org/abs/2505.16625)|[cvbm](https://github.com/caoluyang0830/cvbm)|
|2505.16650|[unsupervised network anomaly detection with autoencoders and traffic images](https://arxiv.org/abs/2505.16650)|[image-based-network-traffic-anomaly-detection](https://github.com/michaelneri/image-based-network-traffic-anomaly-detection)|
|2505.16658|[zero-shot hyperspectral pansharpening using hysteresis-based tuning for spectral quality control](https://arxiv.org/abs/2505.16658)|[rho-pnn](https://github.com/giu-guarino/rho-pnn)|
|2505.16663|[conav: collaborative cross-modal reasoning for embodied navigation](https://arxiv.org/abs/2505.16663)|[CoNav](https://github.com/oceanhao/CoNav)|
|2505.16673|[r1-sharevl: incentivizing reasoning capability of multimodal large language models via share-grpo](https://arxiv.org/abs/2505.16673)|[r1-sharevl](https://github.com/hjyao00/r1-sharevl)|
|2505.16685|[on the use of graphs for satellite image time series](https://arxiv.org/abs/2505.16685)|[graph4sits](https://github.com/corentin-dfg/graph4sits)|
|2505.16740|[robust vision-based runway detection through conformal prediction and conformal map](https://arxiv.org/abs/2505.16740)|[conformal_runway_detection](https://github.com/alyasltd/conformal_runway_detection)|
|2505.16778|[single domain generalization for few-shot counting via universal representation matching](https://arxiv.org/abs/2505.16778)|[urm](https://github.com/jbr97/urm)|
|2505.16792|[repa works until it doesn't: early-stopped, holistic alignment supercharges diffusion training](https://arxiv.org/abs/2505.16792)|[haste](https://github.com/nus-hpc-ai-lab/haste)|
|2505.16793|[reobench: benchmarking robustness of earth observation foundation models](https://arxiv.org/abs/2505.16793)|[reobench](https://github.com/lx709/reobench)|
|2505.16815|[perceptual quality assessment for embodied ai](https://arxiv.org/abs/2505.16815)|[embodiediqa](https://github.com/lcysyzxdxc/embodiediqa)|
|2505.16850|[atr-bench: a federated learning benchmark for adaptation, trust, and reasoning](https://arxiv.org/abs/2505.16850)|[atr-bench](https://github.com/tajamul21/atr-bench)|
|2505.16864|[training-free efficient video generation via dynamic token carving](https://arxiv.org/abs/2505.16864)|[jenga](https://github.com/dvlab-research/jenga)|
|2505.16902|[realengine: simulating autonomous driving in realistic context](https://arxiv.org/abs/2505.16902)|[realengine](https://github.com/fudan-zvg/realengine)|
|2505.16916|[backdoor cleaning without external guidance in mllm fine-tuning](https://arxiv.org/abs/2505.16916)|[bye](https://github.com/xuankunrong/bye)|
|2505.16974|[openseg-r: improving open-vocabulary segmentation via step-by-step visual reasoning](https://arxiv.org/abs/2505.16974)|[openseg-r](https://github.com/hanzy1996/openseg-r)|
|2505.16977|[incorporating visual correspondence into diffusion model for virtual try-on](https://arxiv.org/abs/2505.16977)|[spm-diff](https://github.com/hidream-ai/spm-diff)|
|2505.16985|[extremely simple multimodal outlier synthesis for out-of-distribution detection and segmentation](https://arxiv.org/abs/2505.16985)|[featuremixing](https://github.com/mona4399/featuremixing)|
|2505.17008|[deep mineralogical segmentation of thin section images based on qemscan maps](https://arxiv.org/abs/2505.17008)|[deep-mineralogical-segmentation](https://github.com/ltracegeo/deep-mineralogical-segmentation)|
|2505.17011|[learning adaptive and temporally causal video tokenization in a 1d latent space](https://arxiv.org/abs/2505.17011)|[adaptok](https://github.com/visionxlab/adaptok)|
|2505.17012|[spatialscore: towards unified evaluation for multimodal spatial understanding](https://arxiv.org/abs/2505.17012)|[SpatialScore](https://github.com/haoningwu3639/SpatialScore)|
|2505.17017|[delving into rl for image generation with cot: a study on dpo vs. grpo](https://arxiv.org/abs/2505.17017)|[image-generation-cot](https://github.com/ziyuguo99/image-generation-cot)|
|2505.17018|[sophiavl-r1: reinforcing mllms reasoning with thinking reward](https://arxiv.org/abs/2505.17018)|[sophiavl-r1](https://github.com/kxfan2002/sophiavl-r1)|
|2505.17019|[let androids dream of electric sheep: a human-like image implication understanding and reasoning framework](https://arxiv.org/abs/2505.17019)|[let-androids-dream-of-electric-sheep](https://github.com/ming-zch/let-androids-dream-of-electric-sheep)|
|2505.17020|[crosslmm: decoupling long video sequences from lmms via dual cross-attention mechanisms](https://arxiv.org/abs/2505.17020)|[crosslmm](https://github.com/shilinyan99/crosslmm)|
|2505.17021|[arb: a comprehensive arabic multimodal reasoning benchmark](https://arxiv.org/abs/2505.17021)|[arb](https://github.com/mbzuai-oryx/arb)|
|2505.17022|[got-r1: unleashing reasoning capability of mllm for visual generation with reinforcement learning](https://arxiv.org/abs/2505.17022)|[got-r1](https://github.com/gogoduan/got-r1)|
|2505.01237|[cav-mae sync: improving contrastive audio-visual mask autoencoders via fine-grained alignment](https://arxiv.org/abs/2505.01237)|[cav-mae-sync](https://github.com/edsonroteia/cav-mae-sync)|
|2505.04046|[reliable disentanglement multi-view learning against view adversarial attacks](https://arxiv.org/abs/2505.04046)|[2025-IJCAI-RDML](https://github.com/Willy1005/2025-IJCAI-RDML)|
|2505.04788|[convex relaxation for robust vanishing point estimation in manhattan world](https://arxiv.org/abs/2505.04788)|[globustvp](https://github.com/wu-cvgl/globustvp)|
|2505.05049|[uncertainsam: fast and efficient uncertainty quantification of the segment anything model](https://arxiv.org/abs/2505.05049)|[UncertainSAM](https://github.com/GreenAutoML4FAS/UncertainSAM)|
|2505.05071|[fg-clip: fine-grained visual and textual alignment](https://arxiv.org/abs/2505.05071)|[fg-clip](https://github.com/360cvgroup/fg-clip)|
|2505.12620|[busterx: mllm-powered ai-generated video forgery detection and explanation](https://arxiv.org/abs/2505.12620)|[busterx](https://github.com/l8cv/busterx)|
|2505.13300|[dd-ranking: rethinking the evaluation of dataset distillation](https://arxiv.org/abs/2505.13300)|[dd-ranking](https://github.com/nus-hpc-ai-lab/dd-ranking)|
|2505.14074|[recreating neural activity during speech production with language and speech model embeddings](https://arxiv.org/abs/2505.14074)|[llm_brain_representations](https://github.com/owaismujtaba/llm_brain_representations)|
|2505.14100|[unlocking the power of sam 2 for few-shot segmentation](https://arxiv.org/abs/2505.14100)|[fssam](https://github.com/sam1224/fssam)|
|2505.14707|[crypticbio: a large multimodal dataset for visually confusing biodiversity](https://arxiv.org/abs/2505.14707)|[crypticbio](https://github.com/georgianagmanolache/crypticbio)|
|2505.14708|[draftattention: fast video diffusion via low-resolution attention guidance](https://arxiv.org/abs/2505.14708)|[draft-attention](https://github.com/shawnricecake/draft-attention)|
|2505.14709|[fastcar: cache attentive replay for fast auto-regressive video generation on the edge](https://arxiv.org/abs/2505.14709)|[fast-car](https://github.com/shawnricecake/fast-car)|
|2505.14714|[kgalign: joint semantic-structural knowledge encoding for multimodal fake news detection](https://arxiv.org/abs/2505.14714)|[kgalign](https://github.com/latuanvinh1998/kgalign)|
|2505.14717|[aneumo: a large-scale multimodal aneurysm dataset with computational fluid dynamics simulations and deep learning benchmarks](https://arxiv.org/abs/2505.14717)|[aneumo](https://github.com/xigui-li/aneumo)|
|2505.14747|[lod1 3d city model from lidar: the impact of segmentation accuracy on quality of urban 3d modeling and morphology extraction](https://arxiv.org/abs/2505.14747)|[LiDAR-3D-Building-Modeling](https://github.com/FatemehCh97/LiDAR-3D-Building-Modeling)|
|2505.14846|[open-set semi-supervised learning for long-tailed medical datasets](https://arxiv.org/abs/2505.14846)|[openltr](https://github.com/daniyanaj/openltr)|
|2505.14931|[colors matter: ai-driven exploration of human feature colors](https://arxiv.org/abs/2505.14931)|[Color-Matters-AI-Driven-Exploration-of-Human-Feature-Coloration](https://github.com/AiTaif7/Color-Matters-AI-Driven-Exploration-of-Human-Feature-Coloration)|
|2505.14948|[programmatic video prediction using large language models](https://arxiv.org/abs/2505.14948)|[ProgGen](https://github.com/metro-smiles/ProgGen)|
|2505.14951|[multimae meets earth observation: pre-training multi-modal multi-task masked autoencoders for earth observation tasks](https://arxiv.org/abs/2505.14951)|[multimae-meets-eo](https://github.com/josesosajs/multimae-meets-eo)|
|2505.14983|[toward informed av decision-making: computational model of well-being and trust in mobility](https://arxiv.org/abs/2505.14983)|[wellbeing-trust-model](https://github.com/honda-research-institute/wellbeing-trust-model)|
|2505.15031|[are the confidence scores of reviewers consistent with the review content? evidence from top conference proceedings in ai](https://arxiv.org/abs/2505.15031)|[confidence_score](https://github.com/njust-winchy/confidence_score)|
|2505.15075|[traveling across languages: benchmarking cross-lingual consistency in multimodal llms](https://arxiv.org/abs/2505.15075)|[traveling-across-languages](https://github.com/nlp-waseda/traveling-across-languages)|
|2505.15111|[ipad: iterative proposal-centric end-to-end autonomous driving](https://arxiv.org/abs/2505.15111)|[iPad](https://github.com/Kguo-cs/iPad)|
|2505.15120|[lung nodule-ssm: self-supervised lung nodule detection and classification in thoracic ct images](https://arxiv.org/abs/2505.15120)|[lung-nodule-ssm-self-supervised-lung-nodule-detection-and-classification](https://github.com/emeraldsnrpu/lung-nodule-ssm-self-supervised-lung-nodule-detection-and-classification)|
|2505.15133|[deepkd: a deeply decoupled and denoised knowledge distillation trainer](https://arxiv.org/abs/2505.15133)|[deepkd](https://github.com/haiduo/deepkd)|
|2505.15145|[cinetechbench: a benchmark for cinematographic technique understanding and generation](https://arxiv.org/abs/2505.15145)|[cinetechbench](https://github.com/pris-cv/cinetechbench)|
|2505.15184|[auxdet: auxiliary metadata matters for omni-domain infrared small target detection](https://arxiv.org/abs/2505.15184)|[auxdet](https://github.com/grokcv/auxdet)|
|2505.15185|[monosplat: generalizable 3d gaussian splatting from monocular depth foundation models](https://arxiv.org/abs/2505.15185)|[monosplat](https://github.com/cuhk-aim-group/monosplat)|
|2505.15217|[multimodal conditional information bottleneck for generalizable ai-generated image detection](https://arxiv.org/abs/2505.15217)|[infofd](https://github.com/ant0ny44/infofd)|
|2505.15232|[dc-scene: data-centric learning for 3d scene understanding](https://arxiv.org/abs/2505.15232)|[dc-scene](https://github.com/aigeeksgroup/dc-scene)|
|2505.15234|[sama-unet: enhancing medical image segmentation with self-adaptive mamba-like attention and causal-resonance learning](https://arxiv.org/abs/2505.15234)|[SAMA-UNet](https://github.com/sqbqamar/SAMA-UNet)|
|2505.15270|[scaling diffusion transformers efficiently via $\mu$p](https://arxiv.org/abs/2505.15270)|[Scaling-Diffusion-Transformers-muP](https://github.com/ML-GSAI/Scaling-Diffusion-Transformers-muP)|
|2505.15272|[diffprob: data pruning for face recognition](https://arxiv.org/abs/2505.15272)|[DiffProb](https://github.com/EduardaCaldeira/DiffProb)|
|2505.15282|[exploring in-image machine translation with real-world background](https://arxiv.org/abs/2505.15282)|[debackx](https://github.com/bithlp/debackx)|
|2505.15284|[kernel pca for out-of-distribution detection: non-linear kernel selections and approximations](https://arxiv.org/abs/2505.15284)|[ood-kpca-extension](https://github.com/fanghenshaometeor/ood-kpca-extension)|
|2505.15325|[softhgnn: soft hypergraph neural networks for general visual recognition](https://arxiv.org/abs/2505.15325)|[SoftHGNN](https://github.com/Mengqi-Lei/SoftHGNN)|
|2505.15364|[mhanet: multi-scale hybrid attention network for auditory attention detection](https://arxiv.org/abs/2505.15364)|[mhanet](https://github.com/fchest/mhanet)|
|2505.15379|[the p$^3$ dataset: pixels, points and polygons for multimodal building vectorization](https://arxiv.org/abs/2505.15379)|[pixelspointspolygons](https://github.com/raphaelsulzer/pixelspointspolygons)|
|2505.15435|[timecausality: evaluating the causal ability in time dimension for vision language models](https://arxiv.org/abs/2505.15435)|[timecausality](https://github.com/zeqing-wang/timecausality)|
|2505.15506|[prompt tuning vision language models with margin regularizer for few-shot learning under distribution shifts](https://arxiv.org/abs/2505.15506)|[promptmargin](https://github.com/debarshigit/promptmargin)|
|2505.15545|[seg_3d_by_pc2d: multi-view projection for domain generalization and adaptation in 3d semantic segmentation](https://arxiv.org/abs/2505.15545)|[ia4markings](https://github.com/andrewcaunes/ia4markings)|
|2505.15576|[visual perturbation and adaptive hard negative contrastive learning for compositional reasoning in vision-language models](https://arxiv.org/abs/2505.15576)|[ahnpl](https://github.com/nynu-bdai/ahnpl)|
|2505.15581|[uwsam: segment anything model guided underwater instance segmentation and a large-scale benchmark dataset](https://arxiv.org/abs/2505.15581)|[uiis10k](https://github.com/liamlian0727/uiis10k)|
|2505.15596|[exploring llm-generated feedback for economics essays: how teaching assistants evaluate and envision its use](https://arxiv.org/abs/2505.15596)|[aied2025-exploring-llm-generated-feedback-for-economics-essay](https://github.com/um-lifelong-learning-lab/aied2025-exploring-llm-generated-feedback-for-economics-essay)|
|2505.15628|[snap: a benchmark for testing the effects of capture conditions on fundamental vision tasks](https://arxiv.org/abs/2505.15628)|[snap](https://github.com/ykotseruba/snap)|
|2505.15637|[oral imaging for malocclusion issues assessments: omni dataset, deep learning baselines and benchmarking](https://arxiv.org/abs/2505.15637)|[omni](https://github.com/roundfacej/omni)|
|2505.15644|[fragfake: a dataset for fine-grained detection of edited images with vision language models](https://arxiv.org/abs/2505.15644)|[FragFake](https://github.com/Vincent-HKUSTGZ/FragFake)|
|2505.15649|[the devil is in fine-tuning and long-tailed problems:a new benchmark for scene text detection](https://arxiv.org/abs/2505.15649)|[ltb](https://github.com/pd162/ltb)|
|2505.15809|[mmada: multimodal large diffusion language models](https://arxiv.org/abs/2505.15809)|[mmada](https://github.com/gen-verse/mmada)|
|2505.15816|[streamline without sacrifice -- squeeze out computation redundancy in lmm](https://arxiv.org/abs/2505.15816)|[proxyv](https://github.com/penghao-wu/proxyv)|
|2505.15818|[instructsam: a training-free framework for instruction-oriented remote sensing object recognition](https://arxiv.org/abs/2505.15818)|[InstructSAM](https://github.com/VoyagerXvoyagerx/InstructSAM)|
|2505.04058|[as3d: 2d-assisted cross-modal understanding with semantic-spatial scene graphs for 3d visual grounding](https://arxiv.org/abs/2505.04058)|[AS3D](https://github.com/onmyoji-xiao/AS3D)|
|2505.04612|[fastmap: revisiting dense and scalable structure from motion](https://arxiv.org/abs/2505.04612)|[fastmap](https://github.com/pals-ttic/fastmap)|
|2505.06699|[model steering: learning with a reference model improves generalization bounds and scaling laws](https://arxiv.org/abs/2505.06699)|[drrho-clip](https://github.com/optimization-ai/drrho-clip)|
|2505.07447|[unified continuous generative models](https://arxiv.org/abs/2505.07447)|[UCGM](https://github.com/LINs-Lab/UCGM)|
|2505.08175|[fast text-to-audio generation with adversarial post-training](https://arxiv.org/abs/2505.08175)|[stable-audio-tools](https://github.com/stability-ai/stable-audio-tools)|
|2505.10238|[mtvcrafter: 4d motion tokenization for open-world human image animation](https://arxiv.org/abs/2505.10238)|[mtvcrafter](https://github.com/dingyanb/mtvcrafter)|
|2505.10464|[hwa-unetr: hierarchical window aggregate unetr for 3d multimodal gastric lesion segmentation](https://arxiv.org/abs/2505.10464)|[hwa-unetr](https://github.com/jeming-creater/hwa-unetr)|
|2505.12427|[draglora: online optimization of lora adapters for drag-based image editing in diffusion model](https://arxiv.org/abs/2505.12427)|[draglora](https://github.com/sylvie-x/draglora)|
|2505.12482|[spectral-spatial self-supervised learning for few-shot hyperspectral image classification](https://arxiv.org/abs/2505.12482)|[s4l-fsc](https://github.com/wenchen-chen/s4l-fsc)|
|2505.12499|[contrastive alignment with semantic gap-aware corrections in text-video retrieval](https://arxiv.org/abs/2505.12499)|[gare-text-video-retrieval](https://github.com/musicman217/gare-text-video-retrieval)|
|2505.13232|[starft: robust fine-tuning of zero-shot models via spuriosity alignment](https://arxiv.org/abs/2505.13232)|[starft](https://github.com/alinlab/starft)|
|2505.13483|[emometa: a multimodal dataset for fine-grained emotion classification in chinese metaphors](https://arxiv.org/abs/2505.13483)|[emometa](https://github.com/dutir-ysq/emometa)|
|2505.13539|[eulearn: a 3d database for learning euler characteristics](https://arxiv.org/abs/2505.13539)|[eulearn_db](https://github.com/appliedgeometry/eulearn_db)|
|2505.13669|[geovlm: improving automated vehicle geolocalisation using vision-language matching](https://arxiv.org/abs/2505.13669)|[geovlm](https://github.com/cav-research-lab/geovlm)|
|2505.13773|[model cards for ai teammates: comparing human-ai team familiarization methods for high-stakes environments](https://arxiv.org/abs/2505.13773)|[maisr](https://github.com/gt-cec/maisr)|
|2505.13784|[transfer learning from visual speech recognition to mouthing recognition in german sign language](https://arxiv.org/abs/2505.13784)|[transfer-learning-vsr-mouthing-sign-language](https://github.com/nphamdinh/transfer-learning-vsr-mouthing-sign-language)|
|2505.13813|[flashkat: understanding and addressing performance bottlenecks in the kolmogorov-arnold transformer](https://arxiv.org/abs/2505.13813)|[flashkat](https://github.com/osu-starlab/flashkat)|
|2505.13839|[mgstream: motion-aware 3d gaussian for streamable dynamic scene reconstruction](https://arxiv.org/abs/2505.13839)|[mgstream](https://github.com/pcl3dv/mgstream)|
|2505.13906|[xdementnet: an explainable attention based deep convolutional network to detect alzheimer progression from mri data](https://arxiv.org/abs/2505.13906)|[XdementNET](https://github.com/SoyabulIslamLincoln/XdementNET)|
|2505.13928|[lovr: a benchmark for long video retrieval in multimodal contexts](https://arxiv.org/abs/2505.13928)|[lovr-benchmark](https://github.com/technomad-ds/lovr-benchmark)|
|2505.14008|[multi-label stereo matching for transparent scene depth estimation](https://arxiv.org/abs/2505.14008)|[TranScene](https://github.com/BFZD233/TranScene)|
|2505.14017|[end-to-end cortical surface reconstruction from clinical magnetic resonance images](https://arxiv.org/abs/2505.14017)|[brainnet](https://github.com/simnibs/brainnet)|
|2505.14042|[adversarially pretrained transformers may be universally robust in-context learners](https://arxiv.org/abs/2505.14042)|[universally-robust-in-context-learner](https://github.com/s-kumano/universally-robust-in-context-learner)|
|2505.14049|[learning concept-driven logical rules for interpretable and generalizable medical image classification](https://arxiv.org/abs/2505.14049)|[crl](https://github.com/obiyoag/crl)|
|2505.14059|[dolphin: document image parsing via heterogeneous anchor prompting](https://arxiv.org/abs/2505.14059)|[dolphin](https://github.com/bytedance/dolphin)|
|2505.14124|[intra-class patch swap for self-distillation](https://arxiv.org/abs/2505.14124)|[intra-class-patch-swap](https://github.com/hchoi71/intra-class-patch-swap)|
|2505.14246|[visual agentic reinforcement fine-tuning](https://arxiv.org/abs/2505.14246)|[visual-rft](https://github.com/liuziyu77/visual-rft)|
|2505.14254|[instructing text-to-image diffusion models via classifier-guided semantic optimization](https://arxiv.org/abs/2505.14254)|[caso](https://github.com/chang-yuanyuan/caso)|
|2505.14260|[speculative decoding reimagined for multimodal large language models](https://arxiv.org/abs/2505.14260)|[msd](https://github.com/lyn-lucy/msd)|
|2505.14318|[radar: enhancing radiology report generation with supplementary knowledge injection](https://arxiv.org/abs/2505.14318)|[Radar](https://github.com/wjhou/Radar)|
|2505.14329|[tf-mamba: text-enhanced fusion mamba with missing modalities for robust multimodal sentiment analysis](https://arxiv.org/abs/2505.14329)|[tf-mamba](https://github.com/codemous/tf-mamba)|
|2505.14333|[domain adaptation for multi-label image classification: a discriminator-free approach](https://arxiv.org/abs/2505.14333)|[dda-mlic](https://github.com/cvi2snt/dda-mlic)|
|2505.14346|[egocentric action-aware inertial localization in point clouds](https://arxiv.org/abs/2505.14346)|[ego-inertial-localization](https://github.com/mf-zhang/ego-inertial-localization)|
|2505.14362|[deepeyes: incentivizing "thinking with images" via reinforcement learning](https://arxiv.org/abs/2505.14362)|[deepeyes](https://github.com/visual-agent/deepeyes)|
|2505.14377|[when bias backfires: the modulatory role of counterfactual explanations on the adoption of algorithmic bias in xai-supported human decision-making](https://arxiv.org/abs/2505.14377)|[biasbackfiresxai2025](https://github.com/ukuhl/biasbackfiresxai2025)|
|2505.14414|[diving into the fusion of monocular priors for generalized stereo matching](https://arxiv.org/abs/2505.14414)|[Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching](https://github.com/YaoChengTang/Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching)|
|2505.14454|[video compression commander: plug-and-play inference acceleration for video large language models](https://arxiv.org/abs/2505.14454)|[vidcom2](https://github.com/xuyang-liu16/vidcom2)|
|2505.14460|[visualquality-r1: reasoning-induced image quality assessment via reinforcement learning to rank](https://arxiv.org/abs/2505.14460)|[visualquality-r1](https://github.com/tianhewu/visualquality-r1)|
|2505.14462|[ravenea: a benchmark for multimodal retrieval-augmented visual culture understanding](https://arxiv.org/abs/2505.14462)|[ravenea](https://github.com/yfyuan01/ravenea)|
|2505.14556|[dynadiff: single-stage decoding of images from continuously evolving fmri](https://arxiv.org/abs/2505.14556)|[dynadiff](https://github.com/facebookresearch/dynadiff)|
|2505.14629|[kerl: knowledge-enhanced personalized recipe recommendation using large language models](https://arxiv.org/abs/2505.14629)|[kerl](https://github.com/mohbattharani/kerl)|
|2505.14633|[will ai tell lies to save sick children? litmus-testing ai values prioritization with airiskdilemmas](https://arxiv.org/abs/2505.14633)|[litmusvalues](https://github.com/kellycyy/litmusvalues)|
|2505.14638|[dual precision quantization for efficient and accurate deep neural networks inference](https://arxiv.org/abs/2505.14638)|[neural-compressor](https://github.com/intel/neural-compressor)|
|2505.14646|[cad-coder: an open-source vision-language model for computer-aided design code generation](https://arxiv.org/abs/2505.14646)|[cad-coder](https://github.com/anniedoris/cad-coder)|
|2505.14664|[akrmap: adaptive kernel regression for trustworthy visualization of cross-modal embeddings](https://arxiv.org/abs/2505.14664)|[akrmap](https://github.com/yilinye/akrmap)|
|2505.14687|[grouping first, attending smartly: training-free acceleration for diffusion transformers](https://arxiv.org/abs/2505.14687)|[grat](https://github.com/oliverrensu/grat)|
|2505.01000|[togedule: scheduling meetings with large language models and adaptive representations of group availability](https://arxiv.org/abs/2505.01000)|[togedule](https://github.com/jyoonsong/togedule)|
|2505.01212|[high dynamic range novel view synthesis with single exposure](https://arxiv.org/abs/2505.01212)|[mono-hdr-3d](https://github.com/prinasi/mono-hdr-3d)|
|2505.02831|[no other representation component is needed: diffusion transformers can provide representation guidance by themselves](https://arxiv.org/abs/2505.02831)|[sra](https://github.com/vvvvvjdy/sra)|
|2505.03654|[regrap-llava: reasoning enabled graph-based personalized large language and vision assistant](https://arxiv.org/abs/2505.03654)|[regrap](https://github.com/xyfyyds/regrap)|
|2505.05022|[soap: style-omniscient animatable portraits](https://arxiv.org/abs/2505.05022)|[soap](https://github.com/tingtingliao/soap)|
|2505.05621|[a preliminary study for gpt-4o on image restoration](https://arxiv.org/abs/2505.05621)|[gpt_restoration](https://github.com/noxsine/gpt_restoration)|
|2505.05657|[arraydps: unsupervised blind speech separation with a diffusion prior](https://arxiv.org/abs/2505.05657)|[arraydps](https://github.com/arraydps/arraydps)|
|2505.05678|[instancegen: image generation with instance-level instructions](https://arxiv.org/abs/2505.05678)|[SLD](https://github.com/tsunghan-wu/SLD)|
|2505.05834|[dual-level fuzzy learning with patch guidance for image ordinal regression](https://arxiv.org/abs/2505.05834)|[dfpg-ord](https://github.com/zjumai/dfpg-ord)|
|2505.08586|[preprompt: predictive prompting for class incremental learning](https://arxiv.org/abs/2505.08586)|[PrePrompt](https://github.com/libo-huang/PrePrompt)|
|2505.09926|[adaptclip: adapting clip for universal visual anomaly detection](https://arxiv.org/abs/2505.09926)|[AdaptCLIP](https://github.com/gaobb/AdaptCLIP)|
|2505.11032|[dexgarmentlab: dexterous garment manipulation environment with generalizable policy](https://arxiv.org/abs/2505.11032)|[dexgarmentlab](https://github.com/wayrise/dexgarmentlab)|
|2505.11538|[brainnetmlp: an efficient and effective baseline for functional brain network classification](https://arxiv.org/abs/2505.11538)|[brainnetmlp](https://github.com/jayceonho/brainnetmlp)|
|2505.11581|[questioning representational optimism in deep learning: the fractured entangled representation hypothesis](https://arxiv.org/abs/2505.11581)|[fer](https://github.com/akarshkumar0101/fer)|
|2505.11594|[sageattention3: microscaling fp4 attention for inference and an exploration of 8-bit training](https://arxiv.org/abs/2505.11594)|[SageAttention](https://github.com/thu-ml/SageAttention)|
|2505.11612|[heart2mind: human-centered contestable psychiatric disorder diagnosis system using wearable ecg monitors](https://arxiv.org/abs/2505.11612)|[heart2mind](https://github.com/analytics-everywhere-lab/heart2mind)|
|2505.11703|[loft: lora-fused training dataset generation with few-shot guidance](https://arxiv.org/abs/2505.11703)|[loft](https://github.com/explainableml/loft)|
|2505.11720|[ugodit: unsupervised group deep image prior via transferable weights](https://arxiv.org/abs/2505.11720)|[ugodit](https://github.com/sjames40/ugodit)|
|2505.11797|[medvkan: efficient feature extraction with mamba and kan for medical image segmentation](https://arxiv.org/abs/2505.11797)|[medvkan](https://github.com/beginner-cjh/medvkan)|
|2505.11800|[self-learning hyperspectral and multispectral image fusion via adaptive residual guided subspace diffusion model](https://arxiv.org/abs/2505.11800)|[args-diff](https://github.com/zhu1116/args-diff)|
|2505.11838|[rvtbench: a benchmark for visual reasoning tasks](https://arxiv.org/abs/2505.11838)|[rvt](https://github.com/yiqings/rvt)|
|2505.11842|[video-safetybench: a benchmark for safety evaluation of video lvlms](https://arxiv.org/abs/2505.11842)|[video-safetybench](https://github.com/flageval-baai/video-safetybench)|
|2505.11882|[genzsl: generative zero-shot learning via inductive variational autoencoder](https://arxiv.org/abs/2505.11882)|[genzsl](https://github.com/shiming-chen/genzsl)|
|2505.11909|[bridging the inter-domain gap through low-level features for cross-modal medical image segmentation](https://arxiv.org/abs/2505.11909)|[lowbridge](https://github.com/joshualpf/lowbridge)|
|2505.11913|[joint manifold learning and optimal transport for dynamic imaging](https://arxiv.org/abs/2505.11913)|[joint-manifold-learning-and-ot](https://github.com/SCdummer/joint-manifold-learning-and-ot)|
|2505.12021|[cross-model transfer of task vectors via few-shot orthogonal alignment](https://arxiv.org/abs/2505.12021)|[crossmodeltransfer](https://github.com/kawakera-lab/crossmodeltransfer)|
|2505.12051|[enhanced multimodal hate video detection via channel-wise and modality-wise fusion](https://arxiv.org/abs/2505.12051)|[cmfusion](https://github.com/evelynz10/cmfusion)|
|2505.12066|[beluga whale detection from satellite imagery with point labels](https://arxiv.org/abs/2505.12066)|[beluga-seeker](https://github.com/voyagerxvoyagerx/beluga-seeker)|
|2505.12098|[love: benchmarking and evaluating text-to-video generation and video-to-text interpretation](https://arxiv.org/abs/2505.12098)|[love](https://github.com/intmegroup/love)|
|2505.12120|[histai: an open-source, large-scale whole slide image dataset for computational pathology](https://arxiv.org/abs/2505.12120)|[histai](https://github.com/histai/histai)|
|2505.12155|[softpq: robust instance segmentation evaluation via soft matching and tunable thresholds](https://arxiv.org/abs/2505.12155)|[SoftPQ](https://github.com/rkarmaka/SoftPQ)|
|2505.12191|[ditch the denoiser: emergence of noise robustness in self-supervised learning from data curriculum](https://arxiv.org/abs/2505.12191)|[noisy_dinov2](https://github.com/wenquanlu/noisy_dinov2)|
|2505.12199|[always clear depth: robust monocular depth estimation under adverse weather](https://arxiv.org/abs/2505.12199)|[acdepth](https://github.com/msscao/acdepth)|
|2505.12217|[hyperspectral image land cover captioning dataset for vision language models](https://arxiv.org/abs/2505.12217)|[hypercap](https://github.com/arya-domain/hypercap)|
|2505.12261|[openpros: a large-scale dataset for limited view prostate ultrasound computed tomography](https://arxiv.org/abs/2505.12261)|[openpros](https://github.com/hanchenwang/openpros)|
|2505.12266|[pmq-ve: progressive multi-frame quantization for video enhancement](https://arxiv.org/abs/2505.12266)|[pmq-ve](https://github.com/xiaobigfeng/pmq-ve)|
|2505.12267|[real-time spatial reasoning by mobile robots for reconstruction and navigation in dynamic lidar scenes](https://arxiv.org/abs/2505.12267)|[RTRecon](https://github.com/SZU-VCC/RTRecon)|
|2505.12280|[temporal-spectral-spatial unified remote sensing dense prediction](https://arxiv.org/abs/2505.12280)|[official_tssun](https://github.com/walking-shadow/official_tssun)|
|2505.12307|[logicocr: do your large multimodal models excel at logical reasoning on text-rich images?](https://arxiv.org/abs/2505.12307)|[logicocr](https://github.com/mililab/logicocr)|
|2505.12335|[is artificial intelligence generated image detection a solved problem?](https://arxiv.org/abs/2505.12335)|[aigibench](https://github.com/horizontel/aigibench)|
|2505.12363|[towards visuospatial cognition via hierarchical fusion of visual experts](https://arxiv.org/abs/2505.12363)|[vica](https://github.com/nkkbr/vica)|
|2505.12432|[observe-r1: unlocking reasoning abilities of mllms with dynamic progressive reinforcement learning](https://arxiv.org/abs/2505.12432)|[observe-r1](https://github.com/zrguo/observe-r1)|
|2505.12434|[videorft: incentivizing video reasoning capability in mllms via reinforced fine-tuning](https://arxiv.org/abs/2505.12434)|[videorft](https://github.com/qiwang98/videorft)|
|2505.12513|[globalgeotree: a multi-granular vision-language dataset for global tree species classification](https://arxiv.org/abs/2505.12513)|[globalgeotree](https://github.com/muyang99/globalgeotree)|
|2505.12532|[exploring sparsity for parameter efficient fine tuning using wavelets](https://arxiv.org/abs/2505.12532)|[sparse_peft](https://github.com/bilican/sparse_peft)|
|2505.12547|[promi: an efficient prototype-mixture baseline for few-shot segmentation with bounding-box annotations](https://arxiv.org/abs/2505.12547)|[promi](https://github.com/thalesgroup/promi)|
|2505.12630|[degradation-aware feature perturbation for all-in-one image restoration](https://arxiv.org/abs/2505.12630)|[dfpir](https://github.com/txphome/dfpir)|
|2505.12631|[multi-resolution haar network: enhancing human motion prediction via haar transform](https://arxiv.org/abs/2505.12631)|[haarmodic](https://github.com/xhaughearl/haarmodic)|
|2505.12650|[automat: enabling automated crystal structure reconstruction from microscopy via agentic tool use](https://arxiv.org/abs/2505.12650)|[automat](https://github.com/yyt-2378/automat)|
|2505.12669|[text2midi-inferalign: improving symbolic music generation with inference-time alignment](https://arxiv.org/abs/2505.12669)|[t2m-inferalign](https://github.com/amaai-lab/t2m-inferalign)|
|2505.12674|[few-step diffusion via score identity distillation](https://arxiv.org/abs/2505.12674)|[sid-lsg](https://github.com/mingyuanzhou/sid-lsg)|
|2505.12718|[automated bias assessment in ai-generated educational content using ceat framework](https://arxiv.org/abs/2505.12718)|[Automated-Word-Extraction](https://github.com/EricP66/Automated-Word-Extraction)|
|2505.12742|[mvar: visual autoregressive modeling with scale and spatial markovian conditioning](https://arxiv.org/abs/2505.12742)|[mvar](https://github.com/labshuhanggu/mvar)|
|2505.12766|[reasoning-ocr: can large multimodal models solve complex logical reasoning problems from ocr cues?](https://arxiv.org/abs/2505.12766)|[reasoningocr](https://github.com/hxyz-123/reasoningocr)|
|2505.12820|[rethinking features-fused-pyramid-neck for object detection](https://arxiv.org/abs/2505.12820)|[rethinking-fpn](https://github.com/alanli1997/rethinking-fpn)|
|2505.12834|[a study on the refining handwritten font by mixing font styles](https://arxiv.org/abs/2505.12834)|[FontFusionGAN](https://github.com/KumarAvinash44/FontFusionGAN)|
|2505.12835|[flightgpt: towards generalizable and interpretable uav vision-and-language navigation with vision-language models](https://arxiv.org/abs/2505.12835)|[flightgpt](https://github.com/pendulumclock/flightgpt)|
|2505.12849|[accelerate tarflow sampling with gs-jacobi iteration](https://arxiv.org/abs/2505.12849)|[gs-jacobi_for_tarflow](https://github.com/encoreus/gs-jacobi_for_tarflow)|
|2505.12861|[robust multimodal segmentation with representation regularization and hybrid prototype distillation](https://arxiv.org/abs/2505.12861)|[robustseg](https://github.com/robustseg/robustseg)|
|2505.12897|[epic: explanation of pretrained image classification networks via prototype](https://arxiv.org/abs/2505.12897)|[epic](https://github.com/piotr310100/epic)|
|2505.12903|[towards low-latency event stream-based visual object tracking: a slow-fast approach](https://arxiv.org/abs/2505.12903)|[slowfast_event_track](https://github.com/event-ahu/slowfast_event_track)|
|2505.12908|[dynamic graph induced contour-aware heat conduction network for event-based object detection](https://arxiv.org/abs/2505.12908)|[openevdet](https://github.com/event-ahu/openevdet)|
|2505.12911|[hiero: understanding the hierarchy of human behavior enhances reasoning on egocentric videos](https://arxiv.org/abs/2505.12911)|[hiero](https://github.com/sapeirone/hiero)|
|2505.12912|[uniformity first: uniformity-aware test-time adaptation of vision-language models against image corruption](https://arxiv.org/abs/2505.12912)|[uninfo](https://github.com/kzkadc/uninfo)|
|2505.12944|[calm-pde: continuous and adaptive convolutions for latent space modeling of time-dependent pdes](https://arxiv.org/abs/2505.12944)|[calm-pde](https://github.com/jhagnberger/calm-pde)|
|2505.12998|[a skull-adaptive framework for ai-based 3d transcranial focused ultrasound simulation](https://arxiv.org/abs/2505.12998)|[tfuscapes](https://github.com/camma-public/tfuscapes)|
|2505.12999|[a generalisable head mri defacing pipeline: evaluation on 2,566 meningioma scans](https://arxiv.org/abs/2505.12999)|[defacing_pipeline](https://github.com/cai4cai/defacing_pipeline)|
|2505.13010|[to bias or not to bias: detecting bias in news with bias-detector](https://arxiv.org/abs/2505.13010)|[newsbiasdetector](https://github.com/himel1996/newsbiasdetector)|
|2505.13032|[mmar: a challenging benchmark for deep reasoning in speech, audio, music, and their mix](https://arxiv.org/abs/2505.13032)|[mmar](https://github.com/ddlbojack/mmar)|
|2505.13088|[cross-modal feature fusion for robust point cloud registration with ambiguous geometry](https://arxiv.org/abs/2505.13088)|[coff](https://github.com/zhaoyiww/coff)|
|2505.13137|[learning to adapt to position bias in vision transformer classifiers](https://arxiv.org/abs/2505.13137)|[position-shap](https://github.com/rjbruin/position-shap)|
|2505.13152|[higher fidelity perceptual image and video compression with a latent conditioned residual denoising diffusion model](https://arxiv.org/abs/2505.13152)|[rescdc](https://github.com/jbrenig/rescdc)|
|2505.13201|[matpredict: a dataset and benchmark for learning material properties of diverse indoor objects](https://arxiv.org/abs/2505.13201)|[matpredict](https://github.com/arpan-kusari/matpredict)|
|2505.13211|[magi-1: autoregressive video generation at scale](https://arxiv.org/abs/2505.13211)|[magiattention](https://github.com/sandai-org/magiattention)|
|2505.13215|[hybrid 3d-4d gaussian splatting for fast dynamic scene representation](https://arxiv.org/abs/2505.13215)|[3D-4DGS](https://github.com/ohsngjun/3D-4DGS)|
|2505.13218|[human response to decision support in face matching: the influence of task difficulty and machine accuracy](https://arxiv.org/abs/2505.13218)|[humanresponse-dss-facematching](https://github.com/ealmenzar/humanresponse-dss-facematching)|
|2505.13233|[from local details to global context: advancing vision-language models with attention-based selection](https://arxiv.org/abs/2505.13233)|[abs](https://github.com/bit-da/abs)|
|2505.13235|[writevit: handwritten text generation with vision transformer](https://arxiv.org/abs/2505.13235)|[writevit](https://github.com/hnam-1765/writevit)|
|2505.13307|[rbf++: quantifying and optimizing reasoning boundaries across measurable and unmeasurable capabilities for chain-of-thought reasoning](https://arxiv.org/abs/2505.13307)|[reasoning-boundary](https://github.com/lightchen233/reasoning-boundary)|
|2505.13316|[denoising diffusion probabilistic model for point cloud compression at low bit-rates](https://arxiv.org/abs/2505.13316)|[ddpm-pcc](https://github.com/eidoslab/ddpm-pcc)|
|2505.13390|[mgpbd: a multigrid accelerated global xpbd solver](https://arxiv.org/abs/2505.13390)|[mgpbd](https://github.com/chunleili/mgpbd)|
|2505.13419|[feallm: advancing facial emotion analysis in multimodal large language models with emotional synergy and reasoning](https://arxiv.org/abs/2505.13419)|[feallm](https://github.com/953206211/feallm)|
|2505.13426|[g1: bootstrapping perception and reasoning abilities of vision-language model via reinforcement learning](https://arxiv.org/abs/2505.13426)|[g1](https://github.com/chenllliang/g1)|
|2505.13427|[mm-prm: enhancing multimodal mathematical reasoning with scalable step-level supervision](https://arxiv.org/abs/2505.13427)|[mm-prm](https://github.com/modalminds/mm-prm)|
|2505.13439|[vtbench: evaluating visual tokenizers for autoregressive image generation](https://arxiv.org/abs/2505.13439)|[VTBench](https://github.com/huawei-lin/VTBench)|
|2505.13440|[recollection from pensieve: novel view synthesis via learning from uncalibrated videos](https://arxiv.org/abs/2505.13440)|[pensieve](https://github.com/dwawayu/pensieve)|
|2505.01481|[videohallu: evaluating and mitigating multi-modal hallucinations on synthetic video understanding](https://arxiv.org/abs/2505.01481)|[videohallu](https://github.com/zli12321/videohallu)|
|2505.04258|[rgb-event fusion with self-attention for collision prediction](https://arxiv.org/abs/2505.04258)|[eva](https://github.com/pbonazzi/eva)|
|2505.05848|[refref: a synthetic dataset and benchmark for reconstructing refractive and reflective objects](https://arxiv.org/abs/2505.05848)|[refref](https://github.com/yueyin27/refref)|
|2505.06003|[from pixels to perception: interpretable predictions via instance-wise grouped feature selection](https://arxiv.org/abs/2505.06003)|[p2p](https://github.com/mvandenhi/p2p)|
|2505.07449|[ophora: a large-scale data-driven text-guided ophthalmic surgical video generation model](https://arxiv.org/abs/2505.07449)|[ophora](https://github.com/mar-cry/ophora)|
|2505.10595|[arfc-wahnet: adaptive receptive field convolution and wavelet-attentive hierarchical network for infrared small target detection](https://arxiv.org/abs/2505.10595)|[arfc-wahnet](https://github.com/leaf2001/arfc-wahnet)|
|2505.10610|[mmlongbench: benchmarking long-context vision-language models effectively and thoroughly](https://arxiv.org/abs/2505.10610)|[mmlongbench](https://github.com/edinburghnlp/mmlongbench)|
|2505.10679|[are spatial-temporal graph convolution networks for human action recognition over-parameterized?](https://arxiv.org/abs/2505.10679)|[sparse-st-gcn](https://github.com/davelailai/sparse-st-gcn)|
|2505.10686|[neolightning: a modern reimagination of gesture-based sound design](https://arxiv.org/abs/2505.10686)|[reimaginingthebuchlalightning](https://github.com/yonghyunk1m/reimaginingthebuchlalightning)|
|2505.10687|[roisgan: a region guided generative adversarial framework for murine hippocampal subregion segmentation](https://arxiv.org/abs/2505.10687)|[roisgan](https://github.com/mehediazim/roisgan)|
|2505.10787|[ea-3dgs: efficient and adaptive 3d gaussians with highly enhanced quality for outdoor scenes](https://arxiv.org/abs/2505.10787)|[ea-3dgs](https://github.com/scut-bip-lab/ea-3dgs)|
|2505.10824|[textured mesh quality assessment using geometry and color field similarity](https://arxiv.org/abs/2505.10824)|[fmqm](https://github.com/yyyykf/fmqm)|
|2505.10836|[multimodal event detection: current approaches and defining the new playground through llms and vlms](https://arxiv.org/abs/2505.10836)|[multimodeleventdetection](https://github.com/salokr/multimodeleventdetection)|
|2505.10873|[hashing for structure-based anomaly detection](https://arxiv.org/abs/2505.10873)|[hashing-for-structure-based-anomaly-detection](https://github.com/ineveloppilif/hashing-for-structure-based-anomaly-detection)|
|2505.10874|[multilink: multi-class structure recovery via agglomerative clustering and model selection](https://arxiv.org/abs/2505.10874)|[multilink](https://github.com/magrilu/multilink)|
|2505.10888|[posebench3d: a cross-dataset analysis framework for 3d human pose estimation](https://arxiv.org/abs/2505.10888)|[poselab3d](https://github.com/bryanjvela/poselab3d)|
|2505.10931|[m4-sar: a multi-resolution, multi-polarization, multi-scene, multi-source dataset and benchmark for optical-sar fusion object detection](https://arxiv.org/abs/2505.10931)|[m4-sar](https://github.com/wchao0601/m4-sar)|
|2505.11003|[forensichub: a unified benchmark & codebase for all-domain fake image detection and localization](https://arxiv.org/abs/2505.11003)|[forensichub](https://github.com/scu-zjz/forensichub)|
|2505.11034|[cleanpatrick: a benchmark for image data cleaning](https://arxiv.org/abs/2505.11034)|[cleanpatrick](https://github.com/digital-dermatology/cleanpatrick)|
|2505.11060|[cubic: concept embeddings for unsupervised bias identification using vlms](https://arxiv.org/abs/2505.11060)|[cubic](https://github.com/david-mnd/cubic)|
|2505.11062|[hsrmamba: efficient wavelet stripe state space model for hyperspectral image super-resolution](https://arxiv.org/abs/2505.11062)|[hsrmamba](https://github.com/oldsweet/hsrmamba)|
|2505.11099|[hybrid-emba3d: geometry-aware and cross-path feature hybrid enhanced state space model for point cloud classification](https://arxiv.org/abs/2505.11099)|[hybrid-emba3d](https://github.com/l1277471578/hybrid-emba3d)|
|2505.11129|[phinet v2: a mask-free brain-inspired vision foundation model from video](https://arxiv.org/abs/2505.11129)|[phinetv2](https://github.com/oist/phinetv2)|
|2505.11131|[one image is worth a thousand words: a usability preservable text-image collaborative erasing framework](https://arxiv.org/abs/2505.11131)|[co-erasing](https://github.com/ferry-li/co-erasing)|
|2505.11146|[x2c: a dataset featuring nuanced facial expressions for realistic humanoid imitation](https://arxiv.org/abs/2505.11146)|[x2cnet](https://github.com/lipzh5/x2cnet)|
|2505.11196|[dico: revitalizing convnets for scalable and efficient diffusion modeling](https://arxiv.org/abs/2505.11196)|[dico](https://github.com/shallowdream204/dico)|
|2505.11237|[concept drift guided layernorm tuning for efficient multimodal metaphor identification](https://arxiv.org/abs/2505.11237)|[CDGLT](https://github.com/MSA-LMC/CDGLT)|
|2505.11245|[diffusion-npo: negative preference optimization for better preference aligned generation of diffusion models](https://arxiv.org/abs/2505.11245)|[diffusion-npo](https://github.com/g-u-n/diffusion-npo)|
|2505.11246|[entropy-driven genetic optimization for deep-feature-guided low-light image enhancement](https://arxiv.org/abs/2505.11246)|[entropy-driven-genetic-optimization-for-deep-feature-guided-low-light-image-enhancement](https://github.com/nirjhor-datta/entropy-driven-genetic-optimization-for-deep-feature-guided-low-light-image-enhancement)|
|2505.11293|[breaking the batch barrier (b3) of contrastive learning via smart batch mining](https://arxiv.org/abs/2505.11293)|[b3](https://github.com/raghavlite/b3)|
|2505.11326|[temporally-grounded language generation: a benchmark for real-time vision-language models](https://arxiv.org/abs/2505.11326)|[tglg](https://github.com/yukw777/tglg)|
|2505.11366|[learning multimodal ai algorithms for amplifying limited user input into high-dimensional control space](https://arxiv.org/abs/2505.11366)|[aras](https://github.com/abirilab/aras)|
|2505.11383|[dynam3d: dynamic layered 3d tokens empower vlm for vision-and-language navigation](https://arxiv.org/abs/2505.11383)|[dynam3d](https://github.com/mrzihan/dynam3d)|
|2505.11394|[from fibers to cells: fourier-based registration enables virtual cresyl violet staining from 3d polarized light imaging](https://arxiv.org/abs/2505.11394)|[pli2cells](https://github.com/fzj-inm1-bda/pli2cells)|
|2505.11405|[emotionhallucer: evaluating emotion hallucinations in multimodal large language models](https://arxiv.org/abs/2505.11405)|[emotionhallucer](https://github.com/xxtars/emotionhallucer)|
|2505.11409|[visual planning: let's think only with images](https://arxiv.org/abs/2505.11409)|[visualplanning](https://github.com/yix8/visualplanning)|
|2505.11417|[edgewisepersona: a dataset for on-device user profiling from natural language interactions](https://arxiv.org/abs/2505.11417)|[edgewisepersona](https://github.com/tclresearcheurope/edgewisepersona)|
|2505.11454|[humanibench: a human-centric framework for large multimodal models evaluation](https://arxiv.org/abs/2505.11454)|[humanibench](https://github.com/vectorinstitute/humanibench)|
|2505.03186|[cogenav: versatile audio-visual representation learning via contrastive-generative synchronization](https://arxiv.org/abs/2505.03186)|[cogenav](https://github.com/humanmllm/cogenav)|
|2505.05901|[examining the source of defects from a mechanical perspective for 3d anomaly detection](https://arxiv.org/abs/2505.05901)|[mc4ad](https://github.com/hzzzzzhappy/mc4ad)|
|2505.06512|[hcma: hierarchical cross-model alignment for grounded text-to-image generation](https://arxiv.org/abs/2505.06512)|[hcma](https://github.com/hwang-cs-ime/hcma)|
|2505.08910|[behind maya: building a multilingual vision language model](https://arxiv.org/abs/2505.08910)|[maya](https://github.com/nahidalam/maya)|
|2505.09858|[mission balance: generating under-represented class samples using video diffusion models](https://arxiv.org/abs/2505.09858)|[surgvgen](https://gitlab.com/nct_tso_public/surgvgen)|
|2505.09901|[comparing exploration-exploitation strategies of llms and humans: insights from standard multi-armed bandit tasks](https://arxiv.org/abs/2505.09901)|[exploration](https://github.com/sjgershm/exploration)|
|2505.09927|[ddfp: data-dependent frequency prompt for source free domain adaptation of medical image segmentation](https://arxiv.org/abs/2505.09927)|[SFDA-DDFP](https://github.com/YYinn/SFDA-DDFP)|
|2505.09939|[non-registration change detection: a novel change detection task and benchmark dataset](https://arxiv.org/abs/2505.09939)|[nrcd](https://github.com/shanzard/nrcd)|
|2505.09943|[cspenet: contour-aware and saliency priors embedding network for infrared small target detection](https://arxiv.org/abs/2505.09943)|[cspenet](https://github.com/idip2025/cspenet)|
|2505.09971|[apcotta: continual test-time adaptation for semantic segmentation of airborne lidar point clouds](https://arxiv.org/abs/2505.09971)|[apcotta](https://github.com/gaoyuan2/apcotta)|
|2505.10046|[exploring the deep fusion of large language models and diffusion transformers for text-to-image synthesis](https://arxiv.org/abs/2505.10046)|[fuse-dit](https://github.com/tang-bd/fuse-dit)|
|2505.10049|[advances in radiance field for dynamic scene: from neural field to gaussian field](https://arxiv.org/abs/2505.10049)|[dynamic-radiation-field-paper-list](https://github.com/moonflo/dynamic-radiation-field-paper-list)|
|2505.10055|[psocr: benchmarking large multimodal models for optical character recognition in low-resource pashto language](https://arxiv.org/abs/2505.10055)|[pashtoocr](https://github.com/zirak-ai/pashtoocr)|
|2505.10088|[mmrl++: parameter-efficient and interaction-aware representation learning for vision-language models](https://arxiv.org/abs/2505.10088)|[MMRL](https://github.com/yunncheng/MMRL)|
|2505.10124|[imitate: image registration with context for unknown time frame recovery](https://arxiv.org/abs/2505.10124)|[imitate](https://github.com/kheil-z/imitate)|
|2505.10144|[vrsplat: fast and robust gaussian splatting for virtual reality](https://arxiv.org/abs/2505.10144)|[vrsplat](https://github.com/cekavis/vrsplat)|
|2505.10223|[data-agnostic augmentations for unknown variations: out-of-distribution generalisation in mri segmentation](https://arxiv.org/abs/2505.10223)|[augmentations-for-the-unknown](https://github.com/miagrouput/augmentations-for-the-unknown)|
|2505.10231|[on the interplay of human-ai alignment,fairness, and performance trade-offs in medical imaging](https://arxiv.org/abs/2505.10231)|[aligner](https://github.com/roypic/aligner)|
|2505.10250|[adhmr: aligning diffusion-based human mesh recovery via direct preference optimization](https://arxiv.org/abs/2505.10250)|[adhmr](https://github.com/shenwenhao01/adhmr)|
|2505.10281|[mfoghub: bridging multi-regional and multi-satellite data for global marine fog detection and forecasting](https://arxiv.org/abs/2505.10281)|[mfoghub](https://github.com/kaka0910/mfoghub)|
|2505.10289|[msci: addressing clip's inherent limitations for compositional zero-shot learning](https://arxiv.org/abs/2505.10289)|[msci](https://github.com/ltpwy/msci)|
|2505.10292|[storyreasoning dataset: using chain-of-thought for scene understanding and grounded story generation](https://arxiv.org/abs/2505.10292)|[storyreasoning](https://github.com/daniel3303/storyreasoning)|
|2505.10294|[miphei-vit: multiplex immunofluorescence prediction from h&e images using vit foundation models](https://arxiv.org/abs/2505.10294)|[miphei-vit](https://github.com/sanofi-public/miphei-vit)|
|2505.10348|[listennet: a lightweight spatio-temporal enhancement nested network for auditory attention detection](https://arxiv.org/abs/2505.10348)|[listennet](https://github.com/fchest/listennet)|
|2505.10351|[a unified and scalable membership inference method for visual self-supervised encoder via part-aware capability](https://arxiv.org/abs/2505.10351)|[partcrop](https://github.com/jiepku/partcrop)|
|2505.10420|[learned lightweight smartphone isp with unpaired data](https://arxiv.org/abs/2505.10420)|[learned-lightweight-smartphone-isp-with-unpaired-data](https://github.com/andreiiarhire/learned-lightweight-smartphone-isp-with-unpaired-data)|
|2505.10457|[seal: searching expandable architectures for incremental learning](https://arxiv.org/abs/2505.10457)|[seal](https://github.com/ai-tech-research-lab/seal)|
|2505.10473|[consistent quantity-quality control across scenes for deployment-aware gaussian splatting](https://arxiv.org/abs/2505.10473)|[ControlGS](https://github.com/zhang-fengdi/ControlGS)|
|2505.10496|[chexgenbench: a unified benchmark for fidelity, privacy and utility of synthetic chest radiographs](https://arxiv.org/abs/2505.10496)|[CheXGenBench](https://github.com/Raman1121/CheXGenBench)|
|2505.10518|[multi-token prediction needs registers](https://arxiv.org/abs/2505.10518)|[mutor](https://github.com/nasosger/mutor)|
|2505.10541|[exploring implicit visual misunderstandings in multimodal large language models through attention analysis](https://arxiv.org/abs/2505.10541)|[stme](https://github.com/welldonepf/stme)|
|2505.10551|[does feasibility matter? understanding the impact of feasibility on synthetic training data](https://arxiv.org/abs/2505.10551)|[syntheticdatafeasibility](https://github.com/yiveen/syntheticdatafeasibility)|
|2505.10557|[mathcoder-vl: bridging vision and code for enhanced multimodal mathematical reasoning](https://arxiv.org/abs/2505.10557)|[mathcoder](https://github.com/mathllm/mathcoder)|
|2505.07634|[neural brain: a neuroscience-inspired framework for embodied agents](https://arxiv.org/abs/2505.07634)|[Neural-Brain-for-Embodied-Agents](https://github.com/CNJianLiu/Neural-Brain-for-Embodied-Agents)|
|2505.08527|[leveraging segment anything model for source-free domain adaptation via dual feature guided auto-prompting](https://arxiv.org/abs/2505.08527)|[dfg](https://github.com/xmed-lab/dfg)|
|2505.08568|[thermal detection of people with mobility restrictions for barrier reduction at traffic lights controlled intersections](https://arxiv.org/abs/2505.08568)|[yolo-thermal](https://github.com/leon2014dresden/yolo-thermal)|
|2505.08614|[waveguard: robust deepfake detection and source tracing via dual-tree complex wavelet and graph neural networks](https://arxiv.org/abs/2505.08614)|[waveguard](https://github.com/vpsg-research/waveguard)|
|2505.08817|[towards sfw sampling for diffusion models via external conditioning](https://arxiv.org/abs/2505.08817)|[sfws-stable-diffusion](https://github.com/camilocarvajalreyes/sfws-stable-diffusion)|
|2505.08854|[generative ai for autonomous driving: frontiers and opportunities](https://arxiv.org/abs/2505.08854)|[genai4ad](https://github.com/taco-group/genai4ad)|
|2505.08919|[template-guided reconstruction of pulmonary segments with neural implicit functions](https://arxiv.org/abs/2505.08919)|[impulse](https://github.com/m3dv/impulse)|
|2505.08932|[parameter-efficient fine-tuning of vision foundation model for forest floor segmentation from uav imagery](https://arxiv.org/abs/2505.08932)|[sam_peft](https://github.com/garrulus-project/sam_peft)|
|2505.08961|[differentiable channel selection in self-attention for person re-identification](https://arxiv.org/abs/2505.08961)|[dcs-attention](https://github.com/statistical-deep-learning/dcs-attention)|
|2505.08971|[prioritizing image-related tokens enhances vision-language pre-training](https://arxiv.org/abs/2505.08971)|[prior](https://github.com/yangyi-chen/prior)|
|2505.08999|[towards adaptive meta-gradient adversarial examples for visual tracking](https://arxiv.org/abs/2505.08999)|[amga](https://github.com/pgao-lab/amga)|
|2505.09092|[openlka: an open dataset of lane keeping assist from recent car models under real-world driving conditions](https://arxiv.org/abs/2505.09092)|[openlka](https://github.com/openlka/openlka)|
|2505.09140|[topodit-3d: topology-aware diffusion transformer with bottleneck structure for 3d point cloud generation](https://arxiv.org/abs/2505.09140)|[topodit-3d](https://github.com/zechao-guan/topodit-3d)|
|2505.09168|[drrnet: macro-micro feature fusion and dual reverse refinement for camouflaged object detection](https://arxiv.org/abs/2505.09168)|[drrnet](https://github.com/jerrysunning/drrnet)|
|2505.09252|[zero-shot multi-modal large language model v.s. supervised deep learning: a comparative study on ct-based intracranial hemorrhage subtyping](https://arxiv.org/abs/2505.09252)|[ich_mllms_validation](https://github.com/mileswyn/ich_mllms_validation)|
|2505.09262|[edbench: large-scale electron density data for molecular modeling](https://arxiv.org/abs/2505.09262)|[EDBench](https://github.com/HongxinXiang/EDBench)|
|2505.09263|[few-shot anomaly-driven generation for anomaly classification and segmentation](https://arxiv.org/abs/2505.09263)|[anogen](https://github.com/gaobb/anogen)|
|2505.09264|[learning to detect multi-class anomalies with just one normal image prompt](https://arxiv.org/abs/2505.09264)|[onenip](https://github.com/gaobb/onenip)|
|2505.09306|[predicting butterfly species presence from satellite imagery using soft contrastive regularisation](https://arxiv.org/abs/2505.09306)|[pecl](https://github.com/vdplasthijs/pecl)|
|2505.09323|[q-space guided collaborative attention translation network for flexible diffusion-weighted images synthesis](https://arxiv.org/abs/2505.09323)|[q-catn](https://github.com/idea89560041/q-catn)|
|2505.09350|[procedural low-poly terrain generation with terracing for computer games](https://arxiv.org/abs/2505.09350)|[Procedural-Low-Poly-Terrain-Generation](https://github.com/richardtivolt/Procedural-Low-Poly-Terrain-Generation)|
|2505.09356|[apr-transformer: initial pose estimation for localization in complex environments through absolute pose regression](https://arxiv.org/abs/2505.09356)|[apr-transformer](https://github.com/gt-arc/apr-transformer)|
|2505.09358|[marigold: affordable adaptation of diffusion-based image generators for image analysis](https://arxiv.org/abs/2505.09358)|[marigold](https://github.com/prs-eth/marigold)|
|2505.09372|[make: multi-aspect knowledge-enhanced vision-language pretraining for zero-shot dermatological assessment](https://arxiv.org/abs/2505.09372)|[make](https://github.com/siyuanyan1/make)|
|2505.09393|[umotion: uncertainty-driven human motion estimation from inertial and ultra-wideband units](https://arxiv.org/abs/2505.09393)|[umotion](https://github.com/kk9six/umotion)|
|2505.09413|[sparse point cloud patches rendering via splitting 2d gaussians](https://arxiv.org/abs/2505.09413)|[gaupcrender](https://github.com/murcherful/gaupcrender)|
|2505.09521|[spec2volcamu-net: a spectrogram-to-volume model for eeg-to-fmri reconstruction based on multi-directional time-frequency convolutional attention encoder and vision-mamba u-net](https://arxiv.org/abs/2505.09521)|[spec2volcamu-net](https://github.com/hdy6438/spec2volcamu-net)|
|2505.09528|[conformal bounds on full-reference image quality for imaging inverse problems](https://arxiv.org/abs/2505.09528)|[quality_uq](https://github.com/jwen307/quality_uq)|
|2505.09529|[contactless cardiac pulse monitoring using event cameras](https://arxiv.org/abs/2505.09529)|[contactless_cardiac_pulse_monitoring_using_event_cameras](https://github.com/c3imaging/contactless_cardiac_pulse_monitoring_using_event_cameras)|
|2505.09558|[wavreward: spoken dialogue models with generalist reward evaluators](https://arxiv.org/abs/2505.09558)|[wavreward](https://github.com/jishengpeng/wavreward)|
|2505.09568|[blip3-o: a family of fully open unified multimodal models-architecture, training and dataset](https://arxiv.org/abs/2505.09568)|[blip3o](https://github.com/jiuhaichen/blip3o)|
|2505.05071|[fg-clip: fine-grained visual and textual alignment](https://arxiv.org/abs/2505.05071)|[fg-clip](https://github.com/360cvgroup/fg-clip)|
|2505.07530|[fluxsynid: a framework for identity-controlled synthetic face generation with document and live images](https://arxiv.org/abs/2505.07530)|[FLUXSynID](https://github.com/Raul2718/FLUXSynID)|
|2505.08031|[measuring and predicting variation in the difficulty of questions about data visualizations](https://arxiv.org/abs/2505.08031)|[viz_item_measures_cogsci2025](https://github.com/cogtoolslab/viz_item_measures_cogsci2025)|
|2505.08101|[topology-guided knowledge distillation for efficient point cloud processing](https://arxiv.org/abs/2505.08101)|[pointdistill](https://github.com/hysonlab/pointdistill)|
|2505.08117|[now you see it, now you don't: damage label agreement in drone & satellite post-disaster imagery](https://arxiv.org/abs/2505.08117)|[NowYouSeeItNowYouDont](https://github.com/TManzini/NowYouSeeItNowYouDont)|
|2505.08126|[asynchronous multi-object tracking with an event camera](https://arxiv.org/abs/2505.08126)|[AEMOT](https://github.com/angus-apps/AEMOT)|
|2505.08137|[large language models for computer-aided design: a survey](https://arxiv.org/abs/2505.08137)|[llms-cad-survey-taxonomy](https://github.com/lichengzhanguom/llms-cad-survey-taxonomy)|
|2505.08190|[unsupervised raindrop removal from a single image using conditional diffusion models](https://arxiv.org/abs/2505.08190)|[DropWiper](https://github.com/lhfazry/DropWiper)|
|2505.08196|[adc-gs: anchor-driven deformable and compressed gaussian splatting for dynamic scene reconstruction](https://arxiv.org/abs/2505.08196)|[adc-gs](https://github.com/h-huang774/adc-gs)|
|2505.08231|[hmpnet: a feature aggregation architecture for maritime object detection from a shipborne perspective](https://arxiv.org/abs/2505.08231)|[hmpnet](https://github.com/tustailab/hmpnet)|
|2505.08234|[removing watermarks with partial regeneration using semantic information](https://arxiv.org/abs/2505.08234)|[semanticregen](https://github.com/krtit/semanticregen)|
|2505.08245|[large language model psychometrics: a systematic review of evaluation, validation, and enhancement](https://arxiv.org/abs/2505.08245)|[awesome-llm-psychometrics](https://github.com/valuebyte-ai/awesome-llm-psychometrics)|
|2505.08246|[identifying memorization of diffusion models through p-laplace analysis](https://arxiv.org/abs/2505.08246)|[identifying-memorization-of-diffusion-models-through-p-laplace-analysis](https://github.com/jonathanbrok/identifying-memorization-of-diffusion-models-through-p-laplace-analysis)|
|2505.08247|[skeleton-guided diffusion model for accurate foot x-ray synthesis in hallux valgus diagnosis](https://arxiv.org/abs/2505.08247)|[sccdm](https://github.com/midisec/sccdm)|
|2505.08260|[few-shot novel category discovery](https://arxiv.org/abs/2505.08260)|[fsncd](https://github.com/ashengl/fsncd)|
|2505.08273|[irrmap: a large-scale comprehensive dataset for irrigation method mapping](https://arxiv.org/abs/2505.08273)|[irrmap](https://github.com/nibir088/irrmap)|
|2505.08316|[improving unsupervised task-driven models of ventral visual stream via relative position predictivity](https://arxiv.org/abs/2505.08316)|[unsup-vvs](https://github.com/rdz98/unsup-vvs)|
|2505.08437|[tt-df: a large-scale diffusion-based dataset and benchmark for human body forgery detection](https://arxiv.org/abs/2505.08437)|[tt-df](https://github.com/hashtag00002/tt-df)|
|2505.08455|[vcrbench: exploring long-form causal reasoning capabilities of large video language models](https://arxiv.org/abs/2505.08455)|[vcrbench](https://github.com/pritamqu/vcrbench)|
|2505.08468|[judging the judges: can large vision-language models fairly evaluate chart comprehension and reasoning?](https://arxiv.org/abs/2505.08468)|[chart_lvlm_judge](https://github.com/tahmedge/chart_lvlm_judge)|
|2505.08581|[resurgsam2: referring segment anything in surgical video via credible long-term tracking](https://arxiv.org/abs/2505.08581)|[resurgsam2](https://github.com/jinlab-imvr/resurgsam2)|
|2505.08601|[rejoining fragmented ancient bamboo slips with physics-driven deep learning](https://arxiv.org/abs/2505.08601)|[wisepanda](https://github.com/zhujinchi/wisepanda)|
|2505.08604|[unsupervised out-of-distribution detection in medical imaging using multi-exit class activation maps and feature masking](https://arxiv.org/abs/2505.08604)|[mecam-ood](https://github.com/windstormer/mecam-ood)|
|2505.08617|[openthinkimg: learning to think with images via visual tool reinforcement learning](https://arxiv.org/abs/2505.08617)|[openthinkimg](https://github.com/zhaochen0110/openthinkimg)|
|2505.08723|[timo: spatiotemporal foundation model for satellite image time series](https://arxiv.org/abs/2505.08723)|[timo](https://github.com/mililab/timo)|
|2505.08725|[extending large vision-language model for diverse interactive tasks in autonomous driving](https://arxiv.org/abs/2505.08725)|[drivemonkey](https://github.com/zc-zhao/drivemonkey)|
|2505.02350|[sparse ellipsoidal radial basis function network for point cloud surface representation](https://arxiv.org/abs/2505.02350)|[se-rbfnet](https://github.com/lianbobo/se-rbfnet)|
|2505.05007|[driving with context: online map matching for complex roads using lane markings and scenario recognition](https://arxiv.org/abs/2505.05007)|[lmsr-omm](https://github.com/trv-lab/lmsr-omm)|
|2505.05470|[flow-grpo: training flow matching models via online rl](https://arxiv.org/abs/2505.05470)|[flow_grpo](https://github.com/yifan123/flow_grpo)|
|2505.05573|[prompt to polyp: medical text-conditioned image synthesis with diffusion models](https://arxiv.org/abs/2505.05573)|[imageclefmed-medvqa-gi-2024-mmcp-team](https://github.com/thundercondor/imageclefmed-medvqa-gi-2024-mmcp-team)|
|2505.06393|[toward advancing license plate super-resolution in real-world scenarios: a dataset and benchmark](https://arxiv.org/abs/2505.06393)|[lpsrgan](https://github.com/valfride/lpsrgan)|
|2505.06428|[what do people want to know about artificial intelligence (ai)? the importance of answering end-user questions to explain autonomous vehicle (av) decisions](https://arxiv.org/abs/2505.06428)|[conversationalXAV](https://github.com/comp-hci-lab/conversationalXAV)|
|2505.06469|[kcluster: an llm-based clustering approach to knowledge component discovery](https://arxiv.org/abs/2505.06469)|[KCluster](https://github.com/weiyumou/KCluster)|
|2505.06507|[text-to-cadquery: a new paradigm for cad generation with scalable large model capabilities](https://arxiv.org/abs/2505.06507)|[text-to-cadquery](https://github.com/text-to-cadquery/text-to-cadquery)|
|2505.06517|[edge-enabled vio with long-tracked features for high-accuracy low-altitude iot navigation](https://arxiv.org/abs/2505.06517)|[FLOW-VIO](https://github.com/xiaohong-huang/FLOW-VIO)|
|2505.06527|[improving generalization of medical image registration foundation model](https://arxiv.org/abs/2505.06527)|[fm_sam](https://github.com/promise13/fm_sam)|
|2505.06536|[tacfn: transformer-based adaptive cross-modal fusion network for multimodal emotion recognition](https://arxiv.org/abs/2505.06536)|[tacfn](https://github.com/shuzihuaiyu/tacfn)|
|2505.06578|[compact and efficient neural networks for image recognition based on learned 2d separable transform](https://arxiv.org/abs/2505.06578)|[lst-2d](https://github.com/mak-sim/lst-2d)|
|2505.06592|[batch augmentation with unimodal fine-tuning for multimodal learning](https://arxiv.org/abs/2505.06592)|[multimodal](https://github.com/dipuk0506/multimodal)|
|2505.06646|[reproducing and improving chexnet: deep learning for chest x-ray disease classification](https://arxiv.org/abs/2505.06646)|[Deep-Learning-Project](https://github.com/dstrick17/Deep-Learning-Project)|
|2505.06663|[metor: a unified framework for mutual enhancement of objects and relationships in open-vocabulary video visual relationship detection](https://arxiv.org/abs/2505.06663)|[METOR](https://github.com/wangyongqi558/METOR)|
|2505.06684|[fnbench: benchmarking robust federated learning against noisy labels](https://arxiv.org/abs/2505.06684)|[fnbench](https://github.com/sprinter1999/fnbench)|
|2505.06702|[do language model agents align with humans in rating visualizations? an empirical study](https://arxiv.org/abs/2505.06702)|[Agents-Ratings-in-VIS-Experiments](https://github.com/ZekaiShao25/Agents-Ratings-in-VIS-Experiments)|
|2505.06796|[multimodal fake news detection: mfnd dataset and shallow-deep multitask learning](https://arxiv.org/abs/2505.06796)|[sdml](https://github.com/yunan-wang33/sdml)|
|2505.06934|[whitened clip as a likelihood surrogate of images and captions](https://arxiv.org/abs/2505.06934)|[W_CLIP](https://github.com/rbetser/W_CLIP)|
|2505.06937|[transformer-based dual-optical attention fusion crowd head point counting and localization network](https://arxiv.org/abs/2505.06937)|[tapnet](https://github.com/zz-zik/tapnet)|
|2505.06948|[unsupervised learning for class distribution mismatch](https://arxiv.org/abs/2505.06948)|[research](https://github.com/ruc-dwbi-ml/research)|
|2505.06975|[high-frequency prior-driven adaptive masking for accelerating image super-resolution](https://arxiv.org/abs/2505.06975)|[amsr](https://github.com/shangwei5/amsr)|
|2505.07001|[hallucination-aware multimodal benchmark for gastrointestinal image analysis with large vision-language models](https://arxiv.org/abs/2505.07001)|[hallucination-aware-vlm](https://github.com/bhattarailab/hallucination-aware-vlm)|
|2505.07007|[mellm: exploring llm-powered micro-expression understanding enhanced by subtle motion perception](https://arxiv.org/abs/2505.07007)|[mellm](https://github.com/zyzhangustc/mellm)|
|2505.07019|[a vision-language foundation model for leaf disease identification](https://arxiv.org/abs/2505.07019)|[scold](https://huggingface.co/enalis/scold)|
|2505.07071|[semantic-guided diffusion model for single-step image super-resolution](https://arxiv.org/abs/2505.07071)|[samsr](https://github.com/liu-zihang/samsr)|
|2505.07159|[skull stripping with purely synthetic data](https://arxiv.org/abs/2505.07159)|[PUMBA](https://github.com/pjsjongsung/PUMBA)|
|2505.07161|[towards actionable pedagogical feedback: a multi-perspective analysis of mathematics teaching and tutoring dialogue](https://arxiv.org/abs/2505.07161)|[speak-turn-emb-dialog-act-clf](https://github.com/zihaohe123/speak-turn-emb-dialog-act-clf)|
|2505.07164|[emovlm-kd: fusing distilled expertise with vision-language models for visual emotion analysis](https://arxiv.org/abs/2505.07164)|[emovlm-kd](https://github.com/sange1104/emovlm-kd)|
|2505.07175|[metrics that matter: evaluating image quality metrics for medical image generation](https://arxiv.org/abs/2505.07175)|[GenMed](https://github.com/YashDeo-York/GenMed)|
|2505.07219|[language-driven dual style mixing for single-domain generalized object detection](https://arxiv.org/abs/2505.07219)|[ldds](https://github.com/qinhongda8/ldds)|
|2505.07340|[thalamus: a user simulation toolkit for prototyping multimodal sensing studies](https://arxiv.org/abs/2505.07340)|[Thalamus](https://github.com/kayhan-latifzadeh/Thalamus)|
|2505.07375|[boosting global-local feature matching via anomaly synthesis for multi-class point cloud anomaly detection](https://arxiv.org/abs/2505.07375)|[GLFM-Multi-class-3DAD](https://github.com/hustCYQ/GLFM-Multi-class-3DAD)|
|2505.07387|[feature visualization in 3d convolutional neural networks](https://arxiv.org/abs/2505.07387)|[3dkernelvisualizer](https://github.com/yatanglilab/3dkernelvisualizer)|
|2505.07447|[unified continuous generative models](https://arxiv.org/abs/2505.07447)|[UCGM](https://github.com/LINs-Lab/UCGM)|
|2505.07477|[you only look one step: accelerating backpropagation in diffusion sampling with gradient shortcuts](https://arxiv.org/abs/2505.07477)|[sdo](https://github.com/deng-ai-lab/sdo)|
|2505.07496|[docvxqa: context-aware visual explanations for document question answering](https://arxiv.org/abs/2505.07496)|[docvxqa](https://github.com/dali92002/docvxqa)|
|2505.07689|[anatomical attention alignment representation for radiology report generation](https://arxiv.org/abs/2505.07689)|[a3net](https://github.com/vinh-ai/a3net)|
|2505.07812|[continuous visual autoregressive generation via score maximization](https://arxiv.org/abs/2505.07812)|[ear](https://github.com/shaochenze/ear)|
|2505.02539|[marker-based extrinsic calibration method for accurate multi-camera 3d reconstruction](https://arxiv.org/abs/2505.02539)|[CalibMarker](https://github.com/Tech4DLab/CalibMarker)|
|2505.02835|[r1-reward: training multimodal reward model through stable reinforcement learning](https://arxiv.org/abs/2505.02835)|[r1_reward](https://github.com/yfzhang114/r1_reward)|
|2505.05049|[uncertainsam: fast and efficient uncertainty quantification of the segment anything model](https://arxiv.org/abs/2505.05049)|[UncertainSAM](https://github.com/GreenAutoML4FAS/UncertainSAM)|
|2505.05375|[threshold modulation for online test-time adaptation of spiking neural networks](https://arxiv.org/abs/2505.05375)|[tm-otta-snn](https://github.com/nneurotransmitterr/tm-otta-snn)|
|2505.05504|[image restoration via multi-domain learning](https://arxiv.org/abs/2505.05504)|[swformer](https://github.com/deng-ai-lab/swformer)|
|2505.05505|[apply hierarchical-chain-of-generation to complex attributes text-to-3d generation](https://arxiv.org/abs/2505.05505)|[gascol](https://github.com/wakals/gascol)|
|2505.05510|[how to train your metamorphic deep neural network](https://arxiv.org/abs/2505.05510)|[htty_neumeta](https://github.com/tsommariva/htty_neumeta)|
|2505.05528|[x-transfer attacks: towards super transferable adversarial attacks on clip](https://arxiv.org/abs/2505.05528)|[XTransferBench](https://github.com/HanxunH/XTransferBench)|
|2505.05599|[enhancing satellite object localization with dilated convolutions and attention-aided spatial pooling](https://arxiv.org/abs/2505.05599)|[satellite-object-localization](https://github.com/ai-4-atmosphere-remote-sensing/satellite-object-localization)|
|2505.05621|[a preliminary study for gpt-4o on image restoration](https://arxiv.org/abs/2505.05621)|[gpt_restoration](https://github.com/noxsine/gpt_restoration)|
|2505.05657|[unsupervised blind speech separation with a diffusion prior](https://arxiv.org/abs/2505.05657)|[arraydps](https://github.com/arraydps/arraydps)|
|2505.05659|[v-efficientnets: vector-valued efficiently scaled convolutional neural network models](https://arxiv.org/abs/2505.05659)|[v-nets](https://github.com/mevalle/v-nets)|
|2505.05689|[equivariant imaging biomarkers for robust unsupervised segmentation of histopathology](https://arxiv.org/abs/2505.05689)|[sre_unsupervised_segm](https://github.com/fyc423/sre_unsupervised_segm)|
|2505.05711|[digit: multi-dilated gated encoder and central-adjacent region integrated decoder for temporal action detection transformer](https://arxiv.org/abs/2505.05711)|[digit](https://github.com/dotori-hj/digit)|
|2505.05736|[multimodal integrated knowledge transfer to large language models through preference optimization with biomedical applications](https://arxiv.org/abs/2505.05736)|[mint-llm](https://github.com/wglab/mint-llm)|
|2505.05752|[automating infrastructure surveying: a framework for geometric measurements and compliance assessment using point cloud data](https://arxiv.org/abs/2505.05752)|[surveyautomation](https://github.com/soltanilara/surveyautomation)|
|2505.05812|[towards order of magnitude x-ray dose reduction in breast cancer imaging using phase contrast and deep denoising](https://arxiv.org/abs/2505.05812)|[quell](https://github.com/quell-devs/quell)|
|2505.05829|[accelerating diffusion transformer via increment-calibrated caching with channel-aware singular value decomposition](https://arxiv.org/abs/2505.05829)|[icc](https://github.com/ccccczzy/icc)|
|2505.05834|[dual-level fuzzy learning with patch guidance for image ordinal regression](https://arxiv.org/abs/2505.05834)|[dfpg-ord](https://github.com/zjumai/dfpg-ord)|
|2505.05895|[leveraging vision-language models for visual grounding and analysis of automotive ui](https://arxiv.org/abs/2505.05895)|[ELAM-7B](https://huggingface.co/sparks-solutions/ELAM-7B)|
|2505.05913|[dfen: dual feature equalization network for medical image segmentation](https://arxiv.org/abs/2505.05913)|[dfen](https://github.com/jianjianyin/dfen)|
|2505.05936|[cgtrack: cascade gating network with hierarchical feature aggregation for uav tracking](https://arxiv.org/abs/2505.05936)|[cgtrack](https://github.com/nightwatch-fox11/cgtrack)|
|2505.06002|[task-adapter++: task-specific adaptation with order-aware alignment for few-shot action recognition](https://arxiv.org/abs/2505.06002)|[task-adapter-pp](https://github.com/jaulin-bage/task-adapter-pp)|
|2505.06003|[from pixels to perception: interpretable predictions via instance-wise grouped feature selection](https://arxiv.org/abs/2505.06003)|[p2p](https://github.com/mvandenhi/p2p)|
|2505.06030|[why are you wrong? counterfactual explanations for language grounding with 3d objects](https://arxiv.org/abs/2505.06030)|[why-are-you-wrong](https://github.com/toprei/why-are-you-wrong)|
|2505.06064|[context informed incremental learning improves myoelectric control performance in virtual reality object manipulation tasks](https://arxiv.org/abs/2505.06064)|[ciil-emg-vr](https://github.com/biomedicalits/ciil-emg-vr)|
|2505.06068|[noise-consistent siamese-diffusion for medical image synthesis and segmentation](https://arxiv.org/abs/2505.06068)|[siamese-diffusion](https://github.com/qiukunpeng/siamese-diffusion)|
|2505.06107|[differentiating emigration from return migration of scholars using name-based nationality detection models](https://arxiv.org/abs/2505.06107)|[NameBasedNationalityDetection](https://github.com/FaezeGhorbanpour/NameBasedNationalityDetection)|
|2505.06120|[llms get lost in multi-turn conversation](https://arxiv.org/abs/2505.06120)|[lost_in_conversation](https://github.com/microsoft/lost_in_conversation)|
|2505.06134|[realistic adversarial attacks for robustness evaluation of trajectory prediction models via future state perturbation](https://arxiv.org/abs/2505.06134)|[general-framework-update-adversarial-jeroen](https://github.com/jhagenus/general-framework-update-adversarial-jeroen)|
|2505.06152|[mm-skin: enhancing dermatology vision-language model with an image-text dataset derived from textbooks](https://arxiv.org/abs/2505.06152)|[mm-skin](https://github.com/zwq803/mm-skin)|
|2505.00735|[leveraging depth maps and attention mechanisms for enhanced image inpainting](https://arxiv.org/abs/2505.00735)|[CSCE748_Computational-Photography](https://github.com/7201krap/CSCE748_Computational-Photography)|
|2505.02060|[transforming faces into video stories -- videoface2.0](https://arxiv.org/abs/2505.02060)|[videoface2.0](https://github.com/brkljac/videoface2.0)|
|2505.02393|[uncertainty-weighted image-event multimodal fusion for video anomaly detection](https://arxiv.org/abs/2505.02393)|[ief-vad](https://github.com/eavnjeong/ief-vad)|
|2505.03808|[ai-driven multi-source data fusion for algal bloom severity classification in small inland water bodies: leveraging sentinel-2, dem, and noaa climate data](https://arxiv.org/abs/2505.03808)|[harmfulalgalbloomdetection](https://github.com/ioannisnasios/harmfulalgalbloomdetection)|
|2505.03838|[intellicardiac: an intelligent platform for cardiac image segmentation and classification](https://arxiv.org/abs/2505.03838)|[IntelliCardiac](https://github.com/tiffany9056/IntelliCardiac)|
|2505.03856|[an active inference model of covert and overt visual attention](https://arxiv.org/abs/2505.03856)|[ainf-visual-attention](https://github.com/unizgfer-lamor/ainf-visual-attention)|
|2505.04046|[reliable disentanglement multi-view learning against view adversarial attacks](https://arxiv.org/abs/2505.04046)|[2025-IJCAI-RDML](https://github.com/Willy1005/2025-IJCAI-RDML)|
|2505.04066|[llamapie: proactive in-ear conversation assistants](https://arxiv.org/abs/2505.04066)|[LlamaPIE](https://github.com/chentuochao/LlamaPIE)|
|2505.04281|[ts-diff: two-stage diffusion model for low-light raw image enhancement](https://arxiv.org/abs/2505.04281)|[ts-diff](https://github.com/circcclek/ts-diff)|
|2505.04586|[active sampling for mri-based sequential decision making](https://arxiv.org/abs/2505.04586)|[mri_sequential_active_sampling](https://github.com/vios-s/mri_sequential_active_sampling)|
|2505.04590|[tetweave: isosurface extraction using on-the-fly delaunay tetrahedral grids for gradient-based mesh optimization](https://arxiv.org/abs/2505.04590)|[TetWeave](https://github.com/AlexandreBinninger/TetWeave)|
|2505.04650|[multimodal benchmarking and recommendation of text-to-image generation models](https://arxiv.org/abs/2505.04650)|[Evaluation_generated_images](https://github.com/kapilw25/Evaluation_generated_images)|
|2505.04652|[rethinking boundary detection in deep learning-based medical image segmentation](https://arxiv.org/abs/2505.04652)|[cto](https://github.com/xiaofang007/cto)|
|2505.04656|[meshgen: generating pbr textured mesh with render-enhanced auto-encoder and generative data augmentation](https://arxiv.org/abs/2505.04656)|[meshgen](https://github.com/heheyas/meshgen)|
|2505.04659|[gssplat: generalizable semantic gaussian splatting for novel-view synthesis in 3d scenes](https://arxiv.org/abs/2505.04659)|[gssplat](https://github.com/onmyoji-xiao/gssplat)|
|2505.04668|[sgcr: spherical gaussians for efficient 3d curve reconstruction](https://arxiv.org/abs/2505.04668)|[sgcr](https://github.com/martinyxr/sgcr)|
|2505.04672|[histo-miner: deep learning based tissue features extraction pipeline from h&e whole slide images of cutaneous squamous cell carcinoma](https://arxiv.org/abs/2505.04672)|[Histo-Miner](https://github.com/bozeklab/Histo-Miner)|
|2505.04720|[false promises in medical imaging ai? assessing validity of outperformance claims](https://arxiv.org/abs/2505.04720)|[probability-of-false-claims](https://github.com/IMSY-DKFZ/probability-of-false-claims)|
|2505.04788|[convex relaxation for robust vanishing point estimation in manhattan world](https://arxiv.org/abs/2505.04788)|[globustvp](https://github.com/wu-cvgl/globustvp)|
|2505.04831|[steerable scene generation with post training and inference-time search](https://arxiv.org/abs/2505.04831)|[steerable-scene-generation](https://github.com/nepfaff/steerable-scene-generation)|
|2505.04835|[are synthetic corruptions a reliable proxy for real-world corruptions?](https://arxiv.org/abs/2505.04835)|[benchmarking_robustness](https://github.com/shashankskagnihotri/benchmarking_robustness)|
|2505.04899|[owt: a foundational organ-wise tokenization framework for medical imaging](https://arxiv.org/abs/2505.04899)|[OWT](https://github.com/SifanSong/OWT)|
|2505.04917|[a simple detector with frame dynamics is a strong tracker](https://arxiv.org/abs/2505.04917)|[A-Simple-Detector-is-a-Strong-Tracker](https://github.com/facias914/A-Simple-Detector-is-a-Strong-Tracker)|
|2505.04921|[perception, reason, think, and plan: a survey on large multimodal reasoning models](https://arxiv.org/abs/2505.04921)|[awesome-large-multimodal-reasoning-models](https://github.com/hitsz-tmg/awesome-large-multimodal-reasoning-models)|
|2505.04941|[building-guided pseudo-label learning for cross-modal building damage mapping](https://arxiv.org/abs/2505.04941)|[Building-Guided-Pseudo-Label-Learning-for-Cross-Modal-Building-Damage-Mapping](https://github.com/Henryjiepanli/Building-Guided-Pseudo-Label-Learning-for-Cross-Modal-Building-Damage-Mapping)|
|2505.05001|[stabstitch++: unsupervised online video stitching with spatiotemporal bidirectional warps](https://arxiv.org/abs/2505.05001)|[stabstitch2](https://github.com/nie-lang/stabstitch2)|
|2505.05004|[automated thoracolumbar stump rib detection and analysis in a large ct cohort](https://arxiv.org/abs/2505.05004)|[rib-segmentation](https://github.com/Hendrik-code/rib-segmentation)|
|2505.05022|[soap: style-omniscient animatable portraits](https://arxiv.org/abs/2505.05022)|[soap](https://github.com/tingtingliao/soap)|
|2505.05076|[the city that never settles: simulation-based lidar dataset for long-term place recognition under extreme structural changes](https://arxiv.org/abs/2505.05076)|[cns_dataset](https://github.com/hyunho111/cns_dataset)|
|2505.05091|[dispbench: benchmarking disparity estimation to synthetic corruptions](https://arxiv.org/abs/2505.05091)|[benchmarking_robustness](https://github.com/shashankskagnihotri/benchmarking_robustness)|
|2505.05163|[probabilistic embeddings for frozen vision-language models: uncertainty quantification with gaussian process latent variable models](https://arxiv.org/abs/2505.05163)|[GroVE](https://github.com/vaishwarya96/GroVE)|
|2505.05309|[augmented deep contexts for spatially embedded video coding](https://arxiv.org/abs/2505.05309)|[sevc](https://github.com/esakak/sevc)|
|2505.05343|[hearing and seeing through clip: a framework for self-supervised sound source localization](https://arxiv.org/abs/2505.05343)|[ACL-SSL](https://github.com/swimmiing/ACL-SSL)|
|2505.05422|[toklip: marry visual tokens to clip for multimodal comprehension and generation](https://arxiv.org/abs/2505.05422)|[toklip](https://github.com/tencentarc/toklip)|
|2505.05446|[adaptive markup language generation for contextually-grounded visual document understanding](https://arxiv.org/abs/2505.05446)|[DocMark](https://github.com/Euphoria16/DocMark)|
|2505.05469|[generating physically stable and buildable lego designs from text](https://arxiv.org/abs/2505.05469)|[LegoGPT](https://github.com/AvaLovelace1/LegoGPT)|
|2505.05474|[3d scene generation: a survey](https://arxiv.org/abs/2505.05474)|[awesome-3d-scene-generation](https://github.com/hzxie/awesome-3d-scene-generation)|
|2505.05475|[svad: from single image to 3d avatar via synthetic data generation with video diffusion and data augmentation](https://arxiv.org/abs/2505.05475)|[SVAD](https://github.com/yc4ny/SVAD)|
|2505.01880|[weakly-supervised audio temporal forgery localization via progressive audio-language co-learning network](https://arxiv.org/abs/2505.01880)|[LOCO](https://github.com/ItzJuny/LOCO)|
|2505.02406|[token coordinated prompt attention is needed for visual prompting](https://arxiv.org/abs/2505.02406)|[icml2025-tcpa](https://github.com/zhoujiahuan1991/icml2025-tcpa)|
|2505.02471|[ming-lite-uni: advancements in unified architecture for natural multimodal interaction](https://arxiv.org/abs/2505.02471)|[ming](https://github.com/inclusionai/ming)|
|2505.02567|[unified multimodal understanding and generation models: advances, challenges, and opportunities](https://arxiv.org/abs/2505.02567)|[awesome-unified-multimodal-models](https://github.com/aidc-ai/awesome-unified-multimodal-models)|
|2505.03440|[manvr3d: a platform for human-in-the-loop cell tracking in virtual reality](https://arxiv.org/abs/2505.03440)|[manvr3d](https://github.com/scenerygraphics/manvr3d)|
|2505.03631|[breaking annotation barriers: generalized video quality assessment via ranking-based self-supervision](https://arxiv.org/abs/2505.03631)|[LMM-PVQA](https://github.com/clh124/LMM-PVQA)|
|2505.03836|[obd-finder: explainable coarse-to-fine text-centric oracle bone duplicates discovery](https://arxiv.org/abs/2505.03836)|[obd-finder](https://github.com/cszhanglmu/obd-finder)|
|2505.03859|[deepfakes on demand: the rise of accessible non-consensual deepfake image generators](https://arxiv.org/abs/2505.03859)|[deepfakesondemand](https://github.com/WillHawkins3/deepfakesondemand)|
|2505.03896|[novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation](https://arxiv.org/abs/2505.03896)|[attukan](https://github.com/stevezs315/attukan)|
|2505.03912|[openhelix: a short survey, empirical analysis, and open-source dual-system vla model for robotic manipulation](https://arxiv.org/abs/2505.03912)|[OpenHelix](https://github.com/OpenHelix-robot/OpenHelix)|
|2505.04003|[prototype-based information compensation network for multi-source remote sensing data classification](https://arxiv.org/abs/2505.04003)|[picnet](https://github.com/oucailab/picnet)|
|2505.04058|[as3d: 2d-assisted cross-modal understanding with semantic-spatial scene graphs for 3d visual grounding](https://arxiv.org/abs/2505.04058)|[AS3D](https://github.com/onmyoji-xiao/AS3D)|
|2505.04095|[scalable aerial gnss localization for marine robots](https://arxiv.org/abs/2505.04095)|[aerial_gnss](https://github.com/stevvwen/aerial_gnss)|
|2505.04119|[gaprompt: geometry-aware point cloud prompt for 3d vision model](https://arxiv.org/abs/2505.04119)|[icml2025-vgp](https://github.com/zhoujiahuan1991/icml2025-vgp)|
|2505.04121|[vision graph prompting via semantic low-rank decomposition](https://arxiv.org/abs/2505.04121)|[icml2025-vgp](https://github.com/zhoujiahuan1991/icml2025-vgp)|
|2505.04185|[s3d: sketch-driven 3d model generation](https://arxiv.org/abs/2505.04185)|[s3d](https://github.com/hailsong/s3d)|
|2505.04192|[videopath-llava: pathology diagnostic reasoning through video instruction tuning](https://arxiv.org/abs/2505.04192)|[videopath-llava](https://github.com/trinhvg/videopath-llava)|
|2505.04258|[rgb-event fusion with self-attention for collision prediction](https://arxiv.org/abs/2505.04258)|[eva](https://github.com/pbonazzi/eva)|
|2505.04276|[hdifftg: a lightweight hybrid diffusion-transformer-gcn architecture for 3d human pose estimation](https://arxiv.org/abs/2505.04276)|[hdifftg](https://github.com/circejie/hdifftg)|
|2505.04369|[wdmamba: when wavelet degradation prior meets vision mamba for image dehazing](https://arxiv.org/abs/2505.04369)|[wdmamba](https://github.com/sunj000/wdmamba)|
|2505.04410|[declip: decoupled learning for open-vocabulary dense perception](https://arxiv.org/abs/2505.04410)|[declip](https://github.com/xiaomoguhz/declip)|
|2505.04526|[dfvo: learning darkness-free visible and infrared image disentanglement and fusion all at once](https://arxiv.org/abs/2505.04526)|[dfvo](https://github.com/davin-qi530/dfvo)|
|2505.04540|[registration of 3d point sets using exponential-based similarity matrix](https://arxiv.org/abs/2505.04540)|[esm_icp](https://github.com/aralab-unr/esm_icp)|
|2505.04575|[componential prompt-knowledge alignment for domain incremental learning](https://arxiv.org/abs/2505.04575)|[icml2025-ka-prompt](https://github.com/zhoujiahuan1991/icml2025-ka-prompt)|
|2505.04584|[slideitright: using ai to find relevant slides and provide feedback for open-ended questions](https://arxiv.org/abs/2505.04584)|[slideitright](https://github.com/zqh0421/slideitright)|
|2505.04623|[echoink-r1: exploring audio-visual reasoning in multimodal llms via reinforcement learning](https://arxiv.org/abs/2505.04623)|[echoink](https://github.com/harryhsing/echoink)|
|2505.01884|[adversarial robustness of deep learning models for inland water body segmentation from sar images](https://arxiv.org/abs/2505.01884)|[iwseg-sar-poison](https://github.com/gvcl/iwseg-sar-poison)|
|2505.02048|[regression is all you need for medical image translation](https://arxiv.org/abs/2505.02048)|[yoda](https://github.com/deep-mi/yoda)|
|2505.02064|[rtv-bench: benchmarking mllm continuous perception, understanding and reasoning through real-time video](https://arxiv.org/abs/2505.02064)|[rtv-bench](https://github.com/ljungang/rtv-bench)|
|2505.02704|[vgld: visually-guided linguistic disambiguation for monocular depth scale recovery](https://arxiv.org/abs/2505.02704)|[vgld](https://github.com/pakinwu/vgld)|
|2505.02971|[adversarial robustness analysis of vision-language models in medical image segmentation](https://arxiv.org/abs/2505.02971)|[secure-private-ai](https://github.com/anjilab/secure-private-ai)|
|2505.03007|[ntire 2025 challenge on ugc video enhancement: methods and results](https://arxiv.org/abs/2505.03007)|[ntire25_ugc_video_enhancement](https://github.com/msu-video-group/ntire25_ugc_video_enhancement)|
|2505.03046|[sim2real transfer for vision-based grasp verification](https://arxiv.org/abs/2505.03046)|[hsr-graspsynth](https://github.com/pauamargant/hsr-graspsynth)|
|2505.03114|[path and bone-contour regularized unpaired mri-to-ct translation](https://arxiv.org/abs/2505.03114)|[pabot](https://github.com/kennysyp/pabot)|
|2505.03153|[robust fairness vision-language learning for medical image analysis](https://arxiv.org/abs/2505.03153)|[robust_fairness_for_medical_image](https://github.com/purdue-m2/robust_fairness_for_medical_image)|
|2505.03242|[seeing the abstract: translating the abstract language for vision language models](https://arxiv.org/abs/2505.03242)|[fashionact](https://github.com/davidetalon/fashionact)|
|2505.03299|[towards efficient benchmarking of foundation models in remote sensing: a capabilities encoding approach](https://arxiv.org/abs/2505.03299)|[capabilities-encoding](https://github.com/pierreadorni/capabilities-encoding)|
|2505.03319|[sd-vsum: a method and dataset for script-driven video summarization](https://arxiv.org/abs/2505.03319)|[sd-vsum](https://github.com/idt-iti/sd-vsum)|
|2505.03401|[ddatr: dynamic difference-aware temporal residual network for longitudinal radiology report generation](https://arxiv.org/abs/2505.03401)|[ddatr](https://github.com/xmed-lab/ddatr)|
|2505.03422|[liftfeat: 3d geometry-aware local feature matching](https://arxiv.org/abs/2505.03422)|[liftfeat](https://github.com/lyp-deeplearning/liftfeat)|
|2505.03427|[medarabiq: benchmarking large language models on arabic medical tasks](https://arxiv.org/abs/2505.03427)|[medarabiq](https://github.com/nyuad-cai/medarabiq)|
|2505.03431|[a fusion-guided inception network for hyperspectral image super-resolution](https://arxiv.org/abs/2505.03431)|[fusion](https://github.com/usman1021/fusion)|
|2505.03470|[blending 3d geometry and machine learning for multi-view stereopsis](https://arxiv.org/abs/2505.03470)|[GC-MVSNet-PlusPlus](https://github.com/vkvats/GC-MVSNet-PlusPlus)|
|2505.03480|[modeling musical genre trajectories through pathlet learning](https://arxiv.org/abs/2505.03480)|[music_pathlets](https://github.com/lilianmarey/music_pathlets)|
|2505.03494|[upmad-net: a brain tumor segmentation network with uncertainty guidance and adaptive multimodal feature fusion](https://arxiv.org/abs/2505.03494)|[upmad_net_brainseg](https://github.com/chenzhao2023/upmad_net_brainseg)|
|2505.03507|[modality-guided dynamic graph fusion and temporal diffusion for self-supervised rgb-t tracking](https://arxiv.org/abs/2505.03507)|[gdstrack](https://github.com/lishenglana/gdstrack)|
|2505.03538|[rail: region-aware instructive learning for semi-supervised tooth segmentation in cbct](https://arxiv.org/abs/2505.03538)|[rail](https://github.com/tournesol-saturday/rail)|
|2505.03539|[panoramic out-of-distribution segmentation](https://arxiv.org/abs/2505.03539)|[panoos](https://github.com/mengfeid/panoos)|
|2505.03568|[familiarizing with music: discovery patterns for different music discovery needs](https://arxiv.org/abs/2505.03568)|[familiarizing_with_music](https://github.com/hcai-mms/familiarizing_with_music)|
|2505.03581|[dygenc: encoding a sequence of textual scene graphs to reason and answer questions in dynamic scenes](https://arxiv.org/abs/2505.03581)|[dygenc](https://github.com/linukc/dygenc)|
|2505.03597|[fixed-length dense fingerprint representation](https://arxiv.org/abs/2505.03597)|[flare](https://github.com/yu-yy/flare)|
|2505.03623|[bounding box-guided diffusion for synthesizing industrial images and segmentation map](https://arxiv.org/abs/2505.03623)|[diffusion_labeling](https://github.com/covisionlab/diffusion_labeling)|
|2505.03692|[matching distance and geometric distribution aided learning multiview point cloud registration](https://arxiv.org/abs/2505.03692)|[mdgd](https://github.com/shi-qi-li/mdgd)|
|2505.00630|[vision mamba in remote sensing: a comprehensive survey of techniques, applications and outlook](https://arxiv.org/abs/2505.00630)|[awesome-mamba-in-remote-sensing](https://github.com/baobao0926/awesome-mamba-in-remote-sensing)|
|2505.01431|[zs-vcos: zero-shot outperforms supervised video camouflaged object segmentation](https://arxiv.org/abs/2505.01431)|[vcos](https://github.com/weathon/vcos)|
|2505.01456|[unlearning sensitive information in multimodal llms: benchmark and attack-defense evaluation](https://arxiv.org/abs/2505.01456)|[unlok-vqa](https://github.com/vaidehi99/unlok-vqa)|
|2505.01476|[costfilter-ad: enhancing anomaly detection through matching cost filtering](https://arxiv.org/abs/2505.01476)|[costfilter-ad](https://github.com/zhe-sapi/costfilter-ad)|
|2505.01481|[videohallu: evaluating and mitigating multi-modal hallucinations for synthetic videos](https://arxiv.org/abs/2505.01481)|[videohallu](https://github.com/zli12321/videohallu)|
|2505.01548|[rethinking rgb-event semantic segmentation with a novel bidirectional motion-enhanced event representation](https://arxiv.org/abs/2505.01548)|[BRENet](https://github.com/zyaocoder/BRENet)|
|2505.01583|[tempura: temporal event masked prediction and understanding for reasoning in action](https://arxiv.org/abs/2505.01583)|[tempura](https://github.com/andy-cheng/tempura)|
|2505.01644|[a dual-task synergy-driven generalization framework for pancreatic cancer segmentation in ct scans](https://arxiv.org/abs/2505.01644)|[dual-task-seg](https://github.com/sjtubme-qianlab/dual-task-seg)|
|2505.01699|[component-based fairness in face attribute classification with bayesian network-informed meta learning](https://arxiv.org/abs/2505.01699)|[bnmr-faircompface](https://github.com/yliuaa/bnmr-faircompface)|
|2505.01724|[vistaxa: developing a taxonomy of historical visualizations](https://arxiv.org/abs/2505.01724)|[image-taxonomy-labeler](https://github.com/oldvis/image-taxonomy-labeler)|
|2505.01755|[lensnet: an end-to-end learning framework for empirical point spread function modeling and lensless imaging reconstruction](https://arxiv.org/abs/2505.01755)|[Lensnet](https://github.com/baijiesong/Lensnet)|
|2505.01779|[polar interpolants for thin-shell microstructure homogenization](https://arxiv.org/abs/2505.01779)|[polarinterpolants](https://github.com/antoine-chan-lock/polarinterpolants)|
|2505.01790|[enhancing the learning experience: using vision-language models to generate questions for educational videos](https://arxiv.org/abs/2505.01790)|[aied_2025_video_qg](https://github.com/markossta/aied_2025_video_qg)|
|2505.01854|[accelerating volumetric medical image annotation via short-long memory sam 2](https://arxiv.org/abs/2505.01854)|[slm-sam2](https://github.com/mazurowski-lab/slm-sam2)|
|2505.01938|[hybridgs: high-efficiency gaussian splatting data compression using dual-channel sparse representation and point cloud encoder](https://arxiv.org/abs/2505.01938)|[hybridgs](https://github.com/qi-yangsjtu/hybridgs)|
|2505.02005|[learning heterogeneous mixture of scene experts for large-scale neural radiance fields](https://arxiv.org/abs/2505.02005)|[Switch-NeRF](https://github.com/MiZhenxing/Switch-NeRF)|
|2505.02075|[benchmarking feature upsampling methods for vision foundation models using interactive segmentation](https://arxiv.org/abs/2505.02075)|[isegprobe](https://github.com/havrylovv/isegprobe)|
|2505.02159|[small clips, big gains: learning long-range refocused temporal information for video super-resolution](https://arxiv.org/abs/2505.02159)|[lrti-vsr](https://github.com/labshuhanggu/lrti-vsr)|
|2505.02179|[prodisc-vad: an efficient system for weakly-supervised anomaly detection in video surveillance applications](https://arxiv.org/abs/2505.02179)|[ProDisc-VAD](https://github.com/modadundun/ProDisc-VAD)|
|2505.02182|[robust ai-generated face detection with imbalanced data](https://arxiv.org/abs/2505.02182)|[sp_cup](https://github.com/purdue-m2/sp_cup)|
|2505.02246|[cricket: a self-powered chirping pixel](https://arxiv.org/abs/2505.02246)|[cricket-public](https://github.com/columbiacomputervision/cricket-public)|
|2505.02325|[teda: boosting vision-lanuage models for zero-shot 3d object retrieval via testing-time distribution alignment](https://arxiv.org/abs/2505.02325)|[teda](https://github.com/wangzhichuan123/teda)|
|2505.02331|[vaemo: efficient representation learning for visual-audio emotion with knowledge injection](https://arxiv.org/abs/2505.02331)|[VAEmo](https://github.com/MSA-LMC/VAEmo)|
|2505.02350|[sparse ellipsoidal radial basis function network for point cloud surface representation](https://arxiv.org/abs/2505.02350)|[se-rbfnet](https://github.com/lianbobo/se-rbfnet)|
|2505.02370|[superedit: rectifying and facilitating supervision for instruction-based image editing](https://arxiv.org/abs/2505.02370)|[superedit](https://github.com/bytedance/superedit)|
|2505.02385|[an arbitrary-modal fusion network for volumetric cranial nerves tract segmentation](https://arxiv.org/abs/2505.02385)|[cntseg](https://github.com/ipis-xielei/cntseg)|
|2505.02414|[quadrupedal spine control strategies: exploring correlations between system dynamic responses and human perspectives](https://arxiv.org/abs/2505.02414)|[ester](https://github.com/nickick-icrs/ester)|
|2505.02481|[finger pose estimation for under-screen fingerprint sensor](https://arxiv.org/abs/2505.02481)|[draco](https://github.com/xiongjunguan/draco)|
|2505.02654|[sim2real in endoscopy segmentation with a novel structure aware image translation](https://arxiv.org/abs/2505.02654)|[sim2real-endoscopysegmentation](https://github.com/ropertuz/sim2real-endoscopysegmentation)|
|2505.02705|[multi-view learning with context-guided receptance for image denoising](https://arxiv.org/abs/2505.02705)|[crwkv](https://github.com/seeker98/crwkv)|
|2505.02746|[using knowledge graphs to harvest datasets for efficient clip model training](https://arxiv.org/abs/2505.02746)|[entitynet](https://github.com/lmb-freiburg/entitynet)|
|2505.02753|[advancing generalizable tumor segmentation with anomaly-aware open-vocabulary attention maps and frozen foundation diffusion models](https://arxiv.org/abs/2505.02753)|[diffugts](https://github.com/yankai96/diffugts)|
|2505.02780|[beyond the monitor: mixed reality visualization and ai for enhanced digital pathology workflow](https://arxiv.org/abs/2505.02780)|[path_vis](https://github.com/jaiprakash1824/path_vis)|
|2505.02823|[musar: exploring multi-subject customization from single-subject dataset via attention routing](https://arxiv.org/abs/2505.02823)|[musar](https://github.com/guozinan126/musar)|
|2505.02824|[towards dataset copyright evasion attack against personalized text-to-image diffusion models](https://arxiv.org/abs/2505.02824)|[ceat2i](https://github.com/csyufei/ceat2i)|
|2505.00056|[clustering internet memes through template matching and multi-dimensional similarity](https://arxiv.org/abs/2505.00056)|[meme-clustering](https://github.com/tygobl/meme-clustering)|
|2505.00568|[multimodal masked autoencoder pre-training for 3d mri-based brain tumor analysis with missing modalities](https://arxiv.org/abs/2505.00568)|[bm-mae](https://github.com/lucas-rbnt/bm-mae)|
|2505.00740|[fast2comm:collaborative perception combined with prior knowledge](https://arxiv.org/abs/2505.00740)|[fast2comm](https://github.com/zhangzhengbin-tj/fast2comm)|
|2505.00772|[person detection and re-identification in open-world settings of retail stores and public spaces](https://arxiv.org/abs/2505.00772)|[personReID](https://github.com/brkljac/personReID)|
|2505.00866|[are minimal radial distortion solvers really necessary for relative pose estimation?](https://arxiv.org/abs/2505.00866)|[rdnet](https://github.com/kocurvik/rdnet)|
|2505.00938|[cdformer: cross-domain few-shot object detection transformer against feature confusion](https://arxiv.org/abs/2505.00938)|[CDFormer_code](https://github.com/LONGXUANX/CDFormer_code)|
|2505.01172|[freepca: integrating consistency information across long-short frames in training-free long video generation via principal component analysis](https://arxiv.org/abs/2505.01172)|[freepca](https://github.com/josephtitan/freepca)|
|2505.01224|[rd-uie: relation-driven state space modeling for underwater image enhancement](https://arxiv.org/abs/2505.01224)|[rd-uie](https://github.com/kkoucy/rd-uie)|
|2505.01225|[core-set selection for data-efficient land cover segmentation](https://arxiv.org/abs/2505.01225)|[data-centric-rs-classification](https://github.com/keillernogueira/data-centric-rs-classification)|
|2505.01257|[cameltrack: context-aware multi-cue exploitation for online multi-object tracking](https://arxiv.org/abs/2505.01257)|[CAMELTrack](https://github.com/TrackingLaboratory/CAMELTrack)|
|2505.01406|[vidstamp: a temporally-aware watermark for ownership and integrity in video diffusion models](https://arxiv.org/abs/2505.01406)|[vidstamp](https://github.com/spin-umass/vidstamp)|
|2505.00312|[aware-net: adaptive weighted averaging for robust ensemble network in deepfake detection](https://arxiv.org/abs/2505.00312)|[AWARE-NET](https://github.com/recluzegeek/AWARE-NET)|
|2505.00502|[towards scalable human-aligned benchmark for text-guided image editing](https://arxiv.org/abs/2505.00502)|[HATIE](https://github.com/SuhoRyu/HATIE)|
|2505.00681|[minerva: evaluating complex video reasoning](https://arxiv.org/abs/2505.00681)|[neptune](https://github.com/google-deepmind/neptune)|
|2505.00684|[visual test-time scaling for gui agent grounding](https://arxiv.org/abs/2505.00684)|[regionfocus](https://github.com/tiangeluo/regionfocus)|
|2505.00703|[t2i-r1: reinforcing image generation with collaborative semantic-level and token-level cot](https://arxiv.org/abs/2505.00703)|[t2i-r1](https://github.com/caraj7/t2i-r1)|

